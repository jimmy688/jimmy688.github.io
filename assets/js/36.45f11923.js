(window.webpackJsonp=window.webpackJsonp||[]).push([[36],{1451:function(t,s,a){t.exports=a.p+"assets/img/image-20200320140617360.b855a53f.png"},1452:function(t,s,a){t.exports=a.p+"assets/img/image-20200320140635558.fb95cd09.png"},1453:function(t,s,a){t.exports=a.p+"assets/img/image-20200320140644558.bba8bf9e.png"},1454:function(t,s,a){t.exports=a.p+"assets/img/image-20200314043443688.7ba0f996.png"},2018:function(t,s,a){"use strict";a.r(s);var e=a(17),n=Object(e.a)({},(function(){var t=this,s=t.$createElement,e=t._self._c||s;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h2",{attrs:{id:"sqoop概述"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop概述"}},[t._v("#")]),t._v(" sqoop概述")]),t._v(" "),e("p",[t._v("Sqoop是apache旗下的一款 ”Hadoop和关系数据库之间传输数据“ 的工具")]),t._v(" "),e("p",[t._v("导入数据：将MySQL，Oracle导入数据到Hadoop的HDFS、HIVE、HBASE等数据存储系统")]),t._v(" "),e("p",[t._v("导出数据：从Hadoop的文件系统HDFS中导出数据到关系数据库")]),t._v(" "),e("p",[e("img",{attrs:{src:a(1451),alt:"image-20200320140617360"}})]),t._v(" "),e("h2",{attrs:{id:"sqoop的工作机制"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop的工作机制"}},[t._v("#")]),t._v(" sqoop的工作机制")]),t._v(" "),e("p",[t._v("将导入和导出的命令翻译成mapreduce程序实现")]),t._v(" "),e("p",[t._v("在翻译出的mapreduce中主要是对inputformat和outputformat进行定制")]),t._v(" "),e("h2",{attrs:{id:"sqoop1与sqoop2架构对比"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop1与sqoop2架构对比"}},[t._v("#")]),t._v(" sqoop1与sqoop2架构对比")]),t._v(" "),e("p",[t._v("sqoop在发展中的过程中演进出来了两种不同的架构."),e("a",{attrs:{href:"https://blogs.apache.org/sqoop/entry/apache_sqoop_highlights_of_sqoop#comment-1561314193000",target:"_blank",rel:"noopener noreferrer"}},[t._v("架构演变史"),e("OutboundLink")],1)]),t._v(" "),e("h4",{attrs:{id:"sqoop1架构-常用"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop1架构-常用"}},[t._v("#")]),t._v(" sqoop1架构(常用)")]),t._v(" "),e("p",[e("img",{attrs:{src:a(1452),alt:"image-20200320140635558"}})]),t._v(" "),e("p",[t._v("版本号为1.4.x为sqoop1")]),t._v(" "),e("p",[t._v("在架构上：sqoop1使用sqoop客户端直接提交的方式")]),t._v(" "),e("p",[t._v("访问方式：CLI控制台方式进行访问")]),t._v(" "),e("p",[t._v("安全性：命令或脚本中指定用户数据库名及密码")]),t._v(" "),e("h4",{attrs:{id:"sqoop2架构"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop2架构"}},[t._v("#")]),t._v(" sqoop2架构")]),t._v(" "),e("p",[e("img",{attrs:{src:a(1453),alt:"image-20200320140644558"}})]),t._v(" "),e("p",[t._v("版本号为1.99x为sqoop2")]),t._v(" "),e("p",[t._v("在架构上：sqoop2引入了sqoop server，对connector实现了集中的管理")]),t._v(" "),e("p",[t._v("访问方式：REST API、 JAVA API、 WEB UI以及CLI控制台方式进行访问")]),t._v(" "),e("h4",{attrs:{id:"sqoop1与sqoop2比较"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop1与sqoop2比较"}},[t._v("#")]),t._v(" sqoop1与sqoop2比较")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[t._v("比较")]),t._v(" "),e("th",[t._v("Sqoop1")]),t._v(" "),e("th",[t._v("Sqoop2")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("架构")]),t._v(" "),e("td",[t._v("仅仅使用一个sqoop客户端")]),t._v(" "),e("td",[t._v("引入了sqoop server集中化管理connector,以及rest api，web,UI，并引入安全机制")])]),t._v(" "),e("tr",[e("td",[t._v("部署")]),t._v(" "),e("td",[t._v("部署简单，安装需要root权限，connector必须符合JDBC模型")]),t._v(" "),e("td",[t._v("架构稍复杂，配置部署繁琐")])]),t._v(" "),e("tr",[e("td",[t._v("使用")]),t._v(" "),e("td",[t._v("命令行方式容易出错，格式紧耦合，无法支持所有数据类型，安全机制不够完善，例如密码暴露")]),t._v(" "),e("td",[t._v("多种交互方式，命令行，WebUI，rest API,connector集中化管理，所有的链接安装在sqoop server上，完善权限管理机制，connector规范化，仅仅负责数据的读写。")])])])]),t._v(" "),e("h2",{attrs:{id:"sqoop安装部署"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop安装部署"}},[t._v("#")]),t._v(" sqoop安装部署")]),t._v(" "),e("p",[t._v("Sqoop安装很简单，解压好进行简单的修改就可以使用.")]),t._v(" "),e("p",[t._v("Sqoop是单台机器安装即可。我们以node03为例，进行安装。")]),t._v(" "),e("h3",{attrs:{id:"第一步-下载安装包"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第一步-下载安装包"}},[t._v("#")]),t._v(" 第一步：下载安装包")]),t._v(" "),e("p",[t._v("http://archive.cloudera.com/cdh5/cdh/5/sqoop-1.4.6-cdh5.14.2.tar.gz")]),t._v(" "),e("h3",{attrs:{id:"第二步-上传并解压"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第二步-上传并解压"}},[t._v("#")]),t._v(" 第二步：上传并解压")]),t._v(" "),e("p",[t._v("将我们下载好的安装包上传到node03服务器的/kkb/soft路径下，然后进行解压")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("cd")]),t._v(" /kkb/soft/\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 soft"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("tar")]),t._v(" -zxvf sqoop-1.4.6-cdh5.14.2.tar.gz -C /kkb/install/\n")])])]),e("h3",{attrs:{id:"第三步-修改配置文件"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第三步-修改配置文件"}},[t._v("#")]),t._v(" 第三步：修改配置文件")]),t._v(" "),e("p",[t._v("更改sqoop的配置文件")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("cd")]),t._v(" /kkb/install/sqoop-1.4.6-cdh5.14.2/conf\n"),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("mv")]),t._v(" sqoop-env-template.sh sqoop-env.sh\n"),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("vim")]),t._v(" sqoop-env.sh\n")])])]),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#Set path to where bin/hadoop is available")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("HADOOP_COMMON_HOME")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/kkb/install/hadoop-2.6.0-cdh5.14.2\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#Set path to where hadoop-*-core.jar is available")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("HADOOP_MAPRED_HOME")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/kkb/install/hadoop-2.6.0-cdh5.14.2\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#set the path to where bin/hbase is available")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("HBASE_HOME")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/kkb/install/hbase-1.2.0-cdh5.14.2\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#Set the path to where bin/hive is available")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("HIVE_HOME")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/kkb/install/hive-1.1.0-cdh5.14.2\n")])])]),e("h3",{attrs:{id:"第四步-添加两个必要的jar包"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第四步-添加两个必要的jar包"}},[t._v("#")]),t._v(" 第四步：添加两个必要的jar包")]),t._v(" "),e("p",[t._v("sqoop需要两个额外依赖的jar包，将课件资料当中两个jar包添加到sqoop的lib目录下")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token function"}},[t._v("mv")]),t._v(" /kkb/soft/mysql-connector-java-5.1.38.jar /kkb/install/sqoop-1.4.6-cdh5.14.2/lib/\n"),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("mv")]),t._v(" /kkb/soft/java-json.jar /kkb/install/sqoop-1.4.6-cdh5.14.2/lib/\n")])])]),e("h3",{attrs:{id:"第五步-配置sqoop的环境变量"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第五步-配置sqoop的环境变量"}},[t._v("#")]),t._v(" 第五步：配置sqoop的环境变量")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("sudo vim /etc/profile\n")])])]),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("SQOOP_HOME")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/kkb/install/sqoop-1.4.6-cdh5.14.2\n"),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e("span",{pre:!0,attrs:{class:"token environment constant"}},[t._v("PATH")])]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$SQOOP_HOME")]),t._v("/bin:"),e("span",{pre:!0,attrs:{class:"token environment constant"}},[t._v("$PATH")]),t._v("\n")])])]),e("h2",{attrs:{id:"sqoop命令"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop命令"}},[t._v("#")]),t._v(" Sqoop命令")]),t._v(" "),e("h4",{attrs:{id:"查看命令帮助"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#查看命令帮助"}},[t._v("#")]),t._v(" 查看命令帮助")]),t._v(" "),e("div",{staticClass:"language-ruby extra-class"},[e("pre",{pre:!0,attrs:{class:"language-ruby"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop"),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("@node03")]),t._v(" lib"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ sqoop help \nusage"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sqoop "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("COMMAND")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("ARGS")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("Available")]),t._v(" commands"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  codegen            "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("Generate")]),t._v(" code to interact with database records\n  create"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("hive"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("table  "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("Import")]),t._v(" a table definition into "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("Hive")]),t._v("\n  eval               "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("Evaluate")]),t._v(" a "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("SQL")]),t._v(" statement "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" display the results\n  export             "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("Export")]),t._v(" an "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("HDFS")]),t._v(" directory to a database table\n  help               "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("List")]),t._v(" available commands\n  import             "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("Import")]),t._v(" a table from a database to "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("HDFS")]),t._v("\n  import"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("all"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("tables  "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("Import")]),t._v(" tables from a database to "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("HDFS")]),t._v("\n  import"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("mainframe   "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("Import")]),t._v(" datasets from a mainframe server to "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("HDFS")]),t._v("\n  job                "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("Work")]),t._v(" with saved jobs\n  list"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("databases     "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("List")]),t._v(" available databases on a server\n  list"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("tables        "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("List")]),t._v(" available tables "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" a database\n  merge              "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("Merge")]),t._v(" results of incremental imports\n  metastore          "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("Run")]),t._v(" a standalone "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("Sqoop")]),t._v(" metastore\n  version            "),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("Display")]),t._v(" version information\n")])])]),e("h4",{attrs:{id:"列出所有的数据库"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#列出所有的数据库"}},[t._v("#")]),t._v(" 列出所有的数据库")]),t._v(" "),e("p",[t._v("list-databases     List available databases on a server")]),t._v(" "),e("p",[t._v("查看该命令的具体帮助：")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("sqoop list-databases --help\n\nGeneric options supported are\n-conf "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("configuration file"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("     specify an application configuration "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("file")]),t._v("\n\n-D "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("property"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("value"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("            use value "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" given property\n\n-fs "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("local"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("namenode:port"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("      specify a namenode\n\n-jt "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("local"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("resourcemanager:port"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("    specify a ResourceManager\n\n-files "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("comma separated list of files"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("    specify comma separated files to be copied to the map reduce cluster\n\n-libjars "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("comma separated list of jars"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("    specify comma separated jar files to include "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" the classpath.\n\n-archives "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("comma separated list of archives"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("    specify comma separated archives to be unarchived on the compute machines.\n\n")])])]),e("p",[t._v("列出node03主机所有的数据库")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("bin/sqoop list-databases --connect jdbc:mysql://node03:3306/ --username root --password "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456")]),t._v(" \n\ninformation_schema\nhive\nmysql\nmysqlsource\nperformance_schema\nsys\n")])])]),e("h4",{attrs:{id:"查看某一个数据库下的所有数据表"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#查看某一个数据库下的所有数据表"}},[t._v("#")]),t._v(" 查看某一个数据库下的所有数据表")]),t._v(" "),e("p",[t._v("查看mysqlsource database的所有表")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("bin/sqoop list-tables --connect jdbc:mysql://node03:3306/mysqlsource --username root --password "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456")]),t._v("\n\nflume_meta\nstudent\n")])])]),e("h2",{attrs:{id:"sqoop导入数据"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop导入数据"}},[t._v("#")]),t._v(" sqoop导入数据")]),t._v(" "),e("p",[t._v("sqoop的底层原理本质是一个MapReduce job，sqoop是通过一个MapReduce job 从数据库中导入一个表，这个job从表中逐行抽取数据，接着一行行的数据写入HDFS。")]),t._v(" "),e("p",[t._v("表中的每一行被视为HDFS的记录。所有记录都存储为文本文件的文本数据（或者Avro、sequence文件等二进制数据）")]),t._v(" "),e("h4",{attrs:{id:"查看导入命令import帮助"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#查看导入命令import帮助"}},[t._v("#")]),t._v(" 查看导入命令import帮助")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 ~"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ sqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" --help\n\nCommon arguments:\n   --connect "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("jdbc-uri"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                       Specify JDBC\n                                                              connect\n                                                              string\n   --connection-manager "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("class-name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                          Specify\n                                                              connection\n                                                              manager\n                                                              class name\n   --connection-param-file "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("properties-file"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                  Specify\n                                                              connection\n                                                              parameters\n                                                              "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("file")]),t._v("\n   --driver "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("class-name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                      Manually\n                                                              specify JDBC\n                                                              driver class\n                                                              to use\n   --hadoop-home "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("hdir"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                       Override\n                                                              "),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$HADOOP_MAPR")]),t._v("\n                                                              ED_HOME_ARG\n   --hadoop-mapred-home "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("dir"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                 Override\n                                                              "),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$HADOOP_MAPR")]),t._v("\n                                                              ED_HOME_ARG\n   --help                                                     Print usage\n                                                              instructions\n   --metadata-transaction-isolation-level "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("isolationlevel"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("    Defines the\n                                                              transaction\n                                                              isolation\n                                                              level "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v("\n                                                              metadata\n                                                              queries. For\n                                                              "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("more")]),t._v(" details\n                                                              check\n                                                              java.sql.Con\n                                                              nection\n                                                              javadoc or\n                                                              the JDBC\n                                                              specificaito\n                                                              n\n   --oracle-escaping-disabled "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("boolean"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                       Disable the\n                                                              escaping\n                                                              mechanism of\n                                                              the\n                                                              Oracle/OraOo\n                                                              p connection\n                                                              managers\n-P                                                            Read\n                                                              password\n                                                              from console\n   --password "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("password"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                      Set\n                                                              authenticati\n                                                              on password\n   --password-alias "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("password-alias"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                          Credential\n                                                              provider\n                                                              password\n                                                              "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("alias")]),t._v("\n   --password-file "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("password-file"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                            Set\n                                                              authenticati\n                                                              on password\n                                                              "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("file")]),t._v(" path\n   --relaxed-isolation                                        Use\n                                                              read-uncommi\n                                                              tted\n                                                              isolation\n                                                              "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" imports\n   --skip-dist-cache                                          Skip copying\n                                                              jars to\n                                                              distributed\n                                                              cache\n   --temporary-rootdir "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("rootdir"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                              Defines the\n                                                              temporary\n                                                              root\n                                                              directory\n                                                              "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" the\n                                                              "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v("\n   --throw-on-error                                           Rethrow a\n                                                              RuntimeExcep\n                                                              tion on\n                                                              error\n                                                              occurred\n                                                              during the\n                                                              job\n   --username "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("username"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                      Set\n                                                              authenticati\n                                                              on username\n   --verbose                                                  Print "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("more")]),t._v("\n                                                              information\n                                                              "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v("\n                                                              working\n\nImport control arguments:\n   --append                                                   Imports data\n                                                              "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" append\n                                                              mode\n   --as-avrodatafile                                          Imports data\n                                                              to Avro data\n                                                              files\n   --as-parquetfile                                           Imports data\n                                                              to Parquet\n                                                              files\n   --as-sequencefile                                          Imports data\n                                                              to\n                                                              SequenceFile\n                                                              s\n   --as-textfile                                              Imports data\n                                                              as plain\n                                                              text\n                                                              "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("default"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   --autoreset-to-one-mapper                                  Reset the\n                                                              number of\n                                                              mappers to\n                                                              one mapper\n                                                              "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" no "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("split")]),t._v("\n                                                              key\n                                                              available\n   --boundary-query "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("statement"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                               Set boundary\n                                                              query "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v("\n                                                              retrieving\n                                                              max and min\n                                                              value of the\n                                                              primary key\n   --columns "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("col,col,col"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("..")]),t._v("."),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                 Columns to\n                                                              "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" from\n                                                              table\n   --compression-codec "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("codec"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                Compression\n                                                              codec to use\n                                                              "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v("\n   --delete-target-dir                                        Imports data\n                                                              "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" delete\n                                                              mode\n   --direct                                                   Use direct\n                                                              "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" fast\n                                                              path\n   --direct-split-size "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                    Split the\n                                                              input stream\n                                                              every "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'n'")]),t._v("\n                                                              bytes when\n                                                              importing "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v("\n                                                              direct mode\n-e,--query "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("statement"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                        Import\n                                                              results of\n                                                              SQL\n                                                              "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'statement'")]),t._v("\n   --fetch-size "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                           Set number\n                                                              "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'n'")]),t._v(" of rows\n                                                              to fetch\n                                                              from the\n                                                              database\n                                                              when "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("more")]),t._v("\n                                                              rows are\n                                                              needed\n   --inline-lob-limit "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                     Set the\n                                                              maximum size\n                                                              "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" an\n                                                              inline LOB\n-m,--num-mappers "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                          Use "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'n'")]),t._v(" map\n                                                              tasks to\n                                                              "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v("\n                                                              parallel\n   --mapreduce-job-name "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                Set name "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v("\n                                                              generated\n                                                              mapreduce\n                                                              job\n   --merge-key "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("column"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                       Key "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("column")]),t._v("\n                                                              to use to\n                                                              "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("join")]),t._v(" results\n   --split-by "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("column-name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                   Column of\n                                                              the table\n                                                              used to\n                                                              "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("split")]),t._v(" work\n                                                              "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("units")]),t._v("\n   --split-limit "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("size"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                       Upper Limit\n                                                              of rows per\n                                                              "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("split")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v("\n                                                              "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("split")]),t._v("\n                                                              columns of\n                                                              Date/Time/Ti\n                                                              mestamp and\n                                                              integer\n                                                              types. For\n                                                              "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("date")]),t._v(" or\n                                                              timestamp\n                                                              fields it is\n                                                              calculated\n                                                              "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" seconds.\n                                                              split-limit\n                                                              should be\n                                                              greater than\n                                                              "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n   --table "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("table-name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                       Table to\n                                                              "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("read")]),t._v("\n   --target-dir "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("dir"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                         HDFS plain\n                                                              table\n                                                              destination\n   --validate                                                 Validate the\n                                                              copy using\n                                                              the\n                                                              configured\n                                                              validator\n   --validation-failurehandler "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("validation-failurehandler"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("    Fully\n                                                              qualified\n                                                              class name\n                                                              "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v("\n                                                              ValidationFa\n                                                              ilureHandler\n   --validation-threshold "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("validation-threshold"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("              Fully\n                                                              qualified\n                                                              class name\n                                                              "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v("\n                                                              ValidationTh\n                                                              reshold\n   --validator "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("validator"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                    Fully\n                                                              qualified\n                                                              class name\n                                                              "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" the\n                                                              Validator\n   --warehouse-dir "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("dir"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                      HDFS parent\n                                                              "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" table\n                                                              destination\n   --where "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("where clause"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                     WHERE clause\n                                                              to use\n                                                              during\n                                                              "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v("\n-z,--compress                                                 Enable\n                                                              compression\n\nIncremental "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" arguments:\n   --check-column "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("column"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("        Source "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("column")]),t._v(" to check "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" incremental\n                                  change\n   --incremental "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("import-type"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("    Define an incremental "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" of "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("type")]),t._v("\n                                  "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'append'")]),t._v(" or "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lastmodified'")]),t._v("\n   --last-value "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("value"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("           Last imported value "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" the incremental\n                                  check "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("column")]),t._v("\n\nOutput line formatting arguments:\n   --enclosed-by "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("char"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("               Sets a required field enclosing\n                                      character\n   --escaped-by "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("char"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                Sets the escape character\n   --fields-terminated-by "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("char"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("      Sets the field separator character\n   --lines-terminated-by "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("char"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("       Sets the end-of-line character\n   --mysql-delimiters                 Uses MySQL"),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'s default delimiter set:\n                                      fields: ,  lines: "),e("span",{pre:!0,attrs:{class:"token entity",title:"\\n"}},[t._v("\\n")]),t._v("  escaped-by: \\\n                                      optionally-enclosed-by: '")]),t._v("\n   --optionally-enclosed-by "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("char"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("    Sets a field enclosing character\n\nInput parsing arguments:\n   --input-enclosed-by "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("char"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("               Sets a required field encloser\n   --input-escaped-by "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("char"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                Sets the input escape\n                                            character\n   --input-fields-terminated-by "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("char"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("      Sets the input field separator\n   --input-lines-terminated-by "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("char"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("       Sets the input end-of-line\n                                            char\n   --input-optionally-enclosed-by "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("char"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("    Sets a field enclosing\n                                            character\n\nHive arguments:\n   --create-hive-table                         Fail "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" the target hive\n                                               table exists\n   --hive-database "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("database-name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("             Sets the database name to\n                                               use when importing to hive\n   --hive-delims-replacement "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("arg"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("             Replace Hive record "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("0x01\n                                               and row delimiters "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("r"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                               from imported string fields\n                                               with user-defined string\n   --hive-drop-import-delims                   Drop Hive record "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("0x01 and\n                                               row delimiters "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("r"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" from\n                                               imported string fields\n   --hive-home "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("dir"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                           Override "),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$HIVE_HOME")]),t._v("\n   --hive-import                               Import tables into Hive\n                                               "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Uses Hive's default\n                                               delimiters "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" none are\n                                               set."),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   --hive-overwrite                            Overwrite existing data "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v("\n                                               the Hive table\n   --hive-partition-key "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("partition-key"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("        Sets the partition key to\n                                               use when importing to hive\n   --hive-partition-value "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("partition-value"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("    Sets the partition value to\n                                               use when importing to hive\n   --hive-table "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("table-name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                   Sets the table name to use\n                                               when importing to hive\n   --map-column-hive "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("arg"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                     Override mapping "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v("\n                                               specific "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("column")]),t._v(" to hive\n                                               types.\n\nHBase arguments:\n   --column-family "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("family"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("    Sets the target "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("column")]),t._v(" family "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" the\n                               "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v("\n   --hbase-bulkload            Enables HBase bulk loading\n   --hbase-create-table        If specified, create missing HBase tables\n   --hbase-row-key "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("col"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("       Specifies "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("which")]),t._v(" input "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("column")]),t._v(" to use as the\n                               row key\n   --hbase-table "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("table"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("       Import to "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("table"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" HBase\n\nHCatalog arguments:\n   --hcatalog-database "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("arg"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                        HCatalog database name\n   --hcatalog-home "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("hdir"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                           Override "),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$HCAT_HOME")]),t._v("\n   --hcatalog-partition-keys "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("partition-key"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("        Sets the partition\n                                                    keys to use when\n                                                    importing to hive\n   --hcatalog-partition-values "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("partition-value"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("    Sets the partition\n                                                    values to use when\n                                                    importing to hive\n   --hcatalog-table "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("arg"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                           HCatalog table name\n   --hive-home "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("dir"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                                Override "),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$HIVE_HOME")]),t._v("\n   --hive-partition-key "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("partition-key"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("             Sets the partition key\n                                                    to use when importing\n                                                    to hive\n   --hive-partition-value "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("partition-value"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("         Sets the partition\n                                                    value to use when\n                                                    importing to hive\n   --map-column-hive "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("arg"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                          Override mapping "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v("\n                                                    specific "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("column")]),t._v(" to\n                                                    hive types.\n\nHCatalog "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" specific options:\n   --create-hcatalog-table             Create HCatalog before "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v("\n   --drop-and-create-hcatalog-table    Drop and Create HCatalog before\n                                       "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v("\n   --hcatalog-storage-stanza "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("arg"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("     HCatalog storage stanza "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" table\n                                       creation\n\nAccumulo arguments:\n   --accumulo-batch-size "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("size"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("          Batch size "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" bytes\n   --accumulo-column-family "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("family"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("     Sets the target "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("column")]),t._v(" family "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v("\n                                         the "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v("\n   --accumulo-create-table               If specified, create missing\n                                         Accumulo tables\n   --accumulo-instance "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("instance"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("        Accumulo instance name.\n   --accumulo-max-latency "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("latency"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("      Max "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("write")]),t._v(" latency "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" milliseconds\n   --accumulo-password "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("password"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("        Accumulo password.\n   --accumulo-row-key "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("col"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("              Specifies "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("which")]),t._v(" input "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("column")]),t._v(" to\n                                         use as the row key\n   --accumulo-table "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("table"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("              Import to "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("table"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" Accumulo\n   --accumulo-user "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("user"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                Accumulo user name.\n   --accumulo-visibility "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("vis"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("           Visibility token to be applied to\n                                         all rows imported\n   --accumulo-zookeepers "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("zookeepers"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("    Comma-separated list of\n                                         zookeepers "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("host:port"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nCode generation arguments:\n   --bindir "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("dir"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                             Output directory "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v("\n                                              compiled objects\n   --class-name "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                        Sets the generated class\n                                              name. This overrides\n                                              --package-name. When\n                                              combined with --jar-file,\n                                              sets the input class.\n   --escape-mapping-column-names "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("boolean"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("    Disable special characters\n                                              escaping "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("column")]),t._v(" names\n   --input-null-non-string "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("null-str"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("         Input null non-string\n                                              representation\n   --input-null-string "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("null-str"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("             Input null string\n                                              representation\n   --jar-file "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("file"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                          Disable code generation"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" use\n                                              specified jar\n   --map-column-java "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("arg"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                    Override mapping "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v("\n                                              specific columns to java\n                                              types\n   --null-non-string "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("null-str"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("               Null non-string\n                                              representation\n   --null-string "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("null-str"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                   Null string representation\n   --outdir "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("dir"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                             Output directory "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v("\n                                              generated code\n   --package-name "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("                      Put auto-generated classes\n                                              "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" this package\n")])])]),e("h4",{attrs:{id:"第一步-准备表数据"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第一步-准备表数据"}},[t._v("#")]),t._v(" 第一步：准备表数据")]),t._v(" "),e("p",[t._v("在node03的mysql中创建一个userdb database, 其中包含表：emp, emp_add和emp_conn。")]),t._v(" "),e("p",[t._v("表emp:")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("id")])]),t._v(" "),e("th",[e("strong",[t._v("name")])]),t._v(" "),e("th",[e("strong",[t._v("deg")])]),t._v(" "),e("th",[e("strong",[t._v("salary")])]),t._v(" "),e("th",[e("strong",[t._v("dept")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1201")]),t._v(" "),e("td",[t._v("gopal")]),t._v(" "),e("td",[t._v("manager")]),t._v(" "),e("td",[t._v("50,000")]),t._v(" "),e("td",[t._v("TP")])]),t._v(" "),e("tr",[e("td",[t._v("1202")]),t._v(" "),e("td",[t._v("manisha")]),t._v(" "),e("td",[t._v("Proof reader")]),t._v(" "),e("td",[t._v("50,000")]),t._v(" "),e("td",[t._v("TP")])]),t._v(" "),e("tr",[e("td",[t._v("1203")]),t._v(" "),e("td",[t._v("khalil")]),t._v(" "),e("td",[t._v("php dev")]),t._v(" "),e("td",[t._v("30,000")]),t._v(" "),e("td",[t._v("AC")])]),t._v(" "),e("tr",[e("td",[t._v("1204")]),t._v(" "),e("td",[t._v("prasanth")]),t._v(" "),e("td",[t._v("php dev")]),t._v(" "),e("td",[t._v("30,000")]),t._v(" "),e("td",[t._v("AC")])]),t._v(" "),e("tr",[e("td",[t._v("1205")]),t._v(" "),e("td",[t._v("kranthi")]),t._v(" "),e("td",[t._v("admin")]),t._v(" "),e("td",[t._v("20,000")]),t._v(" "),e("td",[t._v("TP")])])])]),t._v(" "),e("p",[t._v("表emp_add:")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("id")])]),t._v(" "),e("th",[e("strong",[t._v("hno")])]),t._v(" "),e("th",[e("strong",[t._v("street")])]),t._v(" "),e("th",[e("strong",[t._v("city")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1201")]),t._v(" "),e("td",[t._v("288A")]),t._v(" "),e("td",[t._v("vgiri")]),t._v(" "),e("td",[t._v("jublee")])]),t._v(" "),e("tr",[e("td",[t._v("1202")]),t._v(" "),e("td",[t._v("108I")]),t._v(" "),e("td",[t._v("aoc")]),t._v(" "),e("td",[t._v("sec-bad")])]),t._v(" "),e("tr",[e("td",[t._v("1203")]),t._v(" "),e("td",[t._v("144Z")]),t._v(" "),e("td",[t._v("pgutta")]),t._v(" "),e("td",[t._v("hyd")])]),t._v(" "),e("tr",[e("td",[t._v("1204")]),t._v(" "),e("td",[t._v("78B")]),t._v(" "),e("td",[t._v("old city")]),t._v(" "),e("td",[t._v("sec-bad")])]),t._v(" "),e("tr",[e("td",[t._v("1205")]),t._v(" "),e("td",[t._v("720X")]),t._v(" "),e("td",[t._v("hitec")]),t._v(" "),e("td",[t._v("sec-bad")])])])]),t._v(" "),e("p",[t._v("表emp_conn:")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("id")])]),t._v(" "),e("th",[e("strong",[t._v("phno")])]),t._v(" "),e("th",[e("strong",[t._v("email")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1201")]),t._v(" "),e("td",[t._v("2356742")]),t._v(" "),e("td",[t._v("gopal@tp.com")])]),t._v(" "),e("tr",[e("td",[t._v("1202")]),t._v(" "),e("td",[t._v("1661663")]),t._v(" "),e("td",[t._v("manisha@tp.com")])]),t._v(" "),e("tr",[e("td",[t._v("1203")]),t._v(" "),e("td",[t._v("8887776")]),t._v(" "),e("td",[t._v("khalil@ac.com")])]),t._v(" "),e("tr",[e("td",[t._v("1204")]),t._v(" "),e("td",[t._v("9988774")]),t._v(" "),e("td",[t._v("prasanth@ac.com")])]),t._v(" "),e("tr",[e("td",[t._v("1205")]),t._v(" "),e("td",[t._v("1231231")]),t._v(" "),e("td",[t._v("kranthi@tp.com")])])])]),t._v(" "),e("p",[t._v("建表语句如下：直接复制粘贴到node03的mysql命令行即可。")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DATABASE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*!32312 IF NOT EXISTS*/")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("userdb"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/*!40100 DEFAULT CHARACTER SET utf8 */")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("USE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("userdb"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DROP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("IF")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("EXISTS")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("emp"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("emp"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("id"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("name"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("deg"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("salary"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("dept"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("create_time"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TIMESTAMP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CURRENT_TIMESTAMP")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("update_time"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TIMESTAMP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CURRENT_TIMESTAMP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UPDATE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CURRENT_TIMESTAMP")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("is_delete"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BIGINT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'1'")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ENGINE")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INNODB")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CHARSET")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("latin1"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("emp"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("id"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("name"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("deg"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("salary"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("dept"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1201")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'gopal'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'manager'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("50000")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'TP'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1202")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'manisha'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Proof reader'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("50000")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'TP'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1203")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'khalil'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'php dev'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("30000")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'AC'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1204")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'prasanth'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'php dev'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("30000")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'AC'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1205")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'kranthi'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'admin'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("20000")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'TP'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DROP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("IF")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("EXISTS")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("emp_add"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("emp_add"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("id"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("hno"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("street"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("city"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("create_time"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TIMESTAMP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CURRENT_TIMESTAMP")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("update_time"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TIMESTAMP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CURRENT_TIMESTAMP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UPDATE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CURRENT_TIMESTAMP")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("is_delete"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BIGINT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'1'")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ENGINE")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INNODB")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CHARSET")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("latin1"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("emp_add"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("id"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("hno"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("street"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("city"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1201")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'288A'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'vgiri'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'jublee'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1202")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'108I'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'aoc'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sec-bad'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1203")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'144Z'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'pgutta'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'hyd'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1204")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'78B'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'old city'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sec-bad'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1205")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'720X'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'hitec'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sec-bad'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DROP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("IF")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("EXISTS")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("emp_conn"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("emp_conn"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("id"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("phno"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("email"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("create_time"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TIMESTAMP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CURRENT_TIMESTAMP")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("update_time"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TIMESTAMP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CURRENT_TIMESTAMP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UPDATE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CURRENT_TIMESTAMP")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("is_delete"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BIGINT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'1'")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ENGINE")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INNODB")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CHARSET")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("latin1"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("emp_conn"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("id"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("phno"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("email"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1201")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2356742'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'gopal@tp.com'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1202")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'1661663'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'manisha@tp.com'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1203")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'8887776'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'khalil@ac.com'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1204")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'9988774'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'prasanth@ac.com'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1205")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'1231231'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'kranthi@tp.com'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n")])])]),e("h4",{attrs:{id:"第二步-导入数据库表数据到hdfs"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第二步-导入数据库表数据到hdfs"}},[t._v("#")]),t._v(" 第二步：导入数据库表数据到HDFS")]),t._v(" "),e("p",[t._v("将MySQL中的emp表导入到HDFS")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("bin/sqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" --connect jdbc:mysql://node03:3306/userdb --password "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456")]),t._v(" --username root --table emp --m "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## --m 1  表示使用1个maptask")]),t._v("\n")])])]),e("p",[t._v("如果成功执行，那么会得到下面的输出。")]),t._v(" "),e("p",[e("img",{attrs:{src:a(1454),alt:"image-20200314043443688"}})]),t._v(" "),e("p",[t._v('使用以下命令查看导入的数据,数据默认存放在了hdfs的/user/hadoop路径下，表的字段间的分隔符默认使用逗号","。')]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 conf"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -cat /user/hadoop/emp/part-m-00000\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1201")]),t._v(",gopal,manager,50000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1202")]),t._v(",manisha,Proof reader,50000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1203")]),t._v(",khalil,php dev,30000,AC,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1204")]),t._v(",prasanth,php dev,30000,AC,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1205")]),t._v(",kranthi,admin,20000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n")])])]),e("h4",{attrs:{id:"第三步-导入数据库表数据到hdfs指定目录"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第三步-导入数据库表数据到hdfs指定目录"}},[t._v("#")]),t._v(" 第三步：导入数据库表数据到HDFS指定目录")]),t._v(" "),e("ol",[e("li",[e("p",[t._v("使用参数 --target-dir来指定导出目录")])]),t._v(" "),e("li",[e("p",[t._v("使用参数—delete-target-dir来判断导出目录是否存在，如果存在就删掉")])])]),t._v(" "),e("p",[t._v("导入数据：")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("sqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" --connect jdbc:mysql://node03:3306/userdb --username root --password "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456")]),t._v(" --delete-target-dir --table emp --target-dir /sqoop/emp --m "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),e("p",[t._v("查看导入的数据：")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 conf"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -text /sqoop/emp/part-m-00000 "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#使用cat也行")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1201")]),t._v(",gopal,manager,50000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1202")]),t._v(",manisha,Proof reader,50000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1203")]),t._v(",khalil,php dev,30000,AC,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1204")]),t._v(",prasanth,php dev,30000,AC,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1205")]),t._v(",kranthi,admin,20000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n")])])]),e("h4",{attrs:{id:"第四步-导入数据库表数据到hdfs指定目录并指定分隔符"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第四步-导入数据库表数据到hdfs指定目录并指定分隔符"}},[t._v("#")]),t._v(" 第四步：导入数据库表数据到HDFS指定目录并指定分隔符")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("sqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" --connect jdbc:mysql://node03:3306/userdb --username root --password "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456")]),t._v(" --delete-target-dir --table emp --target-dir /sqoop/emp2 --m "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" --fields-terminated-by "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'"),e("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("'")]),t._v("\n")])])]),e("p",[t._v('查看文件内容,是以"\\t"作为分隔符的。')]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 conf"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -text /sqoop/emp2/part-m-00000\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1201")]),t._v(" gopal   manager "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("50000")]),t._v("        TP "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1202")]),t._v("  manisha Proof reader "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("50000")]),t._v("  TP "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1203")]),t._v("  khalil  php dev "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("30000")]),t._v("       AC "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1204")]),t._v("  prasanth  php dev "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("30000")]),t._v("     AC "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1205")]),t._v("  kranthi admin   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("20000")]),t._v("       TP "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),e("h4",{attrs:{id:"第五步-导入数据库表数据到hive表-hive表已存在"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第五步-导入数据库表数据到hive表-hive表已存在"}},[t._v("#")]),t._v(" 第五步：导入数据库表数据到Hive表（hive表已存在）")]),t._v(" "),e("p",[t._v("将我们mysql表当中的数据直接导入到hive表中的话，我们需要将hive的一个叫做hive-exec-1.1.0-cdh5.14.0.jar的jar包拷贝到sqoop的lib目录下")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 ~"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("cp")]),t._v(" /kkb/install/hive-1.1.0-cdh5.14.2/lib/hive-exec-1.1.0-cdh5.14.2.jar /kkb/install/sqoop-1.4.6-cdh5.14.2/lib/\n")])])]),e("p",[t._v("在hive中创建表：")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[t._v("hive "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("default")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("database")]),t._v(" sqooptohive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\nhive "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("default")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" sqooptohive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\nhive "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sqooptohive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" external "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" emp_hive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("name string"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("deg string"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("salary "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("dept string"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("row")]),t._v(" format delimited "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fields")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("terminated")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\001'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),e("p",[t._v("将我们mysql当中的数据导入到hive表当中来：")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("sqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" --connect jdbc:mysql://node03:3306/userdb --username root --password "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456")]),t._v(" --table emp --fields-terminated-by "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'"),e("span",{pre:!0,attrs:{class:"token entity",title:"\\001"}},[t._v("\\001")]),t._v("'")]),t._v(" --hive-import --hive-table sqooptohive.emp_hive --hive-overwrite --delete-target-dir --m "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),e("ul",[e("li",[t._v("--hive-overwrite表示，导入的数据会覆盖hive表中原先存在的数据")])]),t._v(" "),e("p",[t._v("导入成功后，查看hive表数据：")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[t._v("hive "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sqooptohive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" emp_hive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nOK\nemp_hive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("id     emp_hive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name   emp_hive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("deg    emp_hive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("salary emp_hive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dept\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1201")]),t._v("    gopal   manager "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("50000")]),t._v("   TP\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1202")]),t._v("    manisha Proof reader    "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("50000")]),t._v("   TP\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1203")]),t._v("    khalil  php dev "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("30000")]),t._v("   AC\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1204")]),t._v("    prasanth        php dev "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("30000")]),t._v("   AC\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1205")]),t._v("    kranthi admin   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("20000")]),t._v("   TP\n")])])]),e("h4",{attrs:{id:"第六步-导入数据库表数据到hive表-hive表未存在"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第六步-导入数据库表数据到hive表-hive表未存在"}},[t._v("#")]),t._v(" 第六步：导入数据库表数据到Hive表（hive表未存在）")]),t._v(" "),e("p",[t._v("将我们的mysql的表直接导入到hive表当中去")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("sqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" --connect jdbc:mysql://node03:3306/userdb --username root --password "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456")]),t._v(" --table emp_conn --hive-import -m "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" --hive-database sqooptohive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),e("p",[t._v("通过上面这个命令，我们可以直接将我们mysql表当中的数据以及表结构一起倒入到hive当中去,--hive-database sqooptohive表示导入到哪个database。")]),t._v(" "),e("p",[t._v("查看效果：")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[t._v("hive "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sqooptohive"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("show")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("tables")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nOK\ntab_name\nemp_conn "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#")]),t._v("\nemp_hivesh\n")])])]),e("h4",{attrs:{id:"第七步-导入数据库表数据到hbase"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第七步-导入数据库表数据到hbase"}},[t._v("#")]),t._v(" 第七步：导入数据库表数据到hbase")]),t._v(" "),e("p",[t._v("启动zookeeper和hbase")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("zkServer.sh start "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#三台机器都要执行这一行代码")]),t._v("\nstart-hbase.sh "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#node01执行这一行代码")]),t._v("\n")])])]),e("p",[t._v("在mysql当中创建数据库以及数据库表并插入数据")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DATABASE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("IF")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("EXISTS")]),t._v(" library"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("USE")]),t._v(" library"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" book"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    id "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("PRIMARY")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("KEY")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AUTO_INCREMENT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n    NAME "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    price "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" book"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("NAME"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" price"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Lie Sporting'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'30'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" \n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" book "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("NAME"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" price"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Pride & Prejudice'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'70'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" \n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" book "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("NAME"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" price"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Fall of Giants'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'50'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" \n\nmysql"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" book"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("----+-------------------+-------+")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" id "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" NAME              "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" price "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("----+-------------------+-------+")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Lie Sporting      "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),t._v("    "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Pride "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" Prejudice "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("70")]),t._v("    "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Fall "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),t._v(" Giants    "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v("    "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("----+-------------------+-------+")]),t._v("\n")])])]),e("p",[t._v("将mysql表当中的数据导入HBase表当中去（只能指定一个列族）:")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("sqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect jdbc:mysql://node03:3306/library "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table book "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--columns "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id,name,price"')]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--column-family "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"info"')]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hbase-create-table "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hbase-row-key "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hbase-table "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hbase_book"')]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--num-mappers "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--split-by "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("id")]),t._v("\n")])])]),e("p",[t._v("在HBase当中查看表数据")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 install"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hbase shell\n")])])]),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("hbase"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":002:"),e("span",{pre:!0,attrs:{class:"token operator"}},[e("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("0")]),t._v(">")]),t._v(" scan "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'hbase_book'")]),t._v("\nROW           COLUMN+CELL                           \n "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("            "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("column")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("info:name, "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1584163926211")]),t._v(", "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Lie Sporting     \n "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("            "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("column")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("info:price, "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1584163926211")]),t._v(", "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),t._v("              \n "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("            "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("column")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("info:name, "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1584163926211")]),t._v(", "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Pride "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" Prejudice\n "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("            "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("column")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("info:price, "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1584163926211")]),t._v(", "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("70")]),t._v("              \n "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("            "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("column")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("info:name, "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1584163926211")]),t._v(", "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Fall of Giants   \n "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("            "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("column")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("info:price, "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1584163926211")]),t._v(", "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v("              \n")])])]),e("h4",{attrs:{id:"业务系统中表的分类"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#业务系统中表的分类"}},[t._v("#")]),t._v(" 业务系统中表的分类")]),t._v(" "),e("p",[t._v("我们上面的七步都是进行了全表导入，但是有时候我们是不需要进行全表导入的，先来了解一下实际应用中，业务系统中表的分类：")]),t._v(" "),e("p",[t._v("第一大类：业务表")]),t._v(" "),e("ul",[e("li",[t._v("需要做增删改查的操作，如user表")])]),t._v(" "),e("p",[t._v("第二大类：记录表")]),t._v(" "),e("ul",[e("li",[t._v("比如日志记录表  这个表只会一直增加，不会修改，删除")])]),t._v(" "),e("p",[t._v("第三类：码表 字典表")]),t._v(" "),e("ul",[e("li",[t._v("省市区县  一般数据量不大，而且不会变动")])]),t._v(" "),e("p",[t._v("从上面三类表的描述可知：")]),t._v(" "),e("ol",[e("li",[t._v("对于业务表，新添加的数据以及修改的数据都要导入过来，导入变化的数据，没变化的数据，导入之后再不要导入了")]),t._v(" "),e("li",[t._v("对于记录表，新插入的数据需要导入过来，导入新增加的数据即可，导入过的数据再不要导入了")]),t._v(" "),e("li",[t._v("对于码表，一般导入一次即可，有变更再及时导入即可")])]),t._v(" "),e("p",[t._v("因此，可以看到全表导入的情况并不多，下面，我们就来讲讲如何进行非全表导入。")]),t._v(" "),e("h4",{attrs:{id:"第八步-导入数据库表的子集-where"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第八步-导入数据库表的子集-where"}},[t._v("#")]),t._v(" 第八步：导入数据库表的子集--where")]),t._v(" "),e("p",[t._v("sqoop可导入sql where语句的查询结果到hadoop的数据存储系统中。")]),t._v(" "),e("p",[t._v("例子：")]),t._v(" "),e("p",[t._v("查找表emp_add当中city字段的值为sec-bad的所有数据,并将这些数据导入到hdfs上面去")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("sqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" --connect jdbc:mysql://node03:3306/userdb --username root --password "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456")]),t._v(" --table emp_add --target-dir /sqoop/emp_add -m "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" --delete-target-dir --where "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"city = 'sec-bad'\"")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 ~"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -ls /sqoop/emp_add/ \nFound "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" items\n-rw-r--r--   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" hadoop supergroup     "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("23")]),t._v(":28 /sqoop/emp_add/_SUCCESS\n-rw-r--r--   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" hadoop supergroup     "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("210")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("23")]),t._v(":28 /sqoop/emp_add/part-m-00000\n\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 ~"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -cat /sqoop/emp_add/part-m-00000\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1202")]),t._v(",108I,aoc,sec-bad,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1204")]),t._v(",78B,old city,sec-bad,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1205")]),t._v(",720X,hitec,sec-bad,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#从上面结果可以看到，只存储了\"city = 'sec-bad'\"的数据")]),t._v("\n")])])]),e("h4",{attrs:{id:"第九步-导入数据库表的子集-query"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第九步-导入数据库表的子集-query"}},[t._v("#")]),t._v(" 第九步：导入数据库表的子集--query")]),t._v(" "),e("p",[t._v("我们还可以通过 –query参数来指定我们的sql语句，通过sql语句来过滤我们的数据进行导入。")]),t._v(" "),e("p",[t._v("注意事项：")]),t._v(" "),e("ol",[e("li",[t._v("使用sql语句来进行查找是不能加参数--table")]),t._v(" "),e("li",[t._v("并且必须要添加--where条件，")]),t._v(" "),e("li",[t._v("并且--where条件后面必须带一个$CONDITIONS 这个字符串，")]),t._v(" "),e("li",[t._v("并且这个sql语句必须用单引号，不能用双引号")])]),t._v(" "),e("p",[t._v("例子：")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("mysql"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" * from emp_conn"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n+------+---------+-----------------+---------------------+---------------------+--\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("id")]),t._v("   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" phno    "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" email        "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" create_time         "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" update_time  "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" is_delete "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n+------+---------+-----------------+---------------------+---------------------+--\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1201")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2356742")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("gopal@tp.com  "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1202")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1661663")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("manisha@tp.com"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1203")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("8887776")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("khalil@ac.com  "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1204")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("9988774")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("prasanth@ac.com"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1205")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1231231")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("kranthi@tp.com "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n+------+---------+-----------------+---------------------+---------------------+--\n\n\nsqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" --connect jdbc:mysql://node03:3306/userdb --username root --password "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456")]),t._v(" --delete-target-dir -m "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" --query "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'select phno from emp_conn where 1=1 and "),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$CONDITIONS")]),t._v("'")]),t._v(" --target-dir /sqoop/emp_conn \n\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 ~"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -ls /sqoop/emp_query/\nFound "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" items\n-rw-r--r--   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" hadoop supergroup     "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("23")]),t._v(":37 /sqoop/emp_query/_SUCCESS\n-rw-r--r--   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" hadoop supergroup     "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("40")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("23")]),t._v(":37 /sqoop/emp_query/part-m-00000\n\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 ~"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -cat /sqoop/emp_query/part-m-00000\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2356742")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1661663")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("8887776")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("9988774")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1231231")]),t._v("\n")])])]),e("h4",{attrs:{id:"第十步-增量导入数据库表数据到hdfs"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#第十步-增量导入数据库表数据到hdfs"}},[t._v("#")]),t._v(" 第十步：增量导入数据库表数据到HDFS")]),t._v(" "),e("p",[t._v("在实际工作当中，数据的导入，很多时候都是只需要导入增量数据即可，并不需要将表中的数据全部导入到hive或者hdfs当中去，肯定会出现重复的数据的状况，所以我们一般都是选用一些字段进行增量的导入，为了支持增量的导入，sqoop也给我们考虑到了这种情况并且支持增量的导入数据")]),t._v(" "),e("p",[t._v("增量导入是仅导入新添加的表中的行的技术。")]),t._v(" "),e("p",[t._v("下面的语法用于Sqoop导入命令增量选项。")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("--incremental "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("mode"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("  --check-column "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("column name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("  --last value "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("last check "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("column")]),t._v(" value"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" \n")])])]),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("Incremental "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" arguments:\n   --check-column "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("column"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("        Source "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("column")]),t._v(" to check "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" incremental\n                                  change \n                                  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#通过哪一列来检查新增的改变（检查的列）")]),t._v("\n   --incremental "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("import-type"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("    Define an incremental "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" of "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("type")]),t._v("\n                                  "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'append'")]),t._v(" or "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lastmodified'")]),t._v("\n                                  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#指定导入类型，append为追加")]),t._v("\n   --last-value "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("value"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("           Last imported value "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" the incremental\n                                  check "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("column")]),t._v("\n                                  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#最后一个导入的检查的列的值")]),t._v("\n")])])]),e("h6",{attrs:{id:"例子1-这种做法很鸡肋"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#例子1-这种做法很鸡肋"}},[t._v("#")]),t._v(" 例子1（这种做法很鸡肋）：")]),t._v(" "),e("p",[t._v("假如我以id这一列作为判断是否有新增数据的列(--check-column)，上一次导入数据导到了id列值为1203那里，而且表中仅仅会有新增数据的操作，没有更新update数据的操作。")]),t._v(" "),e("p",[t._v("那么，我们可以进行如下导入新增数据的操作：")]),t._v(" "),e("p",[t._v("注意：增量导入的时候，一定不能加参数--delete-target-dir否则会报错")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[t._v("mysql"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" emp"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+----------+--------------+--------+------+---------------------+--------------")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" id   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" name     "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" deg          "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" salary "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" dept "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" create_time         "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" update_time         "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" is_delete "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+----------+--------------+--------+------+---------------------+--------------")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1201")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" gopal    "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" manager      "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("50000")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" TP   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("         "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1202")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" manisha  "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Proof reader "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("50000")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" TP   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("         "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1203")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" khalil   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" php dev      "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("30000")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" AC   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("         "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1204")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" prasanth "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" php dev      "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("30000")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" AC   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("         "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1205")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" kranthi  "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" admin        "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("20000")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" TP   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),t._v(":"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("03")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("         "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+----------+--------------+--------+------+---------------------+-------------")]),t._v("\n")])])]),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("sqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" --connect jdbc:mysql://node03:3306/userdb --username root --password "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456")]),t._v(" --table emp --incremental append --check-column "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("id")]),t._v(" --last-value "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1203")]),t._v(" --m "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" --target-dir /sqoop/increment\n\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 ~"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -cat /sqoop/increment/part-m-00000    \n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1204")]),t._v(",prasanth,php dev,30000,AC,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1205")]),t._v(",kranthi,admin,20000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n")])])]),e("p",[t._v("这种方法虽然实现了增量导入，但是很鸡肋，因为我们怎么上一次导入的id列的最后一个值是什么？而且这种增量导入还是在没有update操作的基础上实现的，实际中很可能是有update数据操作的，有update的话，又要怎么实现增量导入，这时候就用到了sql的TIMESTAMP属性了。")]),t._v(" "),e("h6",{attrs:{id:"例子2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#例子2"}},[t._v("#")]),t._v(" 例子2：")]),t._v(" "),e("p",[t._v("我们在创建emp表的时候，添加了下列两个字段，")]),t._v(" "),e("p",[t._v("create_time TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,")]),t._v(" "),e("p",[t._v("update_time TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE")]),t._v(" "),e("p",[t._v("分别用来记录insert时间以及update时间，我们可以利用--where来设定查询的时间范围，从而实现更强大的增量导入，同时导入insert新增的数据和更新update过的数据。")]),t._v(" "),e("p",[t._v("下面的代码块可以实现导入新增以及更新过的数据：")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("sqoop "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" --connect jdbc:mysql://node03:3306/userdb --username root --password "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456")]),t._v(" --table emp --incremental append --where "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"update_time > '2020-03-14 12:21:02' and is_delete='1' and update_time < '2020-03-14 12:21:05'\"")]),t._v(" --target-dir /sqoop/incement2 --check-column "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("id")]),t._v(" --m "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 ~"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -cat /sqoop/incement2/part-m-00000\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1201")]),t._v(",gopal,manager,50000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1202")]),t._v(",manisha,Proof reader,50000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1203")]),t._v(",khalil,php dev,30000,AC,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1204")]),t._v(",prasanth,php dev,30000,AC,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1205")]),t._v(",kranthi,admin,20000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n")])])]),e("p",[t._v("下面的代码块可以实现导入新增数据(不包括更新过的数据）：")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[t._v("sqoop "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--connect jdbc:mysql://node03:3306/userdb --username root --password 123456 --table emp --incremental append --where \"create_time > '2020-03-14 12:21:02' and is_delete='1' and create_time < '2020-03-14 12:21:05'\" --target-dir /sqoop/incement2 --check-column id --m 1")]),t._v("\n")])])]),e("h4",{attrs:{id:"作业-增量导入数据到hive表中该如何实现-todo"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#作业-增量导入数据到hive表中该如何实现-todo"}},[t._v("#")]),t._v(" 作业：增量导入数据到hive表中该如何实现？(TODO)")]),t._v(" "),e("h4",{attrs:{id:"面试题-如何解决减量数据"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#面试题-如何解决减量数据"}},[t._v("#")]),t._v(" 面试题：如何解决减量数据？？？")]),t._v(" "),e("p",[t._v("假设我们已经将数据库表的数据导入到hdfs了，那么如果数据库表又删除某些数据，如何解决？我们要删掉导入到hdfs的对应部分数据吗？")]),t._v(" "),e("p",[t._v("当然不是。在业务库表中，一般都是做假删除的，比如说添加一个is_delete字段来判断某个记录（行）是不是已被删除的，并不是真的删除。那么若数据库表的数据被删了，那么对应的is_delete字段的对应值就会发生变化，比如说从1变成了0，那么update_time就会发生变化。既然update_time就会发生了变化，我们就可以把减量数据当成更新的数据来处理就行了，只不过是做了删除标记的更新数据罢了。")]),t._v(" "),e("h4",{attrs:{id:"思考问题"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#思考问题"}},[t._v("#")]),t._v(" 思考问题")]),t._v(" "),e("p",[t._v("问题：一行数据被update前，导入到hdfs过一次，后来这行数据被update了，然后该行数据又被导入hdfs了，那么我们就导入了两条同一行的数据（虽然部分值可能不一样）。我们要怎么更新我们的hdfs中的这行数据，怎么找到这两条数据？")]),t._v(" "),e("p",[t._v("解决：使用数据仓库的拉链表来解决。")]),t._v(" "),e("h2",{attrs:{id:"sqoop导出数据"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop导出数据"}},[t._v("#")]),t._v(" Sqoop导出数据")]),t._v(" "),e("h4",{attrs:{id:"从hdfs文件导出数据到mysql"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#从hdfs文件导出数据到mysql"}},[t._v("#")]),t._v(" 从HDFS文件导出数据到mysql")]),t._v(" "),e("p",[t._v("导出前，目标表必须存在于目标数据库中。要导出到数据库的数据内容及路径如下")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 ~"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -ls /sqoop/emp\nFound "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" items\n-rw-r--r--   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" hadoop supergroup          "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":49 /sqoop/emp/_SUCCESS\n-rw-r--r--   "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" hadoop supergroup        "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("381")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":49 /sqoop/emp/part-m-00000\n\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 ~"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -cat /sqoop/emp/part-m-00000\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1201")]),t._v(",gopal,manager,50000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1202")]),t._v(",manisha,Proof reader,50000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1203")]),t._v(",khalil,php dev,30000,AC,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1204")]),t._v(",prasanth,php dev,30000,AC,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1205")]),t._v(",kranthi,admin,20000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n")])])]),e("p",[t._v("node03创建mysql表。")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("emp_out"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("id"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("name"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("deg"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("salary"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("dept"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VARCHAR")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("create_time"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TIMESTAMP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CURRENT_TIMESTAMP")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("update_time"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TIMESTAMP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CURRENT_TIMESTAMP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UPDATE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CURRENT_TIMESTAMP")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v("is_delete"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("`")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BIGINT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'1'")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ENGINE")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INNODB")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CHARSET")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("utf8"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),e("p",[t._v("通过kkb来实现数据的导出，将hdfs的数据导出到mysql当中去")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("sqoop "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" --connect jdbc:mysql://node03:3306/userdb --username root --password "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456")]),t._v(" --table emp_out --export-dir /sqoop/emp --input-fields-terminated-by "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('","')]),t._v("\n")])])]),e("p",[t._v("查看emp_out表是否确实存在数据：")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("mysql"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" * from emp_out"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n+------+----------+--------------+--------+------+---------------------+----------\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("id")]),t._v("   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" name     "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" deg          "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" salary "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" dept "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" create_time         "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" update_ti\n+------+----------+--------------+--------+------+---------------------+----------\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1205")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" kranthi  "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" admin        "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("20000")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" TP   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-1\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1201")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" gopal    "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" manager      "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("50000")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" TP   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-1\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1202")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" manisha  "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Proof reader "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("50000")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" TP   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-1\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1203")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" khalil   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" php dev      "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("30000")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" AC   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-1\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1204")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" prasanth "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" php dev      "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("30000")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" AC   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-03-1\n+------+----------+--------------+--------+------+---------------------+----------\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#数据还有一部分没有复制粘贴过来")]),t._v("\n")])])]),e("h4",{attrs:{id:"从hbase表导出数据到mysql"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#从hbase表导出数据到mysql"}},[t._v("#")]),t._v(" 从Hbase表导出数据到mysql")]),t._v(" "),e("p",[t._v("注意：sqoop不支持我们直接将HBase当中的数据导出，所以我们可以通过以下的转换进行导出。")]),t._v(" "),e("p",[t._v("Hbase→hive外部表→hive内部表→通过sqoop→mysql")]),t._v(" "),e("p",[t._v("需求：将hbase_book这张表当中的数据导出到mysql当中来")]),t._v(" "),e("p",[t._v("**第一步：**创建hive外部表，映射hbase当中的hbase_book表")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[t._v("nohup hive "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--service hiveserver2 2>&1 &")]),t._v("\nbeeline\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("connect")]),t._v(" jdbc:hive2:"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//node03:10000")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(": jdbc:hive2:"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//node03:10000> create database course;")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" EXTERNAL "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" course"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase2mysql "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("name string"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("price "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nSTORED "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'org.apache.hadoop.hive.hbase.HBaseStorageHandler'")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WITH")]),t._v(" SERDEPROPERTIES "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hbase.columns.mapping"')]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('":key,info:name, info:price"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nTBLPROPERTIES"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hbase.table.name"')]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hbase_book"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hbase.mapred.output.outputtable"')]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hbase2mysql"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n \n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(": jdbc:hive2:"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//node03:10000> select * from hbase2mysql;")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-----------------+--------------------+--------------------+--+")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" hbase2mysql"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("id  "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  hbase2mysql"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name  "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" hbase2mysql"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("price  "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-----------------+--------------------+--------------------+--+")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("               "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Lie Sporting       "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),t._v("                 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("               "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Pride "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" Prejudice  "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("70")]),t._v("                 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("               "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Fall "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),t._v(" Giants     "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v("                 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-----------------+--------------------+--------------------+--+")]),t._v("\n")])])]),e("p",[t._v("**第二步：**创建hive内部表")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(": jdbc:hive2:"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//node03:10000> CREATE TABLE course.hbase2mysqlin(id int,name string,price int);")]),t._v("\n")])])]),e("p",[t._v("**第三步：**将外部表数据插入到内部表")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(": jdbc:hive2:"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//node03:10000> insert overwrite table course.hbase2mysqlin select * from course.hbase2mysql;")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(": jdbc:hive2:"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//node03:10000> select * from hbase2mysqlin;")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-------------------+---------------------+----------------------+--+")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" hbase2mysqlin"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("id  "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" hbase2mysqlin"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name  "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" hbase2mysqlin"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("price  "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-------------------+---------------------+----------------------+--+")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("                 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Lie Sporting        "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),t._v("                   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("                 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Pride "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" Prejudice   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("70")]),t._v("                   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("                 "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Fall "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),t._v(" Giants      "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v("                   "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-------------------+---------------------+----------------------+--+")]),t._v("\n")])])]),e("p",[t._v("**第四步：**清空mysql表数据,将book表数据清空")]),t._v(" "),e("p",[t._v("清空book是为了做前后对比，等下要将hive内部表的数据导出到mysql的book表中，清空可以验证是否导出成功。")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[t._v("mysql"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" library"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nmysql"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TRUNCATE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" book"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\nmysql"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" book"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" \nEmpty "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("set")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.00")]),t._v(" sec"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("p",[t._v("**第五步：**获得内部表的数据存放在hdfs的路径")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(": jdbc:hive2:"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//node03:10000> desc formatted  hbase2mysqlin;")]),t._v("\n\nLocation: hdfs:"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//node01:8020/user/hive/warehouse/course.db/hbase2mysqlin")]),t._v("\n")])])]),e("p",[t._v("**第六步：**执行sqoop导出hive内部表数据到mysql")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("sqoop "),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" -connect jdbc:mysql://node03:3306/library -username root -password "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456")]),t._v(" -table book -export-dir /user/hive/warehouse/course.db/hbase2mysqlin --input-fields-terminated-by "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'"),e("span",{pre:!0,attrs:{class:"token entity",title:"\\001"}},[t._v("\\001")]),t._v("'")]),t._v(" --input-null-string "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'"),e("span",{pre:!0,attrs:{class:"token entity",title:"\\\\"}},[t._v("\\\\")]),t._v("N'")]),t._v(" --input-null-non-string "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'"),e("span",{pre:!0,attrs:{class:"token entity",title:"\\\\"}},[t._v("\\\\")]),t._v("N'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),e("p",[t._v("--input-null-string '\\\\N' 表示如果导入的数据是空值，而且是字符串类型的空值，则使用\\N来表示。")]),t._v(" "),e("p",[t._v("--input-null-non-string '\\\\N' 表示如果导入的数据是空值，且不是字符串类型，则使用\\N来表示。")]),t._v(" "),e("p",[t._v("**第七步：**查看效果：")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[t._v("mysql"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" book"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" \n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("----+-------------------+-------+")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" id "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" NAME              "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" price "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("----+-------------------+-------+")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Lie Sporting      "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),t._v("    "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Pride "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v(" Prejudice "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("70")]),t._v("    "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Fall "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),t._v(" Giants    "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),t._v("    "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("----+-------------------+-------+")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("in")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("set")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.00")]),t._v(" sec"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),e("h2",{attrs:{id:"sqoop-job作业-了解即可"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop-job作业-了解即可"}},[t._v("#")]),t._v(" Sqoop job作业（了解即可）")]),t._v(" "),e("p",[t._v("Sqoop作业：将事先定义好的数据导入导出任务按照指定流程运行。Sqoop作业不太常用，了解即可，一般使用Linux shell脚本（将sqoop语句写入脚本中，然后运行脚本）。")]),t._v(" "),e("p",[t._v("创建Sqoop作业的语法：")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[t._v("$ sqoop job "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("generic-args"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("job-args"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("-- "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("subtool-name"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("subtool-args"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("     \n$ sqoop-job "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("generic-args"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("job-args"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("-- "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("subtool-name"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("subtool-args"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("      \n")])])]),e("p",[t._v("创建Sqoop作业示例：")]),t._v(" "),e("p",[t._v("在这里，我们创建一个名为myjob，将RDBMS表的数据导入到HDFS中。")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 ~"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ sqoop job --create myjob -- "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" --connect jdbc:mysql://node03:3306/userdb --username root --password "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456")]),t._v(" --table emp --target-dir /sqoopJob/myjob --delete-target-dir --m "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),e("p",[t._v("注意：")]),t._v(" "),e("ul",[e("li",[t._v("创建job时，-- import是不连在一起的，一定要分开，不能写成--import")]),t._v(" "),e("li",[t._v("要加上--m 1，否则等会运行job时会报错：ERROR tool.ImportTool: Import failed: No primary key could be found for table emp. Please specify one with --split-by or perform a sequential import with '-m 1'. 可能是因为没有primary key才需要加--m 1")])]),t._v(" "),e("p",[t._v("显示存在的作业 (--list)")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 ~"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ sqoop job --list\n\nAvailable jobs:\n  myjob\n")])])]),e("p",[t._v("检查作业(--show)")]),t._v(" "),e("p",[e("strong",[t._v("‘--show’")]),t._v(" 参数用于检查或验证特定的工作，及其详细信息。")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 ~"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ sqoop job --show myjob\nEnter password:  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#需要输入密码(hadoop用户的密码)才能查看job详细信息")]),t._v("\nJob: myjob\nTool: "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v("\nOptions:  \n----------------------------  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#显示了工具Tool和参数options")]),t._v("\nreset.onemapper "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("..")]),t._v(". "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#中间省略了")]),t._v("\nhbase.create.table "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\ncodegen.compile.dir "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" /tmp/sqoop-hadoop/compile/2a2a6614296865eedd8f26a8d8ea0636\ncodegen.output.delimiters.escape "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\ndb.connect.string "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" jdbc:mysql://node03:3306/userdb\n")])])]),e("p",[t._v("执行作业 (--exec)")]),t._v(" "),e("div",{staticClass:"language-sh extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sh"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 ~"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ sqoop job --exec myjob  \n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#查看运行作业后的效果。")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node03 ~"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -cat /sqoopJob/myjob/part-m-00000\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1201")]),t._v(",gopal,manager,50000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1202")]),t._v(",manisha,Proof reader,50000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1203")]),t._v(",khalil,php dev,30000,AC,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1204")]),t._v(",prasanth,php dev,30000,AC,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,1\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1205")]),t._v(",jimmy,admin,20000,TP,2020-03-14 "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v(":21:03.0,2020-03-15 01:27:17.0,1\n")])])]),e("h2",{attrs:{id:"sqoop常用命令及参数-todo"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#sqoop常用命令及参数-todo"}},[t._v("#")]),t._v(" Sqoop常用命令及参数(TODO)")]),t._v(" "),e("h3",{attrs:{id:"常用命令列举"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#常用命令列举"}},[t._v("#")]),t._v(" 常用命令列举")]),t._v(" "),e("p",[t._v("这里给大家列出来了一部分Sqoop操作时的常用参数，以供参考，需要深入学习的可以参看对应类的源代码。")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("序号")])]),t._v(" "),e("th",[e("strong",[t._v("命令")])]),t._v(" "),e("th",[e("strong",[t._v("类")])]),t._v(" "),e("th",[e("strong",[t._v("说明")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1")]),t._v(" "),e("td",[t._v("import")]),t._v(" "),e("td",[t._v("ImportTool")]),t._v(" "),e("td",[t._v("将数据导入到集群")])]),t._v(" "),e("tr",[e("td",[t._v("2")]),t._v(" "),e("td",[t._v("export")]),t._v(" "),e("td",[t._v("ExportTool")]),t._v(" "),e("td",[t._v("将集群数据导出")])]),t._v(" "),e("tr",[e("td",[t._v("3")]),t._v(" "),e("td",[t._v("codegen")]),t._v(" "),e("td",[t._v("CodeGenTool")]),t._v(" "),e("td",[t._v("获取数据库中某张表数据生成Java并打包Jar")])]),t._v(" "),e("tr",[e("td",[t._v("4")]),t._v(" "),e("td",[t._v("create-hive-table")]),t._v(" "),e("td",[t._v("CreateHiveTableTool")]),t._v(" "),e("td",[t._v("创建Hive表")])]),t._v(" "),e("tr",[e("td",[t._v("5")]),t._v(" "),e("td",[t._v("eval")]),t._v(" "),e("td",[t._v("EvalSqlTool")]),t._v(" "),e("td",[t._v("查看SQL执行结果")])]),t._v(" "),e("tr",[e("td",[t._v("6")]),t._v(" "),e("td",[t._v("import-all-tables")]),t._v(" "),e("td",[t._v("ImportAllTablesTool")]),t._v(" "),e("td",[t._v("导入某个数据库下所有表到HDFS中")])]),t._v(" "),e("tr",[e("td",[t._v("7")]),t._v(" "),e("td",[t._v("job")]),t._v(" "),e("td",[t._v("JobTool")]),t._v(" "),e("td",[t._v("用来生成一个sqoop的任务，生成后，该任务并不执行，除非使用命令执行该任务。")])]),t._v(" "),e("tr",[e("td",[t._v("8")]),t._v(" "),e("td",[t._v("list-databases")]),t._v(" "),e("td",[t._v("ListDatabasesTool")]),t._v(" "),e("td",[t._v("列出所有数据库名")])]),t._v(" "),e("tr",[e("td",[t._v("9")]),t._v(" "),e("td",[t._v("list-tables")]),t._v(" "),e("td",[t._v("ListTablesTool")]),t._v(" "),e("td",[t._v("列出某个数据库下所有表")])]),t._v(" "),e("tr",[e("td",[t._v("10")]),t._v(" "),e("td",[t._v("merge")]),t._v(" "),e("td",[t._v("MergeTool")]),t._v(" "),e("td",[t._v("将HDFS中不同目录下面的数据合在一起，并存放在指定的目录中")])]),t._v(" "),e("tr",[e("td",[t._v("11")]),t._v(" "),e("td",[t._v("metastore")]),t._v(" "),e("td",[t._v("MetastoreTool")]),t._v(" "),e("td",[t._v("记录sqoop job的元数据信息，如果不启动metastore实例，则默认的元数据存储目录为：~/.sqoop，如果要更改存储目录，可以在配置文件sqoop-site.xml中进行更改。")])]),t._v(" "),e("tr",[e("td",[t._v("12")]),t._v(" "),e("td",[t._v("help")]),t._v(" "),e("td",[t._v("HelpTool")]),t._v(" "),e("td",[t._v("打印sqoop帮助信息")])]),t._v(" "),e("tr",[e("td",[t._v("13")]),t._v(" "),e("td",[t._v("version")]),t._v(" "),e("td",[t._v("VersionTool")]),t._v(" "),e("td",[t._v("打印sqoop版本信息")])])])]),t._v(" "),e("h3",{attrs:{id:"命令-参数详解"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#命令-参数详解"}},[t._v("#")]),t._v(" 命令&参数详解")]),t._v(" "),e("p",[t._v("刚才列举了一些Sqoop的常用命令，对于不同的命令，有不同的参数，让我们来一一列举说明。")]),t._v(" "),e("p",[t._v("首先来我们来介绍一下公用的参数，所谓公用参数，就是大多数命令都支持的参数。")]),t._v(" "),e("h5",{attrs:{id:"_1、公用参数-数据库连接"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1、公用参数-数据库连接"}},[t._v("#")]),t._v(" 1、公用参数：数据库连接")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("序号")])]),t._v(" "),e("th",[e("strong",[t._v("参数")])]),t._v(" "),e("th",[e("strong",[t._v("说明")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1")]),t._v(" "),e("td",[t._v("--connect")]),t._v(" "),e("td",[t._v("连接关系型数据库的URL")])]),t._v(" "),e("tr",[e("td",[t._v("2")]),t._v(" "),e("td",[t._v("--connection-manager")]),t._v(" "),e("td",[t._v("指定要使用的连接管理类")])]),t._v(" "),e("tr",[e("td",[t._v("3")]),t._v(" "),e("td",[t._v("--driver")]),t._v(" "),e("td",[t._v("JDBC的driver class")])]),t._v(" "),e("tr",[e("td",[t._v("4")]),t._v(" "),e("td",[t._v("--help")]),t._v(" "),e("td",[t._v("打印帮助信息")])]),t._v(" "),e("tr",[e("td",[t._v("5")]),t._v(" "),e("td",[t._v("--password")]),t._v(" "),e("td",[t._v("连接数据库的密码")])]),t._v(" "),e("tr",[e("td",[t._v("6")]),t._v(" "),e("td",[t._v("--username")]),t._v(" "),e("td",[t._v("连接数据库的用户名")])]),t._v(" "),e("tr",[e("td",[t._v("7")]),t._v(" "),e("td",[t._v("--verbose")]),t._v(" "),e("td",[t._v("在控制台打印出详细信息")])])])]),t._v(" "),e("h5",{attrs:{id:"_2、公用参数-import"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2、公用参数-import"}},[t._v("#")]),t._v(" 2、公用参数：import")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("序号")])]),t._v(" "),e("th",[e("strong",[t._v("参数")])]),t._v(" "),e("th",[e("strong",[t._v("说明")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1")]),t._v(" "),e("td",[t._v("--enclosed-by  "),e("code",[t._v("<char>")])]),t._v(" "),e("td",[t._v("给字段值前后加上指定的字符")])]),t._v(" "),e("tr",[e("td",[t._v("2")]),t._v(" "),e("td",[t._v("--escaped-by  "),e("code",[t._v("<char>")])]),t._v(" "),e("td",[t._v("对字段中的双引号加转义符")])]),t._v(" "),e("tr",[e("td",[t._v("3")]),t._v(" "),e("td",[t._v("--fields-terminated-by  "),e("code",[t._v("<char>")])]),t._v(" "),e("td",[t._v("设定每个字段是以什么符号作为结束，默认为逗号")])]),t._v(" "),e("tr",[e("td",[t._v("4")]),t._v(" "),e("td",[t._v("--lines-terminated-by  "),e("code",[t._v("<char>")])]),t._v(" "),e("td",[t._v("设定每行记录之间的分隔符，默认是\\n")])]),t._v(" "),e("tr",[e("td",[t._v("5")]),t._v(" "),e("td",[t._v("--mysql-delimiters")]),t._v(" "),e("td",[t._v("Mysql默认的分隔符设置，字段之间以逗号分隔，行之间以\\n分隔，默认转义符是\\，字段值以单引号包裹。")])]),t._v(" "),e("tr",[e("td",[t._v("6")]),t._v(" "),e("td",[t._v("--optionally-enclosed-by  "),e("code",[t._v("<char>")])]),t._v(" "),e("td",[t._v("给带有双引号或单引号的字段值前后加上指定字符。")])])])]),t._v(" "),e("h5",{attrs:{id:"_3、公用参数-export"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3、公用参数-export"}},[t._v("#")]),t._v(" 3、公用参数：export")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("序号")])]),t._v(" "),e("th",[e("strong",[t._v("参数")])]),t._v(" "),e("th",[e("strong",[t._v("说明")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1")]),t._v(" "),e("td",[t._v("--input-enclosed-by  "),e("code",[t._v("<char>")])]),t._v(" "),e("td",[t._v("对字段值前后加上指定字符")])]),t._v(" "),e("tr",[e("td",[t._v("2")]),t._v(" "),e("td",[t._v("--input-escaped-by  "),e("code",[t._v("<char>")])]),t._v(" "),e("td",[t._v("对含有转移符的字段做转义处理")])]),t._v(" "),e("tr",[e("td",[t._v("3")]),t._v(" "),e("td",[t._v("--input-fields-terminated-by  "),e("code",[t._v("<char>")])]),t._v(" "),e("td",[t._v("字段之间的分隔符")])]),t._v(" "),e("tr",[e("td",[t._v("4")]),t._v(" "),e("td",[t._v("--input-lines-terminated-by  "),e("code",[t._v("<char>")])]),t._v(" "),e("td",[t._v("行之间的分隔符")])]),t._v(" "),e("tr",[e("td",[t._v("5")]),t._v(" "),e("td",[t._v("--input-optionally-enclosed-by  "),e("code",[t._v("<char>")])]),t._v(" "),e("td",[t._v("给带有双引号或单引号的字段前后加上指定字符")])])])]),t._v(" "),e("h5",{attrs:{id:"_4、公用参数-hive"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4、公用参数-hive"}},[t._v("#")]),t._v(" 4、公用参数：hive")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("序号")])]),t._v(" "),e("th",[e("strong",[t._v("参数")])]),t._v(" "),e("th",[e("strong",[t._v("说明")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1")]),t._v(" "),e("td",[t._v("--hive-delims-replacement  "),e("code",[t._v("<arg>")])]),t._v(" "),e("td",[t._v("用自定义的字符串替换掉数据中的\\r\\n和\\013 \\010等字符")])]),t._v(" "),e("tr",[e("td",[t._v("2")]),t._v(" "),e("td",[t._v("--hive-drop-import-delims")]),t._v(" "),e("td",[t._v("在导入数据到hive时，去掉数据中的\\r\\n\\013\\010这样的字符")])]),t._v(" "),e("tr",[e("td",[t._v("3")]),t._v(" "),e("td",[t._v("--map-column-hive  "),e("code",[t._v("<map>")])]),t._v(" "),e("td",[t._v("生成hive表时，可以更改生成字段的数据类型")])]),t._v(" "),e("tr",[e("td",[t._v("4")]),t._v(" "),e("td",[t._v("--hive-partition-key")]),t._v(" "),e("td",[t._v("创建分区，后面直接跟分区名，分区字段的默认类型为string")])]),t._v(" "),e("tr",[e("td",[t._v("5")]),t._v(" "),e("td",[t._v("--hive-partition-value  "),e("code",[t._v("<v>")])]),t._v(" "),e("td",[t._v("导入数据时，指定某个分区的值")])]),t._v(" "),e("tr",[e("td",[t._v("6")]),t._v(" "),e("td",[t._v("--hive-home  "),e("code",[t._v("<dir>")])]),t._v(" "),e("td",[t._v("hive的安装目录，可以通过该参数覆盖之前默认配置的目录")])]),t._v(" "),e("tr",[e("td",[t._v("7")]),t._v(" "),e("td",[t._v("--hive-import")]),t._v(" "),e("td",[t._v("将数据从关系数据库中导入到hive表中")])]),t._v(" "),e("tr",[e("td",[t._v("8")]),t._v(" "),e("td",[t._v("--hive-overwrite")]),t._v(" "),e("td",[t._v("覆盖掉在hive表中已经存在的数据")])]),t._v(" "),e("tr",[e("td",[t._v("9")]),t._v(" "),e("td",[t._v("--create-hive-table")]),t._v(" "),e("td",[t._v("默认是false，即，如果目标表已经存在了，那么创建任务失败。")])]),t._v(" "),e("tr",[e("td",[t._v("10")]),t._v(" "),e("td",[t._v("--hive-table")]),t._v(" "),e("td",[t._v("后面接要创建的hive表,默认使用MySQL的表名")])]),t._v(" "),e("tr",[e("td",[t._v("11")]),t._v(" "),e("td",[t._v("--table")]),t._v(" "),e("td",[t._v("指定关系数据库的表名")])])])]),t._v(" "),e("p",[t._v("公用参数介绍完之后，我们来按照命令介绍命令对应的特有参数。")]),t._v(" "),e("h5",{attrs:{id:"_5、命令-参数-import"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5、命令-参数-import"}},[t._v("#")]),t._v(" 5、命令&参数：import")]),t._v(" "),e("p",[t._v("将关系型数据库中的数据导入到HDFS（包括Hive，HBase）中，如果导入的是Hive，那么当Hive中没有对应表时，则自动创建。")]),t._v(" "),e("p",[e("strong",[t._v("1)")]),t._v(" "),e("strong",[t._v("命令：")])]),t._v(" "),e("p",[t._v("如：导入数据到hive中")]),t._v(" "),e("p",[t._v("$ bin/sqoop import \\  --connect jdbc:mysql://node03:3306/userdb  \\  --username root \\  --password 123456 \\  --table emp \\  --hive-import")]),t._v(" "),e("p",[t._v("如：增量导入数据到hive中，mode=append")]),t._v(" "),e("p",[t._v('append导入：  $  bin/sqoop import \\  --connect  jdbc:mysql://node03:3306/userdb \\  --username  root \\  --password  123456 \\  --table  emp \\  --num-mappers  1 \\  --fields-terminated-by  "\\t" \\  --target-dir  /user/hive/warehouse/emp \\  --check-column  id \\  --incremental  append \\  --last-value  3')]),t._v(" "),e("p",[t._v("易错提醒：append不能与--hive-等参数同时使用（Append mode for hive imports is not yet supported. Please remove the parameter --append-mode）")]),t._v(" "),e("p",[t._v("如：增量导入数据到hdfs中，mode=lastmodified")]),t._v(" "),e("p",[t._v("先在mysql中建表并插入几条数据：")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[t._v(" mysql"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v("  company"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("staff_timestamp"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("varchar")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sex "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("varchar")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  last_modified "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("timestamp")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DEFAULT")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CURRENT_TIMESTAMP")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UPDATE")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CURRENT_TIMESTAMP")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("  mysql"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v("  company"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("staff_timestamp "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sex"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("values")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'AAA'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'female'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("  \n \n mysql"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v("  company"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("staff_timestamp "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sex"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("values")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'BBB'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'female'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("  \n \n "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#先导入一部分数据：  ")]),t._v("\n bin"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("sqoop "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--connect  jdbc:mysql://node03:3306/userdb  --username  root --password  123456   --table  emp_conn  --delete-target-dir    --m  1  ")]),t._v("\n "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#再增量导入一部分数据：  ")]),t._v("\n \n mysql"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v("  company"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("staff_timestamp "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sex"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("values")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'CCC'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'female'")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("  \n \n bin"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("sqoop "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v('--connect  jdbc:mysql://node03:3306/userdb --username  root --password  123456  --table  emp_conn  --check-column  last_modified --incremental  lastmodified --last-value  "2018-0-28 22:20:38"  --m  1  --append  ')]),t._v("\n")])])]),e("p",[t._v("易错提醒：使用lastmodified方式导入数据要指定增量数据是要--append（追加）还是要--merge-key（合并）")]),t._v(" "),e("p",[t._v("易错提醒：--incremental lastmodified模式下，last-value指定的值是会包含于增量导入的数据中。")]),t._v(" "),e("p",[e("strong",[t._v("2)")]),t._v(" "),e("strong",[t._v("参数：")])]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("序号")])]),t._v(" "),e("th",[e("strong",[t._v("参数")])]),t._v(" "),e("th",[e("strong",[t._v("说明")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1")]),t._v(" "),e("td",[t._v("--append")]),t._v(" "),e("td",[t._v("将数据追加到HDFS中已经存在的DataSet中，如果使用该参数，sqoop会把数据先导入到临时文件目录，再合并。")])]),t._v(" "),e("tr",[e("td",[t._v("2")]),t._v(" "),e("td",[t._v("--as-avrodatafile")]),t._v(" "),e("td",[t._v("将数据导入到一个Avro数据文件中")])]),t._v(" "),e("tr",[e("td",[t._v("3")]),t._v(" "),e("td",[t._v("--as-sequencefile")]),t._v(" "),e("td",[t._v("将数据导入到一个sequence文件中")])]),t._v(" "),e("tr",[e("td",[t._v("4")]),t._v(" "),e("td",[t._v("--as-textfile")]),t._v(" "),e("td",[t._v("将数据导入到一个普通文本文件中")])]),t._v(" "),e("tr",[e("td",[t._v("5")]),t._v(" "),e("td",[t._v("--boundary-query  "),e("code",[t._v("<statement>")])]),t._v(" "),e("td",[t._v("边界查询，导入的数据为该参数的值（一条sql语句）所执行的结果区间内的数据。")])]),t._v(" "),e("tr",[e("td",[t._v("6")]),t._v(" "),e("td",[t._v("--columns "),e("code",[t._v("<col1, col2, col3>")])]),t._v(" "),e("td",[t._v("指定要导入的字段")])]),t._v(" "),e("tr",[e("td",[t._v("7")]),t._v(" "),e("td",[t._v("--direct")]),t._v(" "),e("td",[t._v("直接导入模式，使用的是关系数据库自带的导入导出工具，以便加快导入导出过程。")])]),t._v(" "),e("tr",[e("td",[t._v("8")]),t._v(" "),e("td",[t._v("--direct-split-size")]),t._v(" "),e("td",[t._v("在使用上面direct直接导入的基础上，对导入的流按字节分块，即达到该阈值就产生一个新的文件")])]),t._v(" "),e("tr",[e("td",[t._v("9")]),t._v(" "),e("td",[t._v("--inline-lob-limit")]),t._v(" "),e("td",[t._v("设定大对象数据类型的最大值")])]),t._v(" "),e("tr",[e("td",[t._v("10")]),t._v(" "),e("td",[t._v("--m或–num-mappers")]),t._v(" "),e("td",[t._v("启动N个map来并行导入数据，默认4个。")])]),t._v(" "),e("tr",[e("td",[t._v("11")]),t._v(" "),e("td",[t._v("--query或--e "),e("code",[t._v("<statement>")])]),t._v(" "),e("td",[t._v("将查询结果的数据导入，使用时必须伴随参--target-dir，--hive-table，如果查询中有where条件，则条件后必须加上$CONDITIONS关键字")])]),t._v(" "),e("tr",[e("td",[t._v("12")]),t._v(" "),e("td",[t._v("--split-by "),e("code",[t._v("<column-name>")])]),t._v(" "),e("td",[t._v("按照某一列来切分表的工作单元，不能与--autoreset-to-one-mapper连用（请参考官方文档）")])]),t._v(" "),e("tr",[e("td",[t._v("13")]),t._v(" "),e("td",[t._v("--table "),e("code",[t._v("<table-name>")])]),t._v(" "),e("td",[t._v("关系数据库的表名")])]),t._v(" "),e("tr",[e("td",[t._v("14")]),t._v(" "),e("td",[t._v("--target-dir "),e("code",[t._v("<dir>")])]),t._v(" "),e("td",[t._v("指定HDFS路径")])]),t._v(" "),e("tr",[e("td",[t._v("15")]),t._v(" "),e("td",[t._v("--warehouse-dir "),e("code",[t._v("<dir>")])]),t._v(" "),e("td",[t._v("与14参数不能同时使用，导入数据到HDFS时指定的目录")])]),t._v(" "),e("tr",[e("td",[t._v("16")]),t._v(" "),e("td",[t._v("--where")]),t._v(" "),e("td",[t._v("从关系数据库导入数据时的查询条件")])]),t._v(" "),e("tr",[e("td",[t._v("17")]),t._v(" "),e("td",[t._v("--z或--compress")]),t._v(" "),e("td",[t._v("允许压缩")])]),t._v(" "),e("tr",[e("td",[t._v("18")]),t._v(" "),e("td",[t._v("--compression-codec")]),t._v(" "),e("td",[t._v("指定hadoop压缩编码类，默认为gzip(Use Hadoop codec  default gzip)")])]),t._v(" "),e("tr",[e("td",[t._v("19")]),t._v(" "),e("td",[t._v("--null-string  "),e("code",[t._v("<null-string")]),t._v(">")]),t._v(" "),e("td",[t._v("string类型的列如果null，替换为指定字符串")])]),t._v(" "),e("tr",[e("td",[t._v("20")]),t._v(" "),e("td",[t._v("--null-non-string  "),e("code",[t._v("<null-string>")])]),t._v(" "),e("td",[t._v("非string类型的列如果null，替换为指定字符串")])]),t._v(" "),e("tr",[e("td",[t._v("21")]),t._v(" "),e("td",[t._v("--check-column "),e("code",[t._v("<col>")])]),t._v(" "),e("td",[t._v("作为增量导入判断的列名")])]),t._v(" "),e("tr",[e("td",[t._v("22")]),t._v(" "),e("td",[t._v("--incremental "),e("code",[t._v("<mode>")])]),t._v(" "),e("td",[t._v("mode：append或lastmodified")])]),t._v(" "),e("tr",[e("td",[t._v("23")]),t._v(" "),e("td",[t._v("--last-value "),e("code",[t._v("<value>")])]),t._v(" "),e("td",[t._v("指定某一个值，用于标记增量导入的位置")])])])]),t._v(" "),e("h5",{attrs:{id:"_6、命令-参数-export"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_6、命令-参数-export"}},[t._v("#")]),t._v(" 6、命令&参数：export")]),t._v(" "),e("p",[t._v("从HDFS（包括Hive和HBase）中奖数据导出到关系型数据库中。")]),t._v(" "),e("p",[e("strong",[t._v("1)")]),t._v(" "),e("strong",[t._v("命令：")])]),t._v(" "),e("p",[e("strong",[t._v("如：")])]),t._v(" "),e("p",[t._v('$ bin/sqoop export \\  --connect jdbc:mysql://node03:3306/userdb  \\  --username root \\  --password 123456 \\  --table emp_add \\  --export-dir /user/company \\  --input-fields-terminated-by  "\\t" \\  --num-mappers 1')]),t._v(" "),e("p",[e("strong",[t._v("2)")]),t._v(" "),e("strong",[t._v("参数：")])]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("序号")])]),t._v(" "),e("th",[e("strong",[t._v("参数")])]),t._v(" "),e("th",[e("strong",[t._v("说明")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1")]),t._v(" "),e("td",[t._v("--direct")]),t._v(" "),e("td",[t._v("利用数据库自带的导入导出工具，以便于提高效率")])]),t._v(" "),e("tr",[e("td",[t._v("2")]),t._v(" "),e("td",[t._v("--export-dir  "),e("code",[t._v("<dir>")])]),t._v(" "),e("td",[t._v("存放数据的HDFS的源目录")])]),t._v(" "),e("tr",[e("td",[t._v("3")]),t._v(" "),e("td",[t._v("-m或--num-mappers  "),e("code",[t._v("<n>")])]),t._v(" "),e("td",[t._v("启动N个map来并行导入数据，默认4个")])]),t._v(" "),e("tr",[e("td",[t._v("4")]),t._v(" "),e("td",[t._v("--table  "),e("code",[t._v("<table-name>")])]),t._v(" "),e("td",[t._v("指定导出到哪个RDBMS中的表")])]),t._v(" "),e("tr",[e("td",[t._v("5")]),t._v(" "),e("td",[t._v("--update-key  "),e("code",[t._v("<col-name>")])]),t._v(" "),e("td",[t._v("对某一列的字段进行更新操作")])]),t._v(" "),e("tr",[e("td",[t._v("6")]),t._v(" "),e("td",[t._v("--update-mode  "),e("code",[t._v("<mode>")])]),t._v(" "),e("td",[t._v("updateonly  allowinsert(默认)")])]),t._v(" "),e("tr",[e("td",[t._v("7")]),t._v(" "),e("td",[t._v("--input-null-string  "),e("code",[t._v("<null-string>")])]),t._v(" "),e("td",[t._v("请参考import该类似参数说明")])]),t._v(" "),e("tr",[e("td",[t._v("8")]),t._v(" "),e("td",[t._v("--input-null-non-string  "),e("code",[t._v("<null-string>")])]),t._v(" "),e("td",[t._v("请参考import该类似参数说明")])]),t._v(" "),e("tr",[e("td",[t._v("9")]),t._v(" "),e("td",[t._v("--staging-table  "),e("code",[t._v("<staging-table-name>")])]),t._v(" "),e("td",[t._v("创建一张临时表，用于存放所有事务的结果，然后将所有事务结果一次性导入到目标表中，防止错误。")])]),t._v(" "),e("tr",[e("td",[t._v("10")]),t._v(" "),e("td",[t._v("--clear-staging-table")]),t._v(" "),e("td",[t._v("如果第9个参数非空，则可以在导出操作执行前，清空临时事务结果表")])])])]),t._v(" "),e("h5",{attrs:{id:"_7、命令-参数-codegen"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_7、命令-参数-codegen"}},[t._v("#")]),t._v(" 7、命令&参数：codegen")]),t._v(" "),e("p",[t._v("将关系型数据库中的表映射为一个Java类，在该类中有各列对应的各个字段。")]),t._v(" "),e("p",[t._v("如：")]),t._v(" "),e("p",[t._v('$ bin/sqoop codegen \\  --connect jdbc:mysql://node03:3306/userdb  \\  --username root \\  --password 123456 \\  --table emp_add \\  --bindir /home/admin/Desktop/staff  \\  --class-name Staff \\  --fields-terminated-by  "\\t"')]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("序号")])]),t._v(" "),e("th",[e("strong",[t._v("参数")])]),t._v(" "),e("th",[e("strong",[t._v("说明")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1")]),t._v(" "),e("td",[t._v("--bindir  "),e("code",[t._v("<dir>")])]),t._v(" "),e("td",[t._v("指定生成的Java文件、编译成的class文件及将生成文件打包为jar的文件输出路径")])]),t._v(" "),e("tr",[e("td",[t._v("2")]),t._v(" "),e("td",[t._v("--class-name  "),e("code",[t._v("<name>")])]),t._v(" "),e("td",[t._v("设定生成的Java文件指定的名称")])]),t._v(" "),e("tr",[e("td",[t._v("3")]),t._v(" "),e("td",[t._v("--outdir  "),e("code",[t._v("<dir>")])]),t._v(" "),e("td",[t._v("生成Java文件存放的路径")])]),t._v(" "),e("tr",[e("td",[t._v("4")]),t._v(" "),e("td",[t._v("--package-name "),e("code",[t._v("<name>")])]),t._v(" "),e("td",[t._v("包名，如com.z，就会生成com和z两级目录")])]),t._v(" "),e("tr",[e("td",[t._v("5")]),t._v(" "),e("td",[t._v("--input-null-non-string  "),e("code",[t._v("<null-str>")])]),t._v(" "),e("td",[t._v("在生成的Java文件中，可以将null字符串或者不存在的字符串设置为想要设定的值（例如空字符串）")])]),t._v(" "),e("tr",[e("td",[t._v("6")]),t._v(" "),e("td",[t._v("--input-null-string  "),e("code",[t._v("<null-str>")])]),t._v(" "),e("td",[t._v("将null字符串替换成想要替换的值（一般与5同时使用）")])]),t._v(" "),e("tr",[e("td",[t._v("7")]),t._v(" "),e("td",[t._v("--map-column-java "),e("code",[t._v("<arg>")])]),t._v(" "),e("td",[t._v("数据库字段在生成的Java文件中会映射成各种属性，且默认的数据类型与数据库类型保持对应关系。该参数可以改变默认类型，例如：--map-column-java  id=long, name=String")])]),t._v(" "),e("tr",[e("td",[t._v("8")]),t._v(" "),e("td",[t._v("--null-non-string  "),e("code",[t._v("<null-str>")])]),t._v(" "),e("td",[t._v("在生成Java文件时，可以将不存在或者null的字符串设置为其他值")])]),t._v(" "),e("tr",[e("td",[t._v("9")]),t._v(" "),e("td",[t._v("--null-string "),e("code",[t._v("<null-str>")])]),t._v(" "),e("td",[t._v("在生成Java文件时，将null字符串设置为其他值（一般与8同时使用）")])]),t._v(" "),e("tr",[e("td",[t._v("10")]),t._v(" "),e("td",[t._v("--table "),e("code",[t._v("<table-name>")])]),t._v(" "),e("td",[t._v("对应关系数据库中的表名，生成的Java文件中的各个属性与该表的各个字段一一对应")])])])]),t._v(" "),e("h5",{attrs:{id:"_8、命令-参数-create-hive-table"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_8、命令-参数-create-hive-table"}},[t._v("#")]),t._v(" 8、命令&参数：create-hive-table")]),t._v(" "),e("p",[t._v("生成与关系数据库表结构对应的hive表结构。")]),t._v(" "),e("p",[e("strong",[t._v("命令：")])]),t._v(" "),e("p",[t._v("如：")]),t._v(" "),e("p",[t._v("$  bin/sqoop create-hive-table \\  --connect jdbc:mysql://node03:3306/userdb  \\  --username root \\  --password 123456 \\  --table emp_add \\  --hive-table emp_add")]),t._v(" "),e("p",[e("strong",[t._v("参数：")])]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("序号")])]),t._v(" "),e("th",[e("strong",[t._v("参数")])]),t._v(" "),e("th",[e("strong",[t._v("说明")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1")]),t._v(" "),e("td",[t._v("--hive-home  "),e("code",[t._v("<dir>")])]),t._v(" "),e("td",[t._v("Hive的安装目录，可以通过该参数覆盖掉默认的Hive目录")])]),t._v(" "),e("tr",[e("td",[t._v("2")]),t._v(" "),e("td",[t._v("--hive-overwrite")]),t._v(" "),e("td",[t._v("覆盖掉在Hive表中已经存在的数据")])]),t._v(" "),e("tr",[e("td",[t._v("3")]),t._v(" "),e("td",[t._v("--create-hive-table")]),t._v(" "),e("td",[t._v("默认是false，如果目标表已经存在了，那么创建任务会失败")])]),t._v(" "),e("tr",[e("td",[t._v("4")]),t._v(" "),e("td",[t._v("--hive-table")]),t._v(" "),e("td",[t._v("后面接要创建的hive表")])]),t._v(" "),e("tr",[e("td",[t._v("5")]),t._v(" "),e("td",[t._v("--table")]),t._v(" "),e("td",[t._v("指定关系数据库的表名")])])])]),t._v(" "),e("h5",{attrs:{id:"_9、命令-参数-eval"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_9、命令-参数-eval"}},[t._v("#")]),t._v(" 9、命令&参数：eval")]),t._v(" "),e("p",[t._v("可以快速的使用SQL语句对关系型数据库进行操作，经常用于在import数据之前，了解一下SQL语句是否正确，数据是否正常，并可以将结果显示在控制台。")]),t._v(" "),e("p",[e("strong",[t._v("命令：")])]),t._v(" "),e("p",[t._v("如：")]),t._v(" "),e("p",[t._v('$  bin/sqoop eval \\  --connect jdbc:mysql://node03:3306/userdb  \\  --username root \\  --password 123456 \\  --query "SELECT * FROM  emp"')]),t._v(" "),e("p",[e("strong",[t._v("参数：")])]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("序号")])]),t._v(" "),e("th",[e("strong",[t._v("参数")])]),t._v(" "),e("th",[e("strong",[t._v("说明")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1")]),t._v(" "),e("td",[t._v("--query或--e")]),t._v(" "),e("td",[t._v("后跟查询的SQL语句")])])])]),t._v(" "),e("h5",{attrs:{id:"_10、命令-参数-import-all-tables"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_10、命令-参数-import-all-tables"}},[t._v("#")]),t._v(" 10、命令&参数：import-all-tables")]),t._v(" "),e("p",[t._v("可以将RDBMS中的所有表导入到HDFS中，每一个表都对应一个HDFS目录")]),t._v(" "),e("p",[e("strong",[t._v("命令：")])]),t._v(" "),e("p",[t._v("如：")]),t._v(" "),e("p",[t._v("$  bin/sqoop import-all-tables \\  --connect jdbc:mysql://node03:3306/userdb  \\  --username root \\  --password 123456 \\  --warehouse-dir /all_tables")]),t._v(" "),e("p",[e("strong",[t._v("参数：")])]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("序号")])]),t._v(" "),e("th",[e("strong",[t._v("参数")])]),t._v(" "),e("th",[e("strong",[t._v("说明")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1")]),t._v(" "),e("td",[t._v("--as-avrodatafile")]),t._v(" "),e("td",[t._v("这些参数的含义均和import对应的含义一致")])]),t._v(" "),e("tr",[e("td",[t._v("2")]),t._v(" "),e("td",[t._v("--as-sequencefile")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("3")]),t._v(" "),e("td",[t._v("--as-textfile")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("4")]),t._v(" "),e("td",[t._v("--direct")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("5")]),t._v(" "),e("td",[t._v("--direct-split-size  "),e("code",[t._v("<n>")])]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("6")]),t._v(" "),e("td",[t._v("--inline-lob-limit  "),e("code",[t._v("<n>")])]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("7")]),t._v(" "),e("td",[t._v("--m或—num-mappers  "),e("code",[t._v("<n>")])]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("8")]),t._v(" "),e("td",[t._v("--warehouse-dir  "),e("code",[t._v("<dir>")])]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("9")]),t._v(" "),e("td",[t._v("-z或--compress")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("10")]),t._v(" "),e("td",[t._v("--compression-codec")]),t._v(" "),e("td")])])]),t._v(" "),e("h5",{attrs:{id:"_11、命令-参数-job"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_11、命令-参数-job"}},[t._v("#")]),t._v(" 11、命令&参数：job")]),t._v(" "),e("p",[t._v("用来生成一个sqoop任务，生成后不会立即执行，需要手动执行。")]),t._v(" "),e("p",[e("strong",[t._v("命令：")])]),t._v(" "),e("p",[t._v("如：")]),t._v(" "),e("p",[t._v("$ bin/sqoop job \\   --create myjob -- import-all-tables \\   --connect jdbc:mysql://node03:3306/userdb \\   --username root \\   --password 123456  $ bin/sqoop job \\  --list  $ bin/sqoop job \\  --exec myjob")]),t._v(" "),e("p",[t._v("易错提醒：注意import-all-tables和它左边的--之间有一个空格")]),t._v(" "),e("p",[t._v("易错提醒：如果需要连接metastore，则--meta-connect jdbc:hsqldb:hsql://node03:16000/sqoop")]),t._v(" "),e("p",[t._v("参数：")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("序号")])]),t._v(" "),e("th",[e("strong",[t._v("参数")])]),t._v(" "),e("th",[e("strong",[t._v("说明")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1")]),t._v(" "),e("td",[t._v("--create  "),e("code",[t._v("<job-id>")])]),t._v(" "),e("td",[t._v("创建job参数")])]),t._v(" "),e("tr",[e("td",[t._v("2")]),t._v(" "),e("td",[t._v("--delete  "),e("code",[t._v("<job-id>")])]),t._v(" "),e("td",[t._v("删除一个job")])]),t._v(" "),e("tr",[e("td",[t._v("3")]),t._v(" "),e("td",[t._v("--exec  "),e("code",[t._v("<job-id>")])]),t._v(" "),e("td",[t._v("执行一个job")])]),t._v(" "),e("tr",[e("td",[t._v("4")]),t._v(" "),e("td",[t._v("--help")]),t._v(" "),e("td",[t._v("显示job帮助")])]),t._v(" "),e("tr",[e("td",[t._v("5")]),t._v(" "),e("td",[t._v("--list")]),t._v(" "),e("td",[t._v("显示job列表")])]),t._v(" "),e("tr",[e("td",[t._v("6")]),t._v(" "),e("td",[t._v("--meta-connect  "),e("code",[t._v("<jdbc-uri>")])]),t._v(" "),e("td",[t._v("用来连接metastore服务")])]),t._v(" "),e("tr",[e("td",[t._v("7")]),t._v(" "),e("td",[t._v("--show  "),e("code",[t._v("<job-id>")])]),t._v(" "),e("td",[t._v("显示一个job的信息")])]),t._v(" "),e("tr",[e("td",[t._v("8")]),t._v(" "),e("td",[t._v("--verbose")]),t._v(" "),e("td",[t._v("打印命令运行时的详细信息")])])])]),t._v(" "),e("p",[t._v("易错提醒：在执行一个job时，如果需要手动输入数据库密码，可以做如下优化")]),t._v(" "),e("p",[e("code",[t._v("<property> <name>sqoop.metastore.client.record.password</name> <value>true</value> <description>If true, allow saved passwords in the metastore.</description> </property>")])]),t._v(" "),e("h5",{attrs:{id:"_12、命令-参数-list-databases"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_12、命令-参数-list-databases"}},[t._v("#")]),t._v(" 12、命令&参数：list-databases")]),t._v(" "),e("p",[e("strong",[t._v("命令：")])]),t._v(" "),e("p",[t._v("如：")]),t._v(" "),e("p",[t._v("$  bin/sqoop list-databases \\  --connect jdbc:mysql://node03:3306/userdb  \\  --username root \\  --password 123456")]),t._v(" "),e("p",[t._v("**参数：**与公用参数一样")]),t._v(" "),e("h5",{attrs:{id:"_13、命令-参数-list-tables"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_13、命令-参数-list-tables"}},[t._v("#")]),t._v(" 13、命令&参数：list-tables")]),t._v(" "),e("p",[e("strong",[t._v("命令：")])]),t._v(" "),e("p",[t._v("如：")]),t._v(" "),e("p",[t._v("$ bin/sqoop list-tables \\  --connect jdbc:mysql://node03:3306/userdb  \\  --username root \\  --password 123456")]),t._v(" "),e("p",[t._v("**参数：**与公用参数一样")]),t._v(" "),e("h5",{attrs:{id:"_14、命令-参数-merge"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_14、命令-参数-merge"}},[t._v("#")]),t._v(" 14、命令&参数：merge")]),t._v(" "),e("p",[t._v("将HDFS中不同目录下面的数据合并在一起并放入指定目录中")]),t._v(" "),e("p",[t._v("数据环境：")]),t._v(" "),e("p",[t._v("new_staff  1    AAA    male  2    BBB    male  3    CCC    male  4    DDD    male  old_staff  1    AAA    female  2    CCC    female  3    BBB    female  6    DDD    female")]),t._v(" "),e("p",[t._v("易错提醒：上边数据的列之间的分隔符应该为\\t，行与行之间的分割符为\\n，如果直接复制，请检查之。")]),t._v(" "),e("p",[e("strong",[t._v("命令：")])]),t._v(" "),e("p",[t._v("如：")]),t._v(" "),e("p",[t._v('创建JavaBean：  $  bin/sqoop codegen \\  --connect  jdbc:mysql://node03:3306/userdb \\  --username  root \\  --password  123456 \\  --table  emp_conn \\  --bindir  /home/admin/Desktop/staff \\  --class-name  EmpConn \\  --fields-terminated-by  "\\t"     开始合并：  $  bin/sqoop merge \\  --new-data  /test/new/ \\  --onto  /test/old/ \\  --target-dir  /test/merged \\  --jar-file  /home/admin/Desktop/staff/EmpConn.jar \\  --class-name  Staff \\  --merge-key  id  结果：  1    AAA MALE  2    BBB MALE  3    CCC MALE  4    DDD MALE  6    DDD FEMALE')]),t._v(" "),e("p",[t._v("参数：")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("序号")])]),t._v(" "),e("th",[e("strong",[t._v("参数")])]),t._v(" "),e("th",[e("strong",[t._v("说明")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1")]),t._v(" "),e("td",[t._v("--new-data  "),e("code",[t._v("<path>")])]),t._v(" "),e("td",[t._v("HDFS  待合并的数据目录，合并后在新的数据集中保留")])]),t._v(" "),e("tr",[e("td",[t._v("2")]),t._v(" "),e("td",[t._v("--onto  "),e("code",[t._v("<path>")])]),t._v(" "),e("td",[t._v("HDFS合并后，重复的部分在新的数据集中被覆盖")])]),t._v(" "),e("tr",[e("td",[t._v("3")]),t._v(" "),e("td",[t._v("--merge-key  "),e("code",[t._v("<col>")])]),t._v(" "),e("td",[t._v("合并键，一般是主键ID")])]),t._v(" "),e("tr",[e("td",[t._v("4")]),t._v(" "),e("td",[t._v("--jar-file  "),e("code",[t._v("<file>")])]),t._v(" "),e("td",[t._v("合并时引入的jar包，该jar包是通过Codegen工具生成的jar包")])]),t._v(" "),e("tr",[e("td",[t._v("5")]),t._v(" "),e("td",[t._v("--class-name  "),e("code",[t._v("<class>")])]),t._v(" "),e("td",[t._v("对应的表名或对象名，该class类是包含在jar包中的")])]),t._v(" "),e("tr",[e("td",[t._v("6")]),t._v(" "),e("td",[t._v("--target-dir  "),e("code",[t._v("<path>")])]),t._v(" "),e("td",[t._v("合并后的数据在HDFS里存放的目录")])])])]),t._v(" "),e("h5",{attrs:{id:"_15、命令-参数-metastore"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_15、命令-参数-metastore"}},[t._v("#")]),t._v(" 15、命令&参数：metastore")]),t._v(" "),e("p",[t._v("记录了Sqoop job的元数据信息，如果不启动该服务，那么默认job元数据的存储目录为~/.sqoop，可在sqoop-site.xml中修改。")]),t._v(" "),e("p",[e("strong",[t._v("命令：")])]),t._v(" "),e("p",[t._v("如：启动sqoop的metastore服务")]),t._v(" "),e("p",[t._v("$ bin/sqoop metastore")]),t._v(" "),e("p",[e("strong",[t._v("参数：")])]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[e("strong",[t._v("序号")])]),t._v(" "),e("th",[e("strong",[t._v("参数")])]),t._v(" "),e("th",[e("strong",[t._v("说明")])])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("1")]),t._v(" "),e("td",[t._v("--shutdown")]),t._v(" "),e("td",[t._v("关闭metastore")])])])]),t._v(" "),e("hr"),t._v(" "),e("p",[t._v("["),e("a",{attrs:{href:"#_msoanchor_1"}},[t._v("a1]")]),t._v("使用sql语句来进行查找是不能加参数--table")]),t._v(" "),e("p",[t._v("并且必须要添加where条件，")]),t._v(" "),e("p",[t._v("并且where条件后面必须带一个$CONDITIONS 这个字符串，")]),t._v(" "),e("p",[t._v("并且这个sql语句必须用单引号，不能用双引号")])])}),[],!1,null,null,null);s.default=n.exports}}]);