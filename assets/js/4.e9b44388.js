(window.webpackJsonp=window.webpackJsonp||[]).push([[4],{1498:function(t,s,a){t.exports=a.p+"assets/img/image-20200414153227594.48c5d190.png"},1499:function(t,s,a){t.exports=a.p+"assets/img/image-20200414153247802.047676e1.png"},1500:function(t,s,a){t.exports=a.p+"assets/img/image-20200414153311063.9e358597.png"},1501:function(t,s,a){t.exports=a.p+"assets/img/image-20200414153331693.bb28a70b.png"},1502:function(t,s,a){t.exports=a.p+"assets/img/spark.62d0f0f0.png"},1503:function(t,s,a){t.exports=a.p+"assets/img/image-20200414175158839.c699e51e.png"},1504:function(t,s,a){t.exports=a.p+"assets/img/image-20200414172049366.4e524e62.png"},1505:function(t,s,a){t.exports=a.p+"assets/img/image-20200414172114655.4a6e7e96.png"},1506:function(t,s,a){t.exports=a.p+"assets/img/image-20200414172533211.519ada93.png"},1507:function(t,s,a){t.exports=a.p+"assets/img/image-20200414175405614.55fced14.png"},1508:function(t,s,a){t.exports=a.p+"assets/img/image-20200414175505390.021e8a4e.png"},1509:function(t,s,a){t.exports=a.p+"assets/img/image-20200414194201687.1cc47e96.png"},1510:function(t,s,a){t.exports=a.p+"assets/img/1568613632045.bf4edee5.png"},1511:function(t,s,a){t.exports=a.p+"assets/img/image-20200415130448439.1b2a2653.png"},1512:function(t,s,a){t.exports=a.p+"assets/img/image-20200415133258993.7ac58233.png"},1513:function(t,s,a){t.exports=a.p+"assets/img/image-20200415140940717.0dbe4c3f.png"},1514:function(t,s,a){t.exports=a.p+"assets/img/image-20200415141032695.3c38f9fe.png"},1515:function(t,s,a){t.exports=a.p+"assets/img/image-20200415141636967.592e7cbe.png"},1516:function(t,s,a){t.exports=a.p+"assets/img/image-20200415141443569.a6145eda.png"},1517:function(t,s,a){t.exports=a.p+"assets/img/image-20200415141529095.0c23b06a.png"},1518:function(t,s,a){t.exports=a.p+"assets/img/1628624-20190505161932608-1136050215.6e44701f.jpg"},1519:function(t,s,a){t.exports=a.p+"assets/img/image-20200415154218150.d5088665.png"},1520:function(t,s,a){t.exports=a.p+"assets/img/image-20200415154545940.d8e964cd.png"},1521:function(t,s,a){t.exports=a.p+"assets/img/image-20200415155327297.988fa4aa.png"},1522:function(t,s,a){t.exports=a.p+"assets/img/image-20200417025522744.3076c3d3.png"},1523:function(t,s,a){t.exports=a.p+"assets/img/image-20200415201224598.0d38e9a6.png"},1524:function(t,s,a){t.exports=a.p+"assets/img/image-20200415221704529.a5be946b.png"},1525:function(t,s,a){t.exports=a.p+"assets/img/1579070050537.fd0aa8ad.png"},1526:function(t,s,a){t.exports=a.p+"assets/img/image-20200416043037480.03bbf87b.png"},1527:function(t,s,a){t.exports=a.p+"assets/img/1579070153331.051eef8e.png"},1528:function(t,s,a){t.exports=a.p+"assets/img/1579070232110.bc07f573.png"},1529:function(t,s,a){t.exports=a.p+"assets/img/image-20200416123110870.c1348d79.png"},1530:function(t,s,a){t.exports=a.p+"assets/img/image-20200416162320980.1ca863cf.png"},1531:function(t,s,a){t.exports=a.p+"assets/img/image-20200416163718819.cf388296.png"},1532:function(t,s,a){t.exports=a.p+"assets/img/image-20200416164933460.54034453.png"},1533:function(t,s,a){t.exports=a.p+"assets/img/image-20200416173857717.52abff73.png"},1534:function(t,s,a){t.exports=a.p+"assets/img/image-20200416174244879.56d2cc16.png"},1535:function(t,s,a){t.exports=a.p+"assets/img/image-20200416174653942.6f404951.png"},1536:function(t,s,a){t.exports=a.p+"assets/img/image-20200416191119359.ade43fbe.png"},1537:function(t,s,a){t.exports=a.p+"assets/img/yarn-client.03504e03.png"},1538:function(t,s,a){t.exports=a.p+"assets/img/collect.4a1391ec.png"},1539:function(t,s,a){t.exports=a.p+"assets/img/image-20200416204239271.112e3ee6.png"},1540:function(t,s,a){t.exports=a.p+"assets/img/mapreduce_shuffle.3d01431e.png"},1541:function(t,s,a){t.exports=a.p+"assets/img/未优化的HashShuffle机制.1eb1d73a.png"},1542:function(t,s,a){t.exports=a.p+"assets/img/优化后的Shuffle机制.f34a54cc.png"},1543:function(t,s,a){t.exports=a.p+"assets/img/sortshuffle.15ced369.png"},1544:function(t,s,a){t.exports=a.p+"assets/img/bypasssortshuffle.88d96eac.png"},1545:function(t,s,a){t.exports=a.p+"assets/img/数据倾斜.5d19f795.png"},1546:function(t,s,a){t.exports=a.p+"assets/img/20170308091203159.7a7d9c14.png"},1547:function(t,s,a){t.exports=a.p+"assets/img/交互式用户行为分析系统.d04352a8.png"},1548:function(t,s,a){t.exports=a.p+"assets/img/1570609831990.def97e5b.png"},1549:function(t,s,a){t.exports=a.p+"assets/img/随机前缀和扩容RDD.5571274f.png"},1550:function(t,s,a){t.exports=a.p+"assets/img/image-20200417040624865.0bd02299.png"},1551:function(t,s,a){t.exports=a.p+"assets/img/image-20200417042221150.d7b48668.png"},1552:function(t,s,a){t.exports=a.p+"assets/img/image-20200417042533244.730e3426.png"},1553:function(t,s,a){t.exports=a.p+"assets/img/image-20200417094145627.4931f44d.png"},1554:function(t,s,a){t.exports=a.p+"assets/img/image-20200417094636520.31fd3f7e.png"},1555:function(t,s,a){t.exports=a.p+"assets/img/1569037915592-1587626129052.97721b45.png"},1556:function(t,s,a){t.exports=a.p+"assets/img/image-20200417095850150.ab100c62.png"},1557:function(t,s,a){t.exports=a.p+"assets/img/1569047954944-1587626129052.888773b9.png"},1558:function(t,s,a){t.exports=a.p+"assets/img/划分stage-1587626129053.5b48b0c3.png"},1559:function(t,s,a){t.exports=a.p+"assets/img/stage-1587626129053.63e187f2.png"},1560:function(t,s,a){t.exports=a.p+"assets/img/spark任务调度-1587626129053.491791f8.png"},1561:function(t,s,a){t.exports=a.p+"assets/img/spark-1586935313986-1587626129053.eccc2f18.png"},1562:function(t,s,a){t.exports=a.p+"assets/img/job-scheduler-running-1587626129053.77ef4167.png"},1563:function(t,s,a){t.exports=a.p+"assets/img/1569468946521.e3e03e4c.png"},1564:function(t,s,a){t.exports=a.p+"assets/img/1569469087993.c847658a.png"},1565:function(t,s,a){t.exports=a.p+"assets/img/1569469225309.8f8a01a4.png"},1566:function(t,s,a){t.exports=a.p+"assets/img/1569469413038.c62045f6.png"},1567:function(t,s,a){t.exports=a.p+"assets/img/1569469446641.7e4e3874.png"},1568:function(t,s,a){t.exports=a.p+"assets/img/1569492382924.48958415.png"},1569:function(t,s,a){t.exports=a.p+"assets/img/image-20200617193824609.fda16603.png"},1570:function(t,s,a){t.exports=a.p+"assets/img/image-20200417135339845.0d0a2222.png"},1571:function(t,s,a){t.exports=a.p+"assets/img/image-20200417140545035.afe16427.png"},1572:function(t,s){t.exports="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMEAAABJCAYAAACEoUIpAAAOZ0lEQVR4nO1db2wUxxX/7TnYZz5UxUkabByEIT3cNhgpxqmbkH4gSbFwqhgDUUvx9YPBX8D+YFshIok4lD8iyTlSwUiRCVXsFKSUgKGJI5PSKEoIpXWcyg5psBMwNQdGSXNEbYXvLnDbD7OzOzO398/nvV375vfl6d3bN7M7c7Mz783se4qqqiokJHIYLrtvQELCbshBIJHzkINAIudxi9mPY9+GURhSMelWJJV01tH5892JB8HYt2GE/ncTg19F4AqHEC1wSyrprKLrhUGgiN6hzwPXcenrCL4YCyHkBtyYRAiFcIcgecnPCn7rmrLUBsGnEyG9AGASMKFSLuUzUd62Zj5YxDWM2RFECwQK4Q7xFcTIkUQu9aW+7fo8Es4E8UaYpJLOZJr6TBAzgiQv+dnC85AzgaQ5R9OyCcgI0mjcESblUj7T5DzkTJCEKuoouh+pwTCAal8A66vyHHFfkmZjJnDUGs46fnRPMdprF6O9NpY+3tYNXBvS2+TKpfGs3M+eo1cd0z6zk+ch9wmE3xV1FB+21eDYCHnzb1hxlswENT3wN6/Ur3MNPI1W30EAG9H01m54XHMyrn90TzG6TpB+WLT1NNrXzHdc+8wGuTgTmJ4dAsSdNqPAGCrKTfjw9cPobtiO4ZoedDavTFs/0/rT0U8Mcl04eBiv+Q7ClV+JuyOHMDz4Iiqq+PKuHavFc/s/SVJeLKp9AVQF6rDvLydwZc0WlGT5+UVeUYf05SCFK78Sj3b24v4F/PXhoNbP7LXlO/FExxaU2HT/Zvoi4g4COoJCbo0iDhXlGh9WR3FKe6OalptEP9P6p6qfGOS5uhu246z+R5hjWt68uj7466ayZs0Dqv6IF9fa8/wsrwR79Gdd29mL+xfcwLVj6/Hc/kEc37YWYJ7fGABkZlyq/JPMqOd2YXcb8ETHFhRl+f7j6/OwzCYoCC/Hypcn0Nl3Ac2bVxjlTrE8K/nRPYYt0PaIMHAZm8Awkjdi8xHyB3DC/VvFj/yBvNVLG/biwVvnAChE0aPPo24pEI0MYvBvAf364AdvkBmgpgYe1xwUhJfjgadeQAUAXHgbn1+O2v48Bs8j7iAIuQF+RE2d/54SNcqdhvKmnyeo9gXQ8XY/6pYCwEZUVEaBectJQ733O30AsDaAM+7fKp5g/PKXulxVluMHi8jvebgeO4P292M0+h2nH40sxe3FTniedGcCfQQZRob5CEsu/49qVOMMP7HBK+oQvrpI1rnFJVFmBntW+6PTjhzEt42n0XmkAx4XmQEUdRSnWjVvjk33b61cg/bHZtsLAO64s1zXL657E/6+Cb19FHUIHz67XXMtv4gK1w0HPR+P9G2CKfDcTBAzQjMvPxMeAC6MAFGQt1XIBSjqEE6a2DPjB+7DtgMmjTVyH/zu09i2Zv6U7kcJ9qCLGpSaF8oJ7eNpuQB/C20nMvMpH7+OYyPE4F1VFWvjha8fRs86wzgmeysRRzyPwfOI7x1K1+pOwHMzwTSUN5188PgOrcMOoeuXh7g2qPYFsGHJQWIclu/E1pV92PuqB01v7UZFZA7o+fSR3sew9/yXAMq48iOfUjdqKtiIl30KWn1evFkdwKZlzmgflg8XjOI1zS28+aVGFCEv5vqCog3w9nnJTNBWg2O+Uvxd8xAVwRnPIyIr+wS6u7CmB/7mh9PWz6Zc9/9r7tywZgyfLd+Jl56ci+6G7fhv40lsrf+JI+/fKjnrFKA2UTJ96l0ydtsjjng+m74nYMp1xHny+HIWMUbUvOVYvBQYO/B7YvzZcP+ugXayo733z1mrP9EASKSvFnlRvZo03Zkz72Wl/1LT5xHfOwS6hgISr7EEuUjdQrlT0s+0/tT1v7n8OQBg0ZK7QN4cBr5R7sbPf/0bAIfQte/9rN+/EuzRliMA+r3Yd/Qzy+sPFwyl5BUb1tzMLW3dCOIm8wZmYX3/pabPIytnh0SbINPyrOS/Hie7vFGNZ/cJAEBd0UBcqP3eJF4hC3jNXUtxE3MtrY8eIRFnAOoVa997Suepx4j9/yjqKM5ox0AWLrjLEf1rZhNkZZ8gfOljUtnF87iC/Bj5tWO12LauGO21xfC/czXj+qbKs+6/kjsXApiM+eON7K3Bn8YqUQHiLZru+w1rf7CWJ1/h3qghN6AqHvxW28dw5Vei8qellrYHfda1XfwMQD1EZQtKEEIhVMWjzZBA9NwX+Hc0qusTp8NG1NSVZr0/4/M84kebmLimrakmTaxs1mYwl+vegZGYOsEeOnOHJjkvinHWJJJR/VOR061/9kiEeHaG3t9tA9s5z8/CxtNoqS/jjMHMEbsGp04GWp9V7WN2ZkhEtS+ATcsiun5kINYbFtuf1vVfqvKt9bxh7JjvCVivDHta02rKnhrVwXixXGzHCt4t10A7Wn0qmjeP6q5Ts9Ok00XpACjTvFPZ7J/ZREXvkGPiDtFjxPTDFavrE3nXQDvanz+nzwCsfKT3Mew7VZvkjSb5mcI7Lu5QWDi/z365lY36pTz35JnvEwgVJLLCU9FnT5vSGSAd/Uzrl/q5qM/DMTaBpJJmi8pvjCUveQFyJpA052hS7xAAXL0aAgDb48hLKmk28hOYDgIJiVyCTNckkfOIm6nmM5mpRtJZStff833uP5/C2aE0z2qIVOpLfYfpb61PY8fYbiteUkmz4R2S+wSSz0Geh5wJJM05KvMTSLmUC5AzgaQ5R6VNkCZv5C9ow2j0lpT1SVSIp/TIbenVx+g5rD1mB8/D9u8JnC4f3rOY+diHj5tDP6Wca5LBxmXyqWFaYMLYO7l9ZqLclvwETtZPNY/AGV8pzsQT+koBXwDrq4z6dGifZLqhRap79WMsbDyNx+vn6wOM8twHRtWrEEKe49tvJuqLsCw/QQhCjE0NbIKHZPqZ1p+Kfrw8AiQOvzA4hG+MKR3dU4x3vx4HYMQi5UHqozFZjWjO4Hglphesf/60Y6XSfqShFd15Rn+rQzi5I15wBTqbZv/+Y/V4WGYTcAkeusbReWQCT265B9EISfDw0WXnrnmV4GG8pYWNbFpNBm7z5hV6wCvxek/LBNpXlXHl8SDX05hGNzGX81KIPKdnc3sowR606ck3xvXQ9dFzu7C7bT+CuMlcT4IbV/sC6DwyQaJU913QolVPkC8HHdC/IiyLO0QTPCzcshf3L7iBkBtcgod/DAUyKt8qXs9EU74TO5pX6e0RuPcomlYDYwceIiEQk5THg8oJ8nA9Ic/p2dwewQ/eILdSUwOP6wZUxSz5hnY9E6jMKf1pzvOwbJ+A4uL5L3U5m+CBRnhzkh9ZCR4mwXfzK/FoK4m6DJBBO3HFBU/LBJpWA+j3or22GJ3vXE36/AT8G+iOO8s53ogkJ8L+9tHR30+8Y8yMZSTf0K5nApXZ0X+py3mkEItUXGNB4M3lfON9p68ZxQhvUy1/uuWRgafRps0AT/Qe1wNvfXURQE0P4/0h62EAuLjvPmxbJ8TgFJ8fhA9roQppMhAzmyAW9rfPvLo++PsuwN/XAY/rBsIFfPINLjYpOxNkuf/Sk/OwLD9BRdME/C3Uy0Ti+EQ+5RM80BE6JSt/GnnqpSlrPInlpx7C87W7+MYY8aK932Bd+W9jbdc4fjxQh+f2f6JFYstDCIZXjQfh2WQgZjZBuEDsBWe0D3VysJH19PhQzPVhAGfzKxEVPGlctksHPE/Kg4A9fmo+ogrTkocLRtEdJ8HDdJQ/FTnr9dD3AeonsBLGFEqvZyPkbVa9eHcogAfr3oS/ztxrwWNSf0u6yn+I21wuU5tAEb7xs7t9WLla5IW3b4MRsY9LvqG153Xg7sig3p6bqiJ6aEYj26U998/LeWQlP8FU49tPV/3x9NUiL5o0L8YmbSNM1Kf5APTEHVtWEm+Qlmg7Xv08CnVHwb2/2qK/ACjGLl8xfUNZ/fxT0S8Ie/BARz8qQDxE7w0YcrXIiybNG7RJS9GUv8yPptXEruo9+r7t929LfoJU49vH08+0/kz11SUVqABZwu1oXsXpK8EedK0rxuNtrxjRtk1mAiXYgzMn2GUgua78ZySSM/q92GaWPtYBz2+mryoeIflGYv3bF95j/K8ccP8iLM1ZFi5IPAPYucalPI2BmhTndsXaCoyMJqwu0RucwHXxPLobdhGDW4xlWuVHZ98zTHuJkbyd0z5iZnoe5PrhrsVaW9L+JuU5LWddyoMg+QhMzIcLYhM8AEym+zJnZGn0tEzA30KXMLFUoeHa9fVvnul1lIozQfTcLtIGLzWiCImzOIo2gR3twd/PUEzyDToD0uQbNKNPuIBJ1KEl9Kb9felDkp+C5jOws79jB7CF+wRiggcqpwke9MwloUn8q/cxPaP8nqNjKZWfLXlMu6S5T+Iq34kdfanm8RVhyK8dq9VOs4p5k617flVZHpN8wx0yMt0DG/GLmlIAhShgEnW4Lp7Xd5KDx3doM9tGPFznceQ+gSV5jOmbIopB9DYtRK9J+ew+QVnpUgDkbRH46ASC9STdp/1vjEko54cxDONtkeoMSRFNtIxKCqO8Wxf8CMAnehtdqTe8MlY+f7TKj5d9QKvvIJfi1iXMjCEUAlXPoOP1CnQ3bBeema4GbiDkFm1CO/qXhzU2QZEXTUe8SBovXhuhIaaho4uWEO+JjWtGmrHGLEtLquWJf5aSUF7S9khkE+Qv49uIlJel9qnyo/OI36T/YtuD5jE27W+3M2xCEQnPDhkdOmnyBpxe+bm/krP31dWrLCk/HblatAHevgl0vP6C7hkib71IyuUD2iZRq2YLpFS/MXBWVcXK2Tays31mvpxH+nGHRGo64hPwAmVzm+k7r2noZ1r/TNBnZwiznVqn37/T9NPKVEPeaIWSSjqrqPzGWPKSFyBnAklzjsq4Q1Iu5QLkTCBpztGUMtVISOQSZJIOiZyHHAQSOY//A3YxnFsLKxlrAAAAAElFTkSuQmCC"},1573:function(t,s){t.exports="data:image/png;base64,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"},1574:function(t,s,a){t.exports=a.p+"assets/img/image-20200417205422106.7a106f98.png"},1575:function(t,s,a){t.exports=a.p+"assets/img/image-20200418031619386.f8379fc2.png"},1576:function(t,s,a){t.exports=a.p+"assets/img/image-20200418031038117.a119cf76.png"},1577:function(t,s){t.exports="data:image/png;base64,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"},1578:function(t,s,a){t.exports=a.p+"assets/img/image-20200418173539916.9109aadf.png"},1579:function(t,s,a){t.exports=a.p+"assets/img/image-20200419011931846.5c4a6ac9.png"},1580:function(t,s,a){t.exports=a.p+"assets/img/image-20200419015002531.abcb9b26.png"},1581:function(t,s,a){t.exports=a.p+"assets/img/image-20200416204239271-1587626129053.112e3ee6.png"},1582:function(t,s,a){t.exports=a.p+"assets/img/spark性能优化--分配资源.5ebf8ac5.png"},1583:function(t,s,a){t.exports=a.p+"assets/img/rdd重用1.6fec577d.png"},1584:function(t,s,a){t.exports=a.p+"assets/img/rdd重用2.3d1ba6e5.png"},1585:function(t,s,a){t.exports=a.p+"assets/img/task共享数据.eee3133d.png"},1586:function(t,s,a){t.exports=a.p+"assets/img/广播变量.cfe386bf.png"},1587:function(t,s,a){t.exports=a.p+"assets/img/image-20200419135700724.7db21c1d.png"},1588:function(t,s,a){t.exports=a.p+"assets/img/groupByKey.5fdbbc1a.png"},1589:function(t,s,a){t.exports=a.p+"assets/img/reduceByKey.a735f59c.png"},1590:function(t,s,a){t.exports=a.p+"assets/img/image-20200419142802894.bfe41e9c.png"},1591:function(t,s,a){t.exports=a.p+"assets/img/1570604272790.f2118621.png"},1592:function(t,s,a){t.exports=a.p+"assets/img/image2018-11-1_16-39-33.be97fbc3.png"},1593:function(t,s,a){t.exports=a.p+"assets/img/1570604662552.ae2833ff.png"},1594:function(t,s,a){t.exports=a.p+"assets/img/1570604675176.71e159e5.png"},1595:function(t,s,a){t.exports=a.p+"assets/img/1565872653413.873c5f50.png"},1596:function(t,s,a){t.exports=a.p+"assets/img/1565872766577.a48d73d7.png"},2020:function(t,s,a){"use strict";a.r(s);var n=a(17),r=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("p",[t._v("课前准备")]),t._v(" "),n("p",[t._v("安装好对应版本的hadoop集群")]),t._v(" "),n("p",[t._v("安装好对应版本的zookeeper集群")]),t._v(" "),n("h2",{attrs:{id:"课堂主题"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#课堂主题"}},[t._v("#")]),t._v(" 课堂主题")]),t._v(" "),n("p",[t._v("本堂课主要围绕 "),n("strong",[t._v("spark的基础知识点")]),t._v(" 进行讲解。主要包括以下几个方面")]),t._v(" "),n("ol",[n("li",[t._v("spark核心概念")]),t._v(" "),n("li",[t._v("spark集群架构")]),t._v(" "),n("li",[t._v("spark集群安装部署")]),t._v(" "),n("li",[t._v("spark-shell的使用")]),t._v(" "),n("li",[t._v("通过IDEA开发spark程序")]),t._v(" "),n("li",[t._v("RDD弹性分布式数据集的概念")]),t._v(" "),n("li",[t._v("RDD弹性分布式数据集的五大属性")]),t._v(" "),n("li",[t._v("RDD弹性分布式数据集的算子操作分类")]),t._v(" "),n("li",[t._v("RDD弹性分布式数据集的算子操作练习")]),t._v(" "),n("li",[t._v("RDD弹性分布式数据集的依赖关系")]),t._v(" "),n("li",[t._v("RDD弹性分布式数据集的lineage血统机制")]),t._v(" "),n("li",[t._v("RDD弹性分布式数据集的缓存机制")]),t._v(" "),n("li",[t._v("spark任务的DAG有向无环图的构建")]),t._v(" "),n("li",[t._v("spark任务如何划分stage")]),t._v(" "),n("li",[t._v("spark的任务调度流程")]),t._v(" "),n("li",[t._v("spark的运行架构")]),t._v(" "),n("li",[t._v("基于wordcount程序剖析spark任务提交、划分、调度流程")])]),t._v(" "),n("h2",{attrs:{id:"spark是什么"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark是什么"}},[t._v("#")]),t._v(" spark是什么")]),t._v(" "),n("p",[t._v('"Apache Spark" is a unified analytics engine for large-scale data processing.')]),t._v(" "),n("p",[t._v("spark是针对于大规模数据处理的统一分析引擎")]),t._v(" "),n("p",[t._v("spark是在Hadoop基础上的改进，是UC Berkeley AMP lab所开源的类Hadoop MapReduce的通用的并行计算框架，Spark基于map reduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。")]),t._v(" "),n("p",[t._v("spark是基于内存计算框架，计算速度非常之快，但是它仅仅只是涉及到计算，并没有涉及到数据的存储，后期需要使用spark对接外部的数据源，比如hdfs。")]),t._v(" "),n("p",[t._v("注意：spark只做计算不做存储")]),t._v(" "),n("h2",{attrs:{id:"spark的四大特性"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark的四大特性"}},[t._v("#")]),t._v(" spark的四大特性")]),t._v(" "),n("p",[t._v("查看官网可以了解spark的四大特性，spark官网地址：http://spark.apache.org/")]),t._v(" "),n("h4",{attrs:{id:"速度快"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#速度快"}},[t._v("#")]),t._v(" 速度快")]),t._v(" "),n("p",[t._v("spark运行速度相对于hadoop提高100倍,见下图：")]),t._v(" "),n("p",[t._v("Apache Spark使用最先进的DAG调度程序，查询优化程序和物理执行引擎，实现批量和流式数据的高性能。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1498),alt:"image-20200414153227594"}})]),t._v(" "),n("h5",{attrs:{id:"spark比mr快的2个主要原因-面试题"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark比mr快的2个主要原因-面试题"}},[t._v("#")]),t._v(" spark比MR快的2个主要原因（面试题）")]),t._v(" "),n("h6",{attrs:{id:"_1、基于内存"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1、基于内存"}},[t._v("#")]),t._v(" 1、基于内存")]),t._v(" "),n("p",[t._v("mapreduce任务后期再计算的时候，每一个job的输出结果会落地到磁盘，后续有其他的job需要依赖于前面job的输出结果，这个时候就需要进行大量的磁盘io操作。性能就比较低。")]),t._v(" "),n("p",[t._v("spark任务后期再计算的时候，job的输出结果可以保存在内存中，后续有其他的job需要依赖于前面job的输出结果，这个时候就直接从内存中获取得到，避免了磁盘io操作，性能比较高")]),t._v(" "),n("p",[t._v("对于spark程序和mapreduce程序都会产生shuffle阶段，在shuffle阶段中它们产生的数据都会落地到磁盘。")]),t._v(" "),n("h6",{attrs:{id:"_2、进程与线程"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2、进程与线程"}},[t._v("#")]),t._v(" 2、进程与线程")]),t._v(" "),n("p",[t._v("mapreduce任务以进程的方式运行在yarn集群中，比如程序中有100个MapTask，一个task就需要一个进程，这些task要运行就需要开启100个进程。")]),t._v(" "),n("p",[t._v("spark任务以线程的方式运行在进程中，比如程序中有100个MapTask，后期一个task就对应一个线程，这里就不再是进程，这些task需要运行，这里可以极端一点：只需要开启1个进程，在这个进程中启动100个线程就可以了。")]),t._v(" "),n("p",[t._v("进程中可以启动很多个线程，而开启一个进程与开启一个线程需要的时间和调度代价是不一样。 开启一个进程需要的时间远远大于开启一个线程。")]),t._v(" "),n("h4",{attrs:{id:"易用性"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#易用性"}},[t._v("#")]),t._v(" 易用性")]),t._v(" "),n("p",[t._v("可以通过 java/scala/python/R/SQL等不同语言快速去编写spark程序")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1499),alt:"image-20200414153247802"}})]),t._v(" "),n("h4",{attrs:{id:"通用性"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#通用性"}},[t._v("#")]),t._v(" 通用性")]),t._v(" "),n("p",[t._v("spark框架不在是一个简单的框架，可以把spark理解成一个spark生态系统，它内部是包含了很多模块，基于不同的应用场景可以选择对应的模块去使用，见下图：")]),t._v(" "),n("ol",[n("li",[t._v("sparksql：通过sql去开发spark程序做一些离线分析")]),t._v(" "),n("li",[t._v("sparkStreaming：主要是用来解决公司有实时计算的这种场景")]),t._v(" "),n("li",[t._v("Mlib：它封装了一些机器学习的算法库")]),t._v(" "),n("li",[t._v("Graphx：图计算")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(1500),alt:"image-20200414153311063"}})]),t._v(" "),n("h4",{attrs:{id:"兼容性"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#兼容性"}},[t._v("#")]),t._v(" 兼容性")]),t._v(" "),n("p",[t._v("spark程序就是一个计算逻辑程序，这个任务要运行就需要计算资源（内存、cpu、磁盘），哪里可以给当前这个任务提供计算资源，就可以把spark程序提交到哪里去运行。")]),t._v(" "),n("p",[t._v("目前主要的运行方式是下面的standAlone和yarn。")]),t._v(" "),n("p",[t._v("**standAlone：**它是spark自带的独立运行模式，整个任务的资源分配由spark集群的老大Master负责")]),t._v(" "),n("p",[t._v("**yarn：**可以把spark程序提交到yarn中运行，整个任务的资源分配由yarn中的老大ResourceManager负责")]),t._v(" "),n("p",[t._v("mesos：它也是apache开源的一个类似于yarn的资源调度平台")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1501),alt:"image-20200414153331693"}})]),t._v(" "),n("h2",{attrs:{id:"spark集群架构-重要"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark集群架构-重要"}},[t._v("#")]),t._v(" spark集群架构（重要）")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1502),alt:"spark"}})]),t._v(" "),n("ul",[n("li",[t._v("Driver：执行客户端写好的main方法，它会构建一个名叫SparkContext对象，该对象是所有spark程序的执行入口")]),t._v(" "),n("li",[t._v("Application：就是一个spark的应用程序，它是包含了客户端的代码和任务运行的资源信息")]),t._v(" "),n("li",[t._v("ClusterManager：给程序提供计算资源的外部服务,在不同的运行平台，ClusterManager也不同，主要有以下3种：\n"),n("ul",[n("li",[t._v("standAlone：它是spark自带的集群模式，整个任务的资源分配由spark集群的老大Master负责")]),t._v(" "),n("li",[t._v("yarn：可以把spark程序提交到yarn中运行，整个任务的资源分配由yarn中的老大ResourceManager负责")]),t._v(" "),n("li",[t._v("mesos：它也是apache开源的一个类似于yarn的资源调度平台。")])])]),t._v(" "),n("li",[t._v("Master：它是整个spark集群的主节点，负责任务资源的分配")]),t._v(" "),n("li",[t._v("Worker：它是整个spark集群的从节点，负责任务计算的节点")]),t._v(" "),n("li",[t._v("Executor：它是一个进程，它会在worker节点启动该进程（计算资源），一个worker节点可以有多个Executor进程")]),t._v(" "),n("li",[t._v("Task：spark任务是以task线程的方式运行在worker节点对应的executor进程中")])]),t._v(" "),n("h2",{attrs:{id:"spark集群安装部署"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark集群安装部署"}},[t._v("#")]),t._v(" spark集群安装部署")]),t._v(" "),n("p",[t._v("搭建spark集群要事先搭建好zookeeper集群，spark会依赖zookeeper集群来实现Master的高可用。")]),t._v(" "),n("h4",{attrs:{id:"第一步-下载安装包"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第一步-下载安装包"}},[t._v("#")]),t._v(" 第一步：下载安装包")]),t._v(" "),n("p",[t._v("下载安装包：spark-2.3.3-bin-hadoop2.7.tgz")]),t._v(" "),n("p",[t._v("下载地址：")]),t._v(" "),n("p",[t._v("https://archive.apache.org/dist/spark/spark-2.3.3/spark-2.3.3-bin-hadoop2.7.tgz")]),t._v(" "),n("h4",{attrs:{id:"第二步-解压安装包"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第二步-解压安装包"}},[t._v("#")]),t._v(" 第二步：解压安装包")]),t._v(" "),n("p",[t._v("上传安装包到node01,解压，修改名称：")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("cd")]),t._v(" /kkb/soft\nrz\n\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("tar")]),t._v(" -zxvf /kkb/soft/spark-2.3.3-bin-hadoop2.7.tgz -C /kkb/install/\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("cd")]),t._v(" /kkb/install\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mv")]),t._v(" spark-2.3.3-bin-hadoop2.7 spark\n")])])]),n("h4",{attrs:{id:"第三步-修改配置文件"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第三步-修改配置文件"}},[t._v("#")]),t._v(" 第三步：修改配置文件")]),t._v(" "),n("p",[t._v("进入到spark的安装目录下对应的conf文件夹")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("cd")]),t._v(" /kkb/install/spark/conf\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mv")]),t._v(" spark-env.sh.template spark-env.sh\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("vim")]),t._v(" spark-env.sh\n")])])]),n("p",[t._v("添加下面内容")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#配置java的环境变量")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("JAVA_HOME")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/kkb/install/jdk1.8.0_141\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#配置zk相关信息")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("SPARK_DAEMON_JAVA_OPTS")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"-Dspark.deploy.recoveryMode=ZOOKEEPER  -Dspark.deploy.zookeeper.url=node01:2181,node02:2181,node03:2181  -Dspark.deploy.zookeeper.dir=/spark"')]),t._v("\n")])])]),n("p",[t._v("说明：")]),t._v(" "),n("ol",[n("li",[t._v("-Dspark.deploy.recoveryMode=ZOOKEEPER 指定spark的恢复模式为ZOOKEEPER")]),t._v(" "),n("li",[t._v("-Dspark.deploy.zookeeper.url=node01:2181,node02:2181,node03:2181指定zookeeper集群的地址")]),t._v(" "),n("li",[t._v('-Dspark.deploy.zookeeper.dir=/spark" 指定spark在zookeeper中创建的节点（文件），随便设置一个名字即可')])]),t._v(" "),n("p",[t._v("设定spark的从节点：")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mv")]),t._v(" slaves.template slaves\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("vim")]),t._v(" slaves \n")])])]),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#指定spark集群的worker节点")]),t._v("\nnode02\nnode03\n")])])]),n("h4",{attrs:{id:"第四步-分发安装目录到其他机器"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第四步-分发安装目录到其他机器"}},[t._v("#")]),t._v(" 第四步：分发安装目录到其他机器")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[n("span",{pre:!0,attrs:{class:"token function"}},[t._v("scp")]),t._v(" -r /kkb/install/spark node02:/kkb/install\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("scp")]),t._v(" -r /kkb/install/spark node03:/kkb/install\n")])])]),n("h4",{attrs:{id:"第五步-修改spark环境变量"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第五步-修改spark环境变量"}},[t._v("#")]),t._v(" 第五步：修改spark环境变量")]),t._v(" "),n("p",[t._v("所有节点修改/etc/profile")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("sudo vim /etc/profile\n")])])]),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("SPARK_HOME")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/kkb/install/spark\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[n("span",{pre:!0,attrs:{class:"token environment constant"}},[t._v("PATH")])]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token environment constant"}},[t._v("$PATH")]),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$SPARK_HOME")]),t._v("/bin:"),n("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$SPARK_HOME")]),t._v("/sbin\n")])])]),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("source /etc/profile\n")])])]),n("h2",{attrs:{id:"spark集群的启动和停止"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark集群的启动和停止"}},[t._v("#")]),t._v(" spark集群的启动和停止")]),t._v(" "),n("p",[t._v("必须先启动zookeeper集群")]),t._v(" "),n("h4",{attrs:{id:"启动spark"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#启动spark"}},[t._v("#")]),t._v(" 启动spark")]),t._v(" "),n("p",[t._v("在任意一台服务器来执行下列脚本（条件：需要任意2台机器之间实现ssh免密登录），")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$SPARK_HOME")]),t._v("/sbin/start-all.sh\n")])])]),n("p",[t._v("在哪里启动这个脚本，就会在当前该机器启动一个Master进程，整个集群的worker进程的启动由slaves文件决定")]),t._v(" "),n("p",[t._v("后期可以在其他机器单独在启动master,实现高可用：")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$SPARK_HOME")]),t._v("/sbin/start-master.sh\n")])])]),n("p",[t._v("验证是否成功开启：")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node01 conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ xcall jps\n************"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node01 jps ************"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7892")]),t._v(" Jps\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7610")]),t._v(" QuorumPeerMain\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7739")]),t._v(" Master\n************"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node02 jps ************"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7857")]),t._v(" Master\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7941")]),t._v(" Jps\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7751")]),t._v(" Worker\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7611")]),t._v(" QuorumPeerMain\n************"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node03 jps ************"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7921")]),t._v(" Jps\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7802")]),t._v(" Worker\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7643")]),t._v(" QuorumPeerMain\n")])])]),n("h4",{attrs:{id:"停止spark"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#停止spark"}},[t._v("#")]),t._v(" 停止spark")]),t._v(" "),n("p",[t._v("在处于active Master主节点执行")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("$SPARK_HOME/sbin/stop-all.sh\n")])])]),n("p",[t._v("在处于standBy Master主节点执行")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("$SPARK_HOME/sbin/stop-master.sh\n")])])]),n("h2",{attrs:{id:"spark高可用思考问题"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark高可用思考问题"}},[t._v("#")]),t._v(" spark高可用思考问题")]),t._v(" "),n("p",[t._v("问题思考：")]),t._v(" "),n("p",[t._v("1、如何恢复到上一次活着master挂掉之前的状态?")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("在高可用模式下，整个spark集群就有很多个master，其中只有一个master被zk选举成活着的master，其他的多个master都处于standby，同时把整个spark集群的元数据信息通过zk中节点进行保存。\n\n后期如果活着的master挂掉。首先zk会感知到活着的master挂掉，下面开始在多个处于standby中的master进行选举，再次产生一个活着的master，这个活着的master会读取保存在zk节点中的spark集群元数据信息，恢复到上一次master的状态。整个过程在恢复的时候经历过了很多个不同的阶段，每个阶段都需要一定时间，最终恢复到上个活着的master的状态，整个恢复过程一般需要1-2分钟。\n")])])]),n("p",[t._v("2、在master的恢复阶段对任务的影响?")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("a）对已经运行的任务是没有任何影响\n   由于该任务正在运行，说明它已经拿到了计算资源，这个时候就不需要master。\n   \t  \nb) 对即将要提交的任务是有影响\n  由于该任务需要有计算资源，这个时候会找活着的master去申请计算资源，由于没有一个活着的master,该任务是获取不到计算资源，也就是任务无法运行。\n")])])]),n("p",[n("img",{attrs:{src:a(1503),alt:"image-20200414175158839"}})]),t._v(" "),n("h2",{attrs:{id:"spark集群的web管理界面"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark集群的web管理界面"}},[t._v("#")]),t._v(" spark集群的web管理界面")]),t._v(" "),n("p",[t._v("当启动好spark集群之后，可以访问这样一个地址：http://...:8080")]),t._v(" "),n("p",[t._v("比如说，如果node01/node02都启动了Master,则可以访问地址：http://node01:8080和http://node02:8080")]),t._v(" "),n("p",[t._v("可以通过这个web界面观察到很多信息")]),t._v(" "),n("ul",[n("li",[t._v("整个spark集群的详细信息")]),t._v(" "),n("li",[t._v("整个spark集群总的资源信息")]),t._v(" "),n("li",[t._v("整个spark集群已经使用的资源信息")]),t._v(" "),n("li",[t._v("整个spark集群还剩的资源信息")]),t._v(" "),n("li",[t._v("整个spark集群正在运行的任务信息")]),t._v(" "),n("li",[t._v("整个spark集群已经完成的任务信息")])]),t._v(" "),n("p",[t._v("node01：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1504),alt:"image-20200414172049366"}})]),t._v(" "),n("p",[t._v("node02:")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1505),alt:"image-20200414172114655"}})]),t._v(" "),n("p",[t._v("整个spark集群的计算资源是把所有worker节点的资源进行累加，下面是老师的截图：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1506),alt:"image-20200414172533211"}})]),t._v(" "),n("h2",{attrs:{id:"初识spark程序"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#初识spark程序"}},[t._v("#")]),t._v(" 初识spark程序")]),t._v(" "),n("h4",{attrs:{id:"普通模式提交-指定活着的master地址"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#普通模式提交-指定活着的master地址"}},[t._v("#")]),t._v(" 普通模式提交 (指定活着的master地址)")]),t._v(" "),n("p",[t._v("指定的必须是alive状态的Master地址，否则会执行失败。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("cd /kkb/install/spark\n")])])]),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("bin/spark-submit "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--class org.apache.spark.examples.SparkPi "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--master spark://node01:7077 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--executor-memory 1G "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--total-executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\nexamples/jars/spark-examples_2.11-2.3.3.jar "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("####参数说明")]),t._v("\n--class：指定包含main方法的主类\n--master：指定spark集群master地址\n--executor-memory：指定任务在运行的时候需要的每一个executor内存大小\n--total-executor-cores： 指定任务在运行的时候需要总的cpu核数\nexamples/jars/spark-examples_2.11-2.3.3.jar :是spark程序打包成的jar包,spark提供的计算圆周率的测试包\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" ：spark程序要用到的参数\n")])])]),n("p",[t._v("运行结果查看：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1507),alt:"image-20200414175405614"}})]),t._v(" "),n("p",[n("img",{attrs:{src:a(1508),alt:"image-20200414175505390"}})]),t._v(" "),n("h4",{attrs:{id:"高可用模式提交-集群有很多个master"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#高可用模式提交-集群有很多个master"}},[t._v("#")]),t._v(" 高可用模式提交 (集群有很多个master）")]),t._v(" "),n("p",[t._v("当Master有多个的时候，上面的提交方式就显得很麻烦了，因为要找到alive状态的Master很费时间。")]),t._v(" "),n("p",[t._v("企业中，一般都是固定几台机器来启动Master,然后使用高可用模式提交，这个模式会"),n("strong",[t._v("轮询")]),t._v("尝试连接Master列表中的Master,连接成功了就将spark程序提交上去。")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("bin/spark-submit "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--class org.apache.spark.examples.SparkPi "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--master spark://node01:7077,node02:7077,node03:7077 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--executor-memory 1G "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--total-executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\nexamples/jars/spark-examples_2.11-2.3.3.jar "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("\n\nspark集群中有很多个master，并不知道哪一个master是活着的master，即使你知道哪一个master是活着的master，它也有可能下一秒就挂掉，这里就可以把所有master都罗列出来\n--master spark://node01:7077,node02:7077,node03:7077\n\n后期程序会轮训整个master列表，最终找到活着的master，然后向它申请计算资源，最后运行程序。\n")])])]),n("h2",{attrs:{id:"spark-shell使用"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark-shell使用"}},[t._v("#")]),t._v(" spark-shell使用")]),t._v(" "),n("h4",{attrs:{id:"运行spark-shell-master-local-n-读取本地文件"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#运行spark-shell-master-local-n-读取本地文件"}},[t._v("#")]),t._v(" 运行spark-shell --master local[N] 读取本地文件")]),t._v(" "),n("p",[t._v("选项说明：")]),t._v(" "),n("ul",[n("li",[t._v("local 表示程序在本地进行计算，跟spark集群目前没有任何关系")]),t._v(" "),n("li",[t._v("N  它是一个正整数，表示使用N个线程参与任务计算")]),t._v(" "),n("li",[t._v("local[N] 表示本地采用N个线程计算任务")])]),t._v(" "),n("p",[t._v("spark-shell --master local[2]")]),t._v(" "),n("ul",[n("li",[t._v("默认会产生一个SparkSubmit进程")])]),t._v(" "),n("p",[t._v("示例： 读取本地文件进行单词统计")]),t._v(" "),n("h6",{attrs:{id:"第一步-创建文件"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第一步-创建文件"}},[t._v("#")]),t._v(" 第一步：创建文件")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node01 ~"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ "),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("cd")]),t._v(" /tmp\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node01 tmp"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("vi")]),t._v(" words.txt\nhadoop spark spark\nflume flink hadoop hadoop\n")])])]),n("h6",{attrs:{id:"第二步-开启spark-shell"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第二步-开启spark-shell"}},[t._v("#")]),t._v(" 第二步：开启spark-shell")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@node01")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("~")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ spark"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("shell "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v("master local"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("00")]),t._v(" WARN  NativeCodeLoader"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("62")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" Unable to "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("load")]),t._v(" native"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("hadoop library "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" your platform"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" using builtin"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("java classes where applicable\nSetting default log level to "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"WARN"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\nTo adjust logging level use sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" For SparkR"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" use setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\nSpark context Web UI available at http"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("node01"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4040")]),t._v("\nSpark context available as "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sc'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("master "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" local"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" app id "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" local"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1586859312537")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\nSpark session available as "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'spark'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\nWelcome to\n      ____              __\n     "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" __"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("__  ___ _____"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("__\n    _\\ \\"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" _ \\"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" _ `"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" __"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token symbol"}},[t._v("'_")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\n   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("___"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\\_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\\_\\   version "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.3")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".3")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\n         \nUsing Scala version "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2.11")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".8")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Java HotSpot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("TM"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("Bit Server VM"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Java "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.8")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".0")]),t._v("_141"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nType in expressions to "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("have")]),t._v(" them evaluated"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\nType "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("help "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" more information"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" \n")])])]),n("p",[t._v("说明：")]),t._v(" "),n("ol",[n("li",[t._v("Spark context available as 'sc'，启动spark shell的时候，Spark context被初始化为了'sc'")])]),t._v(" "),n("h6",{attrs:{id:"第三步-编写scala程序"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第三步-编写scala程序"}},[t._v("#")]),t._v(" 第三步：编写scala程序")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"file:///tmp/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\nres0"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("flink"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("flume"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//可以简写成下面：")]),t._v("\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"file:///tmp/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\n")])])]),n("p",[t._v("说明：")]),t._v(" "),n("ol",[n("li",[t._v("sc.textFile()——加载数据  大致格式：hadoop spark spark")]),t._v(" "),n("li",[t._v('flatMap(x=>x.split(" "))——扁平化： 大致格式：List(hadoop,spark,spark)')]),t._v(" "),n("li",[t._v("map(x=>(x,1))——映射 大致格式：List((hadoop,1),(spark,1),(spark,1))")]),t._v(" "),n("li",[t._v("reduceByKey((x,y)=>x+y)——按Key聚合  大致格式：(hadoop,List(1,1))-----\x3e(hadoop,2)")]),t._v(" "),n("li",[t._v("collect——收集打印")]),t._v(" "),n("li",[t._v("结果是被装在Array里面的")])]),t._v(" "),n("h4",{attrs:{id:"运行spark-shell-master-local-n-读取hdfs上文件"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#运行spark-shell-master-local-n-读取hdfs上文件"}},[t._v("#")]),t._v(" 运行spark-shell --master local[N] 读取HDFS上文件")]),t._v(" "),n("h6",{attrs:{id:"spark整合hdfs"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark整合hdfs"}},[t._v("#")]),t._v(" spark整合HDFS")]),t._v(" "),n("p",[t._v("在node01上修改配置文件")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token function"}},[t._v("vi")]),t._v(" /kkb/install/spark/conf/spark-env.sh \n")])])]),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("HADOOP_CONF_DIR")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/kkb/install/hadoop-2.6.0-cdh5.14.2/etc/hadoop\n")])])]),n("p",[t._v("分发到其他节点")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[n("span",{pre:!0,attrs:{class:"token function"}},[t._v("sudo")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("scp")]),t._v(" spark-env.sh node02:/kkb/install/spark/conf\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("sudo")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("scp")]),t._v(" spark-env.sh node03:/kkb/install/spark/conf\n")])])]),n("p",[t._v("示例：读取HDFS文件进行单词统计")]),t._v(" "),n("h6",{attrs:{id:"第一步-将文件上传到hdfs"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第一步-将文件上传到hdfs"}},[t._v("#")]),t._v(" 第一步：将文件上传到hdfs")]),t._v(" "),n("p",[t._v("开启hadoop")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("hadoop.sh start\n")])])]),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("hdfs dfs -put /tmp/words.txt /\n")])])]),n("h6",{attrs:{id:"第二步-开启spark-shell-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第二步-开启spark-shell-2"}},[t._v("#")]),t._v(" 第二步：开启spark shell")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("spark-shell --master local[2]\n")])])]),n("h6",{attrs:{id:"第三步-编写spark程序"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第三步-编写spark程序"}},[t._v("#")]),t._v(" 第三步：编写spark程序")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hdfs://node01:8020/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\nres5"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("flink"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("flume"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//简写：")]),t._v("\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\n")])])]),n("h4",{attrs:{id:"运行spark-shell-指定集群中活着master"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#运行spark-shell-指定集群中活着master"}},[t._v("#")]),t._v(" 运行spark-shell 指定集群中活着master")]),t._v(" "),n("p",[t._v("上面的--local方式是本地运行的，没有使用到spark集群，当使用--master指定alive状态的master时就是使用spark集群来运行了。")]),t._v(" "),n("p",[t._v("开启spark shell")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[t._v("spark-shell --master spark://node01:7077 --executor-memory 1g  --total-executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n\n--master spark://node01:7077  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#指定活着的master地址")]),t._v("\n--executor-memory 1g    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#指定每一个executor进程的内存大小")]),t._v("\n--total-executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#指定总的executor进程cpu核数")]),t._v("\n")])])]),n("p",[t._v("开启spark shell，访问web端，会显示（local方式运行spark shell时是不会显示的）：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1509),alt:"image-20200414194201687"}})]),t._v(" "),n("p",[t._v("示例1：读取HDFS上文件进行单词统计")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hdfs://node01:8020/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//实现读取hdfs上文件之后，需要把计算的结果保存到hdfs上")]),t._v("\nsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("saveAsTextFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/out"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("示例2：读取HDFS上文件进行单词统计并将结果保存到HDFS")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hdfs://node01:8020/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("saveAsTextFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hdfs://node01:8020/spark_out"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("查看保存到HDFS的结果,结果被存放到两个文件中：")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node01 tmp"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -ls /spark_out\nFound "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" items\n-rw-r--r--   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" hadoop supergroup          "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-04-14 "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("19")]),t._v(":46 /spark_out/_SUCCESS\n-rw-r--r--   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" hadoop supergroup         "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-04-14 "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("19")]),t._v(":46 /spark_out/part-00000\n-rw-r--r--   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" hadoop supergroup         "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("31")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-04-14 "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("19")]),t._v(":46 /spark_out/part-00001\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node01 tmp"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -cat /spark_out/part-00000\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("flink,1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node01 tmp"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -cat /spark_out/part-00001\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("spark,2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hadoop,3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("flume,1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#为什么结果会保存到两个文件中？后面会讲")]),t._v("\n")])])]),n("h2",{attrs:{id:"通过idea开发spark程序"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#通过idea开发spark程序"}},[t._v("#")]),t._v(" 通过IDEA开发spark程序")]),t._v(" "),n("h4",{attrs:{id:"构建maven工程"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#构建maven工程"}},[t._v("#")]),t._v(" 构建maven工程")]),t._v(" "),n("h6",{attrs:{id:"创建src-main-scala-和-src-test-scala-目录"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#创建src-main-scala-和-src-test-scala-目录"}},[t._v("#")]),t._v(" 创建src/main/scala 和 src/test/scala 目录")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1510),alt:"1568613632045"}})]),t._v(" "),n("h6",{attrs:{id:"添加pom依赖"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#添加pom依赖"}},[t._v("#")]),t._v(" 添加pom依赖")]),t._v(" "),n("p",[t._v("说明：")]),t._v(" "),n("ol",[n("li",[t._v("创建maven工程后，设定maven为自己安装的maven，并在确保settings.xml里面设置了镜像地址为阿里云")]),t._v(" "),n("li",[t._v("如果下载不下来scala-maven-plugin或者maven-shade-plugin，则自己去网上搜索下载，然后存放到本地仓库repository的对应目录，没有对应的目录就自己创建。")]),t._v(" "),n("li",[t._v("比如，import不了scala-maven-plugin，那就将从网上下载的plugin的jar包存放到以下目录：E:\\BaiduNetdiskDownload\\repository\\net\\alchim31\\maven\\scala-maven-plugin")]),t._v(" "),n("li",[t._v("下载maven依赖的好网址：https://mvnrepository.com/")])]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependencies")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.spark"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("spark-core_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.3.3"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependencies")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n\n "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("build")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("sourceDirectory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("src/main/scala"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("sourceDirectory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("testSourceDirectory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("src/test/scala"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("testSourceDirectory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("plugins")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("net.alchim31.maven"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("scala-maven-plugin"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("3.2.2"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("compile"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("testCompile"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("configuration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("args")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("arg")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("-dependencyfile"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("arg")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("arg")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("${project.build.directory}/.scala_dependencies"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("arg")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("args")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("configuration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.maven.plugins"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("maven-shade-plugin"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.4.3"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("phase")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("package"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("phase")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("shade"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("configuration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("filters")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifact")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("*:*"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifact")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("excludes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("META-INF/*.SF"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("META-INF/*.DSA"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("META-INF/*.RSA"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("excludes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("filters")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("transformers")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("transformer")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("implementation")]),n("span",{pre:!0,attrs:{class:"token attr-value"}},[n("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("mainClass")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("mainClass")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("transformer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("transformers")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("configuration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("plugins")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("build")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("h4",{attrs:{id:"spark单词统计-scala-本地运行"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark单词统计-scala-本地运行"}},[t._v("#")]),t._v(" spark单词统计（scala/本地运行)")]),t._v(" "),n("p",[t._v('在windows创建文件"F:\\test\\aa.txt"')]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("hadoop spark spark\nflume hadoop flink\nhive spark hadoop\nspark hbase\n")])])]),n("p",[t._v("创建object,代码开发：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("RDD\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" SparkWordCount "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//构建sparkConf对象 设置application名称和master地址")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sConf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"WordCount"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    \n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//构建sparkContext对象,该对象非常重要，它是所有spark程序的执行入口")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 它内部会构建DAGScheduler和 TaskScheduler对象")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      \n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//设置日志输出级别")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"warn"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//读取数据文件")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"F:\\\\test\\\\aa.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//切分每一行，获取所有单词")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" words"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//每个单词计为1")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" wordAndOne"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("words"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//将相同单词出现的1累加")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" res"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("wordAndOne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//按照单词出现的次数降序排列  第二个参数默认是true表示升序，设置为false表示降序")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" res_sort"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("res"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sortBy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//收集数据")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" res_coll"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("res_sort"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      \n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//打印")]),t._v("\n    res_coll"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      \n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//关闭spark Context")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("p",[t._v("运行输出结果为：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hive"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("flink"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("flume"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h4",{attrs:{id:"spark单词统计-scala-集群运行"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark单词统计-scala-集群运行"}},[t._v("#")]),t._v(" spark单词统计（scala/集群运行)")]),t._v(" "),n("p",[t._v("集群运行与本地运行的代码开发很接近，本次集群运行相对于上面的本地运行代码，修改的地方有：")]),t._v(" "),n("ol",[n("li",[t._v('new SparkConf().setAppName("WordCount")没有加.setMaster("local[2]")')]),t._v(" "),n("li",[t._v("sc.textFile(args(0))数据输入路径采用动态传参")]),t._v(" "),n("li",[t._v("不再有数据收集,即.collect()")]),t._v(" "),n("li",[t._v("res_sort.saveAsTextFile(args(1))结果输出路径采用动态传参")])]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("RDD\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" SparkWordCount "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sConf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"WordCount"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"warn"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" words"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" wordAndOne"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("words"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" res"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("wordAndOne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" res_sort"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("res"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sortBy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    res_sort"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("saveAsTextFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("打成jar包提交到集群中运行")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node01 tmp"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ spark-submit --master spark://node01:7077,node02:7077 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--class SparkWordCount "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--executor-memory 1g "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--total-executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n/tmp/original-MySparkDemo-1.0-SNAPSHOT.jar "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n/words.txt /spark_out1\n")])])]),n("p",[t._v("说明：")]),t._v(" "),n("ol",[n("li",[t._v("运行jar包前，要先创建好数据文件/words.txt")]),t._v(" "),n("li",[t._v("/words.txt指的是hdfs的路径（因为之前spark整合了hdfs)")]),t._v(" "),n("li",[t._v("/out也是hdfs的路径")]),t._v(" "),n("li",[t._v("/tmp/original-MySparkDemo-1.0-SNAPSHOT.jar是linux的本地路径")])]),t._v(" "),n("h4",{attrs:{id:"spark单词统计-java-本地运行-todo"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark单词统计-java-本地运行-todo"}},[t._v("#")]),t._v(" spark单词统计（JAVA/本地运行)TODO")]),t._v(" "),n("p",[t._v("代码开发")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("com"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kaikeba")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("SparkConf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("JavaPairRDD")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("JavaRDD")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("JavaSparkContext")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("FlatMapFunction")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Function2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("PairFunction")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("scala"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tuple2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Arrays")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Iterator")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo: 利用java语言开发spark的单词统计程序")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("JavaWordCount")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//1、创建SparkConf对象")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("SparkConf")]),t._v(" sparkConf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("SparkConf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("setAppName")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"JavaWordCount"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("setMaster")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//2、构建JavaSparkContext对象")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("JavaSparkContext")]),t._v(" jsc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("JavaSparkContext")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//3、读取数据文件")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("JavaRDD")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" jsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("textFile")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"E:\\\\words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('//4、切分每一行获取所有的单词   scala:  data.flatMap(x=>x.split(" "))')]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("JavaRDD")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" wordsJavaRDD "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("flatMap")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("FlatMapFunction")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Iterator")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("call")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" line"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Exception")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" words "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" line"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("split")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Arrays")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("asList")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("words"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("iterator")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//5、每个单词计为1    scala:  wordsJavaRDD.map(x=>(x,1))")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("JavaPairRDD")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" wordAndOne "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" wordsJavaRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapToPair")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("PairFunction")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tuple2")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("call")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Exception")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tuple2")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//6、相同单词出现的1累加    scala:  wordAndOne.reduceByKey((x,y)=>x+y)")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("JavaPairRDD")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" result "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" wordAndOne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduceByKey")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Function2")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("call")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" v1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" v2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Exception")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" v1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" v2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//按照单词出现的次数降序 (单词，次数)  --\x3e(次数,单词).sortByKey----\x3e (单词，次数)")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("JavaPairRDD")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" reverseJavaRDD "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapToPair")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("PairFunction")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tuple2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tuple2")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("call")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tuple2")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Exception")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tuple2")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("JavaPairRDD")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" sortedRDD "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" reverseJavaRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("sortByKey")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapToPair")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("PairFunction")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tuple2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tuple2")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("call")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tuple2")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Exception")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tuple2")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//7、收集打印")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tuple2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" finalResult "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sortedRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tuple2")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" t "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" finalResult"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"单词："')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\t次数："')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n        jsc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("stop")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h2",{attrs:{id:"spark学习推荐"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark学习推荐"}},[t._v("#")]),t._v(" spark学习推荐")]),t._v(" "),n("p",[t._v("看书：《图解spark》")]),t._v(" "),n("p",[t._v("看spark官网：http://spark.apache.org/")]),t._v(" "),n("h2",{attrs:{id:"spark补充1"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark补充1"}},[t._v("#")]),t._v(" spark补充1")]),t._v(" "),n("p",[t._v("用yarn运行spark程序,而不是用Master运行时，就跟spark集群没多大关系了。")]),t._v(" "),n("p",[t._v("spark程序和MapReduce程序一样，本质上都是一个java程序，都有自己的计算逻辑，用yarn运行spark程序时，提交job的方式还是spark-submit,spark程序的计算还是在内存中，很多东西都不变，只是将Master换成了yarn。")]),t._v(" "),n("p",[t._v("yarn可理解成一个资源统一调度框架，不仅仅可以为MapReduce任务分配资源，还可以为spark等任务分配计算资源。")]),t._v(" "),n("h2",{attrs:{id:"rdd"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd"}},[t._v("#")]),t._v(" RDD")]),t._v(" "),n("h3",{attrs:{id:"rdd是什么"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd是什么"}},[t._v("#")]),t._v(" RDD是什么")]),t._v(" "),n("p",[t._v("RDD（Resilient Distributed Dataset）叫做"),n("strong",[t._v("弹性分布式数据集")]),t._v("，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合。"),n("strong",[t._v("RDD是spark core的底层核心")]),t._v("。")]),t._v(" "),n("ul",[n("li",[n("strong",[t._v("Dataset")]),t._v(":就是一个集合，存储很多数据.")]),t._v(" "),n("li",[n("strong",[t._v("Distributed")]),t._v("：它内部的元素进行了分布式存储，方便于后期进行分布式计算.")]),t._v(" "),n("li",[n("strong",[t._v("Resilient")]),t._v("：表示弹性，rdd的数据是可以保存在内存或者是磁盘中.")])]),t._v(" "),n("h3",{attrs:{id:"rdd的五大属性-重要"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd的五大属性-重要"}},[t._v("#")]),t._v(" RDD的五大属性（重要）")]),t._v(" "),n("p",[t._v("ctrl+左击查看RDD的部分源码（如果看不了就download source),源码中对RDD的描述如下：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('/**\n * A Resilient Distributed Dataset (RDD), the basic abstraction in Spark. Represents an immutable,\n * partitioned collection of elements that can be operated on in parallel. This class contains the\n * basic operations available on all RDDs, such as `map`, `filter`, and `persist`. In addition,\n * [[org.apache.spark.rdd.PairRDDFunctions]] contains operations available only on RDDs of key-value\n * pairs, such as `groupByKey` and `join`;\n * [[org.apache.spark.rdd.DoubleRDDFunctions]] contains operations available only on RDDs of\n * Doubles; and\n * [[org.apache.spark.rdd.SequenceFileRDDFunctions]] contains operations available on RDDs that\n * can be saved as SequenceFiles.\n * All operations are automatically available on any RDD of the right type (e.g. RDD[(Int, Int)])\n * through implicit.\n *\n * Internally, each RDD is characterized by five main properties:\n *\n *  - A list of partitions\n *  - A function for computing each split\n *  - A list of dependencies on other RDDs\n *  - Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)\n *  - Optionally, a list of preferred locations to compute each split on (e.g. block locations for\n *    an HDFS file)\n *\n * All of the scheduling and execution in Spark is done based on these methods, allowing each RDD\n * to implement its own way of computing itself. Indeed, users can implement custom RDDs (e.g. for\n * reading data from a new storage system) by overriding these functions. Please refer to the\n * <a href="http://people.csail.mit.edu/matei/papers/2012/nsdi_spark.pdf">Spark paper</a>\n * for more details on RDD internals.\n */')]),t._v("\n")])])]),n("p",[t._v("从上面源码中，可以得到RDD的五大属性：")]),t._v(" "),n("h4",{attrs:{id:"属性1-a-list-of-partitions"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#属性1-a-list-of-partitions"}},[t._v("#")]),t._v(" 属性1：A list of partitions")]),t._v(" "),n("p",[t._v("一个分区列表，这里表示一个rdd有很多分区，每一个分区内部是包含了该RDD的部分数据，spark中任务是以task线程的方式运行， 一个分区就对应一个task线程。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1511),alt:"image-20200415130448439"}})]),t._v(" "),n("p",[t._v("用户可以在创建RDD时指定RDD的分区个数，如果没有指定，那么就会采用默认值。")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("分区数的默认值的计算公式如下：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("RDD的分区数"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("max"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("文件的block个数，defaultMinPartitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//通过Spark Context读取hdfs上的文件来计算分区数")]),t._v("\n")])])]),n("h4",{attrs:{id:"属性2-a-function-for-computing-each-split"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#属性2-a-function-for-computing-each-split"}},[t._v("#")]),t._v(" 属性2：A function for computing each split")]),t._v(" "),n("p",[t._v("一个计算每个分区的函数，这里表示Spark中RDD的计算是以分区为单位的，每个RDD都会实现compute计算函数以达到这个目的.")]),t._v(" "),n("h4",{attrs:{id:"属性3-a-list-of-dependencies-on-other-rdds"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#属性3-a-list-of-dependencies-on-other-rdds"}},[t._v("#")]),t._v(" 属性3：A list of dependencies on other RDDs")]),t._v(" "),n("p",[t._v("一个rdd会依赖于其他多个rdd，这里涉及到rdd与rdd之间的依赖关系，spark任务的容错机制就是根据这个特性（血统）而来。")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd3"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd6"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd4"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd5"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("rdd2依赖于rdd1,而rdd3依赖于rdd2")]),t._v(" "),n("p",[t._v("rdd6依赖于rdd4、rdd5")]),t._v(" "),n("h4",{attrs:{id:"属性4-optionally-a-partitioner-for-key-value-rdds-e-g-to-say-that-the-rdd-is-hash-partitioned"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#属性4-optionally-a-partitioner-for-key-value-rdds-e-g-to-say-that-the-rdd-is-hash-partitioned"}},[t._v("#")]),t._v(" 属性4：Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)")]),t._v(" "),n("p",[t._v("一个Partitioner，即RDD的分区函数（可选项）")]),t._v(" "),n("p",[t._v("当前Spark中实现了两种类型的分区函数，")]),t._v(" "),n("ol",[n("li",[t._v("基于哈希的HashPartitioner，(key.hashcode % 分区数= 分区号)。它是默认值")]),t._v(" "),n("li",[t._v("基于范围的RangePartitioner。")])]),t._v(" "),n("p",[t._v("什么会有Partitioner?")]),t._v(" "),n("ol",[n("li",[t._v("只有对于key-value的RDD(RDD[(String, Int)]),并且产生shuffle，才会有Partitioner，")]),t._v(" "),n("li",[t._v("非key-value的RDD(RDD[String])的Parititioner的值是None。")])]),t._v(" "),n("p",[t._v("Option类型：可以表示有值或者没有值，它有2个子类：")]),t._v(" "),n("ol",[n("li",[t._v("Some：表示封装了值")]),t._v(" "),n("li",[t._v("None：表示没有值")])]),t._v(" "),n("h4",{attrs:{id:"属性5-optionally-a-list-of-preferred-locations-to-compute-each-split-on-e-g-block-locations-for-an-hdfs-file"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#属性5-optionally-a-list-of-preferred-locations-to-compute-each-split-on-e-g-block-locations-for-an-hdfs-file"}},[t._v("#")]),t._v(" 属性5：Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)")]),t._v(" "),n("p",[t._v("一个列表，存储每个Partition的优先位置(可选项)，这里涉及到数据的本地性，数据块位置最优。")]),t._v(" "),n("p",[t._v("spark任务在调度的时候会优先考虑存有数据的节点开启计算任务，减少数据的网络传输，提升计算效率。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1512),alt:"image-20200415133258993"}})]),t._v(" "),n("h3",{attrs:{id:"基于spark的单词统计程序剖析rdd的五大属性"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#基于spark的单词统计程序剖析rdd的五大属性"}},[t._v("#")]),t._v(" 基于spark的单词统计程序剖析rdd的五大属性")]),t._v(" "),n("h5",{attrs:{id:"需求"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#需求"}},[t._v("#")]),t._v(" 需求")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("HDFS上有一个大小为300M的文件，通过spark实现文件单词统计，最后把结果数据保存到HDFS上\n")])])]),n("h5",{attrs:{id:"要执行的代码"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#要执行的代码"}},[t._v("#")]),t._v(" 要执行的代码")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("saveAsTextFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/out"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h5",{attrs:{id:"流程分析"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#流程分析"}},[t._v("#")]),t._v(" 流程分析")]),t._v(" "),n("h6",{attrs:{id:"大致流程"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#大致流程"}},[t._v("#")]),t._v(" 大致流程：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1513),alt:"image-20200415140940717"}})]),t._v(" "),n("h6",{attrs:{id:"每个rdd的解释"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#每个rdd的解释"}},[t._v("#")]),t._v(" 每个rdd的解释：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1514),alt:"image-20200415141032695"}})]),t._v(" "),n("h6",{attrs:{id:"完整图"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#完整图"}},[t._v("#")]),t._v(" 完整图：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1515),alt:"image-20200415141636967"}})]),t._v(" "),n("h6",{attrs:{id:"partitioner的解析"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#partitioner的解析"}},[t._v("#")]),t._v(" partitioner的解析：")]),t._v(" "),n("p",[t._v("rdd1,rdd2,rdd3的partitioner都是None，经过shuffle，rdd4的partitioner为HashPartitioner。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1516),alt:"image-20200415141443569"}})]),t._v(" "),n("p",[n("img",{attrs:{src:a(1517),alt:"image-20200415141529095"}})]),t._v(" "),n("h5",{attrs:{id:"为什么计算小文件会生成两个结果文件"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#为什么计算小文件会生成两个结果文件"}},[t._v("#")]),t._v(" 为什么计算小文件会生成两个结果文件？")]),t._v(" "),n("p",[t._v("通过上面的流程分析，可以知道，"),n("strong",[t._v("加载一个文件时，文件的block个数就是默认的分区个数")]),t._v("，而一个分区对应生成一个结果文件。")]),t._v(" "),n("p",[t._v("那为什么我们之前计算words.txt这么一个只有1个block的小文件时，会生成2个结果文件？按道理不是1个才对？")]),t._v(" "),n("p",[t._v("这跟加载数据文件的textFile()方法的参数有关，首先来看一下textFile()的源码：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      path"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      minPartitions"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" defaultMinPartitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" withScope "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    assertNotStopped"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    hadoopFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" classOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("TextInputFormat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" classOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("LongWritable"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" classOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Text"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      minPartitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pair "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" pair"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("可以看到，textFile方法，有两个参数,path和minPartitions，而我们之前使用的时候，只填了一个参数，如：val data:RDD[String]=sc.textFile(args(0))")]),t._v(" "),n("p",[t._v("这样的话，最小分区数minPartitions就会使用默认值defaultMinPartitions，再来看一下defaultMinPartitions的源码：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" defaultMinPartitions"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" math"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("min"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("defaultParallelism"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("defaultMinPartitions是一个方法，返回值是math.min(defaultParallelism, 2)")]),t._v(" "),n("p",[t._v("defaultParallelism是默认并行度，一般是大于2的数，所以math.min(defaultParallelism, 2)=2")]),t._v(" "),n("p",[t._v("因此，最小分区数minPartitions=2，这就是计算分析小文件会生成2个文件的原因。")]),t._v(" "),n("h3",{attrs:{id:"拓展-并行与并发"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#拓展-并行与并发"}},[t._v("#")]),t._v(" 拓展：并行与并发")]),t._v(" "),n("h4",{attrs:{id:"并发"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#并发"}},[t._v("#")]),t._v(" 并发")]),t._v(" "),n("p",[t._v("并发（Concurrent），在操作系统中，是指一个时间段中有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理机上运行。")]),t._v(" "),n("p",[t._v("并发不是真正意义上的“同时进行”，只是CPU把一个时间段划分成几个时间片段（时间区间），然后在这几个时间区间之间来回切换，由于CPU处理的速度非常快，只要时间间隔处理得当，即可让用户感觉是多个应用程序同时在进行。如：打游戏和听音乐两件事情在"),n("strong",[t._v("同一个时间段内")]),t._v("都是在同一台电脑上完成了"),n("strong",[t._v("从开始到结束的动作")]),t._v("。那么，就可以说听音乐和打游戏是并发的。")]),t._v(" "),n("h4",{attrs:{id:"并行"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#并行"}},[t._v("#")]),t._v(" 并行")]),t._v(" "),n("p",[t._v("并行（Parallel），当系统有一个以上CPU时，当一个CPU执行一个进程时，另一个CPU可以执行另一个进程，两个进程互不抢占CPU资源，可以同时进行，这种方式我们称之为并行(Parallel)。")]),t._v(" "),n("p",[t._v("其实决定并行的因素不是CPU的数量，而是CPU的核心数量，比如一个CPU多个核也可以并行。")]),t._v(" "),n("h4",{attrs:{id:"并行与并发示意图"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#并行与并发示意图"}},[t._v("#")]),t._v(" 并行与并发示意图")]),t._v(" "),n("p",[t._v("如下图所示：（并发与并发示意图）")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1518),alt:"img"}}),t._v("**")]),t._v(" "),n("p",[t._v("所以，并发是在一段时间内宏观上多个程序同时运行，并行是在某一时刻，真正有多个程序在运行。")]),t._v(" "),n("h4",{attrs:{id:"并行和并发的区别"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#并行和并发的区别"}},[t._v("#")]),t._v(" 并行和并发的区别")]),t._v(" "),n("ol",[n("li",[n("p",[t._v("并发，指的是多个事情，在同一时间段内同时发生了。")])]),t._v(" "),n("li",[n("p",[t._v("并行，指的是多个事情，在同一时间点上同时发生了。")])]),t._v(" "),n("li",[n("p",[t._v("并发的多个任务之间是互相抢占资源的。")])]),t._v(" "),n("li",[n("p",[t._v("并行的多个任务之间是不互相抢占资源的。")])])]),t._v(" "),n("p",[t._v("只有在多CPU或者一个CPU多核的情况中，才会发生并行。否则，看似同时发生的事情，其实都是并发执行的。")]),t._v(" "),n("h4",{attrs:{id:"spark的并行"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark的并行"}},[t._v("#")]),t._v(" spark的并行")]),t._v(" "),n("p",[t._v("一个文件有多个block,一个block对应一个分区，一个分区就会对应一个task,一个task对应一个线程，多个线程并行运行：")]),t._v(" "),n("p",[t._v("以上面的300M的文件的计算为例，分析spark中的并行：")]),t._v(" "),n("p",[t._v("并行运行1：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1519),alt:"image-20200415154218150"}})]),t._v(" "),n("p",[t._v("并行运行2：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1520),alt:"image-20200415154545940"}})]),t._v(" "),n("h3",{attrs:{id:"rdd的创建方式"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd的创建方式"}},[t._v("#")]),t._v(" RDD的创建方式")]),t._v(" "),n("p",[t._v("RDD的创建方式有3种：")]),t._v(" "),n("p",[t._v("1、通过已经存在的scala集合去构建，前期做一些测试用到的比较多")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//parallelize可以添加第2个参数，是分区的数量")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hadoop"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hive"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd3"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makeRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//parallelize表示并行化")]),t._v("\n")])])]),n("p",[t._v("无论传入的是什么，元素最终都是用Array封装的：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1521),alt:"image-20200415155327297"}})]),t._v(" "),n("p",[t._v("2、加载外部的数据源去构建")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("3、从已经存在的rdd进行转换生成一个新的rdd")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd3"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h2",{attrs:{id:"rdd的算子"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd的算子"}},[t._v("#")]),t._v(" RDD的算子")]),t._v(" "),n("p",[t._v("算子可以理解成RDD的一些方法。")]),t._v(" "),n("p",[t._v("RDD的算子可以分为2类：")]),t._v(" "),n("p",[t._v("1、transformation（转换）")]),t._v(" "),n("ul",[n("li",[t._v("根据已经存在的rdd转换生成一个新的rdd,  它是延迟加载，它不会立即执行")]),t._v(" "),n("li",[t._v("例如： map / flatMap / reduceByKey 等")])]),t._v(" "),n("p",[t._v("2、action (动作)")]),t._v(" "),n("ul",[n("li",[t._v("它会真正触发任务的运行，将rdd的计算的结果数据返回给Driver端，或者是保存结果数据到外部存储介质中")]),t._v(" "),n("li",[t._v("例如：collect / saveAsTextFile 等")])]),t._v(" "),n("h3",{attrs:{id:"rdd常见的算子操作说明-重要"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd常见的算子操作说明-重要"}},[t._v("#")]),t._v(" RDD常见的算子操作说明(重要)")]),t._v(" "),n("h4",{attrs:{id:"transformation算子"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#transformation算子"}},[t._v("#")]),t._v(" transformation算子")]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[n("strong",[t._v("转换")])]),t._v(" "),n("th",[n("strong",[t._v("含义")])])])]),t._v(" "),n("tbody",[n("tr",[n("td",[n("strong",[t._v("map(func)")])]),t._v(" "),n("td",[t._v("返回一个新的RDD，该RDD由每一个输入元素经过func函数转换后组成")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("filter(func)")])]),t._v(" "),n("td",[t._v("返回一个新的RDD，该RDD由经过func函数计算后返回值为true的输入元素组成")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("flatMap(func)")])]),t._v(" "),n("td",[t._v("类似于map，但是每一个输入元素可以被映射为0或多个输出元素（所以func应该返回一个序列，而不是单一元素）")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("mapPartitions(func)")])]),t._v(" "),n("td",[t._v("类似于map，但独立地在RDD的每一个分片上运行，因此在类型为T的RDD上运行时，func的函数类型必须是Iterator[T] => Iterator[U]")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("mapPartitionsWithIndex(func)")])]),t._v(" "),n("td",[t._v("类似于mapPartitions，但func带有一个整数参数表示分片的索引值，因此在类型为T的RDD上运行时，func的函数类型必须是(Int, Interator[T]) => Iterator[U]")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("union(otherDataset)")])]),t._v(" "),n("td",[t._v("对源RDD和参数RDD求并集后返回一个新的RDD")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("intersection(otherDataset)")])]),t._v(" "),n("td",[t._v("对源RDD和参数RDD求交集后返回一个新的RDD")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("distinct([numTasks]))")])]),t._v(" "),n("td",[t._v("对源RDD进行去重后返回一个新的RDD")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("groupByKey([numTasks])")])]),t._v(" "),n("td",[t._v("在一个(K,V)的RDD上调用，返回一个(K, Iterator[V])的RDD")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("reduceByKey(func, [numTasks])")])]),t._v(" "),n("td",[t._v("在一个(K,V)的RDD上调用，返回一个(K,V)的RDD，使用指定的reduce函数，将相同key的值聚合到一起，与groupByKey类似，reduce任务的个数可以通过第二个可选的参数来设置")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("sortByKey([ascending], [numTasks])")])]),t._v(" "),n("td",[t._v("在一个(K,V)的RDD上调用，K必须实现Ordered接口，返回一个按照key进行排序的(K,V)的RDD")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("sortBy(func,[ascending], [numTasks])")])]),t._v(" "),n("td",[t._v("与sortByKey类似，但是更灵活")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("join(otherDataset, [numTasks])")])]),t._v(" "),n("td",[t._v("在类型为(K,V)和(K,W)的RDD上调用，返回一个相同key对应的所有元素对在一起的(K,(V,W))的RDD")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("cogroup(otherDataset, [numTasks])")])]),t._v(" "),n("td",[t._v("在类型为(K,V)和(K,W)的RDD上调用，返回一个(K,"),n("code",[t._v("(Iterable<V>,Iterable<W>))")]),t._v("类型的RDD")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("coalesce(numPartitions)")])]),t._v(" "),n("td",[t._v("减少 RDD 的分区数到指定值。")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("repartition(numPartitions)")])]),t._v(" "),n("td",[t._v("重新给 RDD 分区")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("repartitionAndSortWithinPartitions(partitioner)")])]),t._v(" "),n("td",[t._v("重新给 RDD 分区，并且每个分区内以记录的 key 排序")])])])]),t._v(" "),n("h4",{attrs:{id:"action算子"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#action算子"}},[t._v("#")]),t._v(" action算子")]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[n("strong",[t._v("动作")])]),t._v(" "),n("th",[n("strong",[t._v("含义")])])])]),t._v(" "),n("tbody",[n("tr",[n("td",[n("strong",[t._v("reduce(func)")])]),t._v(" "),n("td",[t._v("reduce将RDD中元素前两个传给输入函数，产生一个新的return值，新产生的return值与RDD中下一个元素（第三个元素）组成两个元素，再被传给输入函数，直到最后只有一个值为止。")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("collect()")])]),t._v(" "),n("td",[t._v("在驱动程序中，以数组的形式返回数据集的所有元素")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("count()")])]),t._v(" "),n("td",[t._v("返回RDD的元素个数")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("first()")])]),t._v(" "),n("td",[t._v("返回RDD的第一个元素（类似于take(1)）")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("take(n)")])]),t._v(" "),n("td",[t._v("返回一个由数据集的前n个元素组成的数组")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("takeOrdered(n, [ordering])")])]),t._v(" "),n("td",[t._v("返回自然顺序或者自定义顺序的前 n 个元素")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("saveAsTextFile(path)")])]),t._v(" "),n("td",[t._v("将数据集的元素以textfile的形式保存到HDFS文件系统或者其他支持的文件系统，对于每个元素，Spark将会调用toString方法，将它装换为文件中的文本")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("saveAsSequenceFile(path)")])]),t._v(" "),n("td",[t._v("将数据集中的元素以Hadoop sequencefile的格式保存到指定的目录下，可以使HDFS或者其他Hadoop支持的文件系统。")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("saveAsObjectFile(path)")])]),t._v(" "),n("td",[t._v("将数据集的元素，以 Java 序列化的方式保存到指定的目录下")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("countByKey()")])]),t._v(" "),n("td",[t._v("针对(K,V)类型的RDD，返回一个(K,Int)的map，表示每一个key对应的元素个数。")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("foreach(func)")])]),t._v(" "),n("td",[t._v("在数据集的每一个元素上，运行函数func")])]),t._v(" "),n("tr",[n("td",[n("strong",[t._v("foreachPartition(func)")])]),t._v(" "),n("td",[t._v("在数据集的每一个分区上，运行函数func")])])])]),t._v(" "),n("h4",{attrs:{id:"map与mappartitions的区别-面试题"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#map与mappartitions的区别-面试题"}},[t._v("#")]),t._v(" map与mapPartitions的区别（面试题）")]),t._v(" "),n("ol",[n("li",[t._v("map含义：返回一个新的RDD，该RDD由每一个输入元素经过func函数转换后组成")]),t._v(" "),n("li",[t._v("mapPartitions含义：类似于map，但独立地在RDD的每一个分片上运行，因此在类型为T的RDD上运行时，func的函数类型必须是Iterator[T] => Iterator[U]")]),t._v(" "),n("li",[t._v("map是对rdd中的每一个元素进行操作，mapPartitions是对rdd中的每一个分区/task的迭代器进行操作")]),t._v(" "),n("li",[t._v("两者最终实现的效果都是一样的，但是实现的过程不一样。")])]),t._v(" "),n("p",[t._v("MapPartitions的优点：")]),t._v(" "),n("p",[t._v("如果是普通的map，比如一个partition中有1万条数据，那么你的function要执行和计算1万次。")]),t._v(" "),n("p",[n("strong",[t._v("使用MapPartitions操作之后，一个task仅仅会执行一次function")]),t._v("，function一次接收所有的partition数据。只要执行一次就可以了，性能比较高。")]),t._v(" "),n("p",[t._v("如果在map过程中需要频繁创建额外的对象(例如将rdd中的数据通过jdbc写入数据库,map需要为每个元素创建一个链接而mapPartition为每个partition创建一个链接),则mapPartitions效率比map高的多。")]),t._v(" "),n("p",[t._v("SparkSql或DataFrame默认会对程序进行mapPartition的优化。")]),t._v(" "),n("p",[t._v("MapPartitions的缺点：")]),t._v(" "),n("p",[t._v("如果是普通的map操作，一次function的执行就处理一条数据；那么如果内存不够用的情况下， 比如处理了1千条数据了，那么这个时候内存不够了，那么就可以将已经处理完的1千条数据从内存里面垃圾回收掉，或者用其他方法，腾出空间来吧。")]),t._v(" "),n("p",[t._v("所以说普通的"),n("strong",[t._v("map操作通常不会导致内存的OOM（Out Of Memory)异常")]),t._v("。")]),t._v(" "),n("p",[t._v("但是MapPartitions操作，对于大量数据来说，比如甚至一个partition，100万数据，一次传入一个function以后，那么可能一下子内存不够，但是又没有办法去腾出内存空间来，可能就OOM，内存溢出。")]),t._v(" "),n("h4",{attrs:{id:"foreach与foreachpartition的区别-面试题"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#foreach与foreachpartition的区别-面试题"}},[t._v("#")]),t._v(" foreach与foreachPartition的区别（面试题）")]),t._v(" "),n("p",[t._v("与map VS mapPartitions类似")]),t._v(" "),n("h2",{attrs:{id:"面试题1"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#面试题1"}},[t._v("#")]),t._v(" 面试题1")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1522),alt:"image-20200417025522744"}})]),t._v(" "),n("h2",{attrs:{id:"rdd常用的算子操作演示"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd常用的算子操作演示"}},[t._v("#")]),t._v(" RDD常用的算子操作演示")]),t._v(" "),n("p",[t._v("为了方便前期的测试和学习，可以使用spark-shell进行演示")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("spark-shell --master local"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),n("h4",{attrs:{id:"_1-map"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-map"}},[t._v("#")]),t._v(" 1 map")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\nres4"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("40")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("60")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("70")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("80")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \n")])])]),n("h4",{attrs:{id:"_2-filter"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-filter"}},[t._v("#")]),t._v(" 2 filter")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//把rdd1中大于5的元素进行过滤")]),t._v("\nrdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("filter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\n")])])]),n("h4",{attrs:{id:"_3-flatmap"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-flatmap"}},[t._v("#")]),t._v(" 3 flatMap")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\t"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a b c"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"d e f"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"h i j"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取rdd1中元素的每一个字母")]),t._v("\nrdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\n")])])]),n("h4",{attrs:{id:"_4-intersection、union"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-intersection、union"}},[t._v("#")]),t._v(" 4 intersection、union")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//求交集")]),t._v("\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intersection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\nres7"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//求并集")]),t._v("\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd5"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("union"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" rdd5"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\nres6"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h4",{attrs:{id:"_5-distinct"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_5-distinct"}},[t._v("#")]),t._v(" 5 distinct")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//去重")]),t._v("\nrdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("distinct\n")])])]),n("h4",{attrs:{id:"_6-join、groupbykey"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_6-join、groupbykey"}},[t._v("#")]),t._v(" 6 join、groupByKey")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tom"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jerry"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"kitty"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jerry"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tom"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"shuke"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//求join")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd3 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrdd3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\nres8"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tom"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("jerry"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//求并集")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd4 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rdd1 union rdd2\nrdd4"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("groupByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\nres11"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Iterable"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tom"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("CompactBuffer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("jerry"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("CompactBuffer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("shuke"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("CompactBuffer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("kitty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("CompactBuffer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h4",{attrs:{id:"_7-cogroup"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_7-cogroup"}},[t._v("#")]),t._v(" 7 cogroup")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tom"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tom"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jerry"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"kitty"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jerry"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tom"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jim"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//分组")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd3 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cogroup"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrdd3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\nres12"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Iterable"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Iterable"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("jim"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("CompactBuffer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("CompactBuffer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tom"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("CompactBuffer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("CompactBuffer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("jerry"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("CompactBuffer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("CompactBuffer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("kitty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("CompactBuffer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("CompactBuffer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h4",{attrs:{id:"_8-reduce"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_8-reduce"}},[t._v("#")]),t._v(" 8 reduce")]),t._v(" "),n("p",[t._v("示例1：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//reduce聚合")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduce"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("示例2：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd3 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"2"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"3"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"4"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"5"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" rdd3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduce"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nres18"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("12345")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" rdd3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduce"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nres21"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("34512")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//从12345变成了34512")]),t._v("\n")])])]),n("p",[t._v("从上面示例2的代码块可知，同样的操作，出现了不同的结果。")]),t._v(" "),n("p",[t._v("这是因为元素在不同的分区中，每一个分区都是一个独立的task线程去运行（多个分区并行运算）。这些task运行有先后关系。")]),t._v(" "),n("p",[t._v("查看元素的分区情况：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" rdd3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("partitions\nres19"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Partition"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ParallelCollectionPartition"),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@c55")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ParallelCollectionPartition"),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@c56")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" rdd3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("partitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length\nres20"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n")])])]),n("h4",{attrs:{id:"_9-reducebykey、sortbykey"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_9-reducebykey、sortbykey"}},[t._v("#")]),t._v(" 9 reduceByKey、sortByKey")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tom"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jerry"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"kitty"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"shuke"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jerry"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tom"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"shuke"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"kitty"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd3 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("union"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//按key进行聚合")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd4 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rdd3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrdd4"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//按value的降序排序")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd5 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rdd4"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sortByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrdd5"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\n")])])]),n("h4",{attrs:{id:"_10-repartition、coalesce"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_10-repartition、coalesce"}},[t._v("#")]),t._v(" 10 repartition、coalesce")]),t._v(" "),n("h6",{attrs:{id:"两者使用区别"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#两者使用区别"}},[t._v("#")]),t._v(" 两者使用区别")]),t._v(" "),n("p",[t._v("coalesce功能：改变分区数量，只能减少，不能增加")]),t._v(" "),n("p",[t._v("repartition功能：改变分区数量，减少增加都可以")]),t._v(" "),n("p",[t._v("coalesce示例：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("partitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length\nres4"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//************=利用coalesce减少分区数量，成功****************************=")]),t._v("\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("coalesce"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrdd2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" CoalescedRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" at coalesce at "),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("console"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("partitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length\nres5"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("partitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length\nres6"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//************=利用coalesce增加分区数量，失败****************************=")]),t._v("\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd3"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("coalesce"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrdd3"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" CoalescedRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" at coalesce at "),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("console"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" rdd3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("partitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length\nres7"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("partitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length\nres8"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//************=利用repatriation增加分区数量，成功****************************=")]),t._v("\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd4"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("repartition"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrdd4"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" MapPartitionsRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" at repartition at "),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("console"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" rdd4"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("partitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length\nres9"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("partitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length\nres10"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n")])])]),n("p",[t._v("为什么repartition可以增加分区数量，而coalesce不可以，两者又有什么区别，我们来看一下源码：")]),t._v(" "),n("p",[t._v("repartition方法的源码（源码在RDD.scala搜索即可）：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" repartition"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("numPartitions"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implicit")]),t._v(" ord"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Ordering"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("T"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("T"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" withScope "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    coalesce"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("numPartitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" shuffle "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("从源码可以看出，repartition方法体调用了coalesce方法，该coalesce方法有2个参数，第2个参数是shuffle = true。再来看一下coalesce方法的源码：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" coalesce"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("numPartitions"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" shuffle"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Boolean")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n               partitionCoalescer"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Option"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("PartitionCoalescer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Option"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("empty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implicit")]),t._v(" ord"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Ordering"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("T"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("T"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" withScope "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("可看到，coalesce方法的第二个参数是shuffle，但是值却是false，这与repartition方法体里调用的coalesce参数值刚好相反。")]),t._v(" "),n("p",[t._v("因此，可以推断出，repartition能够的增加分区的数量的根本原因是将shuffle参数设为了true。")]),t._v(" "),n("p",[t._v("使用建议：因为shuffle是比较消耗资源的，所以如果要减少分区的数量时，尽量使用coalesce。")]),t._v(" "),n("h6",{attrs:{id:"改变分区数量的应用场景举例"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#改变分区数量的应用场景举例"}},[t._v("#")]),t._v(" 改变分区数量的应用场景举例：")]),t._v(" "),n("p",[t._v("要执行的操作：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("saveAsTextFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/out"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("假如words.txt文件很大,那么会产生很多个分区，比如1000个分区，每个分区数据量可能有点小。")]),t._v(" "),n("p",[t._v("如果直接保存数据到hdfs上，那么会产生很多个小文件(hdfs不适合处理小文件)。")]),t._v(" "),n("p",[t._v('为了减少在hdfs生成的小文件数量，可以在saveAsTextFile("/out")之前添加一个步骤来减少分区数量，代码如下：')]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd4"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd5"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd4"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("coalesce"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nrdd5"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("saveAsTextFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/out"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h6",{attrs:{id:"有无shuffle的示意图"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#有无shuffle的示意图"}},[t._v("#")]),t._v(" 有无shuffle的示意图：")]),t._v(" "),n("p",[t._v("可以看到，减少分区数量如果使用repartition会产生shuffle，shuffle阶段要进行计算分区号和交叉传送等操作，明显麻烦比无shuffle时麻烦很多，消耗资源。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1523),alt:"image-20200415201224598"}})]),t._v(" "),n("h4",{attrs:{id:"_11-map、mappartitions、mappartitionswithindex"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_11-map、mappartitions、mappartitionswithindex"}},[t._v("#")]),t._v(" 11 map、mapPartitions、mapPartitionsWithIndex")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" to "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\nrdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mapPartitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("iter "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//map：用于遍历RDD,将函数f应用于每一个元素，返回新的RDD(transformation算子)。")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//mapPartitions:用于遍历操作RDD中的每一个分区，返回生成一个新的RDD（transformation算子）。")]),t._v("\n")])])]),n("p",[t._v("总结：")]),t._v(" "),n("p",[t._v("如果在映射的过程中需要频繁创建额外的对象，使用mapPartitions要比map高效")]),t._v(" "),n("p",[t._v("比如，将RDD中的所有数据通过JDBC连接写入数据库，如果使用map函数，可能要为每一个元素都创建一个connection，这样开销很大，如果使用mapPartitions，那么只需要针对每一个分区建立一个connection。")]),t._v(" "),n("p",[t._v("mapPartitionsWithIndex的使用：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" to "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ParallelCollectionRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" at parallelize at "),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("console"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//index表示分区号  可以获取得到每一个元素属于哪一个分区")]),t._v("\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mapPartitionsWithIndex"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("index"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("index"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\nres11"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h4",{attrs:{id:"_12-foreach、foreachpartition"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_12-foreach、foreachpartition"}},[t._v("#")]),t._v(" 12 foreach、foreachPartition")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//foreach实现对rdd1里的每一个元素乘10然后打印输出")]),t._v("\nrdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//foreachPartition实现对rdd1里的每一个元素乘10然后打印输出")]),t._v("\nrdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreachPartition"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("iter "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//foreach:用于遍历RDD,将函数f应用于每一个元素，无返回值(action算子)。")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//foreachPartition: 用于遍历操作RDD中的每一个分区。无返回值(action算子)。")]),t._v("\n")])])]),n("p",[t._v("总结：一般使用mapPartitions或者foreachPartition算子比map和foreach更加高效，推荐使用。")]),t._v(" "),n("hr"),t._v(" "),n("p",[t._v("-----------------------------录播分界线-----------------------------------------")]),t._v(" "),n("hr"),t._v(" "),n("h2",{attrs:{id:"案例1-使用java实现spark的wordcount"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#案例1-使用java实现spark的wordcount"}},[t._v("#")]),t._v(" 案例1：使用Java实现spark的wordCount")]),t._v(" "),n("h5",{attrs:{id:"案例需求"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#案例需求"}},[t._v("#")]),t._v(" 案例需求：")]),t._v(" "),n("p",[t._v("单词计数")]),t._v(" "),n("h5",{attrs:{id:"第一步-创建maven工程-引入依赖"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第一步-创建maven工程-引入依赖"}},[t._v("#")]),t._v(" 第一步：创建maven工程，引入依赖")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[t._v(" "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependencies")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.spark"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("spark-core_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.3.3"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependencies")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n")])])]),n("h5",{attrs:{id:"第二步-代码开发"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第二步-代码开发"}},[t._v("#")]),t._v(" 第二步：代码开发")]),t._v(" "),n("p",[t._v("说明：")]),t._v(" "),n("ol",[n("li",[t._v("使用Java编写spark程序，其实跟scala的步骤是一样的，只不过写法有点变化而已。")]),t._v(" "),n("li",[t._v("scala的RDD对应Java中的JavaRDD")]),t._v(" "),n("li",[t._v("scala的SparkContext对应Java中的JavaSparkContext")]),t._v(" "),n("li",[t._v("scala方法中的参数为函数时，在Java中要改成对象，因为Java是面向对象的，这是scala相对于Java非常不同的地方。")]),t._v(" "),n("li",[t._v("编写spark程序的大致步骤如下：")])]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("JavaPairRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("JavaRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("JavaSparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("FlatMapFunction"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("Function2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("PairFunction"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("scala"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("Tuple2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("Arrays"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("Iterator"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\npublic "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" MyJavaSpark "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    public static void main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//1、创建spark Conf")]),t._v("\n        SparkConf sparkConf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"WordCount"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//2、创建spark Context")]),t._v("\n        JavaSparkContext javaSparkContext "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" JavaSparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//3、读取数据")]),t._v("\n        JavaRDD"),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" stringJavaRDD "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" javaSparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"F:\\\\test\\\\aa.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//4、切分每一行数据为一个个单词")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" JavaRDD"),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" wordsRDD "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" stringJavaRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" FlatMapFunction"),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            public Iterator"),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" call"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),t._v(" s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" throws Exception "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" s1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" Arrays"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("asList"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iterator"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//5、每个单词计为1")]),t._v("\n        JavaPairRDD"),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" wordAndOneRDD "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" wordsRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mapToPair"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" PairFunction"),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            public Tuple2"),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" call"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),t._v(" s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" throws Exception "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Tuple2"),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//6、相同的单词累加1")]),t._v("\n        JavaPairRDD"),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" resultRDD "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" wordAndOneRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Function2"),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            public Integer call"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Integer v1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Integer v2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" throws Exception "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" v1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" v2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//7、收集数据")]),t._v("\n        List"),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tuple2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" collectRDD "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" resultRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//8、打印数据")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Tuple2"),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("collectRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            System"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"单词："')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"次数："')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//9、关闭资源")]),t._v("\n        javaSparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("运行结果为：")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("单词：hive次数：1\n单词：flink次数：1\n单词：spark次数：4\n单词：hadoop次数：3\n单词：flume次数：1\n单词：hbase次数：1\n")])])]),n("h2",{attrs:{id:"案例2-实现点击流日志数据分析"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#案例2-实现点击流日志数据分析"}},[t._v("#")]),t._v(" 案例2：实现点击流日志数据分析")]),t._v(" "),n("p",[t._v("点击流日志数据：用户在网站的浏览行为记录")]),t._v(" "),n("h5",{attrs:{id:"案例数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#案例数据"}},[t._v("#")]),t._v(" 案例数据")]),t._v(" "),n("p",[t._v("资料中的access.log文件，文件里一行数据的格式大致如下：")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v('60.208.6.156 - - [18/Sep/2013:06:49:48 +0000] "GET /wp-content/uploads/2013/07/rcassandra.png HTTP/1.0" 200 185524 "http://cos.name/category/software/packages/" "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36"\n')])])]),n("ol",[n("li",[t._v("数据中的横杠-也是一个字段， 表示无")]),t._v(" "),n("li",[t._v("一行数据代表一次访问。")]),t._v(" "),n("li",[t._v("第1个字段是用户的ip地址")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(1524),alt:"image-20200415221704529"}})]),t._v(" "),n("h5",{attrs:{id:"统计pv"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#统计pv"}},[t._v("#")]),t._v(" 统计PV")]),t._v(" "),n("p",[t._v("PV：页面浏览量，是网站各个网页被浏览的总次数。对应于access.log中的数据，一行数据就是一条浏览记录。")]),t._v(" "),n("p",[t._v("因此，要获取PV，实质是要统计access.log文件中行数。")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" PV "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkconf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"PV"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"E:\\\\LearningAll\\\\8-HadoopEcosystem-Video\\\\spark下载资料\\\\spark课程录播资料\\\\案例数据\\\\access.log"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" pv"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pv"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("运行结果为：")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("14619\n")])])]),n("h5",{attrs:{id:"统计uv"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#统计uv"}},[t._v("#")]),t._v(" 统计UV")]),t._v(" "),n("p",[t._v("UV（Unique Visitor）是独立访客数。放在这里就是有多少个不同的ip地址的访客访问过网站，相同ip地址的访客，无论访问网站多少次，都只算入UV一次。")]),t._v(" "),n("p",[t._v("因此，spark程序的大致步骤是：加载每一行数据，获取每一行数据的ip地址，对ip地址去重，然后统计ip数量。")]),t._v(" "),n("p",[t._v("代码开发:")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" PV "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkconf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"PV"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"E:\\\\LearningAll\\\\8-HadoopEcosystem-Video\\\\spark下载资料\\\\spark课程录播资料\\\\案例数据\\\\access.log"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取每一行的ip地址：")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//去重：")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd3"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("distinct"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" uv"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("uv"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("1050\n")])])]),n("h5",{attrs:{id:"获取被访问的topn页面地址"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#获取被访问的topn页面地址"}},[t._v("#")]),t._v(" 获取被访问的TopN页面地址")]),t._v(" "),n("p",[t._v("数据文件里每一行数据代表一次访问，每一行数据的第11个字段是被访问的页面地址，如")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token number"}},[t._v("60.208")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".6")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".156")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Sep"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2013")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("06")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("49")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("48")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"GET /wp-content/uploads/2013/07/rcassandra.png HTTP/1.0"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("185524")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://cos.name/category/software/packages/"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36"')]),t._v("\n")])])]),n("p",[t._v('中的"http://cos.name/category/software/packages/"。')]),t._v(" "),n("p",[t._v('但是，有些行的数据是不完整的，可能没有第11个字段，或者第11个字段的值是 "-" ，因此，我们首先要进行数据的处理，然后再分析数据。')]),t._v(" "),n("p",[t._v('注意，"-"中的双引号是包括在数据里面的，千万别少写了，特别注意下面代码块中的第11行代码。')]),t._v(" "),n("p",[t._v("代码开发")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" PV "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkconf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"PV"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"E:\\\\LearningAll\\\\8-HadoopEcosystem-Video\\\\spark下载资料\\\\spark课程录播资料\\\\案例数据\\\\access.log"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//处理数据，使得每一行数据至少有11个字段")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("filter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('//处理数据，使得每一行数据的第11个字段都不为 "-"，注意，双引号也包括在里面')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data3"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("filter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\"-\\""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取第11个字段")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd10"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//每个计1")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd10"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//统计")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("result1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//排序")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sortRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("result2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sortBy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取Top5")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" finalRes"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sortRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("take"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//打印：")]),t._v("\n    finalRes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("运行结果为：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://blog.fens.me/category/hadoop-action/"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("547")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://blog.fens.me/"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("377")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://blog.fens.me/wp-admin/post.php?post=2445&action=edit&message=10"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("360")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://blog.fens.me/r-json-rjson/"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("274")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://blog.fens.me/angularjs-webstorm-ide/"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("271")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h2",{attrs:{id:"案例3-读取文件数据写入到mysql表中"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#案例3-读取文件数据写入到mysql表中"}},[t._v("#")]),t._v(" 案例3：读取文件数据写入到mysql表中")]),t._v(" "),n("h5",{attrs:{id:"创建maven工程"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#创建maven工程"}},[t._v("#")]),t._v(" 创建maven工程")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependencies")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.spark"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("spark-core_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.3.3"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n     "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("mysql"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n     "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("mysql-connector-java"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n     "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("5.1.38"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\t"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependencies")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("h5",{attrs:{id:"案例数据-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#案例数据-2"}},[t._v("#")]),t._v(" 案例数据")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("1,tony,18\n2,xiaoqiang,20\n3,xiaoming,15\n4,laowang,45\n")])])]),n("h5",{attrs:{id:"创建mysql表"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#创建mysql表"}},[t._v("#")]),t._v(" 创建mysql表")]),t._v(" "),n("p",[t._v("在node03登录mysql,创建一个表，Person")]),t._v(" "),n("div",{staticClass:"language-sql extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sql"}},[n("code",[t._v("mysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("database")]),t._v(" demo1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nmysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" demo1\nmysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("name "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("varchar")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("age "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("h5",{attrs:{id:"通过foreach算子实现"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#通过foreach算子实现"}},[t._v("#")]),t._v(" 通过foreach算子实现")]),t._v(" "),n("p",[t._v("大致步骤：加载数据--》处理数据后将数据封装到RDD中--》foreach遍历数据，创建mysql连接，写入数据")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Connection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DriverManager"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" PreparedStatement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("RDD\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" Data2MysqlForeach "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkkconf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"ForeachMysql"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkkconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"E:\\\\LearningAll\\\\8-HadoopEcosystem-Video\\\\spark下载资料\\\\spark课程录播资料\\\\案例数据\\\\person.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('","')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    data2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" conne"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Connection "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//创建连接")]),t._v("\n        conne "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DriverManager"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getConnection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbc:mysql://node03:3306/demo1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"root"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"123456"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//定义sql语句，?是占位符")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sql1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"insert into person(id,name,age) values(?,?,?)"')]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取prepareStatement对象，这个对象可以对sql语句进行预编译")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ps "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" conne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("prepareStatement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sql1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//给sql语句的问号?赋值，1代表第一个问号，2代表第二个问号...")]),t._v("\n        ps"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        ps"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        ps"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//执行sql语句")]),t._v("\n        ps"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("execute"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("catch")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" ex"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Exception "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ex"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getMessage"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("finally")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conne"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("conne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("p",[t._v("查看mysql的person表,如下，已经写入成功：")]),t._v(" "),n("div",{staticClass:"language-sql extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sql"}},[n("code",[t._v("mysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+-----------+------+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" id   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" name      "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" age  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+-----------+------+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" laowang   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("45")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" tony      "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" xiaoqiang "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" xiaoming  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+-----------+------+")]),t._v("\n")])])]),n("p",[t._v("说明：")]),t._v(" "),n("ol",[n("li",[t._v("通过foreach算子来实现的话，观察代码，会发现，foreach每遍历一条数据，就会创建一个mysql连接，如果存在大量数据的话，无疑是很耗时的。")]),t._v(" "),n("li",[t._v("从person表可看到，插入的数据的顺序并不是跟源数据一致的，这是因为受到了多个分区并行执行的影响。")])]),t._v(" "),n("h5",{attrs:{id:"通过foreachpartition算子实现"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#通过foreachpartition算子实现"}},[t._v("#")]),t._v(" 通过foreachPartition算子实现")]),t._v(" "),n("p",[t._v("通过foreachPartition来实现与foreach来实现的源代码差不多，只需要修改几个地方,代码如下：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Connection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DriverManager"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" PreparedStatement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("RDD\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" Data2MysqlForeachPartition "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkkconf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"ForeachMysql"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkkconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"E:\\\\LearningAll\\\\8-HadoopEcosystem-Video\\\\spark下载资料\\\\spark课程录播资料\\\\案例数据\\\\person.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('","')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    data2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreachPartition"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("iter"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" conne"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Connection "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//创建连接")]),t._v("\n        conne "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DriverManager"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getConnection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbc:mysql://node03:3306/demo1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"root"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"123456"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//定义sql语句，?是占位符")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sql1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"insert into person(id,name,age) values(?,?,?)"')]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取prepareStatement对象，这个对象可以对sql语句进行预编译")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ps "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" conne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("prepareStatement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sql1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//给sql语句的问号?赋值，1代表第一个问号，2代表第二个问号...")]),t._v("\n        iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          ps"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          ps"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          ps"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n          ps"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addBatch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//执行sql语句")]),t._v("\n        ps"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("executeBatch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("catch")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" ex"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Exception "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ex"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getMessage"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("finally")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conne"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("conne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("p",[t._v("再次查看person表：")]),t._v(" "),n("div",{staticClass:"language-sql extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sql"}},[n("code",[t._v("mysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+-----------+------+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" id   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" name      "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" age  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+-----------+------+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" laowang   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("45")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" tony      "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" xiaoqiang "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" xiaoming  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" tony      "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" laowang   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("45")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" xiaoqiang "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" xiaoming  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+-----------+------+")]),t._v("\n")])])]),n("h5",{attrs:{id:"小结"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),n("ol",[n("li",[n("p",[t._v("foreach算子实现获取得到一条一条的数据之后，然后进行获取对应的数据库连接，实现把数据插入到mysql表中，这里rdd中有N条数据，这里就需要与mysql数据库创建N次连接，它是比较浪费资源")])]),t._v(" "),n("li",[n("p",[t._v("foreachPartition算子实现以分区为单位与mysql数据库来创建数据库连接，可以大大减少与mysql数据创建的连接数，有助于程序的性能提升。所以后期推荐大家使用foreachPartition算子")])])]),t._v(" "),n("h2",{attrs:{id:"案例4-读取文件数据写入到hbase表中"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#案例4-读取文件数据写入到hbase表中"}},[t._v("#")]),t._v(" 案例4：读取文件数据写入到hbase表中")]),t._v(" "),n("h5",{attrs:{id:"案例数据-3"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#案例数据-3"}},[t._v("#")]),t._v(" 案例数据")]),t._v(" "),n("p",[t._v("数据是资料中的users.dat文件，数据的大致格式如下，以::为分隔符，一共5个字段，分别是id,gender,age,position,code")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("1::F::1::10::48067\n2::M::56::16::70072\n3::M::25::15::55117\n4::M::45::7::02460\n5::M::25::20::55455\n6::F::50::9::55117\n7::M::35::1::06810\n")])])]),n("h5",{attrs:{id:"添加pom依赖-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#添加pom依赖-2"}},[t._v("#")]),t._v(" 添加pom依赖")]),t._v(" "),n("p",[t._v("在之前案例的pom的基础上，添加以下依赖：")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[t._v("        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.hbase"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("hbase-client"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("1.2.1"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("h5",{attrs:{id:"创建hbase表"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#创建hbase表"}},[t._v("#")]),t._v(" 创建hbase表")]),t._v(" "),n("p",[t._v("确保hbase、hadoop、zookeeper都正常开启，进入hbase shell，创建表person")]),t._v(" "),n("div",{staticClass:"language-sql extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sql"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("start")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sh\n\nhbase shell\n\nhbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("001")]),t._v(":"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'person'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'f1'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'f2'")]),t._v("\n")])])]),n("h5",{attrs:{id:"代码开发"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#代码开发"}},[t._v("#")]),t._v(" 代码开发")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("HBaseConfiguration"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TableName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("client"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Connection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ConnectionFactory"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" Data2Hbase "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkConf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hbase"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"E:\\\\LearningAll\\\\8-HadoopEcosystem-Video\\\\spark下载资料\\\\spark课程录播资料\\\\案例数据\\\\users.dat"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"::"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    data2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreachPartition"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("iter"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" conne"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Connection"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("HBaseConfiguration"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hbase.zookeeper.quorum"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01:2181,node02:2181,node03:2181"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        conne"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ConnectionFactory"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createConnection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" tablePerson"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("conne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getTable"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("TableName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("valueOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"person"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" put"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getBytes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addColumn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"f1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getBytes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"gender"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getBytes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getBytes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addColumn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"f1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getBytes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getBytes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getBytes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addColumn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"f1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getBytes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"position"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getBytes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getBytes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addColumn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"f1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getBytes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"code"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getBytes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getBytes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          tablePerson"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("put"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("catch")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" ex"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Exception "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ex"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getMessage"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("finally")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conne"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("conne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("p",[t._v("查看hbase中的person表，部分数据如下：")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[t._v("scan "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'person'")]),t._v("                                                                                  \n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("999")]),t._v("                 "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("column")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("f1:age, "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1586981613489")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),t._v("                   \n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("999")]),t._v("                 "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("column")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("f1:code, "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1586981613489")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("62558")]),t._v("               \n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("999")]),t._v("                 "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("column")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("f1:gender, "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1586981613489")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("M                 \n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("999")]),t._v("                 "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("column")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("f1:position, "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("timestamp")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1586981613489")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("value")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),t._v("   \n")])])]),n("h2",{attrs:{id:"案例5-实现ip地址查询"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#案例5-实现ip地址查询"}},[t._v("#")]),t._v(" 案例5：实现ip地址查询")]),t._v(" "),n("h5",{attrs:{id:"需求分析"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#需求分析"}},[t._v("#")]),t._v(" 需求分析")]),t._v(" "),n("p",[t._v("在互联网中，我们经常会见到城市热点图这样的报表数据，例如在百度统计中，会统计今年的热门旅游城市、热门报考学校等，会将这样的信息显示在热点图中。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1525),alt:"1579070050537"}})]),t._v(" "),n("p",[t._v("要想实现上面热点图效果，我们需要通过日志信息（运行商或者网站自己生成）和城市ip段信息来判断用户的ip段，统计热点经纬度。")]),t._v(" "),n("p",[t._v("示意图：基站下放给用户可以上网的ip地址，通过这个ip地址就可以定位用户的坐标（经纬度）。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1526),alt:"image-20200416043037480"}})]),t._v(" "),n("h5",{attrs:{id:"案例数据-4"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#案例数据-4"}},[t._v("#")]),t._v(" 案例数据")]),t._v(" "),n("p",[t._v("1、日志信息数据: 20090121000132.394251.http.format")]),t._v(" "),n("p",[t._v("各字段分别表示：时间戳|ip地址|.......,只需要留意前2个字段")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1527),alt:"1579070153331"}})]),t._v(" "),n("p",[t._v("2、城市ip段信息数据: ip.txt，类似于码表数据")]),t._v(" "),n("p",[t._v("开始数字和结束数字分别是开始ip和结束ip经过算法计算得到的值。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1528),alt:"1579070232110"}})]),t._v(" "),n("h5",{attrs:{id:"开发思路"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#开发思路"}},[t._v("#")]),t._v(" 开发思路")]),t._v(" "),n("p",[t._v("1、 加载城市ip段信息，获取ip起始数字和结束数字，经度，维度")]),t._v(" "),n("p",[t._v("2、 加载日志数据，获取ip信息，然后使用相同的算法将ip转换为数字，和ip段比较")]),t._v(" "),n("p",[t._v("3、 比较的时候采用二分法查找，找到对应的经度和维度")]),t._v(" "),n("p",[t._v("4、 然后对经度和维度做单词计数")]),t._v(" "),n("h5",{attrs:{id:"广播变量"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#广播变量"}},[t._v("#")]),t._v(" 广播变量")]),t._v(" "),n("p",[t._v("在本次的ip案例中，要将日志数据中的每个ip都拿去跟城市ip信息数据进行匹配，为每个日志数据中的ip匹配对应的经纬度，而如果每个task都加载一份城市ip信息数据到内存中的话，无疑是非常消耗内存的，因此需要将城市ip信息数据封装在广播变量里，作为共享数据。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1529),alt:"image-20200416123110870"}})]),t._v(" "),n("h5",{attrs:{id:"代码实现"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#代码实现"}},[t._v("#")]),t._v(" 代码实现")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("RDD\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" CityIp "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" ip2Long"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ip"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ipSpl"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ip"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\."')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" ipLong"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0L")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("<-")]),t._v("ipSpl"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      ipLong"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toLong "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" ipLong"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<<")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8L")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    ipLong\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" binarySearch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ipLong"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cityIp"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//定义码表数组的起始下标：")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" startIndex"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//定义码表数组的结束下标：")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" endIndex"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("cityIp"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("startIndex"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v("endIndex"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" middleIndex"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("startIndex"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("endIndex"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//如果正好满足中间的元组的IP数值")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ipLong "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" cityIp"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("middleIndex"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toLong "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" ipLong"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v("cityIp"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("middleIndex"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toLong"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" middleIndex\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ipLong "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" cityIp"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("middleIndex"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toLong"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        startIndex"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("middleIndex"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ipLong"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("cityIp"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("middleIndex"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toLong"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        endIndex"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("middleIndex\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//-1表示下标没有找到")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkconf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Ip"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//加载ip码表数据")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ipData"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"E:\\\\LearningAll\\\\8-HadoopEcosystem-Video\\\\spark下载资料\\\\spark课程录播资料\\\\案例数据\\\\ip.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//处理ip码表数据")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ipData2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ipData"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\|"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//创建广播变量")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" bdIP"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("broadcast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ipData2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//加载运营商日志数据")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" logData"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"E:\\\\LearningAll\\\\8-HadoopEcosystem-Video\\\\spark下载资料\\\\spark课程录播资料\\\\案例数据\\\\20090121000132.394251.http.format"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//处理运营商日志数据")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" logIps"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("logData"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\|"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//遍历日志数据中的每个ip，将ip转为Long类型数值")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" andOneRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("logIps"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mapPartitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("iter"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取广播变量的数据")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" cityIp"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("bdIP"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//遍历日志的ip，将ip转为数值")]),t._v("\n      iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ipLong"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ip2Long"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取ipLong在ip码表对应的索引数值（获取ipLong处在城市ipx信息表的第几行的ip数值区间）")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" index"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("binarySearch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ipLong"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cityIp"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toInt\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取下标对应的经纬度等信息")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" resultJW"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("cityIp"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("index"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//封装数据,作为返回值")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resultJW"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("resultJW"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_4"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//相同的经纬度出现累加1")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" finalResult"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("andOneRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//打印数据：")]),t._v("\n    finalResult"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("p",[t._v("运行结果为：")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("((106.51107,106.51107),91)\n((108.948024,108.948024),1824)\n((114.502461,114.502461),383)\n((106.27633,106.27633),36)\n((102.712251,102.712251),126)\n((107.08166,107.08166),29)\n((116.405285,116.405285),1535)\n((107.7601,107.7601),85)\n((107.39007,107.39007),47)\n((106.57434,106.57434),177)\n((106.56347,106.56347),3)\n((106.504962,106.504962),400)\n")])])]),n("h5",{attrs:{id:"小结-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#小结-2"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),n("p",[t._v("该案例比较贴近实际的真实需求，含金量是比较高，这里使用了广播变量知识点、二分查询、ip地址转成Long类型数字，大家多多练习！掌握spark中的RDD编程。")]),t._v(" "),n("h2",{attrs:{id:"spark程序的序列化问题"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark程序的序列化问题"}},[t._v("#")]),t._v(" spark程序的序列化问题")]),t._v(" "),n("h4",{attrs:{id:"transformation操作为什么需要序列化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#transformation操作为什么需要序列化"}},[t._v("#")]),t._v(" transformation操作为什么需要序列化")]),t._v(" "),n("p",[t._v("spark是分布式执行引擎，其核心抽象是弹性分布式数据集RDD，其代表了分布在不同节点的数据。Spark的计算是在executor上分布式执行的，所以用户执行RDD的map，flatMap，reduceByKey等transformation 操作时可能有如下执行过程：")]),t._v(" "),n("ol",[n("li",[t._v("代码中对象在driver本地序列化")]),t._v(" "),n("li",[t._v("对象序列化后传输到远程executor节点")]),t._v(" "),n("li",[t._v("远程executor节点反序列化对象")]),t._v(" "),n("li",[t._v("最终远程节点执行")])]),t._v(" "),n("p",[t._v("这些操作要序列化的原因：")]),t._v(" "),n("p",[t._v("我们知道，transformation这些算子都是要传入参数的，而且很多的参数都是函数，类似于闭包，闭包可简单理解成“定义在一个函数内部的函数”。")]),t._v(" "),n("p",[t._v("假如说作为算子参数的函数是：x=>(x,外部定义的对象或变量等)，外部定义的对象或变量等是在driver端创建的，那么如果作为算子参数的函数要使用外部的东西，就要从driver端拉取外部对象等过来到当前executor，从而使用。")]),t._v(" "),n("p",[t._v("因此，对象在执行中需要序列化通过网络传输，则必须经过序列化过程。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1530),alt:"image-20200416162320980"}})]),t._v(" "),n("h4",{attrs:{id:"spark的任务序列化异常原因"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark的任务序列化异常原因"}},[t._v("#")]),t._v(" spark的任务序列化异常原因")]),t._v(" "),n("h5",{attrs:{id:"报错的可能原因"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#报错的可能原因"}},[t._v("#")]),t._v(" 报错的可能原因")]),t._v(" "),n("p",[t._v("在编写spark程序中，由于在map，foreachPartition等算子内部使用了外部定义的变量和函数，从而引发Task未序列化问题。")]),t._v(" "),n("p",[t._v("然而spark算子在计算过程中使用外部变量在许多情形下确实在所难免，比如在filter算子根据外部指定的条件进行过滤，map根据相应的配置进行变换。")]),t._v(" "),n("p",[t._v("经常会出现“org.apache.spark.SparkException: Task not serializable”这个错误，出现这个错误的原因可能是：")]),t._v(" "),n("ol",[n("li",[t._v("这些算子使用了外部的变量，但是这个变量不能序列化。")]),t._v(" "),n("li",[t._v("当前类使用了“extends Serializable”声明支持序列化，但是由于某些字段不支持序列化，仍然会导致整个类序列化时出现问题，最终导致出现Task未序列化问题。")])]),t._v(" "),n("h5",{attrs:{id:"示例1"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#示例1"}},[t._v("#")]),t._v(" 示例1：")]),t._v(" "),n("p",[t._v("数据库连接定义在了foreachPartition算子外部，当算子内部要使用该连接时，就出现了序列化错误。这是因为这个数据库连接是在driver端构建的，而数据库连接没有实现序列化，无法传输到不同机器的executor，就报错了。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1531),alt:"image-20200416163718819"}})]),t._v(" "),n("h5",{attrs:{id:"示例2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#示例2"}},[t._v("#")]),t._v(" 示例2：")]),t._v(" "),n("p",[t._v("看下图，serialDemo是在object外部定义的类，虽然serialDemo extends Serializable实现序列化，但是，因为该类里面的数据库连接是conne是不支持序列化的，导致序列化不成功。虽然引用的是name变量，但还是报错了。")]),t._v(" "),n("p",[t._v("如果函数中使用了该类对象的成员变量，该类除了要实现序列化之外，"),n("strong",[t._v("所有的成员变量必须要实现序列化")]),t._v("。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1532),alt:"image-20200416164933460"}})]),t._v(" "),n("h4",{attrs:{id:"spark中解决序列化问题的办法"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark中解决序列化问题的办法"}},[t._v("#")]),t._v(" spark中解决序列化问题的办法")]),t._v(" "),n("ol",[n("li",[t._v("如果函数中使用了该类对象，该类要实现序列化，序列化方法：class xxx extends Serializable{}")]),t._v(" "),n("li",[t._v("如果函数中使用了该类对象的成员变量，该类除了要实现序列化之外，所有的成员变量必须要实现序列化")]),t._v(" "),n("li",[t._v("对于不能序列化的成员变量使用**“@transient”**标注，告诉编译器不需要序列化")]),t._v(" "),n("li",[t._v("也可将依赖的变量独立放到一个小的class中，让这个class支持序列化，这样做可以减少网络传输量，提高效率。")]),t._v(" "),n("li",[t._v("可以把对象的创建直接在该函数中构建这样避免需要序列化")])]),t._v(" "),n("p",[t._v("因此，遵从这些方法，将上面示例2中的代码改成如下就可以运行成功了：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Connection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DriverManager"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" PreparedStatement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" serialDemo "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" Serializable "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"krystal"')]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@transient")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conne "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DriverManager"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getConnection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbc:mysql://node03:3306/demo1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"root"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"123456"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" Data2MysqlForeachPartition "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkkconf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"ForeachMysql"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkkconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" to "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sd"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" serialDemo"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("sd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("运行结果为：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("krystal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("krystal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("krystal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("krystal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("krystal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("krystal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("krystal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("krystal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("krystal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("krystal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h2",{attrs:{id:"spark-on-yarn"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark-on-yarn"}},[t._v("#")]),t._v(" spark on yarn")]),t._v(" "),n("p",[t._v("spark程序可以提交到yarn中去运行，此时spark任务所需要的计算资源由yarn中的老大ResourceManager去分配")]),t._v(" "),n("p",[t._v("官网资料地址: http://spark.apache.org/docs/2.3.3/running-on-yarn.html")]),t._v(" "),n("h4",{attrs:{id:"环境准备"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#环境准备"}},[t._v("#")]),t._v(" 环境准备")]),t._v(" "),n("ol",[n("li",[t._v("安装hadoop集群")]),t._v(" "),n("li",[t._v("安装spark环境")])]),t._v(" "),n("p",[t._v("注意：")]),t._v(" "),n("p",[t._v("这里不需要安装spark集群，只需要解压spark安装包到任意一台服务器，然后修改文件spark-env.sh:")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#指定java的环境变量")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("JAVA_HOME")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/kkb/install/jdk1.8.0_141\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#指定hadoop的配置文件目录")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("HADOOP_CONF_DIR")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/kkb/install/hadoop-2.6.0-cdh5.14.2/etc/hadoop\n")])])]),n("p",[t._v("因为我们之前安装过了spark集群，包含了spark环境，所以我们不需要做任何操作")]),t._v(" "),n("h4",{attrs:{id:"sparkonyarn模式"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparkonyarn模式"}},[t._v("#")]),t._v(" sparkOnYarn模式")]),t._v(" "),n("p",[t._v("按照Spark应用程序中的driver分布方式不同，Spark on YARN有两种模式：")]),t._v(" "),n("ol",[n("li",[t._v("yarn-client模式")]),t._v(" "),n("li",[t._v("yarn-cluster`模式")])]),t._v(" "),n("h5",{attrs:{id:"yarn-cluster模式"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#yarn-cluster模式"}},[t._v("#")]),t._v(" yarn-cluster模式")]),t._v(" "),n("p",[t._v("提交spark的测试程序到yarn运行：")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("spark-submit --class org.apache.spark.examples.SparkPi "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--master "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("yarn")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--deploy-mode cluster "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--driver-memory 1g "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--executor-memory 1g "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n/kkb/install/spark/examples/jars/spark-examples_2.11-2.3.3.jar "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#特别注意 ")]),t._v("\n\t--master 的值是yarn\n\t--deploy-mode 的值是cluster，表示使用cluster模式运行\n")])])]),n("p",[t._v("如果运行出现错误，可能是虚拟内存不足，可以添加参数")]),t._v(" "),n("p",[t._v("vim yarn-site.xml")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--容器是否会执行物理内存限制，默认为True--\x3e")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("yarn.nodemanager.pmem-check-enabled"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("false"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--容器是否会执行虚拟内存限制，默认为True--\x3e")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("yarn.nodemanager.vmem-check-enabled"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("false"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("p",[t._v("说明：")]),t._v(" "),n("p",[t._v("1、使用cluster集群模式时，如果在运行中途，在运行窗口界面按ctrl+c是终止不了spark程序的运行的，虽然窗口不再有打印输出，但是程序还是在运行着的。如下：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1533),alt:"image-20200416173857717"}})]),t._v(" "),n("p",[t._v("2、ctrl+c停止打印输出后，我们去查看http://node01:8088/cluster的信息，发现该任务执行成功了：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1534),alt:"image-20200416174244879"}})]),t._v(" "),n("p",[t._v("3、点击该Application的ID，查看log,可看到运行结果：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1535),alt:"image-20200416174653942"}})]),t._v(" "),n("p",[t._v("4、即使不使用ctrl+c中断打印信息的输出，程序在运行完成后（state：Finished代表运行完成），在Linux的运行输出窗口依然是看不到Pi的结果输出的。这跟cluster模式运行有关。")]),t._v(" "),n("h5",{attrs:{id:"yarn-client模式"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#yarn-client模式"}},[t._v("#")]),t._v(" yarn-client模式")]),t._v(" "),n("p",[t._v("提交spark的测试程序到yarn运行：")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("spark-submit --class org.apache.spark.examples.SparkPi "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--master "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("yarn")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--deploy-mode client "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--driver-memory 1g "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--executor-memory 1g "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n/kkb/install/spark/examples/jars/spark-examples_2.11-2.3.3.jar "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("\n")])])]),n("p",[t._v("说明：")]),t._v(" "),n("ol",[n("li",[t._v("在client模式下，如果ctrl+c中断了输出，等同于停止了程序的运行。")]),t._v(" "),n("li",[t._v("在client模式下，可以在Linux的运行输出窗口看到Pi结果的输出")])]),t._v(" "),n("h4",{attrs:{id:"两种模式的原理"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#两种模式的原理"}},[t._v("#")]),t._v(" 两种模式的原理")]),t._v(" "),n("p",[t._v("首先来回顾以下MapReduce程序运行在yarn的大致流程：")]),t._v(" "),n("ol",[n("li",[t._v("客户端与ResourceManager进行通信，申请Application")]),t._v(" "),n("li",[t._v("客户端提交jar包到hdfs")]),t._v(" "),n("li",[t._v("RM向集群的某个NodeManager申请开启ApplicationMaster,该NM就启动一个Container，在该Container里面启动ApplicationMaster")]),t._v(" "),n("li",[t._v("ApplicationMaster向RM申请在某些NodeManager启动容器，给task运行，然后NM就会启动一些Container给task运行")])]),t._v(" "),n("h5",{attrs:{id:"yarn-cluster模式原理"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#yarn-cluster模式原理"}},[t._v("#")]),t._v(" yarn-cluster模式原理：")]),t._v(" "),n("p",[t._v("结合yanr的工作机制,yarn-cluter模式执行spark程序的大致流程如下：")]),t._v(" "),n("ol",[n("li",[t._v("客户端提交Application到RM")]),t._v(" "),n("li",[t._v("RM找到某个节点上NodeManager，申请Container来启动一个ApplicationMaster。")]),t._v(" "),n("li",[t._v("ApplicationMaster启动后，会在内部构建一个spark context对象。SparkContext的底层调度器由taskScheduler变成了YarnClusterScheduler。")]),t._v(" "),n("li",[t._v("在之前了解到，SparkContext对象是在Driver端的，因此，Driver端也是在该ApplicationMaster进程内部的。ApplicationMaster跟driver端捆绑在一起了，ApplicationMaster在哪里，driver端就在哪里。")]),t._v(" "),n("li",[t._v("构建好SparkContext对象后，ApplicationMaster会向RM申请计算资源Container。")]),t._v(" "),n("li",[t._v("然后在某些NodeManager节点上就会启动Container,在Container上启动executor")]),t._v(" "),n("li",[t._v("最后，YarnClusterScheduler就会提交task到executor上运行")])]),t._v(" "),n("p",[t._v("了解yarn-cluster模式的机制后，就可以理解：为什么ctrl+c终止客户端终端停止不了spark程序的运行了。")]),t._v(" "),n("p",[t._v("这是因为Driver端跟客户端不在同一个节点，比如客户端在node01,而nodemanager和dirver都在node02。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1536),alt:"image-20200416191119359"}})]),t._v(" "),n("h5",{attrs:{id:"yarn-client模式原理"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#yarn-client模式原理"}},[t._v("#")]),t._v(" yarn-client模式原理：")]),t._v(" "),n("p",[t._v("client模式与cluster模式的流程很相似，只不过是Driver端的位置发生了变化，Driver端跟客户端捆绑在了一起，YarnClusterScheduler也变成了YarnClientScheduler。")]),t._v(" "),n("p",[t._v("因此，当使用client模式时，如果我们停掉了客户端终端，就相当于停掉了Driver端，导致程序运行失败。这也是我们输出日志显示不停地尝试连接Driver端的原因。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1537),alt:"yarn-client"}})]),t._v(" "),n("h4",{attrs:{id:"两种模式的区别"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#两种模式的区别"}},[t._v("#")]),t._v(" 两种模式的区别")]),t._v(" "),n("p",[t._v("yarn-cluster模式")]),t._v(" "),n("ul",[n("li",[t._v("spark程序的"),n("strong",[t._v("Driver程序在YARN中运行")]),t._v("，运行结果不能在客户端显示，并且客户端可以在启动应用程序后消失应用的。")]),t._v(" "),n("li",[t._v("最好运行那些将结果最终保存在外部存储介质（如HDFS、Redis、Mysql），客户端的终端显示的仅是作为YARN的job的简单运行状况。")])]),t._v(" "),n("p",[t._v("yarn-client模式")]),t._v(" "),n("ul",[n("li",[t._v("spark程序的"),n("strong",[t._v("Driver运行在Client上")]),t._v("，应用程序运行结果会在客户端显示，所有适合运行结果有输出的应用程序（如spark-shell）")])]),t._v(" "),n("p",[t._v("总结")]),t._v(" "),n("ol",[n("li",[t._v("最大的区别就是Driver端的位置不一样。")]),t._v(" "),n("li",[t._v("yarn-cluster: Driver端运行在yarn集群中，与ApplicationMaster进程在一起。")]),t._v(" "),n("li",[t._v("yarn-client:  Driver端运行在提交任务的客户端,与ApplicationMaster进程没关系,经常用于进行测试")])]),t._v(" "),n("h2",{attrs:{id:"collect-算子操作剖析"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#collect-算子操作剖析"}},[t._v("#")]),t._v(" collect 算子操作剖析")]),t._v(" "),n("p",[t._v("collect算子操作的作用：")]),t._v(" "),n("ol",[n("li",[t._v("它是一个action操作，会触发任务的运行")]),t._v(" "),n("li",[t._v("它会把RDD的数据进行收集之后，以数组的形式返回给Driver端")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(1538),alt:"collect"}})]),t._v(" "),n("p",[t._v("总结：")]),t._v(" "),n("ol",[n("li",[n("p",[t._v("默认Driver端的内存大小为1G，由参数 spark.driver.memory 设置。")])]),t._v(" "),n("li",[n("p",[t._v("如果某个rdd的数据量超过了Driver端默认的1G内存，对rdd调用collect操作，这里会出现Driver端的内存溢出（OOM），所有这个"),n("strong",[t._v("collect操作存在一定的风险，实际开发代码一般不会使用")]),t._v("。比如说rdd的数据量达到了10G，rdd.collect这个操作非常危险，很有可能出现driver端的内存不足")])]),t._v(" "),n("li",[n("p",[t._v("广播变量也会占用Driver端一定的内存空间。")])]),t._v(" "),n("li",[n("p",[t._v("实际企业中一般都会把该参数调大，比如5G/10G等。")]),t._v(" "),n("p",[t._v("可以在代码中修改该参数，如下")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark.driver.memory"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"5G"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])]),t._v(" "),n("h2",{attrs:{id:"spark任务中资源参数剖析"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark任务中资源参数剖析"}},[t._v("#")]),t._v(" spark任务中资源参数剖析")]),t._v(" "),n("p",[t._v("通过开发工具开发好spark程序后达成jar包最后提交到集群中运行")]),t._v(" "),n("p",[t._v("提交任务脚本如下")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("spark-submit "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--master spark://node01:7077,node02:7077 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--class com.kaikeba.WordCountOnSpark "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--executor-memory 1g  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--total-executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\noriginal-spark_class03-1.0-SNAPSHOT.jar "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n/words.txt  /out\n")])])]),n("h4",{attrs:{id:"executor-memory"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#executor-memory"}},[t._v("#")]),t._v(" --executor-memory")]),t._v(" "),n("ul",[n("li",[t._v("表示每一个executor进程需要的内存大小，它决定了后期操作数据的速度")])]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("比如说一个rdd的数据量大小为5g,这里给定的executor-memory为2g, 在这种情况下，内存是存储不下，它会把一部分数据保存在内存中，还有一部分数据保存在磁盘，后续需要用到该rdd的结果数据，可以从内存和磁盘中获取得到，这里就涉及到一定的磁盘io操作。\n\n,这里给定的executor-memory为10g，这里数据就可以完全在内存中存储下，后续需要用到该rdd的数据，就可以直接从内存中获取，这样一来，避免了大量的磁盘io操作。性能得到提升。\n\n\n在实际的工作，这里 --executor-memory 需要设置的大一点。\n比如说10G/20G/30G等\n")])])]),n("h4",{attrs:{id:"total-executor-cores"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#total-executor-cores"}},[t._v("#")]),t._v(" --total-executor-cores")]),t._v(" "),n("p",[t._v("--total-executor-cores表示任务运行需要总的cpu核数，它决定了任务并行运行的粒度")]),t._v(" "),n("p",[t._v("比如说要处理100个task，注意一个cpu在同一时间只能处理一个task线程。")]),t._v(" "),n("ol",[n("li",[n("p",[t._v("如果给定的总的cpu核数是5个，这里就需要100/5=20个批次才可以把这100个task运行完成，如果平均每个task运行1分钟，这里最后一共运行20分钟。")])]),t._v(" "),n("li",[n("p",[t._v("如果给定的总的cpu核数是20个，这里就需要100/20=5个批次才可以把这100个task运行完成，如果平均每个task运行1分钟，这里最后一共运行5分钟。")])]),t._v(" "),n("li",[n("p",[t._v("如果如果给定的总的cpu核数是100个，这里就需要100/100=1个批次才可以把这100个task运行完成，如果平均每个task运行1分钟，这里最后一共运行1分钟。")])])]),t._v(" "),n("p",[t._v("在实际的生产环境中，--total-executor-cores 这个参数一般也会设置的大一点，比如说 30个/50个/100个")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1539),alt:"image-20200416204239271"}})]),t._v(" "),n("h4",{attrs:{id:"总结"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),n("p",[t._v("后期对于spark程序的优化，可以从这2个参数入手，无论你把哪一个参数调大，对程序运行的效率来说都会达到一定程度的提升，加大计算资源它是最直接、最有效果的优化手段。")]),t._v(" "),n("p",[t._v("在计算资源有限的情况下，可以考虑其他方面，比如说代码层面，JVM层面等")]),t._v(" "),n("h2",{attrs:{id:"spark的shuffle原理分析"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark的shuffle原理分析"}},[t._v("#")]),t._v(" spark的shuffle原理分析")]),t._v(" "),n("h4",{attrs:{id:"shuffle概述"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#shuffle概述"}},[t._v("#")]),t._v(" shuffle概述")]),t._v(" "),n("p",[t._v("Shuffle就是对数据进行重组，由于分布式计算的特性和要求，在实现细节上更加繁琐和复杂。")]),t._v(" "),n("p",[t._v("在MapReduce框架，Shuffle是连接Map和Reduce之间的桥梁，Map阶段通过shuffle读取数据并输出到对应的Reduce；而Reduce阶段负责从Map端拉取数据并进行计算。")]),t._v(" "),n("p",[t._v("在整个shuffle过程中，往往伴随着大量的磁盘和网络I/O。所以shuffle性能的高低也直接决定了整个程序的性能高低。"),n("strong",[t._v("Spark也会有自己的shuffle实现过程。")])]),t._v(" "),n("p",[t._v("MapReduce Shuffle流程图：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1540),alt:"mapreduce_shuffle"}})]),t._v(" "),n("h4",{attrs:{id:"spark中的shuffle介绍"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark中的shuffle介绍"}},[t._v("#")]),t._v(" spark中的shuffle介绍")]),t._v(" "),n("p",[t._v("在DAG调度的过程中，Stage阶段的划分是根据是否有shuffle过程，也就是存在wide Dependency宽依赖的时候,需要进行shuffle,这时候会将作业job划分成多个Stage，每一个stage内部有很多可以并行运行的task。")]),t._v(" "),n("p",[t._v("stage与stage之间的过程就是shuffle阶段，在Spark的中，负责shuffle过程的执行、计算和处理的组件主要就是ShuffleManager，也即shuffle管理器。ShuffleManager随着Spark的发展有两种实现的方式，分别为HashShuffleManager和SortShuffleManager，因此spark的Shuffle有Hash Shuffle和Sort Shuffle两种。")]),t._v(" "),n("h4",{attrs:{id:"hashshuffle机制"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#hashshuffle机制"}},[t._v("#")]),t._v(" HashShuffle机制")]),t._v(" "),n("h5",{attrs:{id:"hashshuffle概述"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#hashshuffle概述"}},[t._v("#")]),t._v(" HashShuffle概述")]),t._v(" "),n("p",[t._v("在Spark 1.2以前，默认的shuffle计算引擎是HashShuffleManager。")]),t._v(" "),n("p",[t._v("该ShuffleManager-HashShuffleManager有着一个非常严重的弊端，就是会产生大量的中间磁盘文件，进而由大量的磁盘IO操作影响了性能。因此在Spark 1.2以后的版本中，默认的ShuffleManager改成了SortShuffleManager。")]),t._v(" "),n("p",[t._v("SortShuffleManager相较于HashShuffleManager来说，有了一定的改进。主要就在于每个Task在进行shuffle操作时，虽然也会产生较多的临时磁盘文件，但是最后会将所有的临时文件合并(merge)成一个磁盘文件，因此每个Task就只有一个磁盘文件。在下一个stage的shuffle read task拉取自己的数据时，只要根据索引读取每个磁盘文件中的部分数据即可。")]),t._v(" "),n("p",[t._v("HashShuffleManager的运行机制主要分成两种:")]),t._v(" "),n("ol",[n("li",[t._v("一种是"),n("strong",[t._v("普通运行机制")])]),t._v(" "),n("li",[t._v("另一种是"),n("strong",[t._v("合并的运行机制")]),t._v("。合并机制主要是通过复用buffer来优化Shuffle过程中产生的小文件的数量。")])]),t._v(" "),n("p",[t._v("Hash shuffle是不具有排序的Shuffle。")]),t._v(" "),n("h5",{attrs:{id:"普通机制的hash-shuffle"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#普通机制的hash-shuffle"}},[t._v("#")]),t._v(" 普通机制的Hash shuffle")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1541),alt:"未优化的HashShuffle机制"}})]),t._v(" "),n("p",[n("strong",[t._v("图解")])]),t._v(" "),n("p",[t._v("这里我们先明确一个假设前提：每个Executor只有1个CPU core，也就是说，无论这个Executor上分配多少个task线程，同一时间都只能执行一个task线程。")]),t._v(" "),n("p",[t._v("图中有3个ReduceTask，从ShuffleMapTask 开始那边各自把自己进行 Hash 计算(分区器：hash/numreduce取模)，分类出3个不同的类别，每个 ShuffleMapTask 都分成3种类别的数据，想把不同的数据汇聚然后计算出最终的结果，所以ReduceTask 会在属于自己类别的数据收集过来，汇聚成一个同类别的大集合，每1个ShuffleMapTask输出3份本地文件，这里有4个ShuffleMapTask，所以总共输出了4 x 3个分类文件 = 12个本地小文件。")]),t._v(" "),n("p",[n("strong",[t._v("shuffle Write阶段")])]),t._v(" "),n("p",[t._v("主要就是在一个stage结束计算之后，为了下一个stage可以执行shuffle类的算子(比如reduceByKey，groupByKey)，而将每个task处理的数据按key进行“分区”。所谓“分区”，就是对相同的key执行hash算法，从而将相同key都写入同一个磁盘文件中，而每一个磁盘文件都只属于reduce端的stage的一个task。在将数据写入磁盘之前，会先将数据写入内存缓冲Buffer中，当内存缓冲填满之后，才会溢写到磁盘文件中去。")]),t._v(" "),n("p",[t._v("那么每个执行shuffle write的task，要为下一个stage创建多少个磁盘文件呢? 很简单，下一个stage的task有多少个，当前stage的每个task就要创建多少份磁盘文件。比如下一个stage总共有100个task，那么当前stage的每个task都要创建100份磁盘文件。如果当前stage有50个task，总共有10个Executor，每个Executor执行5个Task，那么每个Executor上总共就要创建500个磁盘文件，所有Executor上会创建5000个磁盘文件。由此可见，未经优化的shuffle write操作所产生的磁盘文件的数量是极其惊人的。")]),t._v(" "),n("p",[n("strong",[t._v("shuffle Read阶段")])]),t._v(" "),n("p",[t._v("shuffle read，通常就是一个stage刚开始时要做的事情。此时该stage的每一个task就需要将上一个stage的计算结果中的所有相同key，从各个节点上通过网络都拉取到自己所在的节点上，然后进行key的聚合或连接等操作。由于shuffle write的过程中，task给Reduce端的stage的每个task都创建了一个磁盘文件，因此shuffle read的过程中，每个task只要从上游stage的所有task所在节点上，拉取属于自己的那一个磁盘文件即可。")]),t._v(" "),n("p",[t._v("shuffle read的拉取过程是一边拉取一边进行聚合的。每个shuffle read task都会有一个自己的buffer缓冲，每次都只能拉取与buffer缓冲相同大小的数据，然后通过内存中的一个Map进行聚合等操作。聚合完一批数据后，再拉取下一批数据，并放到buffer缓冲中进行聚合操作。以此类推，直到最后将所有数据到拉取完，并得到最终的结果。")]),t._v(" "),n("p",[n("strong",[t._v("注意")])]),t._v(" "),n("ol",[n("li",[n("p",[t._v("buffer起到的是缓存作用，缓存能够加速写磁盘，提高计算的效率,shuffle write task buffer的默认大小32k,shuffle read task buffer的默认大小是48M。")])]),t._v(" "),n("li",[n("p",[t._v("分区器：根据hash/numRedcue取模决定数据由几个Reduce处理，也决定了写入几个buffer中")])]),t._v(" "),n("li",[n("p",[t._v("block file：磁盘小文件，从图中我们可以知道磁盘小文件的个数计算公式：\nblock file=M*R")])]),t._v(" "),n("li",[n("p",[t._v("M为map task的数量，R为Reduce的数量，一般Reduce的数量等于buffer的数量，都是由分区器决定的")])])]),t._v(" "),n("p",[n("strong",[t._v("Hash shuffle普通机制的问题")])]),t._v(" "),n("p",[t._v("（1)Shuffle阶段在磁盘上会产生海量的小文件，建立通信和拉取数据的次数变多,此时会产生大量耗时低效的 IO 操作 (因为产生过多的小文件)")]),t._v(" "),n("p",[t._v("（2)可能导致OOM，大量耗时低效的 IO 操作 ，导致写磁盘时的对象过多，读磁盘时候的对象也过多，这些对象存储在堆内存中，会导致堆内存不足，相应会导致频繁的GC，GC会导致OOM。由于内存中需要保存海量文件操作句柄和临时信息，如果数据处理的规模比较庞大的话，内存不可承受，会出现 OOM 等问题")]),t._v(" "),n("h5",{attrs:{id:"合并机制的hash-shuffle"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#合并机制的hash-shuffle"}},[t._v("#")]),t._v(" 合并机制的Hash shuffle")]),t._v(" "),n("p",[t._v("合并机制就是复用buffer缓冲区，开启合并机制的配置是spark.shuffle.consolidateFiles。该参数默认值为false，将其设置为true即可开启优化机制。")]),t._v(" "),n("p",[t._v("通常来说，如果我们使用HashShuffleManager，那么都建议开启这个选项。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1542),alt:"优化后的Shuffle机制"}})]),t._v(" "),n("ul",[n("li",[n("strong",[t._v("图解")])])]),t._v(" "),n("p",[t._v("这里有6个这里有6个shuffleMapTask，数据类别还是分成3种类型，因为Hash算法会根据你的 Key 进行分类，在同一个进程中，无论是有多少过Task，都会把同样的Key放在同一个Buffer里，然后把Buffer中的数据写入以Core数量为单位的本地文件中，(一个Core只有一种类型的Key的数据)。")]),t._v(" "),n("p",[t._v("每1个Task所在的进程中，分别写入共同进程中的3份本地文件，这里有6个shuffleMapTasks，所以总共输出是 2个Cores x 3个分类文件 = 6个本地小文件。")]),t._v(" "),n("ul",[n("li",[n("strong",[t._v("注意")])])]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("、启动HashShuffle的合并机制ConsolidatedShuffle的配置：\n\tspark.shuffle.consolidateFiles"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("true\n\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("、block "),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("file")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Core*R  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#产生文件的数量")]),t._v("\n\tCore为CPU的核数，R为ReduceTask的数量\n")])])]),n("ul",[n("li",[n("strong",[t._v("Hash shuffle合并机制的问题")])])]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("  \t如果 Reducer 端的并行任务或者是数据分片过多的话则 Core * Reducer Task 依旧过大，也会产生很多小文件。\n")])])]),n("h4",{attrs:{id:"sort-shuffle机制"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sort-shuffle机制"}},[t._v("#")]),t._v(" Sort shuffle机制")]),t._v(" "),n("p",[t._v("SortShuffleManager的运行机制主要分成两种，")]),t._v(" "),n("ul",[n("li",[t._v("一种是"),n("strong",[t._v("普通运行机制")])]),t._v(" "),n("li",[t._v("另一种是"),n("strong",[t._v("bypass运行机制")])])]),t._v(" "),n("h5",{attrs:{id:"sort-shuffle的普通机制"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sort-shuffle的普通机制"}},[t._v("#")]),t._v(" Sort shuffle的普通机制")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1543),alt:"sortshuffle"}})]),t._v(" "),n("ul",[n("li",[n("strong",[t._v("图解")])])]),t._v(" "),n("p",[t._v("在该模式下，数据会先写入一个数据结构，聚合算子写入Map，一边通过Map局部聚合，一边写入内存。Join算子写入ArrayList直接写入内存中。然后需要判断是否达到阈值（5M），如果达到就会将内存数据结构的数据写入到磁盘，清空内存数据结构。")]),t._v(" "),n("p",[t._v("在溢写磁盘前，先根据key进行排序，排序过后的数据，会分批写入到磁盘文件中。默认批次为10000条，数据会以每批一万条写入到磁盘文件。写入磁盘文件通过缓冲区溢写的方式，每次溢写都会产生一个磁盘文件，也就是说一个task过程会产生多个临时文件.")]),t._v(" "),n("p",[t._v("最后在每个task中，将所有的临时文件合并，这就是merge过程，此过程将所有临时文件读取出来，一次写入到最终文件。意味着一个task的所有数据都在这一个文件中。同时单独写一份索引文件，标识下游各个task的数据在文件中的索引start offset和end offset。")]),t._v(" "),n("p",[t._v("这样算来如果第一个stage 50个task，每个Executor执行一个task，那么无论下游有几个task，就需要50*2=100个磁盘文件。")]),t._v(" "),n("ul",[n("li",[n("strong",[t._v("好处")])])]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("  1. 小文件明显变少了，一个task只生成一个file文件\n  \n  2. file文件整体有序，加上索引文件的辅助，查找变快，虽然排序浪费一些性能，但是查找变快很多\n")])])]),n("h5",{attrs:{id:"bypass模式的sortshuffle"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#bypass模式的sortshuffle"}},[t._v("#")]),t._v(" bypass模式的sortShuffle")]),t._v(" "),n("p",[t._v("bypass机制运行条件")]),t._v(" "),n("ul",[n("li",[t._v("shuffle map task数量小于spark.shuffle.sort.bypassMergeThreshold参数的值")]),t._v(" "),n("li",[t._v("不是聚合类的shuffle算子（比如reduceByKey）")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(1544),alt:"bypasssortshuffle"}})]),t._v(" "),n("ul",[n("li",[n("strong",[t._v("好处")])])]),t._v(" "),n("p",[t._v("该机制与sortshuffle的普通机制相比，在shuffleMapTask不多的情况下，首先写的机制是不同，其次不会进行排序。这样就可以节约一部分性能开销。")]),t._v(" "),n("ul",[n("li",[n("strong",[t._v("总结")])])]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("在shuffleMapTask数量小于默认值200时，启用bypass模式的sortShuffle(原因是数据量本身比较少，没必要进行sort全排序，因为数据量少本身查询速度就快，正好省了sort的那部分性能开销。)\n \n 该机制与普通SortShuffleManager运行机制的不同在于：\n    第一: 磁盘写机制不同；\n    第二: 不会进行sort排序；\n")])])]),n("h2",{attrs:{id:"spark-shuffle参数调优"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark-shuffle参数调优"}},[t._v("#")]),t._v(" Spark Shuffle参数调优")]),t._v(" "),n("p",[n("strong",[t._v("spark.shuffle.file.buffer")])]),t._v(" "),n("ul",[n("li",[t._v("默认值：32k")]),t._v(" "),n("li",[t._v("参数说明：该参数用于设置shuffle write task的BufferedOutputStream的buffer缓冲大小。将数据写到磁盘文件之前，会先写入buffer缓冲中，待缓冲写满之后，才会溢写到磁盘。")]),t._v(" "),n("li",[t._v("调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如64k），从而减少shuffle write过程中溢写磁盘文件的次数，也就可以减少磁盘IO次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。")])]),t._v(" "),n("p",[n("strong",[t._v("spark.reducer.maxSizeInFlight")])]),t._v(" "),n("ul",[n("li",[t._v("默认值：48m")]),t._v(" "),n("li",[t._v("参数说明：该参数用于设置shuffle read task的buffer缓冲大小，而这个buffer缓冲决定了每次能够拉取多少数据。")]),t._v(" "),n("li",[t._v("调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如96m），从而减少拉取数据的次数，也就可以减少网络传输的次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。")])]),t._v(" "),n("p",[n("strong",[t._v("spark.shuffle.io.maxRetries")])]),t._v(" "),n("ul",[n("li",[t._v("默认值：3")]),t._v(" "),n("li",[t._v("参数说明：shuffle read task从shuffle write task所在节点拉取属于自己的数据时，如果因为网络异常导致拉取失败，是会自动进行重试的。该参数就代表了可以重试的最大次数。如果在指定次数之内拉取还是没有成功，就可能会导致作业执行失败。")]),t._v(" "),n("li",[t._v("调优建议：对于那些包含了特别耗时的shuffle操作的作业，建议增加重试最大次数（比如60次），以避免由于JVM的full gc或者网络不稳定等因素导致的数据拉取失败。在实践中发现，对于针对超大数据量（数十亿~上百亿）的shuffle过程，调节该参数可以大幅度提升稳定性。")])]),t._v(" "),n("p",[n("strong",[t._v("spark.shuffle.io.retryWait")])]),t._v(" "),n("ul",[n("li",[t._v("默认值：5s")]),t._v(" "),n("li",[t._v("参数说明：具体解释同上，该参数代表了每次重试拉取数据的等待间隔，默认是5s。")]),t._v(" "),n("li",[t._v("调优建议：建议加大间隔时长（比如60s），以增加shuffle操作的稳定性。")])]),t._v(" "),n("p",[n("strong",[t._v("spark.shuffle.memoryFraction")]),t._v("（Spark1.6是这个参数，1.6以后参数变了，具体参考上一讲Spark内存模型知识）")]),t._v(" "),n("ul",[n("li",[t._v("默认值：0.2")]),t._v(" "),n("li",[t._v("参数说明：该参数代表了Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是20%。")]),t._v(" "),n("li",[t._v("调优建议：在资源参数调优中讲解过这个参数。如果内存充足，而且很少使用持久化操作，建议调高这个比例，给shuffle read的聚合操作更多内存，以避免由于内存不足导致聚合过程中频繁读写磁盘。在实践中发现，合理调节该参数可以将性能提升10%左右。")])]),t._v(" "),n("p",[n("strong",[t._v("spark.shuffle.manager")])]),t._v(" "),n("ul",[n("li",[t._v("默认值：sort")]),t._v(" "),n("li",[t._v("参数说明：该参数用于设置ShuffleManager的类型。Spark 1.5以后，有三个可选项：hash、sort和tungsten-sort。HashShuffleManager是Spark 1.2以前的默认选项，但是Spark 1.2以及之后的版本默认都是SortShuffleManager了。Spark1.6以后把hash方式给移除了，tungsten-sort与sort类似，但是使用了tungsten计划中的堆外内存管理机制，内存使用效率更高。")]),t._v(" "),n("li",[t._v("调优建议：由于SortShuffleManager默认会对数据进行排序，因此如果你的业务逻辑中需要该排序机制的话，则使用默认的SortShuffleManager就可以；而如果你的业务逻辑不需要对数据进行排序，那么建议参考后面的几个参数调优，通过bypass机制或优化的HashShuffleManager来避免排序操作，同时提供较好的磁盘读写性能。这里要注意的是，tungsten-sort要慎用，因为之前发现了一些相应的bug。")])]),t._v(" "),n("p",[n("strong",[t._v("spark.shuffle.sort.bypassMergeThreshold")])]),t._v(" "),n("ul",[n("li",[t._v("默认值：200")]),t._v(" "),n("li",[t._v("参数说明：当ShuffleManager为SortShuffleManager时，如果shuffle read task的数量小于这个阈值（默认是200），则shuffle write过程中不会进行排序操作，而是直接按照未经优化的HashShuffleManager的方式去写数据，但是最后会将每个task产生的所有临时磁盘文件都合并成一个文件，并会创建单独的索引文件。")]),t._v(" "),n("li",[t._v("调优建议：当你使用SortShuffleManager时，如果的确不需要排序操作，那么建议将这个参数调大一些，大于shuffle read task的数量。那么此时就会自动启用bypass机制，map-side就不会进行排序了，减少了排序的性能开销。但是这种方式下，依然会产生大量的磁盘文件，因此shuffle write性能有待提高。")])]),t._v(" "),n("h2",{attrs:{id:"数据倾斜原理和现象分析"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#数据倾斜原理和现象分析"}},[t._v("#")]),t._v(" 数据倾斜原理和现象分析")]),t._v(" "),n("h4",{attrs:{id:"数据倾斜概述"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#数据倾斜概述"}},[t._v("#")]),t._v(" 数据倾斜概述")]),t._v(" "),n("p",[t._v("有的时候，我们可能会遇到大数据计算中一个最棘手的问题——数据倾斜，此时Spark作业的性能会比期望差很多。")]),t._v(" "),n("p",[t._v("数据倾斜调优，就是使用各种技术方案解决不同类型的数据倾斜问题，以保证Spark作业的性能。")]),t._v(" "),n("h4",{attrs:{id:"数据倾斜发生时的现象"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#数据倾斜发生时的现象"}},[t._v("#")]),t._v(" 数据倾斜发生时的现象")]),t._v(" "),n("p",[t._v("1、绝大多数task执行得都非常快，但个别task执行极慢")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("\t你的大部分的task，都执行的特别快，很快就执行完了，剩下几个task，执行的特别特别慢，\n前面的task，一般10s可以执行完5个；最后发现某个task，要执行1个小时，2个小时才能执行完一个task。\n\t\n\t这个时候就出现数据倾斜了。\n这种方式还算好的，因为虽然老牛拉破车一样，非常慢，但是至少还能跑。\n")])])]),n("p",[t._v("2、绝大数task执行很快，有的task直接报OOM (Jvm Out Of Memory) 异常")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("\t运行的时候，其他task都很快执行完了，也没什么特别的问题；但是有的task，就是会突然间报了一个OOM，JVM Out Of Memory，内存溢出了，task failed，task lost，resubmitting task等日志异常信息。反复执行几次都到了某个task就是跑不通，最后就挂掉。\n\n\t某个task就直接OOM，那么基本上也是因为数据倾斜了，task分配的数量实在是太大了！！！所以内存放不下，然后你的task每处理一条数据，还要创建大量的对象。内存爆掉了。\n")])])]),n("h4",{attrs:{id:"数据倾斜发生的原理"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#数据倾斜发生的原理"}},[t._v("#")]),t._v(" 数据倾斜发生的原理")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1545),alt:"数据倾斜"}})]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("如上图所示：\n\t在进行任务计算shuffle操作的时候，第一个task和第二个task各分配到了1万条数据；需要5分钟计算完毕；第一个和第二个task，可能同时在5分钟内都运行完了；第三个task要98万条数据，98 * 5 = 490分钟 = 8个小时；\n\t本来另外两个task很快就运行完毕了（5分钟），第三个task数据量比较大，要8个小时才能运行完，就导致整个spark作业，也得8个小时才能运行完。最终导致整个spark任务计算特别慢。\n")])])]),n("h4",{attrs:{id:"数据倾斜如何定位原因"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#数据倾斜如何定位原因"}},[t._v("#")]),t._v(" 数据倾斜如何定位原因")]),t._v(" "),n("h6",{attrs:{id:"方法1-主要是根据log日志信息去定位"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#方法1-主要是根据log日志信息去定位"}},[t._v("#")]),t._v(" 方法1：主要是根据log日志信息去定位")]),t._v(" "),n("p",[t._v("数据倾斜只会发生在shuffle过程中。这里给大家罗列一些常用的并且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。")]),t._v(" "),n("p",[t._v("出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。因为某个或者某些key对应的数据，远远的高于其他的key。")]),t._v(" "),n("h6",{attrs:{id:"方法2-分析定位逻辑"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#方法2-分析定位逻辑"}},[t._v("#")]),t._v(" 方法2：分析定位逻辑")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("\t由于代码中有大量的shuffle操作，一个job会划分成很多个stage，首先要看的，就是数据倾斜发生在第几个stage中。\n\t可以在任务运行的过程中，观察任务的UI界面，可以观察到每一个stage中运行的task的数据量，从而进一步确定是不是task分配的数据不均匀导致了数据倾斜。\n\t比如下图中，倒数第三列显示了每个task的运行时间。明显可以看到，有的task运行特别快，只需要几秒钟就可以运行完;而有的task运行特别慢，需要几分钟才能运行完，此时单从运行时间上看就已经能够确定发生数据倾斜了。\n\t此外，倒数第一列显示了每个task处理的数据量，明显可以看到，运行时间特别短的task只需要处理几百KB的数据即可，而运行时间特别长的task需要处理几千KB的数据，处理的数据量差了10倍。此时更加能够确定是发生了数据倾斜。\n")])])]),n("p",[n("img",{attrs:{src:a(1546),alt:"20170308091203159"}})]),t._v(" "),n("h6",{attrs:{id:"方法3-某个task莫名其妙内存溢出的情况"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#方法3-某个task莫名其妙内存溢出的情况"}},[t._v("#")]),t._v(" 方法3：某个task莫名其妙内存溢出的情况")]),t._v(" "),n("p",[t._v("这种情况下去定位出问题的代码就比较容易了。我们建议直接看yarn-client模式下本地log的异常栈，或者是通过YARN查看yarn-cluster模式下的log中的异常栈。")]),t._v(" "),n("p",[t._v("一般来说，通过异常栈信息就可以定位到你的代码中哪一行发生了内存溢出。然后在那行代码附近找找，一般也会有shuffle类算子，此时很可能就是这个算子导致了数据倾斜。")]),t._v(" "),n("p",[t._v("但是大家要注意的是，不能单纯靠偶然的内存溢出就判定发生了数据倾斜。因为自己编写的代码的bug，以及偶然出现的数据异常，也可能会导致内存溢出。因此还是要按照上面所讲的方法，通过Spark Web UI查看报错的那个stage的各个task的运行时间以及分配的数据量，才能确定是否是由于数据倾斜才导致了这次内存溢出。")]),t._v(" "),n("h6",{attrs:{id:"方法4-查看导致数据倾斜的key的数据分布情况"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#方法4-查看导致数据倾斜的key的数据分布情况"}},[t._v("#")]),t._v(" 方法4：查看导致数据倾斜的key的数据分布情况")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("\t知道了数据倾斜发生在哪里之后，通常需要分析一下那个执行了shuffle操作并且导致了数据倾斜的RDD/Hive表，查看一下其中key的分布情况。这主要是为之后选择哪一种技术方案提供依据。针对不同的key分布与不同的shuffle算子组合起来的各种情况，可能需要选择不同的技术方案来解决。\n此时根据你执行操作的情况不同，可以有很多种查看key分布的方式：\n\t如果是Spark SQL中的group by、join语句导致的数据倾斜，那么就查询一下SQL中使用的表的key分布情况。\n\t如果是对Spark RDD执行shuffle算子导致的数据倾斜，那么可以在Spark作业中加入查看key分布的代码，比如RDD.countByKey()。然后对统计出来的各个key出现的次数，collect/take到客户端打印一下，就可以看到key的分布情况。\n\t举例来说，对于上面所说的单词计数程序，如果确定了是stage1的reduceByKey算子导致了数据倾斜，那么就应该看看进行reduceByKey操作的RDD中的key分布情况，在这个例子中指的就是pairs RDD。如下示例，我们可以先对pairs采样10%的样本数据，然后使用countByKey算子统计出每个key出现的次数，最后在客户端遍历和打印样本数据中各个key的出现次数。\n")])])]),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sampledPairs "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pairs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sample"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sampledWordCounts "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sampledPairs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("countByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsampledWordCounts"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//sample算子时用来抽样用的，其有3个参数")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//withReplacement：表示抽出样本后是否在放回去，true表示会放回去，这也就意味着抽出的样本可能有重复")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//fraction ：抽出多少，这是一个double类型的参数,0-1之间，eg:0.3表示抽出30%")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//seed：表示一个种子，根据这个seed随机抽取，一般情况下只用前两个参数就可以，那么这个参数是干嘛的呢，这个参数一般用于调试，有时候不知道是程序出问题还是数据出了问题，就可以将这个参数设置为定值")]),t._v("\n")])])]),n("h4",{attrs:{id:"数据倾斜原因总结"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#数据倾斜原因总结"}},[t._v("#")]),t._v(" 数据倾斜原因总结")]),t._v(" "),n("p",[t._v("数据本身问题")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("（1）、key本身分布不均衡（包括大量的key为空）\n（2）、key的设置不合理\n")])])]),n("p",[t._v("spark使用不当的问题")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("（1）、shuffle时的并发度不够\n（2）、计算方式有误\t\n")])])]),n("h4",{attrs:{id:"数据倾斜的后果"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#数据倾斜的后果"}},[t._v("#")]),t._v(" 数据倾斜的后果")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("（1）spark中的stage的执行时间受限于最后那个执行完成的task,因此运行缓慢的任务会拖垮整个程序的运行速度（分布式程序运行的速度是由最慢的那个task决定的）。\n\n（2）过多的数据在同一个task中运行，将会把executor内存撑爆，导致OOM内存溢出。\n")])])]),n("h2",{attrs:{id:"spark中数据倾斜的解决方案"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark中数据倾斜的解决方案"}},[t._v("#")]),t._v(" spark中数据倾斜的解决方案")]),t._v(" "),n("h5",{attrs:{id:"解决方案一-使用hive-etl预处理数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#解决方案一-使用hive-etl预处理数据"}},[t._v("#")]),t._v(" 解决方案一：使用Hive ETL预处理数据")]),t._v(" "),n("p",[t._v("方案适用场景："),n("strong",[t._v("导致数据倾斜的是Hive表")]),t._v("。如果该Hive表中的数据本身很不均匀(比如某个key对应了100万数据，其他key才对应了10条数据)，而且业务场景需要频繁使用Spark对Hive表执行某个分析操作，那么比较适合使用这种技术方案。")]),t._v(" "),n("p",[t._v("方案实现思路：此时可以评估一下，是否可以通过Hive来进行数据预处理(即通过Hive ETL预先对数据按照key进行聚合，或者是预先和其他表进行join)，然后在"),n("strong",[t._v("Spark作业中针对的数据源就不是原来的Hive表了，而是预处理后的Hive表")]),t._v("。此时由于数据已经预先进行过聚合或join操作了，那么在Spark作业中也就不需要使用原先的shuffle类算子执行这类操作了。")]),t._v(" "),n("p",[t._v("方案实现原理：这种方案从根源上解决了数据倾斜，因为彻底避免了在Spark中执行shuffle类算子，那么肯定就不会有数据倾斜的问题了。但是这里也要提醒一下大家，这种方式属于治标不治本。因为毕竟数据本身就存在分布不均匀的问题，所以Hive ETL中进行group by或者join等shuffle操作时，还是会出现数据倾斜，导致Hive ETL的速度很慢。我们"),n("strong",[t._v("只是把数据倾斜的发生提前到了Hive ETL中，避免Spark程序发生数据倾斜而已")]),t._v("。")]),t._v(" "),n("p",[t._v("方案优点：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，"),n("strong",[t._v("Spark作业的性能会大幅度提升")]),t._v("。")]),t._v(" "),n("p",[t._v("方案缺点："),n("strong",[t._v("治标不治本，Hive ETL中还是会发生数据倾斜")]),t._v("。")]),t._v(" "),n("p",[t._v("方案实践经验：在一些Java系统与Spark结合使用的项目中，会出现Java代码频繁调用Spark作业的场景，而且对Spark作业的执行性能要求很高，就比较适合使用这种方案。将数据倾斜提前到上游的Hive ETL，每天仅执行一次，只有那一次是比较慢的，而之后每次Java调用Spark作业时，执行速度都会很快，能够提供更好的用户体验。")]),t._v(" "),n("p",[t._v("项目实践经验：有一个交互式用户行为分析系统中使用了这种方案，该系统主要是允许用户通过Java Web系统提交数据分析统计任务，后端通过Java提交Spark作业进行数据分析统计。要求Spark作业速度必须要快，尽量在10分钟以内，否则速度太慢，用户体验会很差。所以我们将有些Spark作业的shuffle操作提前到了Hive ETL中，从而让Spark直接使用预处理的Hive中间表，尽可能地减少Spark的shuffle操作，大幅度提升了性能，将部分作业的性能提升了6倍以上。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1547),alt:"交互式用户行为分析系统"}})]),t._v(" "),n("h5",{attrs:{id:"解决方案二-过滤少数导致倾斜的key"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#解决方案二-过滤少数导致倾斜的key"}},[t._v("#")]),t._v(" 解决方案二：过滤少数导致倾斜的key")]),t._v(" "),n("p",[t._v("方案适用场景：如果发现"),n("strong",[t._v("导致倾斜的key就少数几个，而且对计算本身的影响并不大")]),t._v("的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。")]),t._v(" "),n("p",[t._v("方案实现思路：如果我们判断那少数几个数据量特别多的key，对作业的执行和计算结果不是特别重要的话，那么干脆就"),n("strong",[t._v("直接过滤掉那少数几个key")]),t._v("。比如，在Spark SQL中可以使用where子句过滤掉这些key或者在Spark Core中对RDD执行filter算子过滤掉这些key。如果需要每次作业执行时，动态判定哪些key的数据量最多然后再进行过滤，那么可以使用sample算子对RDD进行采样，然后计算出每个key的数量，取数据量最多的key过滤掉即可。")]),t._v(" "),n("p",[t._v("方案实现原理：将导致数据倾斜的key给过滤掉之后，这些key就不会参与计算了，自然不可能产生数据倾斜。")]),t._v(" "),n("p",[t._v("方案优点：实现简单，而且效果也很好，可以完全规避掉数据倾斜。")]),t._v(" "),n("p",[t._v("方案缺点：适用场景不多，"),n("strong",[t._v("大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个")]),t._v("。")]),t._v(" "),n("p",[t._v("方案实践经验：在项目中我们也采用过这种方案解决数据倾斜。有一次发现某一天Spark作业在运行的时候突然OOM了，追查之后发现，是Hive表中的某一个key在那天数据异常，导致数据量暴增。因此就采取每次执行前先进行采样，计算出样本中数据量最大的几个key之后，直接在程序中将那些key给过滤掉。")]),t._v(" "),n("h5",{attrs:{id:"解决方案三-提高shuffle操作的并行度-效果差"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#解决方案三-提高shuffle操作的并行度-效果差"}},[t._v("#")]),t._v(" 解决方案三：提高shuffle操作的并行度("),n("strong",[t._v("效果差")]),t._v(")")]),t._v(" "),n("p",[t._v("方案适用场景：如果我们必须要对数据倾斜迎难而上，那么建议优先使用这种方案，因为这是处理数据倾斜最简单的一种方案。")]),t._v(" "),n("p",[t._v("方案实现思路：在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个shuffle算子执行时shuffle read task的数量。对于Spark SQL中的shuffle类语句，比如group by、join等，需要设置一个参数，即spark.sql.shuffle.partitions，该参数代表了shuffle read task的并行度，该值默认是200，对于很多场景来说都有点过小。")]),t._v(" "),n("p",[t._v("方案实现原理：增加shuffle read task的数量，可以让原本分配给一个task的多个key分配给多个task，从而让每个task处理比原来更少的数据。举例来说，如果原本有5个key，每个key对应10条数据，这5个key都是分配给一个task的，那么这个task就要处理50条数据。而增加了shuffle read task以后，每个task就分配到一个key，即每个task就处理10条数据，那么自然每个task的执行时间都会变短了。具体原理如下图所示。")]),t._v(" "),n("p",[t._v("方案优点：实现起来比较简单，可以有效缓解和减轻数据倾斜的影响。")]),t._v(" "),n("p",[t._v("方案缺点：只是缓解了数据倾斜而已，没有彻底根除问题，根据实践经验来看，其"),n("strong",[t._v("效果有限")]),t._v("。")]),t._v(" "),n("p",[t._v("方案实践经验：该方案通常无法彻底解决数据倾斜，因为如果出现一些极端情况，比如某个key对应的数据量有100万，那么无论你的task数量增加到多少，这个对应着100万数据的key肯定还是会分配到一个task中去处理，因此注定还是会发生数据倾斜的。所以这种方案只能说是在发现数据倾斜时尝试使用的第一种手段，尝试去用最简单的方法缓解数据倾斜而已，或者是和其他方案结合起来使用。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1548),alt:"1570609831990"}})]),t._v(" "),n("h5",{attrs:{id:"解决方案四-两阶段聚合-局部聚合-全局聚合"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#解决方案四-两阶段聚合-局部聚合-全局聚合"}},[t._v("#")]),t._v(" 解决方案四：两阶段聚合（局部聚合+全局聚合）")]),t._v(" "),n("p",[t._v("方案适用场景："),n("strong",[t._v("对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时")]),t._v("，比较适用这种方案。")]),t._v(" "),n("p",[t._v("方案实现思路：这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先"),n("strong",[t._v("给每个key都打上一个随机数")]),t._v("，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后"),n("strong",[t._v("将各个key的前缀给去掉")]),t._v("，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。")]),t._v(" "),n("p",[t._v("方案实现原理：将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。具体原理见下图。")]),t._v(" "),n("p",[t._v("方案优点：对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。")]),t._v(" "),n("p",[t._v("方案缺点："),n("strong",[t._v("仅仅适用于聚合类的shuffle操作，适用范围相对较窄")]),t._v("。如果是join类的shuffle操作，还得用其他的解决方案。")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//案例")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//  如果使用reduceByKey因为数据倾斜造成运行失败的问题。具体操作流程如下:")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//    (1) 将原始的 key 转化为  随机值 + key  (随机值 = Random.nextInt)")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//    (2) 对数据进行 reduceByKey(func)")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//    (3) 将  随机值+key 转成 key")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//    (4) 再对数据进行 reduceByKey(func)")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" WordCountAggTest "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"WordCount"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" array "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"you you"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"you you"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"you you"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"you you"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"you you"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"you you"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"you you"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jump jump"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" line "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" line"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" prefix "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" util"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nextInt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("prefix"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"_"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("word"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n       "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" wc "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" newWord"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("wc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"_"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" count"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("wc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2\n         "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newWord"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("count"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n       "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" wc "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"单词："')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("wc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" 次数："')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("wc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n注：我们这儿使用的是reduceByKey天然的有调优的效果，如果这儿是groupBykey那么发生数据倾斜的概率就会更大，更严重。\n")])])]),n("h5",{attrs:{id:"解决方案五-将reduce-join转为map-join"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#解决方案五-将reduce-join转为map-join"}},[t._v("#")]),t._v(" 解决方案五：将reduce join转为map join")]),t._v(" "),n("p",[t._v("方案适用场景：在"),n("strong",[t._v("对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小")]),t._v("（比如几百M或者一两G），比较适用此方案。")]),t._v(" "),n("p",[t._v("方案实现思路：不使用join算子进行连接操作，而"),n("strong",[t._v("使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作")]),t._v("，彻底避免数据倾斜的发生和出现。将较小RDD中的数据直接通过collect算子拉取到Driver端的内存中来，然后对其创建一个Broadcast变量；接着对另外一个RDD执行map类算子，在算子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。")]),t._v(" "),n("p",[t._v("方案实现原理：普通的join是会走shuffle过程的，而一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join，此时就是reduce join。但是如果一个RDD是比较小的，则可以采用广播小RDD全量数据+map算子来实现与join同样的效果，也就是map join，此时就不会发生shuffle操作，也就不会发生数据倾斜。具体原理如下图所示。")]),t._v(" "),n("p",[t._v("方案优点：对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。")]),t._v(" "),n("p",[t._v("方案缺点：适用场景较少，因为这个方案"),n("strong",[t._v("只适用于一个大表和一个小表的情况")]),t._v("。毕竟我们需要将小表进行广播，此时会比较消耗内存资源，driver和每个Executor内存中都会驻留一份小RDD的全量数据。如果我们广播出去的RDD数据比较大，比如10G以上，那么就可能发生内存溢出了。因此并不适合两个都是大表的情况。")]),t._v(" "),n("p",[t._v("![reduce joinz转换为map join ](spark.assets/reduce joinz转换为map join .png)")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" MapJoinTest "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n \n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"WordCount"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" lista"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      Tuple2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"001"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"令狐冲"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      Tuple2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"002"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"任盈盈"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n     "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//数据量小一点")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" listb"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      Tuple2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"001"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"一班"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      Tuple2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"002"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"二班"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" listaRDD "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lista"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" listbRDD "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("listb"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//val result: RDD[(String, (String, String))] = listaRDD.join(listbRDD)")]),t._v("\n     "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//设置广播变量")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" listbBoradcast "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("broadcast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("listbRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    listaRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("  tuple "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" key "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tuple"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" name "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tuple"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" map "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" listbBoradcast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toMap\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" className "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("className"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" tuple "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"班级号"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("tuple"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" 姓名："')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("tuple"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" 班级名："')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("tuple"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h5",{attrs:{id:"解决方案六-采样倾斜key并分拆join操作"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#解决方案六-采样倾斜key并分拆join操作"}},[t._v("#")]),t._v(" 解决方案六：采样倾斜key并分拆join操作")]),t._v(" "),n("p",[t._v("方案适用场景：两个RDD/Hive表进行join的时候，如果数据量都比较大，无法采用“解决方案五”，那么此时可以看一下两个RDD/Hive表中的key分布情况。"),n("strong",[t._v("如果出现数据倾斜，是因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀")]),t._v("，那么采用这个解决方案是比较合适的。")]),t._v(" "),n("p",[t._v("方案实现思路：\n　　1、对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，"),n("strong",[t._v("计算出来数据量最大的是哪几个key")]),t._v("。\n　　2、然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key形成另外一个RDD。\n　　3、接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀，不会导致倾斜的大部分key也形成另外一个RDD。\n　　4、再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，"),n("strong",[t._v("此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。")]),t._v("\n　　5、而另外两个普通的RDD就照常join即可。\n　　6、最后将两次join的结果使用union算子合并起来即可，就是最终的join结果。")]),t._v(" "),n("p",[t._v("方案实现原理：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，可以将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。")]),t._v(" "),n("p",[t._v("方案优点：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，采用该方式可以用最有效的方式打散key进行join。而且只需要针对少数倾斜key对应的数据进行扩容n倍，不需要对全量数据进行扩容。避免了占用过多内存。")]),t._v(" "),n("p",[t._v("方案缺点：如果导致倾斜的key特别多的话，比如成千上万个key都导致数据倾斜，那么这种方式也不适合。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1549),alt:"随机前缀和扩容RDD"}})]),t._v(" "),n("h5",{attrs:{id:"解决方案七-使用随机前缀和扩容rdd进行join"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#解决方案七-使用随机前缀和扩容rdd进行join"}},[t._v("#")]),t._v(" 解决方案七：使用随机前缀和扩容RDD进行join")]),t._v(" "),n("p",[t._v("方案适用场景：如果在进行join操作时，RDD中有大量的key导致数据倾斜，那么进行分拆key也没什么意义，此时就只能使用这一种方案来解决问题了。")]),t._v(" "),n("p",[t._v("方案实现思路：\n　　1、该方案的实现思路基本和“解决方案六”类似，首先查看RDD/Hive表中的数据分布情况，找到那个造成数据倾斜的RDD/Hive表，比如有多个key都对应了超过1万条数据。\n　　2、然后将该RDD的每条数据都打上一个n以内的随机前缀。\n　　3、同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，扩容出来的每条数据都依次打上一个0~n的前缀。\n　　4、最后将两个处理后的RDD进行join即可。")]),t._v(" "),n("p",[t._v("方案实现原理：将原先一样的key通过附加随机前缀变成不一样的key，然后就可以将这些处理后的“不同key”分散到多个task中去处理，而不是让一个task处理大量的相同key。该方案与“解决方案六”的不同之处就在于，上一种方案是尽量只对少数倾斜key对应的数据进行特殊处理，由于处理过程需要扩容RDD，因此上一种方案扩容RDD后对内存的占用并不大；而这一种方案是针对有大量倾斜key的情况，没法将部分key拆分出来进行单独处理，因此只能对整个RDD进行数据扩容，对内存资源要求很高。")]),t._v(" "),n("p",[t._v("方案优点：对join类型的数据倾斜基本都可以处理，而且效果也相对比较显著，性能提升效果非常不错。")]),t._v(" "),n("p",[t._v("方案缺点：该方案更多的是缓解数据倾斜，而不是彻底避免数据倾斜。而且需要对整个RDD进行扩容，对内存资源要求很高。")]),t._v(" "),n("p",[t._v("方案实践经验：曾经开发一个数据需求的时候，发现一个join导致了数据倾斜。优化之前，作业的执行时间大约是60分钟左右；使用该方案优化之后，执行时间缩短到10分钟左右，性能提升了6倍。")]),t._v(" "),n("h5",{attrs:{id:"解决方案八-把上面的几种数据倾斜的解决方案综合的灵活运行"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#解决方案八-把上面的几种数据倾斜的解决方案综合的灵活运行"}},[t._v("#")]),t._v(" 解决方案八：把上面的几种数据倾斜的解决方案综合的灵活运行")]),t._v(" "),n("p",[t._v("------------------------spark第三次课-------------------------------------")]),t._v(" "),n("h2",{attrs:{id:"rdd的依赖关系"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd的依赖关系"}},[t._v("#")]),t._v(" RDD的依赖关系")]),t._v(" "),n("h5",{attrs:{id:"依赖类型"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#依赖类型"}},[t._v("#")]),t._v(" 依赖类型")]),t._v(" "),n("p",[t._v("RDD根据依赖关系，可以分为父RDD和子RDD，父RDD就是被子RDD依赖的RDD。")]),t._v(" "),n("p",[t._v("而父RDD与子RDD的依赖关系，可以分为两种类型：")]),t._v(" "),n("ol",[n("li",[t._v("窄依赖（narrow dependency）")]),t._v(" "),n("li",[t._v("宽依赖（wide dependency）")])]),t._v(" "),n("h5",{attrs:{id:"窄依赖"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#窄依赖"}},[t._v("#")]),t._v(" 窄依赖")]),t._v(" "),n("p",[t._v("窄依赖：指的是每一个父RDD的Partition最多被子RDD的一个Partition使用，可比喻为独生子女。")]),t._v(" "),n("p",[t._v("map/flatMap/filter/union等算子操作都是窄依赖，所有的窄依赖不会产生shuffle")]),t._v(" "),n("h5",{attrs:{id:"宽依赖"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#宽依赖"}},[t._v("#")]),t._v(" 宽依赖")]),t._v(" "),n("p",[t._v("宽依赖：指的是多个子RDD的Partition会依赖同一个父RDD的Partition，可比喻为超生。")]),t._v(" "),n("p",[t._v("reduceByKey/sortByKey/groupBy/groupByKey/join等算子操作都是宽依赖，所有的宽依赖会产生shuffle")]),t._v(" "),n("h5",{attrs:{id:"示意图"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#示意图"}},[t._v("#")]),t._v(" 示意图")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1550),alt:"image-20200417040624865"}})]),t._v(" "),n("h5",{attrs:{id:"补充说明"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#补充说明"}},[t._v("#")]),t._v(" 补充说明")]),t._v(" "),n("p",[t._v("由上图可知，join分为宽依赖和窄依赖，如果RDD有相同的partitioner(本质是看分区函数或者分区逻辑是否相同），那么将不会引起shuffle，这种join是窄依赖，反之就是宽依赖。详情看下图：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1551),alt:"image-20200417042221150"}})]),t._v(" "),n("h2",{attrs:{id:"lineage-血统-理解即可"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#lineage-血统-理解即可"}},[t._v("#")]),t._v(" lineage（血统）理解即可")]),t._v(" "),n("p",[t._v("RDD只支持粗粒度转换：即只记录单个块上执行的单个操作。")]),t._v(" "),n("p",[t._v("那么，就需要创建RDD的一系列Lineage（即血统）记录下来，以便恢复丢失的分区。")]),t._v(" "),n("p",[t._v("RDD的Lineage会记录RDD的元数据信息和转换行为，lineage保存了RDD的依赖关系，当该RDD的部分分区数据丢失时，它可以根据这些信息来重新运算和恢复丢失的数据分区。")]),t._v(" "),n("p",[t._v("比如，下图中的rdd2的1号分区的数据丢失了，那么就可以根据血统lineage保存的RDD的依赖关系和转换行为等，将rdd1中的数据进行flatMap操作恢复丢失的数据。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1552),alt:"image-20200417042533244"}})]),t._v(" "),n("h2",{attrs:{id:"rdd的缓存机制-★★★★★"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd的缓存机制-★★★★★"}},[t._v("#")]),t._v(" RDD的缓存机制（★★★★★)")]),t._v(" "),n("h4",{attrs:{id:"什么是rdd的缓存"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#什么是rdd的缓存"}},[t._v("#")]),t._v(" 什么是rdd的缓存")]),t._v(" "),n("p",[t._v("spark可以把一个rdd的数据缓存起来，后续有其他的job需要用到该rdd的结果数据，可以直接从缓存中获取得到，避免了重复计算。缓存是加快后续对该数据的访问操作。")]),t._v(" "),n("h4",{attrs:{id:"如何对rdd设置缓存"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#如何对rdd设置缓存"}},[t._v("#")]),t._v(" 如何对rdd设置缓存")]),t._v(" "),n("p",[t._v("可以通过persist方法或cache方法将前面的RDD的数据缓存。但这两个方法被调用时不会立即执行缓存操作，而是触发后面的action时，才将RDD缓存在计算节点的内存中，并供后面重用。")]),t._v(" "),n("p",[t._v("persist方法和cache方法的源代码如下，可以看到cache方法内调用了persist方法，persist方法的参数的默认值是StorageLevel.MEMORY_ONLY。")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n   * Persist this RDD with the default storage level (`MEMORY_ONLY`).\n   */")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" persist"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" persist"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("MEMORY_ONLY"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n   * Persist this RDD with the default storage level (`MEMORY_ONLY`).\n   */")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" cache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" persist"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("StorageLevel的部分源码带，StorageLevel是一个object，里面定义了不同的变量来表示不同的存储级别。")]),t._v(" "),n("ol",[n("li",[t._v("NONE 不进行缓存")]),t._v(" "),n("li",[t._v("DISK_ONLY 缓存到磁盘    DISK_ONLY_2 缓存到磁盘,2份")]),t._v(" "),n("li",[t._v("MEMORY_ONLY 缓存到内存    MEMORY_ONLY_2 缓存到内存2份")]),t._v(" "),n("li",[t._v("MEMORY_ONLY_SER 序列化后缓存到内存  MEMORY_ONLY_SER_2 序列化后缓存到内存2份")]),t._v(" "),n("li",[t._v("MEMORY_AND_DISK  缓存到内存或磁盘 MEMORY_AND_DISK_2  缓存到内存或磁盘2份")]),t._v(" "),n("li",[t._v("MEMORY_AND_DISK_SER 缓存到内存或磁盘且序列化  MEMORY_AND_DISK_SER_2 ...")]),t._v(" "),n("li",[t._v("OFF_HEAP 缓存到堆外")])]),t._v(" "),n("p",[t._v("注意：MEMORY_AND_DISK并不是把数据缓存一部分在内存中一部分在磁盘中，而是优先考虑内存，内存不够了才缓存到磁盘。")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" StorageLevel "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" NONE "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" DISK_ONLY "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" DISK_ONLY_2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" MEMORY_ONLY "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" MEMORY_ONLY_2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" MEMORY_ONLY_SER "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" MEMORY_ONLY_SER_2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" MEMORY_AND_DISK "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" MEMORY_AND_DISK_2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" MEMORY_AND_DISK_SER "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" MEMORY_AND_DISK_SER_2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" OFF_HEAP "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h4",{attrs:{id:"cache和persist的使用示例"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#cache和persist的使用示例"}},[t._v("#")]),t._v(" cache和persist的使用示例")]),t._v(" "),n("p",[t._v("打开spark shell")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[t._v("spark-shell --master spark://node01:7077 --executor-memory 1g --total-executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n")])])]),n("p",[t._v("登录8080端口的spark页面，找到spark shell对应的Application，点击Spark shell")]),t._v(" "),n("img",{staticStyle:{zoom:"67%"},attrs:{src:"spark.assets/image-20200417093437067.png",alt:"image-20200417093437067"}}),t._v(" "),n("p",[t._v("点击后，就进入了http://node01:4040/jobs/，然后切换到Storage")]),t._v(" "),n("img",{staticStyle:{zoom:"67%"},attrs:{src:"spark.assets/image-20200417093646386.png",alt:"image-20200417093646386"}}),t._v(" "),n("p",[t._v("往spark shell一行行执行下列代码，注意刷新观察Storage界面的变化。")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd3"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cache\nrdd3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\n")])])]),n("p",[t._v("执行完rdd3.collect后，页面才发生了变化，如下图，图中显示存储在内存中的大小为440.0B，磁盘为0：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1553),alt:"image-20200417094145627"}})]),t._v(" "),n("p",[t._v("继续执行下列代码：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd4"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd5"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd4"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("persist"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("storage"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DISK_ONLY"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrdd5"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\n")])])]),n("p",[t._v("执行rdd5.collect后，页面再次发生变化，如下图：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1554),alt:"image-20200417094636520"}})]),t._v(" "),n("h4",{attrs:{id:"cache和persist的区别-面试题"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#cache和persist的区别-面试题"}},[t._v("#")]),t._v(" cache和persist的区别（"),n("strong",[t._v("面试题")]),t._v("）")]),t._v(" "),n("p",[t._v("简述下如何对RDD设置缓存，以及它们的区别是什么？")]),t._v(" "),n("p",[t._v("对RDD设置缓存成可以调用rdd的2个方法： 一个是cache，一个是persist，调用这2个方法都可以对rdd的数据设置缓存，但不是立即就触发缓存执行，后面需要有action，才会触发缓存的执行。")]),t._v(" "),n("p",[t._v("cache方法和persist方法区别：")]),t._v(" "),n("ol",[n("li",[t._v("cache:   默认是把数据缓存在内存中，其本质就是调用persist方法；")]),t._v(" "),n("li",[t._v("persist：可以把数据缓存在内存或者是磁盘，有丰富的缓存级别，这些缓存级别都被定义在StorageLevel这个object中。")])]),t._v(" "),n("h4",{attrs:{id:"什么时候需要设置缓存"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#什么时候需要设置缓存"}},[t._v("#")]),t._v(" 什么时候需要设置缓存？")]),t._v(" "),n("p",[t._v("首先理解一个概念：transformation算子是延迟加载的，只有在触发action时才会被执行，job执行完之后，前面所有rdd的数据就都不存在了，如果没有action算子，各个rdd之间就只是一个转换")]),t._v(" "),n("p",[t._v("1、某个rdd的数据后期被使用了多次")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1555),alt:"1569037915592"}})]),t._v(" "),n("p",[t._v("如上图所示的计算逻辑：")]),t._v(" "),n("p",[t._v("当第一次使用rdd2做相应的算子操作得到rdd3的时候，就会从rdd1开始计算，先读取HDFS上的文件，然后对rdd1 做对应的算子操作得到rdd2,再由rdd2计算之后得到rdd3。同样为了计算得到rdd4，前面的逻辑会被重新计算。")]),t._v(" "),n("p",[t._v("默认情况下多次对同一个rdd执行算子操作， rdd都会对这个rdd及之前的父rdd全部重新计算一次。 这种情况在实际开发代码的时候会经常遇到，但是我们一定要避免一个rdd重复计算多次，否则会导致性能急剧降低。")]),t._v(" "),n("p",[t._v("因此，可以把多次使用到的rdd，也就是公共rdd进行持久化，避免后续需要，再次重新计算，提升效率。如下图，在设置了rdd2.cache或rdd2.persist后，得到rrd3时（假设rdd2--\x3erdd3是一个action），步骤还是HDFS--\x3erdd1--\x3erdd2--\x3erdd3，但是因为rdd3是rdd2经过action算子操作得到的，rrd2的数据得到缓存。")]),t._v(" "),n("p",[t._v("那么生成rdd4的时候，步骤就简单了很多，直接从缓存中获取数据，计算得到rdd4。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1556),alt:"image-20200417095850150"}})]),t._v(" "),n("p",[t._v("2、为了获取得到一个rdd的结果数据，经过了大量的算子操作或者是计算逻辑比较复杂,总之某个rdd的数据来之不易时，可以进行缓存：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("函数"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("函数"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("函数"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xxx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xxx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xxx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xxx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xxx\n")])])]),n("h4",{attrs:{id:"清除缓存数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#清除缓存数据"}},[t._v("#")]),t._v(" 清除缓存数据")]),t._v(" "),n("p",[t._v("自动清除")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("一个application应用程序结束之后，对应的缓存数据也就自动清除\n")])])]),n("p",[t._v("手动清除")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("调用rdd的unpersist方法\n")])])]),n("h2",{attrs:{id:"rdd的checkpoint机制-★★★★★"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd的checkpoint机制-★★★★★"}},[t._v("#")]),t._v(" RDD的checkpoint机制（★★★★★)")]),t._v(" "),n("h4",{attrs:{id:"checkpoint概念"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#checkpoint概念"}},[t._v("#")]),t._v(" checkpoint概念")]),t._v(" "),n("p",[t._v("我们可以对rdd的数据进行缓存，保存在内存或者是磁盘中。后续就可以直接从内存或者磁盘中获取得到，但是它们不是特别安全。")]),t._v(" "),n("p",[t._v("cache")]),t._v(" "),n("p",[t._v("它是直接把数据保存在内存中，后续操作起来速度比较快，直接从内存中获取得到。但这种方式很不安全，由于服务器挂掉或者是进程终止，会导致数据的丢失。")]),t._v(" "),n("p",[t._v("persist")]),t._v(" "),n("p",[t._v("它可以把数据保存在本地磁盘中，后续可以从磁盘中获取得到该数据，但它也不是特别安全，由于系统管理员一些误操作删除了，或者是磁盘损坏，也有可能导致数据的丢失。")]),t._v(" "),n("p",[t._v("checkpoint（检查点）")]),t._v(" "),n("p",[t._v("它是提供了一种相对而言更加可靠的数据持久化方式。它是把数据保存在分布式文件系统，比如HDFS上。这里就是利用了HDFS高可用性，高容错性（多副本）来最大程度保证数据的安全性。")]),t._v(" "),n("h4",{attrs:{id:"如何设置checkpoint"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#如何设置checkpoint"}},[t._v("#")]),t._v(" 如何设置checkpoint")]),t._v(" "),n("p",[t._v("1、在hdfs上设置一个checkpoint目录")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setCheckpointDir"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hdfs://node01:8020/checkpoint"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n")])])]),n("p",[t._v("2、对需要做checkpoint操作的rdd调用checkpoint方法")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("checkpoint\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n")])])]),n("p",[t._v("3、最后需要有一个action操作去触发任务的运行")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\n")])])]),n("p",[t._v("查看缓存中hdfs中的数据：")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node01 ~"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ hdfs dfs -ls /checkpoint/e237e2bb-dc0e-47d9-851f-26687b0d7dbe/rdd-5\nFound "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" items\n-rw-r--r--   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" hadoop supergroup         "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("53")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-04-17 "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(":20 /checkpoint/e237e2bb-dc0e-47d9-851f-26687b0d7dbe/rdd-5/part-00000\n-rw-r--r--   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" hadoop supergroup          "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),t._v("-04-17 "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(":20 /checkpoint/e237e2bb-dc0e-47d9-851f-26687b0d7dbe/rdd-5/part-00001\n")])])]),n("h4",{attrs:{id:"cache、persist、checkpoint三者区别"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#cache、persist、checkpoint三者区别"}},[t._v("#")]),t._v(" cache、persist、checkpoint三者区别")]),t._v(" "),n("p",[t._v("cache和persist")]),t._v(" "),n("ul",[n("li",[t._v("cache默认数据缓存在内存中")]),t._v(" "),n("li",[t._v("persist可以把数据保存在内存或者磁盘中")]),t._v(" "),n("li",[t._v("后续要触发 cache 和 persist 持久化操作，需要有一个action操作")]),t._v(" "),n("li",[t._v("它不会开启其他新的任务，一个action操作就对应一个job")]),t._v(" "),n("li",[t._v("它不会改变rdd的依赖关系，程序运行完成后对应的缓存数据就自动消失")])]),t._v(" "),n("p",[t._v("checkpoint")]),t._v(" "),n("ul",[n("li",[n("p",[t._v("可以把数据持久化写入到hdfs上")])]),t._v(" "),n("li",[n("p",[t._v("后续要触发checkpoint持久化操作，需要有一个action操作，"),n("strong",[n("strong",[t._v("后续会开启新的job执行checkpoint操作")])])])]),t._v(" "),n("li",[n("p",[t._v("它会改变rdd的依赖关系，后续数据丢失了不能够在通过血统进行数据的恢复。")])]),t._v(" "),n("li",[n("p",[t._v("程序运行完成后对应的checkpoint数据就不会消失")])])]),t._v(" "),n("p",[t._v("cache或persisit与checkpoint的结合使用：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("   sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setCheckpointDir"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/checkpoint"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/words.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cache\n   rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("checkpoint\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd3"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   rdd3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\n   \n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//对checkpoint在使用的时候进行优化，在调用checkpoint操作之前，可以先来做一个cache操作，缓存对应rdd的结果数据，后续就可以直接从cache中获取到rdd的数据写入到指定checkpoint目录中   ")]),t._v("\n")])])]),n("h2",{attrs:{id:"dag有向无环图生成"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dag有向无环图生成"}},[t._v("#")]),t._v(" DAG有向无环图生成")]),t._v(" "),n("h4",{attrs:{id:"dag是什么"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dag是什么"}},[t._v("#")]),t._v(" DAG是什么")]),t._v(" "),n("p",[n("strong",[t._v("DAG(Directed Acyclic Graph)")]),t._v(" 叫做有向无环图（有方向,无闭环,代表着数据的流向），原始的RDD通过一系列的转换就形成了DAG。")]),t._v(" "),n("p",[t._v("下图是基于单词统计逻辑得到的DAG有向无环图")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1557),alt:"1569047954944"}})]),t._v(" "),n("h2",{attrs:{id:"dag划分stage-★★★★★"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dag划分stage-★★★★★"}},[t._v("#")]),t._v(" DAG划分stage（★★★★★)")]),t._v(" "),n("h4",{attrs:{id:"stage是什么"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#stage是什么"}},[t._v("#")]),t._v(" stage是什么")]),t._v(" "),n("p",[n("strong",[t._v("一个Job会被拆分为多组Task，每组任务被称为一个stage")])]),t._v(" "),n("p",[t._v("stage表示不同的调度阶段，一个spark job会对应产生很多个stage")]),t._v(" "),n("p",[t._v("stage类型一共有2种")]),t._v(" "),n("ol",[n("li",[n("strong",[t._v("ShuffleMapStage")])])]),t._v(" "),n("ul",[n("li",[t._v("最后一个shuffle之前的所有变换的Stage叫ShuffleMapStage\n"),n("ul",[n("li",[t._v("它对应的task是shuffleMapTask")])])])]),t._v(" "),n("ol",{attrs:{start:"2"}},[n("li",[n("strong",[t._v("ResultStage")])])]),t._v(" "),n("ul",[n("li",[t._v("最后一个shuffle之后操作的Stage叫ResultStage，它是最后一个Stage。\n"),n("ul",[n("li",[t._v("它对应的task是ResultTask")])])])]),t._v(" "),n("h4",{attrs:{id:"为什么要划分stage"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#为什么要划分stage"}},[t._v("#")]),t._v(" 为什么要划分stage")]),t._v(" "),n("p",[t._v("根据RDD之间依赖关系的不同将DAG划分成不同的Stage(调度阶段)")]),t._v(" "),n("ul",[n("li",[t._v("对于窄依赖，partition的转换处理在一个Stage中完成计算")]),t._v(" "),n("li",[t._v("对于宽依赖，由于有Shuffle的存在，只能在parent RDD处理完成后，才能开始接下来的计算，")])]),t._v(" "),n("p",[t._v("由于划分完stage之后，在同一个stage中只有窄依赖，没有宽依赖，可以实现流水线计算，\nstage中的每一个分区对应一个task，在同一个stage中就有很多可以并行运行的task。")]),t._v(" "),n("h4",{attrs:{id:"如何划分stage"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#如何划分stage"}},[t._v("#")]),t._v(" 如何划分stage")]),t._v(" "),n("p",[n("strong",[t._v("划分stage的依据就是宽依赖")])]),t._v(" "),n("p",[t._v("划分流程：")]),t._v(" "),n("p",[t._v("(1) 首先根据rdd的算子操作顺序生成DAG有向无环图，接下里从最后一个rdd往前推，创建一个新的stage，把该rdd加入到该stage中，它是最后一个stage。")]),t._v(" "),n("p",[t._v("(2) 在往前推的过程中运行遇到了窄依赖就把该rdd加入到本stage中，如果遇到了宽依赖，就从宽依赖切开，那么最后一个stage也就结束了。")]),t._v(" "),n("p",[t._v("(3) 重新创建一个新的stage，按照第二个步骤继续往前推，一直到最开始的rdd，整个划分stage也就结束了")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1558),alt:"划分stage"}})]),t._v(" "),n("h4",{attrs:{id:"stage与stage之间的关系"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#stage与stage之间的关系"}},[t._v("#")]),t._v(" stage与stage之间的关系")]),t._v(" "),n("p",[t._v("划分完stage之后，每一个stage中有很多可以并行运行的task，后期把每一个stage中的task封装在一个taskSet集合中，最后把一个一个的taskSet集合提交到worker节点上的executor进程中运行。")]),t._v(" "),n("p",[t._v("rdd与rdd之间存在依赖关系，stage与stage之前也存在依赖关系，前面stage中的task先运行，运行完成了再运行后面stage中的task，也就是说后面stage中的task输入数据是前面stage中task的输出结果数据。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1559),alt:"stage"}})]),t._v(" "),n("h2",{attrs:{id:"spark的任务调度"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark的任务调度"}},[t._v("#")]),t._v(" spark的任务调度")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1560),alt:"spark任务调度"}})]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("(1) Driver端运行客户端的main方法，构建SparkContext对象，在SparkContext对象内部依次构建DAGScheduler和TaskScheduler\n\n(2) 按照rdd的一系列操作顺序，来生成DAG有向无环图\n\n(3) DAGScheduler拿到DAG有向无环图之后，按照宽依赖进行stage的划分。每一个stage内部有很多可以并行运行的task，最后封装在一个一个的taskSet集合中，然后把taskSet发送给TaskScheduler\n\n(4) TaskScheduler得到taskSet集合之后，依次遍历取出每一个task提交到worker节点上的executor进程中运行。\n\n(5) 所有task运行完成，整个任务也就结束了\n")])])]),n("h2",{attrs:{id:"spark的运行架构"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark的运行架构"}},[t._v("#")]),t._v(" spark的运行架构")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1561),alt:"spark"}})]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("(1) Driver端向资源管理器Master发送注册和申请计算资源的请求\n\n(2) Master通知对应的worker节点启动executor进程(计算资源)\n\n(3) executor进程向Driver端发送注册并且申请task请求\n\n(4) Driver端运行客户端的main方法，构建SparkContext对象，在SparkContext对象内部依次构建DAGScheduler和TaskScheduler\n\n(5) 按照客户端代码洪rdd的一系列操作顺序，生成DAG有向无环图\n\n(6) DAGScheduler拿到DAG有向无环图之后，按照宽依赖进行stage的划分。每一个stage内部有很多可以并行运行的task，最后封装在一个一个的taskSet集合中，然后把taskSet发送给TaskScheduler\n\n(7) TaskScheduler得到taskSet集合之后，依次遍历取出每一个task提交到worker节点上的executor进程中运行\n\n(8) 所有task运行完成，Driver端向Master发送注销请求，Master通知Worker关闭executor进程，Worker上的计算资源得到释放，最后整个任务也就结束了。\n")])])]),n("h2",{attrs:{id:"基于wordcount程序剖析spark任务的提交、划分、调度流程-★★★★★"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#基于wordcount程序剖析spark任务的提交、划分、调度流程-★★★★★"}},[t._v("#")]),t._v(" 基于wordcount程序剖析spark任务的提交、划分、调度流程（★★★★★)")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1562),alt:"job-scheduler-running"}})]),t._v(" "),n("h2",{attrs:{id:"面试题2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#面试题2"}},[t._v("#")]),t._v(" "),n("strong",[t._v("面试题2")])]),t._v(" "),n("ol",[n("li",[t._v("reduceByKey和groupByKey的区别是什么？")]),t._v(" "),n("li",[t._v("下面哪些操作是宽依赖  flatMap/map/filter/reduceByKey")]),t._v(" "),n("li",[t._v("简述cache和persist的区别")]),t._v(" "),n("li",[t._v("简述如何划分stage")])]),t._v(" "),n("h2",{attrs:{id:"spark第四次课"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark第四次课"}},[t._v("#")]),t._v(" =========*"),n("em",[t._v("spark第四次课========*")])]),t._v(" "),n("h2",{attrs:{id:"sparksql概述"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparksql概述"}},[t._v("#")]),t._v(" sparksql概述")]),t._v(" "),n("h4",{attrs:{id:"sparksql的前世今生"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparksql的前世今生"}},[t._v("#")]),t._v(" sparksql的前世今生")]),t._v(" "),n("ul",[n("li",[t._v("Shark是专门针对于spark的构建大规模数据仓库系统的一个框架")]),t._v(" "),n("li",[t._v("Shark与Hive兼容、同时也依赖于Spark版本")]),t._v(" "),n("li",[t._v("Hivesql底层把sql解析成了mapreduce程序，Shark是把sql语句解析成了Spark任务")]),t._v(" "),n("li",[t._v("随着性能优化的上限，以及集成SQL的一些复杂的分析功能，发现Hive的MapReduce思想限制了Shark的发展。")]),t._v(" "),n("li",[t._v("最后Databricks公司终止对Shark的开发\n"),n("ul",[n("li",[t._v("决定单独开发一个框架，不在依赖hive，把重点转移到了"),n("strong",[t._v("sparksql")]),t._v("这个框架上。")])])])]),t._v(" "),n("h4",{attrs:{id:"什么是sparksql"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#什么是sparksql"}},[t._v("#")]),t._v(" 什么是sparksql")]),t._v(" "),n("p",[t._v("Spark SQL is Apache Spark's module for working with structured data.")]),t._v(" "),n("p",[t._v("SparkSQL是apache Spark用来处理结构化数据的一个模块。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1563),alt:"1569468946521"}})]),t._v(" "),n("h2",{attrs:{id:"sparksql的四大特性"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparksql的四大特性"}},[t._v("#")]),t._v(" sparksql的四大特性")]),t._v(" "),n("h4",{attrs:{id:"易整合"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#易整合"}},[t._v("#")]),t._v(" 易整合")]),t._v(" "),n("p",[t._v("将SQL查询与Spark程序无缝混合")]),t._v(" "),n("p",[t._v("可以使用不同的语言进行代码开发")]),t._v(" "),n("ul",[n("li",[t._v("java")]),t._v(" "),n("li",[t._v("scala")]),t._v(" "),n("li",[t._v("python")]),t._v(" "),n("li",[t._v("R")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(1564),alt:"1569469087993"}})]),t._v(" "),n("h4",{attrs:{id:"统一的数据源访问"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#统一的数据源访问"}},[t._v("#")]),t._v(" 统一的数据源访问")]),t._v(" "),n("p",[t._v("以相同的方式连接到任何数据源，sparksql后期可以采用一种统一的方式去对接任意的外部数据源，不需要使用不同的Api")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v("  dataFrame "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("文件格式的方法名"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"该文件格式的路径"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("img",{attrs:{src:a(1565),alt:"1569469225309"}})]),t._v(" "),n("h4",{attrs:{id:"兼容hive"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#兼容hive"}},[t._v("#")]),t._v(" 兼容hive")]),t._v(" "),n("p",[t._v("sparksql可以支持hivesql这种语法  sparksql兼容hivesql")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1566),alt:"1569469413038"}})]),t._v(" "),n("h4",{attrs:{id:"支持标准的数据库连接"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#支持标准的数据库连接"}},[t._v("#")]),t._v(" 支持标准的数据库连接")]),t._v(" "),n("p",[t._v("sparksql支持标准的数据库连接JDBC或者ODBC")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1567),alt:"1569469446641"}})]),t._v(" "),n("h2",{attrs:{id:"dataframe概述"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dataframe概述"}},[t._v("#")]),t._v(" DataFrame概述")]),t._v(" "),n("p",[t._v("spark core---\x3e操控RDD")]),t._v(" "),n("p",[t._v("spark sql---\x3e操控DataFrame")]),t._v(" "),n("h5",{attrs:{id:"dataframe发展"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dataframe发展"}},[t._v("#")]),t._v(" DataFrame发展")]),t._v(" "),n("p",[t._v("DataFrame前身是schemaRDD,这个schemaRDD是直接继承自RDD，它是RDD的一个实现类")]),t._v(" "),n("p",[t._v("在spark1.3.0之后把schemaRDD改名为DataFrame,它不再继承自RDD，而是自己实现RDD上的一些功能")]),t._v(" "),n("p",[t._v("也可以把dataFrame转换成一个rdd，调用rdd方法即可转换成功，例如 val rdd1=dataFrame.rdd")]),t._v(" "),n("h5",{attrs:{id:"dataframe是什么"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dataframe是什么"}},[t._v("#")]),t._v(" DataFrame是什么")]),t._v(" "),n("p",[t._v("在Spark中，DataFrame是一种"),n("strong",[t._v("以RDD为基础的分布式数据集")]),t._v("，类似于"),n("strong",[t._v("传统数据库的二维表格")])]),t._v(" "),n("p",[t._v("DataFrame带有"),n("strong",[t._v("Schema元信息")]),t._v("，即DataFrame所表示的二维表数据集的每一列都带有名称和类型，但底层做了更多的优化")]),t._v(" "),n("p",[t._v("DataFrame可以从很多数据源构建，比如：已经存在的RDD、结构化文件、外部数据库、Hive表。")]),t._v(" "),n("p",[t._v("RDD可以把它内部元素看成是一个java对象")]),t._v(" "),n("p",[t._v("DataFrame可以把内部元素看成是一个Row对象，它表示一行一行的数据，每一行是固定的数据类型")]),t._v(" "),n("p",[t._v("可以把DataFrame这样去理解-----\x3eRDD+schema元信息, dataFrame相比于rdd来说，多了对数据的描述信息（schema元信息）")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1568),alt:"1569492382924"}})]),t._v(" "),n("p",[n("img",{attrs:{src:a(1569),alt:"image-20200617193824609"}})]),t._v(" "),n("h2",{attrs:{id:"dataframe和rdd的优缺点"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dataframe和rdd的优缺点"}},[t._v("#")]),t._v(" DataFrame和RDD的优缺点")]),t._v(" "),n("h4",{attrs:{id:"rdd优点"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd优点"}},[t._v("#")]),t._v(" RDD优点")]),t._v(" "),n("p",[t._v("1、编译时类型安全，开发会进行类型检查，在编译的时候及时发现错误")]),t._v(" "),n("p",[t._v("2、具有面向对象编程的风格")]),t._v(" "),n("h4",{attrs:{id:"rdd缺点"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd缺点"}},[t._v("#")]),t._v(" RDD缺点")]),t._v(" "),n("p",[t._v("1、构建大量的java对象占用了大量heap堆空间，导致频繁的垃圾回收GC。 :RDD[Java对象]")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("由于数据集RDD它的数据量比较大，后期都需要存储在heap堆中，这里有heap堆中的内存空间有限，出现频繁的垃圾回收（GC），程序在进行垃圾回收的过程中，所有的任务都是暂停。影响程序执行的效率\n")])])]),n("p",[t._v("2、数据的序列化和反序列性能开销很大")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("  在分布式程序中，对象(对象的内容和结构)是先进行序列化，发送到其他服务器，进行大量的网络传输，然后接受到这些序列化的数据之后，再进行反序列化来恢复该对象\n")])])]),n("h4",{attrs:{id:"dataframe优点"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dataframe优点"}},[t._v("#")]),t._v(" DataFrame优点")]),t._v(" "),n("p",[t._v("DataFrame引入了schema元信息和off-heap(堆外)")]),t._v(" "),n("p",[t._v("1、DataFrame引入off-heap，大量的对象构建直接使用操作系统层面上的内存，不再使用heap堆中的内存，这样一来heap堆中的内存空间就比较充足，不会导致频繁GC，程序的运行效率比较高，它是解决了RDD构建大量的java对象占用了大量heap堆空间，导致频繁的GC这个缺点。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1570),alt:"image-20200417135339845"}})]),t._v(" "),n("p",[t._v("2、DataFrame引入了schema元信息---就是数据结构的描述信息，后期spark程序中的大量对象在进行网络传输的时候，只需要把数据的内容本身进行序列化就可以，数据结构信息可以省略掉。这样一来数据网络传输的数据量是有所减少，数据的序列化和反序列性能开销就不是很大了。它是解决了RDD数据的序列化和反序列性能开销很大这个缺点")]),t._v(" "),n("h4",{attrs:{id:"dataframe缺点"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dataframe缺点"}},[t._v("#")]),t._v(" DataFrame缺点")]),t._v(" "),n("p",[t._v("DataFrame引入了schema元信息和off-heap(堆外)它是分别解决了RDD的缺点，同时它也丢失了RDD的优点")]),t._v(" "),n("p",[t._v("1、编译时类型不安全")]),t._v(" "),n("ul",[n("li",[t._v("编译时不会进行类型的检查，这里也就意味着前期是无法在编译的时候发现错误，只有在运行的时候才会发现")])]),t._v(" "),n("p",[t._v("2、不再具有面向对象编程的风格")]),t._v(" "),n("h2",{attrs:{id:"读取文件构建dataframe"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#读取文件构建dataframe"}},[t._v("#")]),t._v(" 读取文件构建DataFrame")]),t._v(" "),n("h5",{attrs:{id:"spark-context与spark-session的关系"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark-context与spark-session的关系"}},[t._v("#")]),t._v(" Spark context与Spark session的关系")]),t._v(" "),n("p",[t._v("在spark2.0之前，要操控rdd就要构建spark context对象，要使用sparksql就要构建sqlcontext对象，要使用hive表就要构建hivecontext对象。")]),t._v(" "),n("p",[t._v("在spark2.0之后，人们觉得这样太麻烦，就出现了spark session,spark session封装了上面的3个对象。")]),t._v(" "),n("p",[t._v("那么，spark2.0之后，就可通过spark session来构建spark context、sql context...")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" sc\nres0"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SparkContext "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SparkContext"),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@5fdb7394")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" spark\nres1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SparkSession "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SparkSession"),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@52285a5f")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//下面是spark封装的东西")]),t._v("\nbaseRelationToDataFrame   close   createDataFrame   emptyDataFrame   experimental   listenerManager   range   readStream     sharedState    sql          stop      table   udf    catalog        conf    createDataset     emptyDataset     implicits  newSession   read    sessionState   sparkContext   sqlContext   streams   time    version   \n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sparkContext   \nres2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SparkContext "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SparkContext"),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@5fdb7394")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//使用spark封装的sparkContext")]),t._v("\nres3"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ParallelCollectionRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" at parallelize at "),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("console"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),t._v("\n")])])]),n("p",[n("img",{attrs:{src:a(1571),alt:"image-20200417140545035"}})]),t._v(" "),n("h5",{attrs:{id:"读取文本文件创建dataframe"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#读取文本文件创建dataframe"}},[t._v("#")]),t._v(" 读取文本文件创建DataFrame")]),t._v(" "),n("p",[t._v("创建文本文件：")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("vi /tmp/person.txt\n1 zhangsan 20\n2 lisi 32\n3 laowang 46\n\nhdfs dfs -put /tmp/person.txt /\n")])])]),n("p",[t._v("第一种方式，从结果可以看到DataFrame默认使用一个string类型的value列")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" personDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/person.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npersonDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//打印schema信息")]),t._v("\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("printSchema\nroot\n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v(" value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nullable "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//展示数据")]),t._v("\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("                                                                 \n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("        value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" zhangsan "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" lisi "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" laowang "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("p",[t._v("第二种方式")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//加载数据")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/person.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//定义一个样例类")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" Person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//把rdd与样例类进行关联")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" personRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("Person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toInt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//把rdd转换成DataFrame")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" personDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("personRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDF\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//打印schema信息")]),t._v("\npersonDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("printSchema\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//展示数据")]),t._v("\npersonDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n")])])]),n("h5",{attrs:{id:"读取json文件创建dataframe"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#读取json文件创建dataframe"}},[t._v("#")]),t._v(" 读取json文件创建DataFrame")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[t._v("hdfs dfs -put /kkb/install/spark/examples/src/main/resources/people.json /\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Michael"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Andy"')]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),t._v(":30"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Justin"')]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),t._v(":19"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" peopleDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("json"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/people.json"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npeopleDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" bigint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("          \n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" peopleDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("printSchema\nroot\n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v(" age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" long "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nullable "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nullable "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" peopleDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("Michael"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   Andy"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("19")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Justin"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("h5",{attrs:{id:"读取parquet文件创建dataframe"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#读取parquet文件创建dataframe"}},[t._v("#")]),t._v(" 读取parquet文件创建DataFrame")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("hdfs dfs -put /kkb/install/spark/examples/src/main/resources/users.parquet /\n")])])]),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" parquetDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parquet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/users.parquet"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nparquetDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" favorite_color"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" more field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" parquetDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("printSchema\nroot\n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nullable "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v(" favorite_color"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nullable "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v(" favorite_numbers"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" array "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nullable "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//数组类型")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v(" element"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" integer "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("containsNull "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//数组元素的类型")]),t._v("\n\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" parquetDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("                                        \n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("favorite_color"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("favorite_numbers"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("Alyssa"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("          "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   Ben"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("           red"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("              "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("h2",{attrs:{id:"dataframe常用操作"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dataframe常用操作"}},[t._v("#")]),t._v(" DataFrame常用操作")]),t._v(" "),n("h4",{attrs:{id:"dsl风格语法"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dsl风格语法"}},[t._v("#")]),t._v(" DSL风格语法")]),t._v(" "),n("p",[t._v("就是sparksql中的DataFrame自身提供了一套自己的Api，可以去使用这套api来做相应的处理。")]),t._v(" "),n("p",[t._v("创建DataFrame")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/person.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" MapPartitionsRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" at map at "),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("console"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//每一行切分而成的多个元素被封装成一个Array,作为RDD的类型")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" Person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndefined "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" Person  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//创建一个样例类")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" PersonRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("Person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toInt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nPersonRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" MapPartitionsRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" at map at "),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("console"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("27")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//将rdd1的每一个Array类型转为一个Person对象")]),t._v("\n\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" PersonDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("PersonRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDF  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//将RDD转为DataFrame")]),t._v("\nPersonDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("id"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" more field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" PersonDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("printSchema\nroot\n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v(" id"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nullable "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nullable "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v(" age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" integer "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nullable "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" PersonDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("                                                              \n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" id"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("zhangsan"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    lisi"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" laowang"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("p",[t._v("DataFrame.select()操作,select操作返回的还是一个DataFrame类型")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" PersonDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nres12"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" PersonDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("zhangsan"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    lisi"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" laowang"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" PersonDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("$"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("zhangsan"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    lisi"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" laowang"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" PersonDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("col"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("zhangsan"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    lisi"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" laowang"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" PersonDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("zhangsan"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    lisi"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" laowang"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" PersonDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("$"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("$"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("$"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show   "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//age+1")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("age "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("zhangsan"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("       "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    lisi"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("       "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("33")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" laowang"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("       "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("47")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("p",[t._v("DataFrame.filter()操作：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" PersonDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("filter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("$"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" id"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   lisi"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("laowang"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("h4",{attrs:{id:"sql风格语法-推荐"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sql风格语法-推荐"}},[t._v("#")]),t._v(" SQL风格语法（推荐）")]),t._v(" "),n("p",[t._v("可以把DataFrame注册成一张表，然后通过**sparkSession.sql(sql语句)**操作")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//DataFrame注册成表")]),t._v("\npersonDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTempView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Person"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//使用SparkSession调用sql方法统计查询")]),t._v("\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from Person"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" id"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("zhangsan"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    lisi"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" laowang"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n\nspark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select name from person"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\nspark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select name,age from person"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\nspark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from person where age >30"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\nspark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select count(*) from person where age >30"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\nspark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select age,count(*) from person group by age"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\nspark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select age,count(*) as count from person group by age"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\nspark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from person order by age desc"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n")])])]),n("h2",{attrs:{id:"dataset概述"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dataset概述"}},[t._v("#")]),t._v(" DataSet概述")]),t._v(" "),n("h5",{attrs:{id:"dataset是什么"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dataset是什么"}},[t._v("#")]),t._v(" DataSet是什么")]),t._v(" "),n("p",[t._v("DataSet是分布式的数据集合，Dataset提供了强类型支持，也是在RDD的每行数据加了类型约束。")]),t._v(" "),n("p",[t._v("强类型：所属类型必须在编译时确定。")]),t._v(" "),n("p",[t._v("DataSet是在Spark1.6中添加的新的接口。它集中了RDD的优点（"),n("strong",[t._v("强类型和可以用强大lambda函数")]),t._v("）以及使用了Spark SQL优化的执行引擎。")]),t._v(" "),n("h5",{attrs:{id:"rdd、dataframe、dataset的区别"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd、dataframe、dataset的区别"}},[t._v("#")]),t._v(" RDD、DataFrame、DataSet的区别")]),t._v(" "),n("p",[t._v("假设RDD中的两行数据长这样")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1572),alt:"1569492571159"}})]),t._v(" "),n("p",[t._v("那么DataFrame中的数据长这样")]),t._v(" "),n("p",[n("img",{attrs:{src:a(346),alt:"1569492595941"}})]),t._v(" "),n("p",[t._v("Dataset中的数据长这样")]),t._v(" "),n("p",[n("img",{attrs:{src:a(346),alt:"1569492595941"}})]),t._v(" "),n("p",[t._v("或者长这样（每行数据是个Object）")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1573),alt:"1569492637053"}})]),t._v(" "),n("p",[t._v("DataSet包含了DataFrame的功能，Spark2.0中两者统一，DataFrame表示为DataSet[Row]，即DataSet的子集。")]),t._v(" "),n("ol",[n("li",[t._v("DataSet可以在编译时检查类型")]),t._v(" "),n("li",[t._v("并且是面向对象的编程接口")])]),t._v(" "),n("h5",{attrs:{id:"dataset与dataframe源码分析"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dataset与dataframe源码分析"}},[t._v("#")]),t._v(" DataSet与DataFrame源码分析")]),t._v(" "),n("p",[t._v("我们来查看以下DataSet与DataFrame的源码，进入IDEA，添加以下pom依赖：")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[t._v("        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.spark"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("spark-sql_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.3.3"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("p",[t._v("按住ctrl+N,搜索DataFrame类，发现搜索不到，搜索DataSet类，成功。download source。")]),t._v(" "),n("p",[t._v("发现DataSet的源码包含以下代码：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" toDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DataFrame "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" queryExecution"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" RowEncoder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("schema"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("toDF()方法是一个返回值类型为DataFrame，点击查看该DataFrame的源码，如下，发现DataFrame类型就是一个Dataset[Row]类型。这就是DataFrame表示为DataSet[Row]，即DataSet的子集的原因。")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("object")]),t._v(" sql "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@DeveloperApi")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@InterfaceStability.Unstable")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" Strategy "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SparkStrategy\n\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" DataFrame "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h5",{attrs:{id:"dataframe与dataset互相转换"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dataframe与dataset互相转换"}},[t._v("#")]),t._v(" DataFrame与DataSet互相转换")]),t._v(" "),n("p",[t._v("把一个DataFrame转换成DataSet")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" dataSet"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("dataFrame"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("as"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("强类型"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),n("p",[t._v("把一个DataSet转换成DataFrame")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" dataFrame"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("dataSet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDF\n")])])]),n("p",[t._v("补充说明: 可以从dataFrame和dataSet获取得到rdd")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("dataFrame"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("dataSet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd\n")])])]),n("p",[t._v("转换示例：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" df"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/person.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" df"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("                                                                 \n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("        value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" zhangsan "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" lisi "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" laowang "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ds"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("df"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("as"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nds"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" ds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("                                                                 \n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("        value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" zhangsan "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" lisi "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" laowang "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("h2",{attrs:{id:"构建dataset"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#构建dataset"}},[t._v("#")]),t._v(" 构建DataSet")]),t._v(" "),n("h5",{attrs:{id:"_1、通过sparksession调用createdataset方法"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1、通过sparksession调用createdataset方法"}},[t._v("#")]),t._v(" 1、通过sparkSession调用createDataset方法")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ds"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createDataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" to "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nds"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" int"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" ds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ds"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createDataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/person.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nds"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" ds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("        value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" zhangsan "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" lisi "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" laowang "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("h5",{attrs:{id:"_2、使用scala集合和rdd调用tods方法"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2、使用scala集合和rdd调用tods方法"}},[t._v("#")]),t._v(" 2、使用scala集合和rdd调用toDS方法")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ds"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/person.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDS\nds"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" ds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("        value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" zhangsan "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" lisi "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" laowang "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDS\nres20"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" int"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDS"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("h5",{attrs:{id:"_3、把一个dataframe转换成dataset"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3、把一个dataframe转换成dataset"}},[t._v("#")]),t._v(" 3、把一个DataFrame转换成DataSet")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" Person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndefined "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" Person\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" peopleDS"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("json"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/people.json"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("as"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\npeopleDS"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" bigint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" peopleDS\nres13"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" bigint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" peopleDS"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("Michael"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   Andy"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("19")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Justin"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("h5",{attrs:{id:"_4、通过一个dataset转换生成一个新的dataset"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4、通过一个dataset转换生成一个新的dataset"}},[t._v("#")]),t._v(" 4、通过一个DataSet转换生成一个新的DataSet")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("scala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("  List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDS"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nres22"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" int"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nscala"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("  List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDS"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("40")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("h2",{attrs:{id:"通过idea开发程序实现把rdd转换dataframe"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#通过idea开发程序实现把rdd转换dataframe"}},[t._v("#")]),t._v(" 通过IDEA开发程序实现把RDD转换DataFrame")]),t._v(" "),n("h5",{attrs:{id:"官网学习如何创建spark-sql-scala程序"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#官网学习如何创建spark-sql-scala程序"}},[t._v("#")]),t._v(" 官网学习如何创建spark sql Scala程序")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1574),alt:"image-20200417205422106"}})]),t._v(" "),n("h5",{attrs:{id:"添加依赖"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#添加依赖"}},[t._v("#")]),t._v(" 添加依赖")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[t._v("        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.spark"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("spark-sql_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.3.3"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("h5",{attrs:{id:"方法1-利用反射机制"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#方法1-利用反射机制"}},[t._v("#")]),t._v(" 方法1：利用反射机制")]),t._v(" "),n("p",[t._v("定义一个样例类，后期直接映射成DataFrame的schema信息。")]),t._v(" "),n("p",[t._v("case class Person(id:String,name:String,age:Int)")]),t._v(" "),n("p",[t._v("适用场景：在开发代码之前，可以先确定好DataFrame的schema元信息")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("RDD\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Column"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" Person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" SparkSqlDemo "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//1、创建SparkSession")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("appName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SparkSqlDemo1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("master"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrCreate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sparkContext\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"F:\\\\test\\\\person.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//将样例类与RDD关联,即RDD[Array[String]]----\x3eRDD[Person]")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" personRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("Person"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toInt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//将RDD转为DataFrame")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//RDD本身是没有toDF方法的,要导入隐式转换(详细参考scala.md)")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("implicits"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("_\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" personDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("personRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("printSchema"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" firstRow"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取第一行数据")]),t._v("\n    println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"firstRow: "')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("firstRow"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" top2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("head"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取前2位数据")]),t._v("\n    top2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取name字段")]),t._v("\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("$"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Column"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("$"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("$"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("$"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//按照age过滤")]),t._v("\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("filter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("$"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" count"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("filter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("$"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"count:"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("count"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//分组")]),t._v("\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("groupBy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("row "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//使用foreach获取每一个row对象中的name字段")]),t._v("\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("row "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getAs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("row "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("row "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("row "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getAs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo：----------------- DSL风格语法--------------------end")]),t._v("\n\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo：----------------- SQL风格语法-----------------start")]),t._v("\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTempView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"person"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//使用SparkSession调用sql方法统计查询")]),t._v("\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from person"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select name from person"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select name,age from person"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from person where age >30"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select count(*) from person where age >30"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select age,count(*) from person group by age"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select age,count(*) as count from person group by age"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from person order by age desc"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo：----------------- SQL风格语法----------------------end")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//关闭sparkSession对象")]),t._v("\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("h5",{attrs:{id:"方法2-通过structtype动态指定schema"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#方法2-通过structtype动态指定schema"}},[t._v("#")]),t._v(" 方法2：通过StructType动态指定Schema")]),t._v(" "),n("p",[t._v("该方法的应用场景：在开发代码之前，无法确定需要的DataFrame对应的schema元信息，需要在开发代码的过程中动态指定。")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("RDD\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("types"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("IntegerType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StringType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StructField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StructType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" StructTypeDemo "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("appName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("master"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrCreate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sparkContext\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"warn"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"F:\\\\test\\\\person.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//使用Row包装一行数据，Row可以封装任意类型任意数目的数据")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rowRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("Row"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toInt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" schema"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("StructType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        StructField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("StringType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("::")]),t._v("\n        StructField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("StringType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("::")]),t._v("\n        StructField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("IntegerType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("::")]),t._v("Nil\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" personDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createDataFrame"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rowRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("schema"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("printSchema"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    personDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTempView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from user"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("说明：")]),t._v(" "),n("ol",[n("li",[t._v("因为后面要使用spark.createDataFrame(rowRDD:RDD[Row],schema:StructType)来创建DataFrame，所以要想创建RDD[Row]和StructType类型的变量")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(1575),alt:"image-20200418031619386"}})]),t._v(" "),n("ol",[n("li",[n("p",[t._v("Row类有伴生对象object Row,伴生对象里有apply方法，该apply方法的参数是Any*,所以创建Row对象时不需要new,参数也可以多种类型和多个，Row(x(0),x(1),x(2).toInt)")])]),t._v(" "),n("li",[n("p",[t._v("StructType的参数类型是：")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1576),alt:"image-20200418031038117"}})])]),t._v(" "),n("li",[n("p",[t._v("StructField是一个样例类，源代码大致如下：")])])]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" StructField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//名称")]),t._v("\n    dataType"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DataType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//数据类型")]),t._v("\n    nullable"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Boolean")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//表示是否允许该值为空")]),t._v("\n    metadata"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Metadata "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Metadata"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("empty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h2",{attrs:{id:"sparksql-操作hivesql"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparksql-操作hivesql"}},[t._v("#")]),t._v(" sparksql 操作hivesql")]),t._v(" "),n("p",[t._v("添加依赖")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[t._v("        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.spark"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("spark-hive_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.3.3"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("p",[t._v("person.txt")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("1 zhangsan 43\n2 lisi 21\n3 laowang 47\n")])])]),n("p",[t._v("Demo1.scala")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("SparkSession\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" Demo1 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//注意：要开启对hive的支持：.enableHiveSupport()")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("appName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark sql control hive sql"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("master"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("enableHiveSupport"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrCreate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sparkContext\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Warn"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n        |create table if not exists person(id string,name string,age int)\n        |row format delimited fields terminated by " "\n        |"""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stripMargin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//stripMargin的作用是将 | 变成空格")]),t._v("\n      \n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"load data local inpath 'file:///F:/test/person.txt' into table person\"")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from person"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("运行结果为：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" id"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("zhangsan"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("43")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    lisi"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" laowang"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("47")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("p",[t._v("说明：")]),t._v(" "),n("ol",[n("li",[t._v("文件的路径一定要加上file:///，否则会报错")]),t._v(" "),n("li",[t._v("运行成功后，会在当前project的根目录下创建两个目录：metastore_db和spark-warehouse")]),t._v(" "),n("li",[t._v("metastore_db用于存放刚才在本地创建的表的元数据，spark-warehouse用于保存表的数据")])]),t._v(" "),n("img",{staticStyle:{zoom:"80%"},attrs:{src:"spark.assets/image-20200418154332266.png",alt:"image-20200418154332266"}}),t._v(" "),n("h2",{attrs:{id:"spark-sql-操作jdbc数据源-★★★★★"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark-sql-操作jdbc数据源-★★★★★"}},[t._v("#")]),t._v(" spark sql 操作JDBC数据源(★★★★★)")]),t._v(" "),n("p",[t._v("spark sql可以通过 JDBC 从关系型数据库中读取数据的方式创建DataFrame，通过对DataFrame一系列的计算后，还可以将数据再写回关系型数据库中")]),t._v(" "),n("h5",{attrs:{id:"通过sparksql加载mysql表中的数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#通过sparksql加载mysql表中的数据"}},[t._v("#")]),t._v(" 通过sparksql加载mysql表中的数据")]),t._v(" "),n("p",[t._v("在node03创建表，准备数据")]),t._v(" "),n("div",{staticClass:"language-sql extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sql"}},[n("code",[t._v("mysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("database")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nmysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nmysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("user")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("name "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("varchar")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("age "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nmysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("user")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("values")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'krystal'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'jimmy'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nmysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("user")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+---------+------+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" id   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" name    "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" age  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+---------+------+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" krystal "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" jimmy   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+---------+------+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("set")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.11")]),t._v(" sec"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("添加mysql连接驱动jar包")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\t"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("mysql"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\t"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("mysql-connector-java"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\t"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("5.1.38"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("p",[t._v("开发代码：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("Properties\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" Demo2 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("appName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("master"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrCreate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" url"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbc:mysql://node03:3306/spark"')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" tableName"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user"')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" properties"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setProperty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"root"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setProperty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"password"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"123456"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" mysqlDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("jdbc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("tableName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    mysqlDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("printSchema"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    mysqlDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    mysqlDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTempView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from user"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("p",[t._v("运行结果为：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("root\n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v(" id"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" integer "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nullable "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" string "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nullable "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),t._v(" age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" integer "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nullable "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n \n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" id"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("krystal"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  jimmy"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("h5",{attrs:{id:"通过sparksql保存结果数据到mysql表中-本地"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#通过sparksql保存结果数据到mysql表中-本地"}},[t._v("#")]),t._v(" 通过sparksql保存结果数据到mysql表中(本地)")]),t._v(" "),n("p",[t._v("继续往user表插入数据：")]),t._v(" "),n("div",{staticClass:"language-sql extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sql"}},[n("code",[t._v("mysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" spark\nmysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("insert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("into")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("user")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("age"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("values")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'zhangsan'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("34")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lisi'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nmysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("user")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+----------+------+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" id   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" name     "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" age  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+----------+------+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" krystal  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" jimmy    "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("22")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" zhangsan "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("34")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" lisi     "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+----------+------+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("set")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.00")]),t._v(" sec"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("代码开发(本地运行)")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("Properties\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" Demo2 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("appName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("master"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrCreate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" url"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbc:mysql://node03:3306/spark"')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" tableName"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user"')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" properties"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setProperty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"root"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setProperty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"password"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"123456"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" mysqlDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("jdbc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("tableName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    mysqlDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTempView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" resultDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from user where age > 30"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    resultDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"append"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("jdbc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user2"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("p",[t._v("查询user2表：")]),t._v(" "),n("div",{staticClass:"language-sql extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sql"}},[n("code",[t._v("mysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" user2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+----------+------+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" id   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" name     "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" age  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+----------+------+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" zhangsan "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("34")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" lisi     "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("46")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("------+----------+------+")]),t._v("\n")])])]),n("p",[t._v("说明：")]),t._v(" "),n("ol",[n("li",[t._v('resultDF.wirte.mode("...")的参数有四种，mode用来指定数据的插入模式。\n//overwrite: 表示覆盖，如果表不存在，事先帮我们创建\n//append   :表示追加， 如果表不存在，事先帮我们创建\n//ignore   :表示忽略，如果表事先存在，就不进行任何操作\n//error    :如果表事先存在就报错（默认选项）')]),t._v(" "),n("li",[t._v("将数据处理后保存到MySQL中，还可以使用rdd方法，详情查看spqrk.md")]),t._v(" "),n("li",[t._v("如果要将本地运行改成打jar包到集群运行，只需要修改2个地方：\n"),n("ol",[n("li",[t._v("删掉.master()")]),t._v(" "),n("li",[t._v("将resultDF.write.mDFode(args(0)).jdbc()的第2个参数设为args(1)")])])])]),t._v(" "),n("h5",{attrs:{id:"通过sparksql保存结果数据到mysql表中-集群"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#通过sparksql保存结果数据到mysql表中-集群"}},[t._v("#")]),t._v(" 通过sparksql保存结果数据到mysql表中(集群)")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("Properties\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" Demo2 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("appName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrCreate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" url"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbc:mysql://node03:3306/spark"')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" tableName"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user"')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" properties"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setProperty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"root"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setProperty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"password"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"123456"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" mysqlDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("jdbc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("tableName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    mysqlDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTempView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" resultDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from user where age > 30"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    resultDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"append"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("jdbc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("p",[t._v("提交任务脚本")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("spark-submit "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--master spark://node01:7077 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--class com.kaikeba.sql.Data2Mysql "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--executor-memory 1g "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--total-executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--driver-class-path /home/hadoop/jars/mysql-connector-java-5.1.38.jar "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--jars /home/hadoop/jars/mysql-connector-java-5.1.38.jar "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\noriginal-spark_class05-1.0-SNAPSHOT.jar "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\nappend  t_kaikeba\n\n\n--driver-class-path：指定一个Driver端所需要的额外jar\n--jars ：指定executor端所需要的额外jar\n")])])]),n("h2",{attrs:{id:"sparksql-保存数据到不同类型文件"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparksql-保存数据到不同类型文件"}},[t._v("#")]),t._v(" sparksql 保存数据到不同类型文件")]),t._v(" "),n("p",[t._v("创建F:\\test\\score.json文件：")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"zhangsan1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"classNum"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"10"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"score"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("90")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"zhangsan11"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"classNum"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"10"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"score"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("90")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"zhangsan2"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"classNum"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"10"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"score"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("80")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"zhangsan3"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"classNum"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"10"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"score"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("95")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"zhangsan4"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"classNum"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"20"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"score"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("90")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"zhangsan5"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"classNum"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"20"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"score"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("91")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"zhangsan6"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"classNum"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"20"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"score"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("86")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"zhangsan7"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"classNum"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"20"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"score"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("78")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"zhangsan8"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"classNum"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"30"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"score"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("60")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"zhangsan9"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"classNum"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"30"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"score"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("88")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"zhangsan10"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"classNum"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"30"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"score"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("95")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("代码开发：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("Properties\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" Demo3 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("appName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("master"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("getOrCreate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" dataDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("json"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"file:///F:/test/score.json"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//处理数据：")]),t._v("\n    dataDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTempView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tableDemo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from tableDemo where score > 80"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//保存数据：")]),t._v("\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("json"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"file:///F:/test/out_json"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parquet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"file:///F:/test/out_parquet"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("save"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"file:///F:/test/out_save"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("csv"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"file:///F:/test/out_csv"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("saveAsTable"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"t1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("partitionBy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"classNum"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("json"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"file:///F:/test/out_partition_json"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("partitionBy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"classNum"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("json"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"file:///F:/test/out_partition2_json"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("说明：")]),t._v(" "),n("ol",[n("li",[t._v("out_xxx等都是目录来的，而且是由程序来创建，不需要事先创建，否则报错")]),t._v(" "),n("li",[t._v("write.save()默认保存为parquet格式")]),t._v(" "),n("li",[t._v("经过partitionBy分区后保存的数据文件如下：")])]),t._v(" "),n("img",{staticStyle:{zoom:"80%"},attrs:{src:"spark.assets/image-20200418172427804.png",alt:"image-20200418172427804"}}),t._v(" "),n("ol",[n("li",[t._v('result.write.saveAsTable("t1")保存表t1在spark-warehouse目录下：')])]),t._v(" "),n("p",[n("img",{attrs:{src:a(1577),alt:"image-20200418172519068"}})]),t._v(" "),n("h2",{attrs:{id:"sparksql中自定义函数-★★★★★"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparksql中自定义函数-★★★★★"}},[t._v("#")]),t._v(" sparksql中自定义函数(★★★★★)")]),t._v(" "),n("p",[t._v("创建文件F:/test/test_udf.txt")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("hello\nHadoop\nDataFrame\nspark\n")])])]),n("p",[t._v("自定义UDF函数")]),t._v(" "),n("p",[t._v("代码开发")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("api"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("UDF1\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("types"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("StringType\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" Demo3 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("appName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("master"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("getOrCreate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" dataDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"file:///F:/test/test_udf.txt"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    dataDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTempView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"udfTest"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//自定义函数方法1:小写--》大写")]),t._v("\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("udf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("register"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"low2Up"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" UDF1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("override")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" call"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" t1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toUpperCase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("StringType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//自定义函数方法2：大写--》小写")]),t._v("\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("udf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("register"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"up2Low"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toLowerCase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select value from udfTest"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select low2Up(value) from udfTest"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select up2Low(value) from udfTest"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("p",[t._v("运行结果为：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("UDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("low2Up"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("            HELLO"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("           HADOOP"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("        DATAFRAME"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("            SPARK"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("UDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("up2Low"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("            hello"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("           hadoop"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("        dataframe"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("            spark"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("p",[t._v("说明：")]),t._v(" "),n("ol",[n("li",[t._v("udf.register()支持的参数如下, (函数名称，函数，返回值类型) ，通过该方法，我们可以自定义函数")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(1578),alt:"image-20200418173539916"}})]),t._v(" "),n("ol",[n("li",[t._v("使用UDF1接口可以自定义1个输入参数的函数，UDF2接口可以自定义2个输入参数的函数，UDF3接口可以自定义3个输入参数的函数，依次类推....")]),t._v(" "),n("li",[t._v("new UDF1[String,String]的第一个参数是要定义的函数的输入参数类型，第二个参数是要定义的函数的返回值类型")]),t._v(" "),n("li")]),t._v(" "),n("h2",{attrs:{id:"sparksql整合hive"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparksql整合hive"}},[t._v("#")]),t._v(" sparksql整合hive")]),t._v(" "),n("h5",{attrs:{id:"spark整合hive步骤"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark整合hive步骤"}},[t._v("#")]),t._v(" spark整合hive步骤")]),t._v(" "),n("p",[t._v("把node03的hive安装目录下的配置文件hive-site.xml拷贝到每一个spark安装目录下对应的conf文件夹中（3台机器）")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("cd")]),t._v(" /kkb/install/hive-1.1.0-cdh5.14.2/conf\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("cp")]),t._v(" hive-site.xml /kkb/install/spark/conf/\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("scp")]),t._v(" hive-site.xml node01:/kkb/install/spark/conf/\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("scp")]),t._v(" hive-site.xml node02:/kkb/install/spark/conf/\n")])])]),n("p",[t._v("把node03的hive的libe目录下的连接mysql驱动的jar包拷贝到spark安装目录下对应的jars文件夹中（3台机器）")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("cd")]),t._v(" /kkb/install/hive-1.1.0-cdh5.14.2/lib\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("cp")]),t._v(" mysql-connector-java-5.1.38.jar /kkb/install/spark/jars/\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("scp")]),t._v(" mysql-connector-java-5.1.38.jar node01:/kkb/install/spark/jars/\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("scp")]),t._v(" mysql-connector-java-5.1.38.jar node02:/kkb/install/spark/jars/\n")])])]),n("p",[t._v("可以使用spark-sql脚本 后期执行sql相关的任务")]),t._v(" "),n("h5",{attrs:{id:"启动hive相关的spark-sql"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#启动hive相关的spark-sql"}},[t._v("#")]),t._v(" 启动hive相关的spark sql")]),t._v(" "),n("p",[t._v("启动整合hive的spark sql")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("spark-sql "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--master spark://node01:7077 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--executor-memory 1g "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--total-executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--conf spark.sql.warehouse.dir"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("hdfs://node01:8020/user/hive/warehouse \n")])])]),n("p",[t._v("启动之后，可以看到如下shell:")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1579),alt:"image-20200419011931846"}})]),t._v(" "),n("p",[t._v("我们之前了解过，spark sql是兼容hive sql 的，因此，在这里我们可以像在hive shell那样，进行对hive数据仓库的操作。如：")]),t._v(" "),n("div",{staticClass:"language-sql extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sql"}},[n("code",[t._v("spark"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("sql")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("default")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("show")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("databases")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\ndatabaseName\ndb1\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("default")]),t._v("\n\nspark"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("sql")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("default")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" db1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\nspark"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("sql")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("default")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("show")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("tables")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("database")]),t._v("        tableName       isTemporary\ndb1     hivedemo        "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\ndb1     sparkdemo1      "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n\nspark"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("sql")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("default")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sparkdemo1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nid      name    age\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("       krystal "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),t._v("\n")])])]),n("h5",{attrs:{id:"写运行spark-sql语句的脚本"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#写运行spark-sql语句的脚本"}},[t._v("#")]),t._v(" 写运行spark sql语句的脚本")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node01 ~"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mkdir")]),t._v(" sparkTest\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("cd")]),t._v(" sparkTest\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("vi")]),t._v(" sparkHiveDemo.sh\n")])])]),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[n("span",{pre:!0,attrs:{class:"token shebang important"}},[t._v("#!/bin/sh")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#定义sparksql提交脚本的头信息")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("SUBMITINFO")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark-sql --master spark://node01:7077 --executor-memory 1g --total-executor-cores 2 --conf spark.sql.warehouse.dir=hdfs://node01:8020/user/hive/warehouse"')]),t._v(" \n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#定义一个sql语句")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("SQL")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from db1.sparkDemo1;"')]),t._v(" \n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#执行sql语句   类似于 hive -e sql语句")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("echo")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),n("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$SUBMITINFO")]),t._v('"')]),t._v(" \n"),n("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("echo")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),n("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$SQL")]),t._v('"')]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$SUBMITINFO")]),t._v(" -e "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),n("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$SQL")]),t._v('"')]),t._v("\n")])])]),n("p",[t._v("运行脚本：")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token function"}},[t._v("sh")]),t._v(" sparkHiveDemo.sh\n")])])]),n("p",[t._v("运行结果为：")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("id      name    age\n1       krystal 21\n")])])]),n("h2",{attrs:{id:"sparksql处理点击流日志数据案例-★★★★★"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparksql处理点击流日志数据案例-★★★★★"}},[t._v("#")]),t._v(" sparksql处理点击流日志数据案例(★★★★★)")]),t._v(" "),n("h5",{attrs:{id:"需求描述"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#需求描述"}},[t._v("#")]),t._v(" 需求描述")]),t._v(" "),n("p",[t._v("通过sparsql对用户访问产生点击流日志数据进行分析处理，计算出对应的指标")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1580),alt:"image-20200419015002531"}})]),t._v(" "),n("h5",{attrs:{id:"工具类开发"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#工具类开发"}},[t._v("#")]),t._v(" 工具类开发")]),t._v(" "),n("p",[t._v("代码开发——校验日志数据进行字段解析提取的工具类AccessLogUtils")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("scala"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("matching"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("Regex\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//定义一个样例类，将切分后的一行数据封装在该类里：")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" AccessLog"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n                      ipAddress"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// IP地址")]),t._v("\n                      clientId"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 客户端唯一标识符")]),t._v("\n                      userId"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 用户唯一标识符")]),t._v("\n                      serverTime"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 服务器时间")]),t._v("\n                      method"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 请求类型/方式")]),t._v("\n                      endpoint"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 请求的资源")]),t._v("\n                      protocol"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 请求的协议名称")]),t._v("\n                      responseCode"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 请求返回值：比如：200、401")]),t._v("\n                      contentSize"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 返回的结果数据大小")]),t._v("\n                      url"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//访问的url地址")]),t._v("\n                      clientBrowser"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//客户端游览器信息")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" MyUtils "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" regex"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Regex"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""^(\\S+) (\\S+) (\\S+) \\[([\\w:/]+\\s[+\\-]\\d{4})\\] "(\\S+) (\\S+) (\\S+)" (\\d{3}) (\\d+) (\\S+) (.*)"""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("r\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//自定义过滤方法来过滤脏数据")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" isValidLine"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("line"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Boolean")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//findFirstMatchIn 是一个匹配方法，返回值是Some或者None")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" options"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("regex"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("findFirstMatchIn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("line"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("options"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isEmpty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//定义一个方法，将一行数据切分，并封装在AccessLog类中，并返回AccessLog对象：")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" parseLine"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("line"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" AccessLog "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" options"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("regex"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("findFirstMatchIn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("line"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" matcher"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("options"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get\n    AccessLog"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      matcher"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("group"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 获取匹配的字符串中的第一组的值")]),t._v("\n      matcher"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("group"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      matcher"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("group"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      matcher"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("group"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      matcher"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("group"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      matcher"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("group"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      matcher"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("group"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      matcher"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("group"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toInt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      matcher"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("group"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toLong"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      matcher"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("group"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      matcher"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("group"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("p",[t._v("说明：")]),t._v(" "),n("ol",[n("li",[t._v("正则表达式：可以利用notepad的正则表达式方式的查找功能来解析每个正则表达式的意思\n"),n("ol",[n("li",[t._v("^代表开头的意思")]),t._v(" "),n("li",[t._v("\\S代表非空格和非Tab键   + 代表至少一个字符  (\\S+)代表至少一个非空格Tab键的字符")]),t._v(" "),n("li",[t._v("(\\S+)代表至少有一个非空格非Tab键的字符")]),t._v(" "),n("li",[t._v("\\[([\\w:/]+\\s[+\\-]\\d{4})\\] 中的\n"),n("ol",[n("li",[t._v("\\[代表 [")]),t._v(" "),n("li",[t._v("\\w代表大小写字母，数字和下划线，")]),t._v(" "),n("li",[t._v("[\\w:/]+代表 大小写字母，数字和下划线、冒号:、斜线/中的任意字符至少一位，")]),t._v(" "),n("li",[t._v("\\s代表空格或tab键")]),t._v(" "),n("li",[t._v("[+\\-]代表 +或者-")]),t._v(" "),n("li",[t._v("\\d{4}代表4为数字")]),t._v(" "),n("li",[t._v("]代表]")]),t._v(" "),n("li",[t._v("匹配举例：[19/Sep/2013:04:08:36 +0000]")])])]),t._v(" "),n("li",[t._v(".*代表任意个数的任意字符")]),t._v(" "),n("li",[t._v("正则表达式中的括号() 代表一个组，我们的正则表达式有11个括号()，所以有11个组")]),t._v(" "),n("li",[t._v('第一个括号就是第1组，依次类推，后期我们可以获取指定第几组的数据，因此，对匹配到的一行数据就不需要split(" ")切分了。')]),t._v(" "),n("li",[t._v("findFirstMatchIn()是匹配到第一个成功匹配的数据")])])]),t._v(" "),n("li",[t._v('val regex:Regex="xxx".r的是字符串上的方法，该方法可以返回一个new Regex对象')]),t._v(" "),n("li",[t._v("正则表达式中会出现特殊字符等，Scala中可以使用三对引号来直接输特殊字符，不需要转义符")])]),t._v(" "),n("h5",{attrs:{id:"指标统计"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#指标统计"}},[t._v("#")]),t._v(" 指标统计")]),t._v(" "),n("p",[t._v("大致步骤：构建sparkSession和sparkContext对象---》加载数据为RDD---》过滤掉脏数据---》将数据转为DataFrame---》将DataFrame注册成一张表---》指标统计分析---》将分析统计结果保存到mysql---》关闭资源")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("Properties\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("RDD\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("SparkSession\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" LogAnalysis "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" url"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbc:mysql://node03:3306/spark"')]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" properties"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setProperty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"user"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"root"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setProperty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"password"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"123456"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("appName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("master"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrCreate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sparkContext\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"warn"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" lineRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"E:\\\\LearningAll\\\\8-HadoopEcosystem-Video\\\\spark下载资料\\\\spark_day05\\\\案例数据\\\\access.log"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" lineCleanRDD2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("lineRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("filter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("line"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("MyUtils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isValidLine"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("line"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" parseRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("AccessLog"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("lineCleanRDD2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("line"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("MyUtils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parseLine"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("line"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//RDD---\x3eDataFrame")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("implicits"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("_\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" dataDF"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("parseRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    dataDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//注册")]),t._v("\n    dataDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTempView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"accesslog"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//开始分析数据")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n        |select\n        |date_sub(from_unixtime(unix_timestamp(),\'yyyy-MM-dd\'),1) as time,\n        |AVG(contentSize) as avg_contentSize,\n        |MAX(contentSize) as max_contentSize,\n        |MIN(contentSize) as min_contentSize\n        |from accesslog\n        |"""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stripMargin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//PV,UV")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n        |select\n        |date_sub(from_unixtime(unix_timestamp(),\'yyyy-MM-dd\'),1) as time,\n        |count(*) as PV,\n        |count(distinct ipAddress) as UV\n        |from accesslog\n        |"""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stripMargin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result3"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n        |select\n        |date_sub(from_unixtime(unix_timestamp(),\'yyyy-MM-dd\'),1) as time,\n        |responseCode as code,\n        |count(*) as count\n        |from accesslog\n        |group by responseCode\n        |"""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stripMargin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//求访问url次数最多的前N位")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result4 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n        |select\n        |*,date_sub(from_unixtime(unix_timestamp(),\'yyyy-MM-dd\'),1) as time\n        |from (\n        |select\n        |url as url,\n        |count(*) as count\n        |from accesslog\n        |group by url) t\n        |order by t.count desc limit 5\n          """')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stripMargin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result4"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//求各个请求方式出现的次数")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result5 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n        |select\n        |date_sub(from_unixtime(unix_timestamp(),\'yyyy-MM-dd\'),1) as time,\n        |method as method,\n        |count(*) as count\n        |from accesslog\n        |group by method\n          """')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stripMargin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result5"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//保存result5数据到mysql")]),t._v("\n    result5"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("jdbc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"t_method"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("properties"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//不需要事先自己创建表")]),t._v("\n\n    spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("说明：")]),t._v(" "),n("ol",[n("li",[t._v("DATE_SUB(date,INTERVAL expr type)是一个将日期减去指定的时间间隔的函数，"),n("em",[t._v("date")]),t._v(" 参数是合法的日期表达式。"),n("em",[t._v("expr")]),t._v(" 参数是您希望添加的时间间隔。")]),t._v(" "),n("li",[t._v('函数：FROM_UNIXTIME\n作用：将MYSQL中以INT(11)存储的时间（时间戳）以"YYYY-MM-DD"格式来显示。\n语法：'),n("strong",[t._v("FROM_UNIXTIME(unix_timestamp,format)")])]),t._v(" "),n("li",[t._v("unix_timestamp()可以获取当前时间的时间戳")]),t._v(" "),n("li",[t._v("unix_timestamp()也可以传入一个date参数，表示获取date的时间戳，Unix timestamp(date) 中的date需满足格式：yyyy-MM-dd HH:mm:ss或者yyyy-MM-dd")]),t._v(" "),n("li",[t._v("date_sub(from_unixtime(unix_timestamp(),'yyyy-MM-dd'),1)表示当前时间减1天，进行减1天的原因大概是在实际工作当中，一般是对昨天的数据进行统计分析的，所以在当前时间减1天")])]),t._v(" "),n("p",[t._v("运行结果为：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("     ipAddress"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("clientId"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("userId"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("          serverTime"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("method"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("            endpoint"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("protocol"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("responseCode"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("contentSize"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("url"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("       clientBrowser"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("194.237")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".142")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".21")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("       "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("     "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Sep"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2013")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("06")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("49.")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("|   GET"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("wp"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("content"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("uploa"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("|HTTP"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("         "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("304")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("          "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"-"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v('"Mozilla'),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4.0")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("com"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("|\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("163.177")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".71")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".12")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("       "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("     "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Sep"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2013")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("06")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("49.")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("|  HEAD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("                   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("HTTP"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("         "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("         "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"-"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"DNSPod-Monitor/1.0"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("163.177")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".71")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".12")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("       "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("     "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Sep"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2013")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("06")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("49.")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("|  HEAD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("                   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("HTTP"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("         "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("         "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"-"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"DNSPod-Monitor/1.0"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("101.226")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".68")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".137")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("       "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("     "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Sep"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2013")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("06")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("49.")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("|  HEAD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("                   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("HTTP"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("         "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("         "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"-"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"DNSPod-Monitor/1.0"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("101.226")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".68")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".137")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("       "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("     "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("Sep"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2013")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("06")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("49.")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("|  HEAD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("                   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("HTTP"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("         "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("         "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"-"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"DNSPod-Monitor/1.0"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\nonly showing top "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(" rows\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("      time"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   avg_contentSize"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("max_contentSize"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("min_contentSize"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15882.708061002179")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("         "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("432916")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("              "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("      time"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   PV"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  UV"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("13770")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1027")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("      time"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("code"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("count"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("500")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("502")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("301")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("94")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("400")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("13")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("403")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("404")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("201")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("408")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("12340")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("304")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("949")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("499")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("302")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("152")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("                 url"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("count"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("      time"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("                 "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"-"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5204")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v('"http'),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("blog"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("|  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("547")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v('"http'),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("blog"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("|  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("377")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v('"http'),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("blog"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("|  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("360")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v('"http'),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("blog"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fens"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("|  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("274")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("      time"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("method"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("count"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  POST"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("449")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  HEAD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2941")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   GET"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10380")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("p",[t._v("查看保存到mysql的数据：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("mysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" show tables"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" Tables_in_spark "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" t_method        "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" t_students      "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" user            "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" user2           "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" rows in set "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.00")]),t._v(" sec"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nmysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" select "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" from t_method"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" time       "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" method "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" count "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" POST   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("449")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" HEAD   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2941")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("04")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("18")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" GET    "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10380")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n")])])]),n("h2",{attrs:{id:"spark调优-分配更多的资源"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark调优-分配更多的资源"}},[t._v("#")]),t._v(" Spark调优——分配更多的资源")]),t._v(" "),n("p",[t._v("分配更多的资源是性能优化调优的王道，就是增加和分配更多的资源，这对于性能和速度上的提升是显而易见的。")]),t._v(" "),n("p",[t._v("基本上，在一定范围之内，增加资源与性能的提升，是成正比的；写完了一个复杂的spark作业之后，进行性能调优的时候，首先第一步，就是要来调节最优的资源配置；")]),t._v(" "),n("p",[t._v("在这个基础之上，如果说你的spark作业，能够分配的资源达到了你的能力范围的顶端之后，无法再分配更多的资源了，公司资源有限；那么才是考虑去做后面的这些性能调优的点。")]),t._v(" "),n("p",[t._v("相关问题：")]),t._v(" "),n("ol",[n("li",[t._v("分配哪些资源？")]),t._v(" "),n("li",[t._v("在哪里可以设置这些资源？")]),t._v(" "),n("li",[t._v("剖析为什么分配这些资源之后，性能可以得到提升？")])]),t._v(" "),n("h4",{attrs:{id:"分配哪些资源"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#分配哪些资源"}},[t._v("#")]),t._v(" 分配哪些资源")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("executor"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("memory、executor"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("cores、driver"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("memory\n")])])]),n("h4",{attrs:{id:"在哪里可以设置这些资源"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#在哪里可以设置这些资源"}},[t._v("#")]),t._v(" 在哪里可以设置这些资源")]),t._v(" "),n("p",[t._v("在实际的生产环境中，提交spark任务时，使用spark-submit shell脚本，在里面调整对应的参数。")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[t._v("spark-submit "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n --master spark://node1:7077 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n --class com.kaikeba.WordCount "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n --num-executors "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("    配置executor的数量\n --driver-memory 1g "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("   配置driver的内存（影响不大）\n --executor-memory 1g "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v(" 配置每一个executor的内存大小\n --executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("   配置每一个executor的cpu个数\n /export/servers/wordcount.jar\n")])])]),n("h4",{attrs:{id:"参数调节到多大-算是最大"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#参数调节到多大-算是最大"}},[t._v("#")]),t._v(" 参数调节到多大，算是最大")]),t._v(" "),n("p",[t._v("Standalone模式")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v(" \t先计算出公司spark集群上的所有资源 每台节点的内存大小和cpu核数，\n \t比如：一共有20台worker节点，每台节点8g内存，10个cpu。\n \t实际任务在给定资源的时候，可以给20个executor、每个executor的内存8g、每个executor的使用的cpu个数10。\n")])])]),n("p",[t._v("Yarn模式")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v(" \t先计算出yarn集群的所有大小，比如一共500g内存，100个cpu；\n \t这个时候可以分配的最大资源，比如给定50个executor、每个executor的内存大小10g,每个executor使用的cpu个数为2。\n")])])]),n("p",[t._v("使用原则")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("在资源比较充足的情况下，尽可能的使用更多的计算资源，尽量去调节到最大的大小\n")])])]),n("h4",{attrs:{id:"为什么调大资源以后性能可以提升"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#为什么调大资源以后性能可以提升"}},[t._v("#")]),t._v(" 为什么调大资源以后性能可以提升")]),t._v(" "),n("h5",{attrs:{id:"executor-memory-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#executor-memory-2"}},[t._v("#")]),t._v(" --executor-memory")]),t._v(" "),n("ul",[n("li",[t._v("表示每一个executor进程需要的内存大小，它决定了后期操作数据的速度")])]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("比如说一个rdd的数据量大小为5g,这里给定的executor-memory为2g, 在这种情况下，内存是存储不下，它会把一部分数据保存在内存中，还有一部分数据保存在磁盘，后续需要用到该rdd的结果数据，可以从内存和磁盘中获取得到，这里就涉及到一定的磁盘io操作。\n\n,这里给定的executor-memory为10g，这里数据就可以完全在内存中存储下，后续需要用到该rdd的数据，就可以直接从内存中获取，这样一来，避免了大量的磁盘io操作。性能得到提升。\n\n\n在实际的工作，这里 --executor-memory 需要设置的大一点。\n比如说10G/20G/30G等\n")])])]),n("h5",{attrs:{id:"total-executor-cores-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#total-executor-cores-2"}},[t._v("#")]),t._v(" --total-executor-cores")]),t._v(" "),n("p",[t._v("--total-executor-cores表示任务运行需要总的cpu核数，它决定了任务并行运行的粒度")]),t._v(" "),n("p",[t._v("比如说要处理100个task，注意一个cpu在同一时间只能处理一个task线程。")]),t._v(" "),n("ol",[n("li",[n("p",[t._v("如果给定的总的cpu核数是5个，这里就需要100/5=20个批次才可以把这100个task运行完成，如果平均每个task运行1分钟，这里最后一共运行20分钟。")])]),t._v(" "),n("li",[n("p",[t._v("如果给定的总的cpu核数是20个，这里就需要100/20=5个批次才可以把这100个task运行完成，如果平均每个task运行1分钟，这里最后一共运行5分钟。")])]),t._v(" "),n("li",[n("p",[t._v("如果如果给定的总的cpu核数是100个，这里就需要100/100=1个批次才可以把这100个task运行完成，如果平均每个task运行1分钟，这里最后一共运行1分钟。")])])]),t._v(" "),n("p",[t._v("在实际的生产环境中，--total-executor-cores 这个参数一般也会设置的大一点，比如说 30个/50个/100个")]),t._v(" "),n("p",[t._v("注意：如果分配的cpu核数比总的task线程数量还打会造成资源浪费。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1581),alt:"image-20200416204239271"}})]),t._v(" "),n("p",[n("img",{attrs:{src:a(1582),alt:"spark性能优化--分配资源"}})]),t._v(" "),n("h2",{attrs:{id:"spark调优-提高并行度"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark调优-提高并行度"}},[t._v("#")]),t._v(" Spark调优——提高并行度")]),t._v(" "),n("h4",{attrs:{id:"spark的并行度指的是什么"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark的并行度指的是什么"}},[t._v("#")]),t._v(" Spark的并行度指的是什么")]),t._v(" "),n("p",[t._v("spark作业中，各个stage的task的数量，也就代表了spark作业在各个阶段stage的并行度！")]),t._v(" "),n("p",[t._v("当分配完所能分配的最大资源了，然后对应资源去调节程序的并行度，如果并行度没有与资源相匹配，那么导致你分配下去的资源都浪费掉了。同时并行运行，还可以让每个task要处理的数量变少（很简单的原理。合理设置并行度，可以充分利用集群资源，减少每个task处理数据量，而增加性能加快运行速度。）")]),t._v(" "),n("h4",{attrs:{id:"如何提高并行度"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#如何提高并行度"}},[t._v("#")]),t._v(" 如何提高并行度")]),t._v(" "),n("h5",{attrs:{id:"可以设置task的数量"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#可以设置task的数量"}},[t._v("#")]),t._v(" 可以设置task的数量")]),t._v(" "),n("p",[t._v("task数量至少设置成与spark Application 的总cpu core 数量相同。最理想情况，150个core，分配150task，一起运行，差不多同一时间运行完毕")]),t._v(" "),n("p",[t._v("官方推荐，task数量，设置成spark Application 总cpu core数量的2~3倍 。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",[n("code",[t._v("比如150个cpu core ，基本设置task数量为300~500. 与理想情况不同的，有些task会运行快一点，比如50s就完了，有些task 可能会慢一点，要一分半才运行完，所以如果你的task数量，刚好设置的跟cpu core 数量相同，可能会导致资源的浪费。\n")])])]),n("p",[t._v("因为比如150个task中10个先运行完了，剩余140个还在运行，但是这个时候，就有10个cpu core空闲出来了，导致浪费。如果设置2~3倍，那么一个task运行完以后，另外一个task马上补上来，尽量让cpu core不要空闲。同时尽量提升spark运行效率和速度。提升性能。")]),t._v(" "),n("h5",{attrs:{id:"设置task数量方法1-spark-default-parallelism"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#设置task数量方法1-spark-default-parallelism"}},[t._v("#")]),t._v(" 设置task数量方法1——spark.default.parallelism")]),t._v(" "),n("p",[t._v("spark.default.parallelism")]),t._v(" "),n("p",[t._v("参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。")]),t._v(" "),n("p",[t._v("参数调优建议：Spark作业的默认task数量为500~1000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。")]),t._v(" "),n("p",[t._v("可以通过在构建SparkConf对象的时候设置，例如：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark.defalut.parallelism"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"500"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h5",{attrs:{id:"设置task数量方法2-给rdd重新设置partition的数量"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#设置task数量方法2-给rdd重新设置partition的数量"}},[t._v("#")]),t._v(" 设置task数量方法2——给RDD重新设置partition的数量")]),t._v(" "),n("p",[t._v("使用rdd.repartition 来重新分区，该方法会生成一个新的rdd，使其分区数变大。")]),t._v(" "),n("p",[t._v("此时由于一个partition对应一个task，那么对应的task个数越多，通过这种方式也可以提高并行度。")]),t._v(" "),n("h5",{attrs:{id:"设置task数量方法3-提高sparksql运行的task数量"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#设置task数量方法3-提高sparksql运行的task数量"}},[t._v("#")]),t._v(" 设置task数量方法3——提高sparksql运行的task数量")]),t._v(" "),n("p",[t._v("通过设置参数 spark.sql.shuffle.partitions=500  默认为200；")]),t._v(" "),n("p",[t._v("可以适当增大，来提高并行度。 比如设置为 spark.sql.shuffle.partitions=500。")]),t._v(" "),n("p",[t._v("该参数的作用：Configures the number of partitions to use when shuffling data for joins or aggregations.")]),t._v(" "),n("h2",{attrs:{id:"spark调优-rdd的重用和持久化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark调优-rdd的重用和持久化"}},[t._v("#")]),t._v(" Spark调优——RDD的重用和持久化")]),t._v(" "),n("h5",{attrs:{id:"实际开发遇到的情况说明"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#实际开发遇到的情况说明"}},[t._v("#")]),t._v(" 实际开发遇到的情况说明")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1583),alt:"rdd重用1"}})]),t._v(" "),n("p",[t._v("如上图所示的计算逻辑：")]),t._v(" "),n("p",[t._v("（1）当第一次使用rdd2做相应的算子操作得到rdd3的时候，就会从rdd1开始计算，先读取HDFS上的文件，然后对rdd1做对应的算子操作得到rdd2,再由rdd2计算之后得到rdd3。同样为了计算得到rdd4，前面的逻辑会被重新计算。")]),t._v(" "),n("p",[t._v("（3）默认情况下多次对一个rdd执行算子操作，去获取不同的rdd，都会对这个rdd及之前的父rdd全部重新计算一次。这种情况在实际开发代码的时候会经常遇到，但是我们一定要避免一个rdd重复计算多次，否则会导致性能急剧降低。")]),t._v(" "),n("p",[t._v("总结：可以把多次使用到的rdd，也就是公共rdd进行持久化，避免后续需要，再次重新计算，提升效率。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1584),alt:"rdd重用2"}})]),t._v(" "),n("h5",{attrs:{id:"如何对rdd进行持久化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#如何对rdd进行持久化"}},[t._v("#")]),t._v(" 如何对rdd进行持久化")]),t._v(" "),n("p",[t._v("可以调用rdd的cache或者persist方法。")]),t._v(" "),n("p",[t._v("（1）cache方法默认是把数据持久化到内存中 ，例如：rdd.cache ，其本质还是调用了persist方法")]),t._v(" "),n("p",[t._v("（2）persist方法中有丰富的缓存级别，这些缓存级别都定义在StorageLevel这个object中，可以结合实际的应用场景合理的设置缓存级别。")]),t._v(" "),n("p",[t._v("例如： rdd.persist(StorageLevel.MEMORY_ONLY),这是cache方法的实现。")]),t._v(" "),n("h5",{attrs:{id:"rdd持久化的时可以采用序列化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#rdd持久化的时可以采用序列化"}},[t._v("#")]),t._v(" rdd持久化的时可以采用序列化")]),t._v(" "),n("p",[t._v("（1）如果正常将数据持久化在内存中，那么可能会导致内存的占用过大，这样的话，也许会导致OOM内存溢出。")]),t._v(" "),n("p",[t._v("（2）当纯内存无法支撑公共RDD数据完全存放的时候，就优先考虑使用序列化的方式在纯内存中存储。将RDD的每个partition的数据，序列化成一个字节数组；序列化后，大大减少内存的空间占用。")]),t._v(" "),n("p",[t._v("（3）序列化的方式，唯一的缺点就是，在获取数据的时候，需要反序列化。但是可以减少占用的空间和便于网络传输")]),t._v(" "),n("p",[t._v("（4）如果序列化纯内存方式，还是导致OOM，内存溢出；就只能考虑磁盘的方式，内存+磁盘的普通方式（无序列化）。")]),t._v(" "),n("p",[t._v("（5）为了数据的高可靠性，而且内存充足，可以使用双副本机制，进行持久化")]),t._v(" "),n("p",[t._v("持久化的双副本机制，持久化后的一个副本，因为机器宕机了，副本丢了，就还是得重新计算一次；")]),t._v(" "),n("p",[t._v("持久化的每个数据单元，存储一份副本，放在其他节点上面，从而进行容错；")]),t._v(" "),n("p",[t._v("一个副本丢了，不用重新计算，还可以使用另外一份副本。这种方式，仅仅针对你的内存资源极度充足。")]),t._v(" "),n("p",[t._v("比如: StorageLevel.MEMORY_ONLY_2")]),t._v(" "),n("h2",{attrs:{id:"spark调优-广播变量的使用"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark调优-广播变量的使用"}},[t._v("#")]),t._v(" Spark调优——广播变量的使用")]),t._v(" "),n("h5",{attrs:{id:"场景描述"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#场景描述"}},[t._v("#")]),t._v(" 场景描述")]),t._v(" "),n("p",[t._v("在实际工作中可能会遇到这样的情况，由于要处理的数据量非常大，这个时候可能会在一个stage中出现大量的task，比如有1000个task，这些task都需要一份相同的数据来处理业务，这份数据的大小为100M，该数据会拷贝1000份副本，通过网络传输到各个task中去，给task使用。")]),t._v(" "),n("p",[t._v("这里会涉及大量的网络传输开销，同时至少需要的内存为1000*100M=100G，这个内存开销是非常大的。不必要的内存的消耗和占用，就导致了你在进行RDD持久化到内存，也许就没法完全在内存中放下；就只能写入磁盘，最后导致后续的操作在磁盘IO上消耗性能；这对于spark任务处理来说就是一场灾难。")]),t._v(" "),n("p",[t._v("由于内存开销比较大，task在创建对象的时候，可能会出现堆内存放不下所有对象，就会导致频繁的垃圾回收器的回收GC。GC的时候一定是会导致工作线程停止，也就是导致Spark暂停工作那么一点时间。频繁GC的话，对Spark作业的运行的速度会有相当可观的影响。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1585),alt:"task共享数据"}})]),t._v(" "),n("h5",{attrs:{id:"广播变量引入"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#广播变量引入"}},[t._v("#")]),t._v(" 广播变量引入")]),t._v(" "),n("p",[t._v("Spark中分布式执行的代码需要传递到各个executor的task上运行。对于一些只读、固定的数据,每次都需要Driver广播到各个Task上，这样效率低下。广播变量允许将变量只广播给各个executor。")]),t._v(" "),n("p",[t._v("该executor上的各个task再从所在节点的BlockManager(负责管理某个executor对应的内存和磁盘上的数据)获取变量，而不是从Driver获取变量，从而提升了效率。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1586),alt:"广播变量"}})]),t._v(" "),n("p",[t._v("广播变量，初始的时候，就在Drvier上有一份副本。通过在Driver把共享数据转换成广播变量。")]),t._v(" "),n("p",[t._v("task在运行的时候，想要使用广播变量中的数据，此时首先会在自己本地的Executor对应的BlockManager中，尝试获取变量副本；如果本地没有，那么就从Driver远程拉取广播变量副本，并保存在本地的BlockManager中；")]),t._v(" "),n("p",[t._v("此后这个executor上的task，都会直接使用本地的BlockManager中的副本。那么这个时候所有该executor中的task都会使用这个广播变量的副本。也就是说一个executor只需要在第一个task启动时，获得一份广播变量数据，之后的task都从本节点的BlockManager中获取相关数据。")]),t._v(" "),n("p",[t._v("executor的BlockManager除了从driver上拉取，也可能从其他节点的BlockManager上拉取变量副本，网络距离越近越好。")]),t._v(" "),n("h5",{attrs:{id:"使用广播变量后的性能分析"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#使用广播变量后的性能分析"}},[t._v("#")]),t._v(" 使用广播变量后的性能分析")]),t._v(" "),n("p",[t._v("比如一个任务需要50个executor，1000个task，共享数据为100M。")]),t._v(" "),n("p",[t._v("(1)在不使用广播变量的情况下，1000个task，就需要该共享数据的1000个副本，也就是说有1000份数需要大量的网络传输和内存开销存储。耗费的内存大小1000"),n("em",[t._v("100=100G.")])]),t._v(" "),n("p",[t._v("(2)使用了广播变量后，50个executor就只需要50个副本数据，而且不一定都是从Driver传输到每个节点，还可能是就近从最近的节点的executor的blockmanager上拉取广播变量副本，网络传输速度大大增加；内存开销 50*100M=5G")]),t._v(" "),n("p",[t._v("总结：\n不使用广播变量的内存开销为100G，使用后的内存开销5G，这里就相差了20倍左右的网络传输性能损耗和内存开销，使用广播变量后对于性能的提升和影响，还是很可观的。\n广播变量的使用不一定会对性能产生决定性的作用。比如运行30分钟的spark作业，可能做了广播变量以后，速度快了2分钟，或者5分钟。但是一点一滴的调优，积少成多。最后还是会有效果的。")]),t._v(" "),n("h5",{attrs:{id:"广播变量使用注意事项"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#广播变量使用注意事项"}},[t._v("#")]),t._v(" 广播变量使用注意事项")]),t._v(" "),n("ol",[n("li",[n("p",[t._v("能不能将一个RDD使用广播变量广播出去？")]),t._v(" "),n("p",[t._v("不能，因为RDD是不存储数据的。可以将RDD的结果广播出去。")])]),t._v(" "),n("li",[n("p",[t._v("广播变量只能在Driver端定义，不能在Executor端定义。")])]),t._v(" "),n("li",[n("p",[t._v("在Driver端可以修改广播变量的值，在Executor端无法修改广播变量的值。")])]),t._v(" "),n("li",[n("p",[t._v("如果executor端用到了Driver的变量，如果不使用广播变量在Executor有多少task就有多少Driver端的变量副本。")])]),t._v(" "),n("li",[n("p",[t._v("如果Executor端用到了Driver的变量，如果使用广播变量在每个Executor中只有一份Driver端的变量副本。")])])]),t._v(" "),n("h5",{attrs:{id:"如何使用广播变量"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#如何使用广播变量"}},[t._v("#")]),t._v(" 如何使用广播变量")]),t._v(" "),n("p",[t._v("(1) 通过sparkContext的broadcast方法把数据转换成广播变量，类型为Broadcast，")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" broadcastArray"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Broadcast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("broadcast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("(2) 然后executor上的BlockManager就可以拉取该广播变量的副本获取具体的数据。")]),t._v(" "),n("p",[t._v("获取广播变量中的值可以通过调用其value方法")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" array"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" broadcastArray"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value\n")])])]),n("h2",{attrs:{id:"spark调优-尽量避免使用shuffle类算子"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark调优-尽量避免使用shuffle类算子"}},[t._v("#")]),t._v(" Spark调优——尽量避免使用shuffle类算子")]),t._v(" "),n("h5",{attrs:{id:"shuffle描述"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#shuffle描述"}},[t._v("#")]),t._v(" shuffle描述")]),t._v(" "),n("p",[t._v("spark中的shuffle涉及到数据要进行大量的网络传输，下游阶段的task任务需要通过网络拉取上阶段task的输出数据，shuffle过程，简单来说，就是将分布在集群中多个节点上的同一个key，拉取到同一个节点上，进行聚合或join等操作。比如reduceByKey、join等算子，都会触发shuffle操作。")]),t._v(" "),n("p",[t._v("如果有可能的话，要尽量避免使用shuffle类算子。")]),t._v(" "),n("p",[t._v("因为Spark作业运行过程中，最消耗性能的地方就是shuffle过程。")]),t._v(" "),n("h5",{attrs:{id:"哪些算子操作会产生shuffle"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#哪些算子操作会产生shuffle"}},[t._v("#")]),t._v(" 哪些算子操作会产生shuffle")]),t._v(" "),n("p",[t._v("spark程序在开发的过程中使用reduceByKey、join、distinct、repartition等算子操作，这里都会产生shuffle，由于shuffle这一块是非常耗费性能的，实际开发中尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。")]),t._v(" "),n("h5",{attrs:{id:"避免产生shuffle的小案例"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#避免产生shuffle的小案例"}},[t._v("#")]),t._v(" 避免产生shuffle的小案例")]),t._v(" "),n("p",[t._v("错误的做法：")]),t._v(" "),n("p",[t._v("传统的join操作会导致shuffle操作。因为两个RDD中，相同的key都需要通过网络拉取到一个节点上，由一个task进行join操作。")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd3 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("img",{attrs:{src:a(1587),alt:"image-20200419135700724"}})]),t._v(" "),n("p",[t._v("正确的做法：Broadcast+map的join操作，不会导致shuffle操作")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 使用Broadcast将一个数据量较小的RDD作为广播变量。")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2Data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rdd2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd2DataBroadcast "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("broadcast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd2Data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 在rdd1.map算子中，可以从rdd2DataBroadcast中，获取rdd2的所有数据。")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 然后进行遍历，如果发现rdd2中某条数据的key与rdd1的当前数据的key是相同的，那么就判定可以进行join。")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 此时就可以根据自己需要的方式，将rdd1当前数据与rdd2中可以连接的数据，拼接在一起（String或Tuple）。")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" rdd3 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rdd1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd2DataBroadcast"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//写一个方法来事先拼接操作")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 注意，以上操作，建议仅仅在rdd2的数据量比较少（比如几百M，或者一两G）的情况下使用。")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 因为每个Executor的内存中，都会驻留一份rdd2的全量数据。")]),t._v("\n")])])]),n("h5",{attrs:{id:"使用map-side预聚合的shuffle操作"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#使用map-side预聚合的shuffle操作"}},[t._v("#")]),t._v(" 使用map-side预聚合的shuffle操作")]),t._v(" "),n("p",[t._v("map-side预聚合")]),t._v(" "),n("p",[t._v("如果因为业务需要，一定要使用shuffle操作，无法用map类的算子来替代，那么尽量使用可以map-side预聚合的算子。")]),t._v(" "),n("p",[t._v("所谓的map-side预聚合，说的是在每个节点本地对相同的key进行一次聚合操作，类似于MapReduce中的本地combiner。")]),t._v(" "),n("p",[t._v("map-side预聚合之后，每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。")]),t._v(" "),n("p",[t._v("通常来说，在可能的情况下，建议使用reduceByKey或者aggregateByKey算子来替代掉groupByKey算子。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合。而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。")]),t._v(" "),n("p",[t._v("比如如下两幅图，就是典型的例子，分别基于reduceByKey和groupByKey进行单词计数。其中第一张图是groupByKey的原理图，可以看到，没有进行任何本地聚合时，所有数据都会在集群节点之间传输；第二张图是reduceByKey的原理图，可以看到，每个节点本地的相同key数据，都进行了预聚合，然后才传输到其他节点上进行全局聚合。")]),t._v(" "),n("p",[n("strong",[t._v("groupByKey进行单词计数原理")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(1588),alt:"1577080609633"}})]),t._v(" "),n("p",[n("strong",[t._v("reduceByKey单词计数原理")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(1589),alt:"1577080686083"}})]),t._v(" "),n("h2",{attrs:{id:"spark调优-使用高性能的算子"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark调优-使用高性能的算子"}},[t._v("#")]),t._v(" Spark调优——使用高性能的算子")]),t._v(" "),n("h5",{attrs:{id:"使用reducebykey-aggregatebykey替代groupbykey"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#使用reducebykey-aggregatebykey替代groupbykey"}},[t._v("#")]),t._v(" 使用reduceByKey/aggregateByKey替代groupByKey")]),t._v(" "),n("ul",[n("li",[t._v("reduceByKey/aggregateByKey 可以进行预聚合操作，减少数据的传输量，提升性能")]),t._v(" "),n("li",[t._v("groupByKey 不会进行预聚合操作，进行数据的全量拉取，性能比较低")])]),t._v(" "),n("h5",{attrs:{id:"使用mappartitions替代普通map"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#使用mappartitions替代普通map"}},[t._v("#")]),t._v(" 使用mapPartitions替代普通map")]),t._v(" "),n("p",[t._v("mapPartitions类的算子，一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些。")]),t._v(" "),n("p",[t._v("但是有的时候，使用mapPartitions会出现OOM（内存溢出）的问题。因为单次函数调用就要处理掉一个partition所有的数据，如果内存不够，垃圾回收时是无法回收掉太多对象的，很可能出现OOM异常。所以使用这类操作时要慎重！")]),t._v(" "),n("h5",{attrs:{id:"使用foreachpartitions替代foreach"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#使用foreachpartitions替代foreach"}},[t._v("#")]),t._v(" 使用foreachPartitions替代foreach")]),t._v(" "),n("p",[t._v("原理类似于“使用mapPartitions替代map”，也是一次函数调用处理一个partition的所有数据，而不是一次函数调用处理一条数据。")]),t._v(" "),n("p",[t._v("在实践中发现，foreachPartitions类的算子，对性能的提升还是很有帮助的。比如在foreach函数中，将RDD中所有数据写MySQL，那么如果是普通的foreach算子，就会一条数据一条数据地写，每次函数调用可能就会创建一个数据库连接，此时就势必会频繁地创建和销毁数据库连接，性能是非常低下；")]),t._v(" "),n("p",[t._v("但是如果用foreachPartitions算子一次性处理一个partition的数据，那么对于每个partition，只要创建一个数据库连接即可，然后执行批量插入操作，此时性能是比较高的。实践中发现，对于1万条左右的数据量写MySQL，性能可以提升30%以上。")]),t._v(" "),n("h5",{attrs:{id:"使用filter之后进行coalesce操作"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#使用filter之后进行coalesce操作"}},[t._v("#")]),t._v(" 使用filter之后进行coalesce操作")]),t._v(" "),n("p",[t._v("通常对一个RDD执行filter算子过滤掉RDD中较多数据后（比如30%以上的数据），建议使用coalesce算子，手动减少RDD的partition数量，将RDD中的数据压缩到更少的partition中去。")]),t._v(" "),n("p",[t._v("因为filter之后，RDD的每个partition中都会有很多数据被过滤掉，此时如果照常进行后续的计算，其实每个task处理的partition中的数据量并不是很多，有一点资源浪费，而且此时处理的task越多，可能速度反而越慢。")]),t._v(" "),n("p",[t._v("因此用coalesce减少partition数量，将RDD中的数据压缩到更少的partition之后，只要使用更少的task即可处理完所有的partition。在某些场景下，对于性能的提升会有一定的帮助。")]),t._v(" "),n("h5",{attrs:{id:"使用repartitionandsortwithinpartitions替代repartition与sort类操作"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#使用repartitionandsortwithinpartitions替代repartition与sort类操作"}},[t._v("#")]),t._v(" 使用repartitionAndSortWithinPartitions替代repartition与sort类操作")]),t._v(" "),n("p",[t._v("repartitionAndSortWithinPartitions是Spark官网推荐的一个算子，官方建议，如果需要在repartition重分区之后，还要进行排序，建议直接使用repartitionAndSortWithinPartitions算子。")]),t._v(" "),n("p",[t._v("因为该算子可以一边进行重分区的shuffle操作，一边进行排序。shuffle与sort两个操作同时进行，比先shuffle再sort来说，性能可能是要高的。")]),t._v(" "),n("h2",{attrs:{id:"spark调优-使用kryo优化序列化性能"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark调优-使用kryo优化序列化性能"}},[t._v("#")]),t._v(" Spark调优——使用Kryo优化序列化性能")]),t._v(" "),n("h5",{attrs:{id:"spark序列化介绍"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark序列化介绍"}},[t._v("#")]),t._v(" spark序列化介绍")]),t._v(" "),n("p",[t._v("Spark在进行任务计算的时候，会涉及到数据跨进程的网络传输、数据的持久化，这个时候就需要对数据进行序列化。Spark默认采用Java的序列化器。默认java序列化的优缺点如下:")]),t._v(" "),n("p",[t._v("其好处：处理起来方便，不需要我们手动做其他操作，只需要在使用一个对象和变量的时候，实现Serializble接口即可。")]),t._v(" "),n("p",[t._v("其缺点：默认的序列化机制的效率不高，序列化的速度比较慢；序列化以后的数据，占用的内存空间相对还是比较大。")]),t._v(" "),n("p",[t._v("Spark支持使用Kryo序列化机制。Kryo序列化机制，比默认的Java序列化机制，速度要快，序列化后的数据要更小，大概是Java序列化机制的1/10。所以Kryo序列化优化以后，可以让网络传输的数据变少；在集群中耗费的内存资源大大减少。")]),t._v(" "),n("h5",{attrs:{id:"kryo序列化启用后生效的地方"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#kryo序列化启用后生效的地方"}},[t._v("#")]),t._v(" Kryo序列化启用后生效的地方")]),t._v(" "),n("p",[t._v("Kryo序列化机制，一旦启用以后，会生效的几个地方：")]),t._v(" "),n("p",[t._v("（1）算子函数中使用到的外部变量")]),t._v(" "),n("p",[t._v("算子中的外部变量可能来着与driver需要涉及到网络传输，就需要用到序列化。")]),t._v(" "),n("p",[t._v("最终可以优化网络传输的性能，优化集群中内存的占用和消耗")]),t._v(" "),n("p",[t._v("（2）持久化RDD时进行序列化，StorageLevel.MEMORY_ONLY_SER")]),t._v(" "),n("p",[t._v("将rdd持久化时，对应的存储级别里，需要用到序列化。")]),t._v(" "),n("p",[t._v("最终可以优化内存的占用和消耗；持久化RDD占用的内存越少，task执行的时候，创建的对象，就不至于频繁的占满内存，频繁发生GC。")]),t._v(" "),n("p",[t._v("（3）产生shuffle的地方，也就是宽依赖")]),t._v(" "),n("p",[t._v("下游的stage中的task，拉取上游stage中的task产生的结果数据，跨网络传输，需要用到序列化。最终可以优化网络传输的性能")]),t._v(" "),n("h5",{attrs:{id:"如何开启kryo序列化机制"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#如何开启kryo序列化机制"}},[t._v("#")]),t._v(" 如何开启Kryo序列化机制")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 创建SparkConf对象。")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 设置序列化器为KryoSerializer。")]),t._v("\nconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark.serializer"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"org.apache.spark.serializer.KryoSerializer"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 注册要序列化的自定义类型。")]),t._v("\nconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("registerKryoClasses"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("classOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("MyClass1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" classOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("MyClass2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h2",{attrs:{id:"spark调优-使用fastutil优化数据格式"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark调优-使用fastutil优化数据格式"}},[t._v("#")]),t._v(" Spark调优——使用fastutil优化数据格式")]),t._v(" "),n("h5",{attrs:{id:"fastutil介绍"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#fastutil介绍"}},[t._v("#")]),t._v(" fastutil介绍")]),t._v(" "),n("p",[t._v("fastutil是扩展了Java标准集合框架（Map、List、Set；HashMap、ArrayList、HashSet）的类库，提供了特殊类型的map、set、list和queue；")]),t._v(" "),n("p",[t._v("fastutil能够提供更小的内存占用，更快的存取速度；我们使用fastutil提供的集合类，来替代自己平时使用的JDK的原生的Map、List、Set.")]),t._v(" "),n("h5",{attrs:{id:"fastutil好处"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#fastutil好处"}},[t._v("#")]),t._v(" fastutil好处")]),t._v(" "),n("p",[t._v("fastutil集合类，可以减小内存的占用，并且在进行集合的遍历、根据索引（或者key）获取元素的值和设置元素的值的时候，提供更快的存取速度")]),t._v(" "),n("h5",{attrs:{id:"spark中应用fastutil的场景和使用"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark中应用fastutil的场景和使用"}},[t._v("#")]),t._v(" Spark中应用fastutil的场景和使用")]),t._v(" "),n("h6",{attrs:{id:"算子函数使用了外部变量"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#算子函数使用了外部变量"}},[t._v("#")]),t._v(" 算子函数使用了外部变量")]),t._v(" "),n("p",[t._v("（1）你可以使用Broadcast广播变量优化；")]),t._v(" "),n("p",[t._v("（2）可以使用Kryo序列化类库，提升序列化性能和效率；")]),t._v(" "),n("p",[t._v("（3）如果外部变量是某种比较大的集合，那么可以考虑使用fastutil改写外部变量；")]),t._v(" "),n("p",[t._v("首先从源头上就减少内存的占用(fastutil)，通过广播变量进一步减少内存占用，再通过Kryo序列化类库进一步减少内存占用。")]),t._v(" "),n("h6",{attrs:{id:"算子函数里使用了比较大的集合map-list"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#算子函数里使用了比较大的集合map-list"}},[t._v("#")]),t._v(" 算子函数里使用了比较大的集合Map/List")]),t._v(" "),n("p",[t._v("在你的算子函数里，也就是task要执行的计算逻辑里面，如果有逻辑中，出现，要创建比较大的Map、List等集合，可能会占用较大的内存空间，而且可能涉及到消耗性能的遍历、存取等集合操作； 那么此时，可以考虑将这些集合类型使用fastutil类库重写，")]),t._v(" "),n("p",[t._v("使用了fastutil集合类以后，就可以在一定程度上，减少task创建出来的集合类型的内存占用。\n避免executor内存频繁占满，频繁唤起GC，导致性能下降。")]),t._v(" "),n("h6",{attrs:{id:"fastutil的使用"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#fastutil的使用"}},[t._v("#")]),t._v(" fastutil的使用")]),t._v(" "),n("p",[t._v("第一步：在pom.xml中引用fastutil的包")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[t._v("    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("fastutil"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("fastutil"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("5.0.9"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("p",[t._v("第二步：平时使用List(Integer)的替换成IntList即可。")]),t._v(" "),n("p",[n("code",[t._v("List<Integer>")]),t._v("的元素类型对应到fastutil就是IntList类型")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",[n("code",[t._v("使用说明：\n")])])]),n("p",[t._v("基本都是类似于IntList的格式，前缀就是集合的元素类型；")]),t._v(" "),n("p",[t._v("特殊的就是Map，Int2IntMap，代表了key-value映射的元素类型。")]),t._v(" "),n("h2",{attrs:{id:"spark调优-调节数据本地化等待时长"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark调优-调节数据本地化等待时长"}},[t._v("#")]),t._v(" Spark调优——调节数据本地化等待时长")]),t._v(" "),n("p",[t._v("Spark在Driver上对Application的每一个stage的task进行分配之前，都会计算出每个task要计算的是哪个分片数据，RDD的某个partition；Spark的task分配算法，优先会希望每个task正好分配到它要计算的数据所在的节点，这样的话就不用在网络间传输数据；")]),t._v(" "),n("p",[t._v("但是通常来说，有时事与愿违，可能task没有机会分配到它的数据所在的节点，为什么呢，可能那个节点的计算资源和计算能力都满了；所以这种时候，通常来说，Spark会等待一段时间，默认情况下是3秒（不是绝对的，还有很多种情况，对不同的本地化级别，都会去等待），到最后实在是等待不了了，就会选择一个比较差的本地化级别，比如说将task分配到距离要计算的数据所在节点比较近的一个节点，然后进行计算。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1590),alt:"image-20200419142802894"}})]),t._v(" "),n("h5",{attrs:{id:"本地化级别"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#本地化级别"}},[t._v("#")]),t._v(" 本地化级别")]),t._v(" "),n("p",[t._v("（1）PROCESS_LOCAL：进程本地化")]),t._v(" "),n("p",[t._v("代码和数据在同一个进程中，也就是在同一个executor中；计算数据的task由executor执行，数据在executor的BlockManager中；性能最好")]),t._v(" "),n("p",[t._v("（2）NODE_LOCAL：节点本地化")]),t._v(" "),n("p",[t._v("代码和数据在同一个节点中；比如说数据作为一个HDFS block块，就在节点上，而task在节点上某个executor中运行；或者是数据和task在一个节点上的不同executor中；数据需要在进程间进行传输；性能其次")]),t._v(" "),n("p",[t._v("（3）RACK_LOCAL：机架本地化")]),t._v(" "),n("p",[t._v("数据和task在一个机架的两个节点上；数据需要通过网络在节点之间进行传输； 性能比较差")]),t._v(" "),n("p",[t._v("（4）ANY：无限制")]),t._v(" "),n("p",[t._v("数据和task可能在集群中的任何地方，而且不在一个机架中；性能最差")]),t._v(" "),n("h5",{attrs:{id:"数据本地化等待时长"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#数据本地化等待时长"}},[t._v("#")]),t._v(" 数据本地化等待时长")]),t._v(" "),n("p",[t._v("spark.locality.wait，默认是3s")]),t._v(" "),n("p",[t._v("首先采用最佳的方式，等待3s后降级,还是不行，继续降级...,最后还是不行，只能够采用最差的。")]),t._v(" "),n("h5",{attrs:{id:"如何调节参数并且测试"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#如何调节参数并且测试"}},[t._v("#")]),t._v(" 如何调节参数并且测试")]),t._v(" "),n("p",[t._v("修改spark.locality.wait参数，默认是3s，可以增加")]),t._v(" "),n("p",[t._v("下面是每个数据本地化级别的等待时间，默认都是跟spark.locality.wait时间相同，默认都是3s")]),t._v(" "),n("p",[t._v("(可查看spark官网对应参数说明，如下图所示)")]),t._v(" "),n("p",[t._v("spark.locality.wait.node")]),t._v(" "),n("p",[t._v("spark.locality.wait.process")]),t._v(" "),n("p",[t._v("spark.locality.wait.rack")]),t._v(" "),n("p",[t._v("在代码中设置：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark.locality.wait"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"10"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("然后把程序提交到spark集群中运行，注意观察日志，spark作业的运行日志，推荐大家在测试的时候，先用client模式，在本地就直接可以看到比较全的日志。")]),t._v(" "),n("p",[t._v("日志里面会显示，starting task .... PROCESS LOCAL、NODE LOCAL.....")]),t._v(" "),n("p",[t._v("例如：")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[t._v("Starting task "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" stage "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("TID "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(", "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("192.168")]),t._v(".200.102, partition "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(", NODE_LOCAL, "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5254")]),t._v(" bytes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("观察大部分task的数据本地化级别，如果大多都是PROCESS_LOCAL，那就不用调节了。")]),t._v(" "),n("p",[t._v("如果是发现，好多的级别都是NODE_LOCAL、ANY，那么最好就去调节一下数据本地化的等待时长。应该是要反复调节，每次调节完以后，再来运行，观察日志 看看大部分的task的本地化级别有没有提升；看看整个spark作业的运行时间有没有缩短。")]),t._v(" "),n("p",[t._v("注意注意：在调节参数、运行任务的时候，别本末倒置，本地化级别倒是提升了， 但是因为大量的等待时长，spark作业的运行时间反而增加了，那就还是不要调节了。")]),t._v(" "),n("h2",{attrs:{id:"spark调优-基于spark内存模型调优"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark调优-基于spark内存模型调优"}},[t._v("#")]),t._v(" Spark调优——基于Spark内存模型调优")]),t._v(" "),n("h4",{attrs:{id:"spark中executor内存划分"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark中executor内存划分"}},[t._v("#")]),t._v(" spark中executor内存划分")]),t._v(" "),n("p",[t._v("Executor的内存主要分为三块")]),t._v(" "),n("ul",[n("li",[t._v("第一块是让task执行我们自己编写的代码时使用；")]),t._v(" "),n("li",[t._v("第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用")]),t._v(" "),n("li",[t._v("第三块是让RDD缓存时使用")])]),t._v(" "),n("h4",{attrs:{id:"spark的内存模型"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spark的内存模型"}},[t._v("#")]),t._v(" spark的内存模型")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("\t在spark1.6版本以前 spark的executor使用的静态内存模型，但是在spark1.6开始，多增加了一个统一内存模型。\n\t通过spark.memory.useLegacyMode 这个参数去配置\n\t\t\t默认这个值是false，代表用的是新的动态内存模型；\n\t\t\t如果想用以前的静态内存模型，那么就要把这个值改为true。\n")])])]),n("h5",{attrs:{id:"静态内存模型"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#静态内存模型"}},[t._v("#")]),t._v(" 静态内存模型")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1591),alt:"1570604272790"}})]),t._v(" "),n("p",[t._v("实际上就是把我们的一个executor分成了三部分，")]),t._v(" "),n("ol",[n("li",[t._v("Storage内存区域，")]),t._v(" "),n("li",[t._v("execution区域，")]),t._v(" "),n("li",[t._v("Others其他区域。")])]),t._v(" "),n("p",[t._v("如果使用的静态内存模型，那么用这几个参数去控制：")]),t._v(" "),n("ol",[n("li",[t._v("spark.storage.memoryFraction：默认0.6")]),t._v(" "),n("li",[t._v("spark.shuffle.memoryFraction：默认0.2")]),t._v(" "),n("li",[t._v("所以第三部分就是0.2")])]),t._v(" "),n("p",[t._v("如果我们cache数据量比较大，或者是我们的广播变量比较大，那我们就把spark.storage.memoryFraction这个值调大一点。")]),t._v(" "),n("p",[t._v("但是如果我们代码里面没有广播变量，也没有cache，shuffle又比较多，那我们要把spark.shuffle.memoryFraction 这值调大。")]),t._v(" "),n("h6",{attrs:{id:"静态内存模型的缺点"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#静态内存模型的缺点"}},[t._v("#")]),t._v(" 静态内存模型的缺点")]),t._v(" "),n("p",[t._v("我们配置好了Storage内存区域和execution区域后，我们的一个任务假设execution内存不够用了，但是它的Storage内存区域是空闲的，两个之间不能互相借用，不够灵活，所以才出来我们新的统一内存模型。")]),t._v(" "),n("h5",{attrs:{id:"统一内存模型"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#统一内存模型"}},[t._v("#")]),t._v(" 统一内存模型")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1592),alt:"img"}})]),t._v(" "),n("p",[t._v("动态内存模型先是预留了300m内存，防止内存溢出。动态内存模型把整体内存分成了两部分，由这个参数表示spark.memory.fraction 这个指的默认值是0.6 代表另外的一部分是0.4,")]),t._v(" "),n("p",[t._v("然后spark.memory.fraction 这部分又划分成为两个小部分。这两小部分共占整体内存的0.6 .这两部分其实就是：Storage内存和execution内存。由spark.memory.storageFraction 这个参数去调配，因为两个共占0.6。如果spark.memory.storageFraction这个值配的是0.5,那说明这0.6里面 storage占了0.5，也就是executor占了0.3 。")]),t._v(" "),n("p",[t._v("统一内存模型有什么特点呢?")]),t._v(" "),n("p",[t._v("Storage内存和execution内存 可以相互借用。不用像静态内存模型那样死板，但是是有规则的")]),t._v(" "),n("p",[n("strong",[t._v("场景一")]),t._v(": Execution使用的时候发现内存不够了，然后就会把storage的内存里的数据驱逐到磁盘上,腾出来的内存空间将借给Execution。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1593),alt:"1570604662552"}})]),t._v(" "),n("p",[n("strong",[t._v("场景二")]),t._v(": 一开始execution的内存使用得不多，但是storage使用的内存多，所以storage就借用了execution的内存，但是后来execution也要需要内存了，这个时候就会把storage的内存里的数据写到磁盘上，腾出内存空间。")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1594),alt:"1570604675176"}})]),t._v(" "),n("p",[t._v("为什么受伤的都是storage呢？是因为execution里面的数据是马上就要用的，而storage里的数据不一定马上就要用。")]),t._v(" "),n("h6",{attrs:{id:"任务提交脚本参考"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#任务提交脚本参考"}},[t._v("#")]),t._v(" 任务提交脚本参考")]),t._v(" "),n("p",[t._v("以下是一份spark-submit命令的示例，大家可以参考一下，并根据自己的实际情况进行调节")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[t._v("./bin/spark-submit "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --master yarn-cluster "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --num-executors "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --executor-memory 6G "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --driver-memory 1G "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --conf spark.default.parallelism"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --conf spark.storage.memoryFraction"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n  --conf spark.shuffle.memoryFraction"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.3")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n")])])]),n("h6",{attrs:{id:"个人经验"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#个人经验"}},[t._v("#")]),t._v(" 个人经验")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token class-name"}},[n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lang"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("OutOfMemoryError")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ExecutorLostFailure")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Executor")]),t._v(" exit code 为"),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("143")]),t._v("\nexecutor lost\nhearbeat time out\nshuffle file lost\n\n如果遇到以上问题，很有可能就是内存除了问题，可以先尝试增加内存。如果还是解决不了，那么请听下一次数据倾斜调优的课。\n")])])]),n("h2",{attrs:{id:"招聘要求介绍"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#招聘要求介绍"}},[t._v("#")]),t._v(" 招聘要求介绍")]),t._v(" "),n("p",[n("img",{attrs:{src:a(1595),alt:"1565872653413"}})]),t._v(" "),n("p",[n("img",{attrs:{src:a(1596),alt:"1565872766577"}})])])}),[],!1,null,null,null);s.default=r.exports},346:function(t,s){t.exports="data:image/png;base64,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"}}]);