(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{1412:function(t,a,s){t.exports=s.p+"assets/img/streaming-arch-1608485794544.645c1861.png"},1413:function(t,a,s){t.exports=s.p+"assets/img/image-20200422150253653-1608485794544.4653d71a.png"},1414:function(t,a,s){t.exports=s.p+"assets/img/sparkStreaming架构流程-1608485794544.e466e465.png"},1415:function(t,a,s){t.exports=s.p+"assets/img/streaming-dstream-1608485794544.fabdf95b.png"},1416:function(t,a,s){t.exports=s.p+"assets/img/streaming-dstream-ops-1608485794544.ecc85f84.png"},1417:function(t,a,s){t.exports=s.p+"assets/img/DStream逻辑图-1608485794544.90b9e380.png"},1418:function(t,a,s){t.exports=s.p+"assets/img/1582444394566-1608485794544.a62380ac.png"},1419:function(t,a,s){t.exports=s.p+"assets/img/image-20200423000846608-1608485794544.c5978fae.png"},1420:function(t,a,s){t.exports=s.p+"assets/img/image-20200423003440585-1608485794544.9aa78933.png"},1421:function(t,a,s){t.exports=s.p+"assets/img/1582444992866-1608485794544.ad6e1770.png"},1422:function(t,a,s){t.exports=s.p+"assets/img/image-20200423035855381-1608485794544.a4195a90.png"},1423:function(t,a,s){t.exports=s.p+"assets/img/image-20200423035950826-1608485794544.e88692d4.png"},1424:function(t,a,s){t.exports=s.p+"assets/img/image-20200423040120447-1608485794545.1bc0ac38.png"},1425:function(t,a,s){t.exports=s.p+"assets/img/1567414277097-1584924072316-1608485794545.5a6af600.png"},1426:function(t,a,s){t.exports=s.p+"assets/img/1567414739556-1584924084233-1608485794545.a8320463.png"},1427:function(t,a,s){t.exports=s.p+"assets/img/1567414846715-1584924092832-1608485794545.f2b16e22.png"},1428:function(t,a,s){t.exports=s.p+"assets/img/image-20200424042337680-1608485794545.2a3408cf.png"},1429:function(t,a,s){t.exports=s.p+"assets/img/1567416495877-1608485794545.1417b123.png"},1430:function(t,a,s){t.exports=s.p+"assets/img/1567417919912-1608485794545.3d4219f6.png"},1431:function(t,a,s){t.exports=s.p+"assets/img/Task推测机制-1608485794545.4bc9a959.png"},1432:function(t,a,s){t.exports=s.p+"assets/img/image-20200424142427376-1608485794545.3b646446.png"},1433:function(t,a,s){t.exports=s.p+"assets/img/image-20200424143312397-1608485794545.0a5a9a90.png"},1434:function(t,a,s){t.exports=s.p+"assets/img/image-20200424154359505-1608485794545.f66632ba.png"},1435:function(t,a,s){t.exports=s.p+"assets/img/image-20200424170120758-1608485794545.0f8715ff.png"},1436:function(t,a,s){t.exports=s.p+"assets/img/kafka08SaveOffset2ZK-1608485794545.64dd9c48.png"},1437:function(t,a,s){t.exports=s.p+"assets/img/1567325066744-1608485794545.b042984f.png"},1438:function(t,a,s){t.exports=s.p+"assets/img/1585058900250-1608485794545.098bf077.png"},1439:function(t,a,s){t.exports=s.p+"assets/img/1585058915092-1608485794545.4f21ba92.png"},1440:function(t,a,s){t.exports=s.p+"assets/img/1567327168554-1608485794545.45fc942e.png"},1441:function(t,a,s){t.exports=s.p+"assets/img/1567327191622-1608485794545.79783499.png"},1442:function(t,a,s){t.exports=s.p+"assets/img/1567327216060-1608485794545.1a3bdc95.png"},1443:function(t,a,s){t.exports=s.p+"assets/img/1567327351927-1608485794545.165c3b8b.png"},1444:function(t,a,s){t.exports=s.p+"assets/img/1567327385166-1608485794545.7363d307.png"},1445:function(t,a,s){t.exports=s.p+"assets/img/1567327412253-1608485794545.4547d784.png"},2016:function(t,a,s){"use strict";s.r(a);var n=s(17),e=Object(n.a)({},(function(){var t=this,a=t.$createElement,n=t._self._c||a;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("p",[t._v("大数据实时技术框架发展")]),t._v(" "),n("blockquote",[n("p",[t._v("(1)storm:")]),t._v(" "),n("p",[t._v("​\t它是一个实时的处理框架，可以实现来一条数据就处理一条数据，实时性非常高，但吞吐量很低。")]),t._v(" "),n("p",[t._v("​\t已经被淘汰了。")]),t._v(" "),n("p",[t._v("(2)sparkstreaming:")]),t._v(" "),n("p",[t._v("​\t它不能算是实时的处理引擎，其本质是批处理，只不过由于要处理的数据是源源不断的，并且每个\t\t批次非常小，然后处理起来很快，让我们感觉有实时的效果。是微批处理。")]),t._v(" "),n("p",[t._v("​\t从严格意义来说，sparkstreaming并不是一个实时处理框架，可以理解是准实时的。")]),t._v(" "),n("p",[t._v("​\t特性：实时性不高，吞吐量比较高。")]),t._v(" "),n("p",[t._v("(2)flink:")]),t._v(" "),n("p",[t._v("​\t它是真正意义上的实时处理框架，来一条数据就处理一条数据，它的实时性非常高，吞吐量也非常\t\t高。是未来大数据的发展方向。")])]),t._v(" "),n("h2",{attrs:{id:"sparkstreaming简介"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparkstreaming简介"}},[t._v("#")]),t._v(" SparkStreaming简介")]),t._v(" "),n("p",[t._v("SparkStreaming是对于Spark核心API的拓展，从而"),n("strong",[t._v("支持对于实时数据流的可拓展，高吞吐量和容错性流处理")]),t._v("。数据可以由多个源取得，例如：Kafka，Flume，Twitter，ZeroMQ，Kinesis或者TCP接口，同时可以使用由如map，reduce，join和window这样的高层接口描述的复杂算法进行处理。最终，处理过的数据可以被推送到文件系统，数据库和HDFS。")]),t._v(" "),n("p",[t._v("数据从Kafka上获得时，我们可以把SparkStreaming理解成Kafka的消费者程序。")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1412),alt:"Spark Streaming"}})]),t._v(" "),n("p",[t._v("Spark Streaming 是基于spark的流式批处理引擎，其"),n("strong",[t._v("基本原理是把输入数据以某一时间间隔批量的处理，当批处理间隔缩短到秒级时，便可以用于处理实时数据流。")])]),t._v(" "),n("p",[t._v("流式：源源不断地数据流入")]),t._v(" "),n("p",[t._v("流式批处理：一批批的数据源源不断地流入")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1413),alt:"image-20200422150253653"}})]),t._v(" "),n("h2",{attrs:{id:"sparkstreaming架构流程"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparkstreaming架构流程"}},[t._v("#")]),t._v(" SparkStreaming架构流程")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1414),alt:"sparkStreaming架构流程"}})]),t._v(" "),n("ol",[n("li",[t._v("将sparkstreaming程序打成jar包，提交到spark集群。")]),t._v(" "),n("li",[t._v("SparkStreaming就是一个application，需要创建流式处理的上下文对象StreamingContext,该StreamingContext内部会封装一个sparkContext,sparkContext是运行在Driver之上。根据不同的运行模式，在对应的服务器构建一个Driver。")]),t._v(" "),n("li",[t._v("==Driver端发送Receiver（接收器）对象到某个executor进程==中，receiver是用来接收数据源的数据的，默认只有一个，可以配置多个，Receiver会占用一个线程。")]),t._v(" "),n("li",[t._v("==Receiver会把接收到的一条条数据封装成一个个block==，然后把这些block数据写入到当前executor的内存中。==默认是每200ms之内接收的数据就是一个block，通过设置block-interval来改变这个值。==")]),t._v(" "),n("li",[t._v("Receiver把接收到的数据块block的信息通知给Driver。这里会有向Driver端申请资源的步骤，暂时省略，跟之前学习spark时讲的申请资源流程大致一样。")]),t._v(" "),n("li",[t._v("申请好资源后，会在不同的机器节点启动其它的executor，executor里面也会有task,一个task(线程）将会处理一个block块的数据。")]),t._v(" "),n("li",[t._v("==Driver端根据一定的时间间隔，把这些block块组成一个RDD==，然后对这些RDD进行处理。==其中一个block就是RDD中的1个partition，一个partition对应1个task任务==。默认的批处理时间间隔batch-size=1s,")]),t._v(" "),n("li",[t._v("按照批处理时间间隔和产生block的时间间隔的默认值，可以知道：每隔1s就会生成一个job,这个job对应的RDD的分区数为1s/200ms=5个。")])]),t._v(" "),n("h2",{attrs:{id:"sparkstreaming程序入口"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparkstreaming程序入口"}},[t._v("#")]),t._v(" SparkStreaming程序入口")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"NetworkWordCount"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//或者")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h2",{attrs:{id:"什么是dstream"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#什么是dstream"}},[t._v("#")]),t._v(" 什么是DStream")]),t._v(" "),n("p",[t._v("==离散数据流或者DStream是SparkStreaming提供的基本抽象==。其表现数据的连续流，这个输入数据流可以来自于源，也可以来自于转换输入流产生的已处理数据流。==内部而言，一个DStream以一系列连续的RDDs所展现==，这些RDD是Spark对于不变的，分布式数据集的抽象。一个DStream中的每个RDD都包含来自一定间隔的数据，如下图：")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1415),alt:""}})]),t._v(" "),n("p",[t._v("==在DStream上使用的任何操作都会转换为针对底层RDD的操作，每一次对Dstream的处理都是针对当前批次生成的RDD数据==。例如：之前那个将行的流转变为词流的例子中，flatMap操作应用于行DStream的每个RDD上 从而产生words DStream的RDD。如下图：")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1416),alt:"Spark Streaming"}})]),t._v(" "),n("p",[n("img",{attrs:{src:s(1417),alt:"DStream逻辑图"}})]),t._v(" "),n("h2",{attrs:{id:"dstream算子操作"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dstream算子操作"}},[t._v("#")]),t._v(" DStream算子操作")]),t._v(" "),n("h4",{attrs:{id:"transformations"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#transformations"}},[t._v("#")]),t._v(" Transformations")]),t._v(" "),n("p",[t._v("==实现把一个DStream转换生成一个新的DStream，延迟加载不会触发任务的执行==")]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[n("strong",[t._v("Transformation")])]),t._v(" "),n("th",[n("strong",[t._v("Meaning")])])])]),t._v(" "),n("tbody",[n("tr",[n("td",[t._v("map(func)")]),t._v(" "),n("td",[t._v("对DStream中的各个元素进行func函数操作，然后返回一个新的DStream")])]),t._v(" "),n("tr",[n("td",[t._v("flatMap(func)")]),t._v(" "),n("td",[t._v("与map方法类似，只不过各个输入项可以被输出为零个或多个输出项")])]),t._v(" "),n("tr",[n("td",[t._v("filter(func)")]),t._v(" "),n("td",[t._v("过滤出所有函数func返回值为true的DStream元素并返回一个新的DStream")])]),t._v(" "),n("tr",[n("td",[t._v("repartition(numPartitions)")]),t._v(" "),n("td",[t._v("增加或减少DStream中的分区数，从而改变DStream的并行度")])]),t._v(" "),n("tr",[n("td",[t._v("union(otherStream)")]),t._v(" "),n("td",[t._v("将源DStream和输入参数为otherDStream的元素合并，并返回一个新的DStream.")])]),t._v(" "),n("tr",[n("td",[t._v("count()")]),t._v(" "),n("td",[t._v("通过对DStream中的各个RDD中的元素进行计数，然后返回只有一个元素的RDD构成的DStream")])]),t._v(" "),n("tr",[n("td",[t._v("reduce(func)")]),t._v(" "),n("td",[t._v("对源DStream中的各个RDD中的元素利用func进行聚合操作，然后返回只有一个元素的RDD构成的新的DStream.")])]),t._v(" "),n("tr",[n("td",[t._v("countByValue()")]),t._v(" "),n("td",[t._v("对于元素类型为K的DStream，返回一个元素为（K,Long）键值对形式的新的DStream，Long对应的值为源DStream中各个RDD的key出现的次数")])]),t._v(" "),n("tr",[n("td",[t._v("reduceByKey(func, [numTasks])")]),t._v(" "),n("td",[t._v("利用func函数对源DStream中的key进行聚合操作，然后返回新的（K，V）对构成的DStream")])]),t._v(" "),n("tr",[n("td",[t._v("join(otherStream, [numTasks])")]),t._v(" "),n("td",[t._v("输入为（K,V)、（K,W）类型的DStream，返回一个新的（K，（V，W））类型的DStream")])]),t._v(" "),n("tr",[n("td",[t._v("cogroup(otherStream, [numTasks])")]),t._v(" "),n("td",[t._v("输入为（K,V)、（K,W）类型的DStream，返回一个新的 (K, Seq[V], Seq[W]) 元组类型的DStream")])]),t._v(" "),n("tr",[n("td",[t._v("transform(func)")]),t._v(" "),n("td",[t._v("通过RDD-to-RDD函数作用于DStream中的各个RDD，可以是任意的RDD操作，从而返回一个新的RDD")])]),t._v(" "),n("tr",[n("td",[t._v("updateStateByKey(func)")]),t._v(" "),n("td",[t._v("根据key的之前状态值和key的新值，对key进行更新，返回一个新状态的DStream")])]),t._v(" "),n("tr",[n("td",[t._v("reduceByKeyAndWindow")]),t._v(" "),n("td",[t._v("窗口函数操作，实现按照window窗口大小来进行计算")])])])]),t._v(" "),n("h4",{attrs:{id:"output-operations"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#output-operations"}},[t._v("#")]),t._v(" Output Operations")]),t._v(" "),n("p",[t._v("输出算子操作，==触发任务的真正运行==")]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[t._v("Output Operation")]),t._v(" "),n("th",[t._v("Meaning")])])]),t._v(" "),n("tbody",[n("tr",[n("td",[t._v("print()")]),t._v(" "),n("td",[t._v("打印到控制台")])]),t._v(" "),n("tr",[n("td",[t._v("saveAsTextFiles(prefix, [suffix])")]),t._v(" "),n("td",[t._v('保存流的内容为文本文件，文件名为"prefix-TIME_IN_MS[.suffix]".')])]),t._v(" "),n("tr",[n("td",[t._v("saveAsObjectFiles(prefix, [suffix])")]),t._v(" "),n("td",[t._v('保存流的内容为SequenceFile，文件名为 "prefix-TIME_IN_MS[.suffix]".')])]),t._v(" "),n("tr",[n("td",[t._v("saveAsHadoopFiles(prefix, [suffix])")]),t._v(" "),n("td",[t._v('保存流的内容为hadoop文件，文件名为 "prefix-TIME_IN_MS[.suffix]".')])]),t._v(" "),n("tr",[n("td",[t._v("foreachRDD(func)")]),t._v(" "),n("td",[t._v("对Dstream里面的每个RDD执行func")])])])]),t._v(" "),n("h2",{attrs:{id:"数据源-socket"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#数据源-socket"}},[t._v("#")]),t._v(" 数据源--socket")]),t._v(" "),n("h4",{attrs:{id:"需求"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#需求"}},[t._v("#")]),t._v(" 需求")]),t._v(" "),n("p",[t._v("使用sparkStreaming实时接收socket数据，实现单词计数")]),t._v(" "),n("h4",{attrs:{id:"业务处理流程图"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#业务处理流程图"}},[t._v("#")]),t._v(" 业务处理流程图")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1418),alt:"1582444394566"}})]),t._v(" "),n("h4",{attrs:{id:"安装并开启socket服务"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#安装并开启socket服务"}},[t._v("#")]),t._v(" 安装并开启socket服务")]),t._v(" "),n("p",[t._v("首先在linux服务器node01上用yum 安装nc工具，==nc命令是netcat命令的简称==,它是用来设置路由器。我们可以利用它向某个端口发送数据。")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("yum -y "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("install")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("nc")]),t._v("\n")])])]),n("p",[t._v("执行命令向指定的端口发送数据(模拟socket)")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[n("span",{pre:!0,attrs:{class:"token function"}},[t._v("nc")]),t._v(" -lk "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9999")]),t._v(" \n")])])]),n("h4",{attrs:{id:"pom-xml配置"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#pom-xml配置"}},[t._v("#")]),t._v(" pom.xml配置")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("properties")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--注意这里，设置了version,在后面就可以引用这些值了，如${scala.version}--\x3e")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("scala.version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.11.8"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("scala.version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("spark.version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.3.3"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("spark.version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" \n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("properties")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependencies")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.scala-lang"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("scala-library"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("${scala.version}"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--2.11.8--\x3e")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.spark"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("spark-streaming_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("${spark.version}"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--2.3.3--\x3e")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependencies")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("build")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("sourceDirectory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("src/main/scala"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("sourceDirectory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("testSourceDirectory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("src/test/scala"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("testSourceDirectory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("plugins")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("net.alchim31.maven"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("scala-maven-plugin"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("3.2.2"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("compile"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("testCompile"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("configuration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("args")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("arg")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("-dependencyfile"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("arg")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("arg")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("${project.build.directory}/.scala_dependencies"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("arg")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("args")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("configuration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.maven.plugins"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("maven-shade-plugin"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.4.3"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("phase")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("package"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("phase")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("shade"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("configuration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("filters")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifact")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("*:*"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifact")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("excludes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("META-INF/*.SF"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("META-INF/*.DSA"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("META-INF/*.RSA"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("excludes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("filters")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("transformers")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("transformer")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("implementation")]),n("span",{pre:!0,attrs:{class:"token attr-value"}},[n("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("mainClass")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("mainClass")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("transformer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("transformers")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("configuration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("plugins")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("build")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("h4",{attrs:{id:"开发sparkstreaming程序"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#开发sparkstreaming程序"}},[t._v("#")]),t._v(" 开发sparkStreaming程序")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("com"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("jimmy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dstream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("ReceiverInputDStream\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" MySocket "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"socketDemo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"warn"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("ReceiverInputDStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("socketTextStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9999")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//开启流式计算")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//这个表示程序不会停止运行，除非手动中断")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h4",{attrs:{id:"运行程序"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#运行程序"}},[t._v("#")]),t._v(" 运行程序")]),t._v(" "),n("p",[t._v("运行上面的Scala程序后，在node01上模拟socket以不同的速度发送数据，输入一些单词，空格隔开（要跟代码设置的分隔符一致），如下图：")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1419),alt:"image-20200423000846608"}})]),t._v(" "),n("p",[t._v("然后观察IDEA的程序运行界面，会出现类似下面格式的输出信息，每隔1000ms(1s)就会打印一次信息，可以结合sparkstreaming架构流程来分析。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("-------------------------------------------\nTime: 1587571532000 ms\n-------------------------------------------\n(spark,2)\n(hadoop,4)\n-------------------------------------------\nTime: 1587571533000 ms\n-------------------------------------------\n(,1)\n(spark,5)\n(hadoop,10)\n\n-------------------------------------------\nTime: 1587571534000 ms\n-------------------------------------------\n\n-------------------------------------------\nTime: 1587571535000 ms\n-------------------------------------------\n\n-------------------------------------------\nTime: 1587571536000 ms\n-------------------------------------------\n")])])]),n("h4",{attrs:{id:"思考问题"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#思考问题"}},[t._v("#")]),t._v(" 思考问题")]),t._v(" "),n("p",[t._v('思考一个问题：在sparkstreaming中，能不能只设置一个线程来运行，如setMaster("local[1]")。')]),t._v(" "),n("p",[t._v("答案是不可以，因为Receiver本身就占用了一个线程，一个CPU同一时间只能运行一个线程，只设置一个CPU的话，Receiver线程会一直占用着这个cpu，所以没有cpu去执行计算任务。")]),t._v(" "),n("h4",{attrs:{id:"剖析"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#剖析"}},[t._v("#")]),t._v(" 剖析")]),t._v(" "),n("p",[t._v("==每一个DStream只负责计算当前批次产生的数据，之前批次的数据，计算完成之后就不存在了。==")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1420),alt:"image-20200423003440585"}})]),t._v(" "),n("h2",{attrs:{id:"数据源-hdfs"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#数据源-hdfs"}},[t._v("#")]),t._v(" 数据源--HDFS")]),t._v(" "),n("h4",{attrs:{id:"需求-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#需求-2"}},[t._v("#")]),t._v(" 需求")]),t._v(" "),n("p",[t._v("通过sparkStreaming监控hdfs上的目录，有新的文件产生，就把数据拉取过来进行处理")]),t._v(" "),n("h4",{attrs:{id:"业务处理流程图-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#业务处理流程图-2"}},[t._v("#")]),t._v(" 业务处理流程图")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1421),alt:"1582444992866"}})]),t._v(" "),n("h4",{attrs:{id:"创建监听目录"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#创建监听目录"}},[t._v("#")]),t._v(" 创建监听目录")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("hdfs dfs -mkdir /dataStreamingDemo\n")])])]),n("h4",{attrs:{id:"代码开发"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#代码开发"}},[t._v("#")]),t._v(" 代码开发")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("com"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("jimmy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("log4j"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Level"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Logger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dstream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("ReceiverInputDStream\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" MySocket "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    Logger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getLogger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"org"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Level"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ERROR"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"socketDemo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"warn"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" value "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFileStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hdfs://node01:8020/dataStreamingDemo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//开启流式计算")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//这个表示程序不会停止运行，除非手动中断")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("blockquote",[n("p",[t._v("注意：")]),t._v(" "),n("ol",[n("li")])]),t._v(" "),n("h4",{attrs:{id:"运行程序-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#运行程序-2"}},[t._v("#")]),t._v(" 运行程序")]),t._v(" "),n("p",[t._v("创建数据文件：")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("vi /tmp/words.txt\n\nhadoop spark spark\nflume flink hadoop hadoop\n")])])]),n("p",[t._v("运行sparkStreaming程序,然后上传文件到hdfs的/dataStreamingDemo目录")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("hdfs dfs -put /tmp/words.txt /dataStreamingDemo\n")])])]),n("p",[t._v("观察IDEA程序运行界面，输出结果大致如下：")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("Time: 1587583799000 ms\n-------------------------------------------\n\n-------------------------------------------\nTime: 1587583800000 ms\n-------------------------------------------\n(flink,1)\n(spark,2)\n(hadoop,3)\n(flume,1)\n\n-------------------------------------------\nTime: 1587583801000 ms\n-------------------------------------------\n\n-------------------------------------------\n")])])]),n("h4",{attrs:{id:"报错问题"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#报错问题"}},[t._v("#")]),t._v(" 报错问题")]),t._v(" "),n("p",[t._v("程序之前运行时，报错："),n("a",{attrs:{href:"https://www.cnblogs.com/dongxiucai/p/10245896.html",target:"_blank",rel:"noopener noreferrer"}},[t._v('Exception in thread "main" java.lang.NoClassDefFoundError: org/apache/hadoop/fs/CanUnbuffer'),n("OutboundLink")],1)]),t._v(" "),n("p",[t._v("这可能是因为pom依赖添加了hbase依赖的原因，导致出现一些异常，将hbase的依赖删掉就可以正常运行了。或者可以尝试将hbase的依赖放在hadoop依赖的后面。")]),t._v(" "),n("p",[t._v("在该程序中，正确的pom.xml的配置如下：")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("properties")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--注意这里，设置了version,在后面就可以引用这些值了，如${scala.version}--\x3e")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("scala.version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.11.8"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("scala.version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("spark.version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.3.3"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("spark.version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" \n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("properties")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependencies")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.scala-lang"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("scala-library"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("${scala.version}"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--2.11.8--\x3e")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.spark"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("spark-streaming_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("${spark.version}"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--2.3.3--\x3e")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependencies")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n\n "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("build")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("sourceDirectory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("src/main/scala"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("sourceDirectory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("testSourceDirectory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("src/test/scala"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("testSourceDirectory")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("plugins")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("net.alchim31.maven"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("scala-maven-plugin"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("3.2.2"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("compile"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("testCompile"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("configuration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("args")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("arg")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("-dependencyfile"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("arg")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("arg")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("${project.build.directory}/.scala_dependencies"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("arg")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("args")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("configuration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.maven.plugins"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("maven-shade-plugin"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.4.3"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("phase")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("package"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("phase")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("shade"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("goals")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("configuration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("filters")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifact")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("*:*"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifact")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("excludes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("META-INF/*.SF"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("META-INF/*.DSA"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("META-INF/*.RSA"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("exclude")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("excludes")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("filters")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("transformers")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("transformer")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("implementation")]),n("span",{pre:!0,attrs:{class:"token attr-value"}},[n("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("mainClass")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("mainClass")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("transformer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("transformers")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("configuration")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("execution")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("executions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("plugin")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("plugins")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("build")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("h2",{attrs:{id:"自定义数据源todo"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#自定义数据源todo"}},[t._v("#")]),t._v(" 自定义数据源TODO")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n  * 自定义一个Receiver，这个Receiver从socket中接收数据\n  * 使用方式：nc -lk 8888\n  */")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("com"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kaikeba"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("io"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("BufferedReader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" InputStreamReader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("Socket\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nio"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("charset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("StandardCharsets\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("SparkConf\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("internal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("Logging\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("storage"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("StorageLevel\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dstream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ReceiverInputDStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("receiver"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("Receiver\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n  * 自定义数据源\n  */")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" CustomReceiver "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   Logger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getLogger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"org"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Level"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ERROR"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// todo: 1、创建SparkConf对象")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkConf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" SparkConf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                              "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"CustomReceiver"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                              "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// todo: 2、创建StreamingContext对象")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo: 3、调用 receiverStream api，将自定义的Receiver传进去")]),t._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" receiverStream "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("receiverStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" CustomReceiver"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8888")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo: 4、对数据进行处理")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" receiverStream\n                                                      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                                      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                                      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo: 5、打印结果")]),t._v("\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo: 6、开启流式计算")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n  * 自定义source数据源\n  * @param host\n  * @param port\n  */")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" CustomReceiver"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("host"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("port"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" Receiver"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("MEMORY_AND_DISK_SER"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" Logging"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("override")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" onStart"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//启动一个线程，开始接受数据")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Thread"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"socket receiver"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("override")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" run"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            receive"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/** Create a socket connection and receive data until receiver is stopped */")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" receive"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" socket"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Socket "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" userInput"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      logInfo"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Connecting to "')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" host "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('":"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" port"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      socket "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Socket"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("host"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" port"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      logInfo"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Connected to "')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" host "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('":"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" port"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" reader "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" BufferedReader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" InputStreamReader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("socket"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getInputStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StandardCharsets"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("UTF_8"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n      userInput "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" reader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("readLine"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("isStopped "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" userInput "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        store"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("userInput"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        userInput "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" reader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("readLine"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      reader"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      socket"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      logInfo"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Stopped receiving"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      restart"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Trying to connect again"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("catch")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" e"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("net"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ConnectException "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("\n        restart"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Error connecting to "')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" host "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('":"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" port"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" e"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Throwable "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("\n        restart"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Error receiving data"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("override")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" onStop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h2",{attrs:{id:"集群运行sparkstreaming程序"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#集群运行sparkstreaming程序"}},[t._v("#")]),t._v(" 集群运行sparkStreaming程序")]),t._v(" "),n("p",[t._v("自己开发wordcount程序，然后打包上传到集群，并打开任务运行界面，查看一下任务运行情况。")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("com"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("jimmy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("log4j"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Level"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Logger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" MySocket "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    Logger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getLogger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"org"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Level"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ERROR"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"socketDemo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"warn"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" value "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFileStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//开启流式计算")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//这个表示程序不会停止运行，除非手动中断")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("运行jar包")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[t._v("spark-submit --class com.jimmy.streaming.MySocket --master spark://node01:7077 --executor-memory 1g --total-executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" originaMySparkDemo-1.0-SNAPSHOT.jar /dataStreamingDemo\n")])])]),n("p",[t._v("上传文件到监听目录:")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("hdfs dfs -put /tmp/words.txt /dataStreamingDemo/\n")])])]),n("p",[t._v("观察效果：")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1422),alt:"image-20200423035855381"}})]),t._v(" "),n("p",[t._v("查看sparkStreaming的任务运行界面，可以看到一些图表等：")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1423),alt:"image-20200423035950826"}})]),t._v(" "),n("p",[t._v("查看Executors，可以发现，driver运行在node01上")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1424),alt:"image-20200423040120447"}})]),t._v(" "),n("h2",{attrs:{id:"transformation-高级算子"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#transformation-高级算子"}},[t._v("#")]),t._v(" Transformation 高级算子")]),t._v(" "),n("h4",{attrs:{id:"updatestatebykey-统计分析所有批次"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#updatestatebykey-统计分析所有批次"}},[t._v("#")]),t._v(" updateStateByKey——统计分析所有批次")]),t._v(" "),n("p",[t._v("需求: sparkStreaming接受socket数据实现所有批次的单词次数累加")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("com"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("jimmy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" UpdateDemo "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkconf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"warn"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("checkpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hdfs://node01:8020/ck"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//缓存历史批次的数据")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("socketTextStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9999")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("updateStateByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("myUpdateFunc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" myUpdateFunc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("currentValue"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Seq"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("historyValues"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Option"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Option"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" newValue"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("currentValue"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sum"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("historyValues"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrElse"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    Some"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newValue"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("源码分析：")]),t._v(" "),n("blockquote",[n("p",[t._v("查看updateStateByKey的源码如下：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" updateStateByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("S"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" ClassTag"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n   updateFunc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Seq"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("V"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Option"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("S"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" Option"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("S"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n   numPartitions"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("K"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" S"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withScope "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n updateStateByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("updateFunc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" defaultPartitioner"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("numPartitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("从源码可知，该算子需要传入一个函数：(Seq[V], Option[S]) => Option[S],所以我们需要自己自定义一个符合参数类型要求的函数：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" myUpdateFunc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("currentValue"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Seq"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("historyValues"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Option"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Option"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" newValue"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("currentValue"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sum"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("historyValues"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrElse"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n Some"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newValue"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//将单词在所有批次出现的总次数")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("ol",[n("li",[t._v("这个myUpdateFunc函数传入updateStateByKey后，将会依次作用于所有批次的不同单词。")]),t._v(" "),n("li",[t._v("currentValue:当前批次中==每一个单词出现的所有的1的集合==，如List(1,1,1,1),对该集合进行.sum操作就可以获得某个单词在当前批次出现的次数。")]),t._v(" "),n("li",[t._v("historyValues:之前批次中==每个单词出现的总次数==,Option类型表示存在或者不存在。Some表示存在有值，None表示没有")])])]),t._v(" "),n("p",[t._v("运行程序：")]),t._v(" "),n("blockquote",[n("p",[t._v("1、启动socket服务，nc -lk 9999，运行sparkStreaming程序")]),t._v(" "),n("p",[t._v("2、socket发送hadoop hadoop hadoop hadoop,此时程序界面显示如下，可以发现，打印的信息是所有批次的综合")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("-------------------------------------------\nTime: 1587634964000 ms\n-------------------------------------------\n(hadoop,4)\n\n-------------------------------------------\nTime: 1587634966000 ms\n-------------------------------------------\n(hadoop,4)\n\n-------------------------------------------\nTime: 1587634968000 ms\n-------------------------------------------\n(hadoop,4)\n")])])]),n("p",[t._v("3、socket继续发送flink spark hadoop，此时程序界面显示如下，可以发现，当前批次与历史批次的数据进行了汇总再输出")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("-------------------------------------------\nTime: 1587634980000 ms\n-------------------------------------------\n(flink,1)\n(spark,1)\n(hadoop,5)\n\n-------------------------------------------\nTime: 1587634982000 ms\n-------------------------------------------\n(flink,1)\n(spark,1)\n(hadoop,5)\n")])])])]),t._v(" "),n("h4",{attrs:{id:"mapwithstate-统计分析所有批次"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#mapwithstate-统计分析所有批次"}},[t._v("#")]),t._v(" mapWithState——统计分析所有批次")]),t._v(" "),n("p",[t._v("mapWithState也是可以实现所有批次的累加，但是它相对于updateStateByKey，==性能更高==。")]),t._v(" "),n("p",[t._v("需求: sparkStreaming接受socket数据实现所有批次的单词次数累加")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("com"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("jimmy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("RDD\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dstream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" MapWithStateDStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Durations"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" State"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StateSpec"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Time"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" mapDemo1 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkconf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"warn"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("checkpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hdfs://node01:8020/ck2"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//定义一个用于初始化的RDD")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" initRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parallelize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hadoop"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("socketTextStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9999")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" MyStateSpec"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("StateSpec"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("time"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Time"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("currentValue"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Option"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("historyState"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("State"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" newValue"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("currentValue"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrElse"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("historyState"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOption"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrElse"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" output"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("newValue"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("historyState"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isTimingOut"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        historyState"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newValue"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      Some"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("initialState"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("initRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("timeout"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Durations"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("MapWithStateDStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mapWithState"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("MyStateSpec"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stateSnapshots"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("源码分析：")]),t._v(" "),n("blockquote",[n("p",[t._v("查看mapWithState的源码，如下：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" mapWithState"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("StateType"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" ClassTag"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" MappedType"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" ClassTag"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n   spec"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" StateSpec"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("K"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" V"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StateType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" MappedType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" MapWithStateDStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("K"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" V"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StateType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" MappedType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" MapWithStateDStreamImpl"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("K"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" V"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StateType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" MappedType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("self")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n   spec"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("asInstanceOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("StateSpecImpl"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("K"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" V"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StateType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" MappedType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("mapWithState算子需要一个参数：spec: StateSpec[K, V, StateType, MappedType]")]),t._v(" "),n("p",[t._v("StateSpec是一个object，里面有一个function方法，这个方法可以返回一个StateSpec[KeyType, ValueType, StateType, MappedType]，正好是mapWithState算子需要的参数类型，源码如下：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" StateSpec "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("KeyType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ValueType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StateType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" MappedType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n   mappingFunction"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Time"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" KeyType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Option"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("ValueType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" State"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("StateType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" Option"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("MappedType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" StateSpec"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("KeyType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ValueType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StateType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" MappedType"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n ClosureCleaner"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("clean"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mappingFunction"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" checkSerializable "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StateSpecImpl"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mappingFunction"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("p",[t._v("function方法需要一个函数作为参数：mappingFunction: (Time, KeyType, Option[ValueType], State[StateType]) => Option[MappedType]")]),t._v(" "),n("p",[t._v("下面是代码中自己定义function方法的代码：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" MyStateSpec"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("StateSpec"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("function"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("time"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Time"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("currentValue"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Option"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("historyState"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("State"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" newValue"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("currentValue"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrElse"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("historyState"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOption"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrElse"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" output"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("newValue"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("historyState"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isTimingOut"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n     historyState"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newValue"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n   Some"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("initialState"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("initRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("timeout"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Durations"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("key:String是单词，currentValue:Option[Int]是该单词在当前批次的出现次数，historyState:State[Int]是历史批次的次数，封装在State里面。")]),t._v(" "),n("p",[t._v("使用Some封装output，返回出去。")]),t._v(" "),n("p",[t._v(".initialState(initRDD)用于进行初始化，initRDD是自己定义的。")]),t._v(" "),n("p",[t._v(".timeout(Durations.seconds(5))表示如果某个单词（key)超过5s没有出现，该key及其状态state将会被移除掉。")]),t._v(" "),n("p",[t._v("historyState.update(newValue)是用来更新历史批次的state的，if(!historyState.isTimingOut())表示如果某单词（key)超时没有出现，就不更新其state了。")]),t._v(" "),n("p",[t._v("==在这里，打印时，最好使用result.stateSnapshots().print()方式而不是result.print()==")]),t._v(" "),n("p",[t._v("单纯使用print()的效果是下面这样的：")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("flink,1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hadoop,11"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hadoop,12"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#单词的次数加1就会打印一次，不太好。")]),t._v("\n")])])])]),t._v(" "),n("p",[t._v("运行程序：")]),t._v(" "),n("blockquote",[n("p",[t._v("1、打开socket,nc -lk 9999,运行程序，一开始输出结果如下：")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("-------------------------------------------\nTime: 1587654820000 ms\n-------------------------------------------\n(spark,20)\n(hadoop,10)\n")])])]),n("p",[t._v("2、socket发送数据：hadoop hadoop，输出如下，可以看到，hadoop在初始值10的基础上加了2，并且spark在5s之后被移除了。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("-------------------------------------------\nTime: 1587654834000 ms\n-------------------------------------------\n(spark,20)\n(hadoop,12)\n\n-------------------------------------------\nTime: 1587654836000 ms\n-------------------------------------------\n(spark,20)\n(hadoop,12)\n\n-------------------------------------------\nTime: 1587654838000 ms\n-------------------------------------------\n(hadoop,12)\n")])])])]),t._v(" "),n("h4",{attrs:{id:"transform-对dstream中的rdd进行操作"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#transform-对dstream中的rdd进行操作"}},[t._v("#")]),t._v(" transform——对DStream中的RDD进行操作")]),t._v(" "),n("p",[t._v("需求: 获取每一个批次中单词出现次数最多的前3位")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dstream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("DStream\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" Demo "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkconf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"warn"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("checkpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hdfs://node01:8020/ck2"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("socketTextStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9999")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n      flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("transform"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sortrdd"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sortBy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" top3"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sortrdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("take"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"=====top3结果===="')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      top3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"=====top3结果===="')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"原始数据:"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//不能将top3作为结果\t返回，因为不是RDD[(String, Int)]类型")]),t._v("\n      sortrdd\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("运行结果：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("top3结果"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("flink"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("top3结果"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v("\n原始数据"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("\nTime"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1587660264000")]),t._v(" ms\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("--")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hadoop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("flink"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hive"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("flume"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h4",{attrs:{id:"window操作"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#window操作"}},[t._v("#")]),t._v(" Window操作")]),t._v(" "),n("p",[t._v("如果这样设置：val ssc=new StreamingContext(sc,Seconds(2))，就代表每隔2s处理2s的数据，那么现在的需求是：实现每隔4秒统计6秒的数据。")]),t._v(" "),n("p",[t._v("注意：每隔2s处理2s的数据是在处理速度足够快的基础上的，不一定2s就能处理2s的数据，如果2s内处理不完依然会阻塞。")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dstream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("DStream\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" Demo1 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkconf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"warn"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("checkpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hdfs://node01:8020/ck2"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("socketTextStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9999")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("               \n      flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKeyAndWindow"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("blockquote",[n("p",[t._v("查看reduceByKeyAndWindow的源码：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" reduceByKeyAndWindow"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n   reduceFunc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("V"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" V"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" V"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n   windowDuration"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Duration"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n   slideDuration"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Duration\n "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("K"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" V"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withScope "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n reduceByKeyAndWindow"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("reduceFunc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" windowDuration"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                      slideDuration"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" defaultPartitioner"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("该方法需要三个参数：\nreduceFunc: (V, V) => V,  ---\x3e 就是一个函数\nwindowDuration: Duration, ---\x3e 窗口的大小(时间单位)，该窗口会包含N个批次的数据\nslideDuration: Duration   ---\x3e 滑动窗口的时间间隔，表示每隔多久计算一次")]),t._v(" "),n("p",[t._v("以代码中的Seconds(6),Seconds(4)为例，==这样做有个弊端：有些数据可能被重复处理了。因此，我们通常将窗口的大小与滑动窗口的时间间隔设置为一致，如Seconds(4),Seconds(4)==")]),t._v(" "),n("img",{attrs:{src:"sparkstreaming.assets/image-20200424015743703.png"}}),t._v(" "),n("p",[t._v("运行结果如下,可以看到，数据是每隔4s会被处理一次。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("-------------------------------------------\nTime: 1587662178000 ms\n-------------------------------------------\n\n-------------------------------------------\nTime: 1587662182000 ms\n-------------------------------------------\n\n-------------------------------------------\nTime: 1587662186000 ms\n-------------------------------------------\n\n-------------------------------------------\nTime: 1587662190000 ms\n-------------------------------------------\n(hive,2)\n(flink,4)\n(spark,4)\n(hadoop,6)\n(flume,2)\n")])])])]),t._v(" "),n("h2",{attrs:{id:"output-算子"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#output-算子"}},[t._v("#")]),t._v(" Output 算子")]),t._v(" "),n("h4",{attrs:{id:"foreachrdd"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#foreachrdd"}},[t._v("#")]),t._v(" foreachRDD")]),t._v(" "),n("p",[t._v("需求：将WordCount案例中得到的结果通过foreachRDD保存结果到mysql中")]),t._v(" "),n("p",[t._v("在node03登录mysql,创建test database,table wordcount")]),t._v(" "),n("div",{staticClass:"language-sql extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sql"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("database")]),t._v(" test"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" test"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("create")]),t._v(" tabel wordcount"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("varchar")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("count "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[t._v("添加pom依赖：")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("mysql"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("mysql-connector-java"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("5.1.38"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("p",[t._v("开发代码，一共有4个方案：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("com"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("jimmy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("DriverManager\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dstream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("DStream\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" Demo1 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkconf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"warn"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("socketTextStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9999")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n      flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//===============方案1：会出错====================")]),t._v("\n    data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreachRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//注意这里创建的对象都是在Driver端!!!")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conne"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("DriverManager"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getConnection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbc:mysql://node03:3306/test"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"root"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"123456"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" statement"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("conne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("prepareStatement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"insert into wordcount(word,count) values(?,?)"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("record"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//这一块代码的执行是在executor端，需要进行网络传输，会出现task not serializable异常")]),t._v("\n        statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("record"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setInt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("record"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("execute"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        conne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//===============方案2：性能较低====================")]),t._v("\n    data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreachRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("record"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conne"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("DriverManager"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getConnection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbc:mysql://node03:3306/test"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"root"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"123456"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" statement"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("conne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("prepareStatement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"insert into wordcount(word,count) values(?,?)"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("record"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setInt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("record"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("execute"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        conne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//===============方案3：性能高(推荐）====================")]),t._v("\n    data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreachRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreachPartition"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("iter"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conne"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("DriverManager"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getConnection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbc:mysql://node03:3306/test"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"root"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"123456"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" statement"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("conne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("prepareStatement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"insert into wordcount(word,count) values(?,?)"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        conne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAutoCommit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//关闭自动提交！！！")]),t._v("\n\n        iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("record"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("record"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setInt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("record"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addBatch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//添加到一个批次")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("executeBatch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//批量提交该分区所有数据")]),t._v("\n        statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        conne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//===============方案4：性能更高====================")]),t._v("\n    data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreachRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreachPartition"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("iter"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conne"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("DriverManager"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getConnection"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbc:mysql://node03:3306/test"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"root"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"123456"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" statement"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("conne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("prepareStatement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"insert into wordcount(word,count) values(?,?)"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        iter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("record"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("record"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setInt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("record"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("execute"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        statement"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        conne"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  \n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("p",[t._v("运行结果：")]),t._v(" "),n("div",{staticClass:"language-sql extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sql"}},[n("code",[t._v("mysql"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" wordcount"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--------+-------+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" word   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" count "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--------+-------+")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" hive   "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("     "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" flink  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("     "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" spark  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("     "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" hadoop "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("     "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" flume  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("     "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--------+-------+")]),t._v("\n")])])]),n("h2",{attrs:{id:"checkpoint"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#checkpoint"}},[t._v("#")]),t._v(" Checkpoint")]),t._v(" "),n("p",[t._v("checkpoint不仅仅可以保存运算结果中的数据，还可以存储Driver端的信息")]),t._v(" "),n("p",[t._v("==通过checkpoint可以实现Driver端的高可用==")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("com"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("jimmy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" DemoCheckpoint "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" checkpointPath"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hdfs://node01:8020/ckDir"')]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" MycreatingFunc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("StreamingContext"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkconf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"warn"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("checkpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("checkpointPath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//缓存历史批次的数据")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("socketTextStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9999")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n      flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("updateStateByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("myUpdateFunc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrCreate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("checkpointPath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("MycreatingFunc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" myUpdateFunc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("currentValue"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Seq"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("historyValues"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Option"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("Option"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" newValue"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("currentValue"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sum"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("historyValues"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrElse"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    Some"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newValue"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("运行测试")]),t._v(" "),n("blockquote",[n("p",[t._v("运行程序，socket发送数据: hadoop flink,输出信息如下：")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("-------------------------------------------\nTime: 1587670986000 ms\n-------------------------------------------\n(flink,1)\n(hadoop,1)\n")])])]),n("p",[t._v("此时，==终止程序的运行，然后重新启动程序==，继续socket发送数据hadoop flink,  观察输出：")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("-------------------------------------------\nTime: 1587670988000 ms\n-------------------------------------------\n(flink,2)\n(hadoop,2)\n")])])]),n("p",[t._v("可以发现，即使程序中途停止运行了，当程序重新启动时，依然能够接着上次的结果继续运行计算。")]),t._v(" "),n("p",[t._v("==Checkpoint实现Driver的高可用的原理：==")]),t._v(" "),n("ol",[n("li",[t._v("val ssc=StreamingContext.getOrCreate(checkpointPath,MycreatingFunc)尝试创建StreamingContext时，==先去checkpointPath里找，看看有没有Driver的元数据信息，没有的话就根据MycreatingFunc方法来获取一个StreamingContext==")]),t._v(" "),n("li",[t._v("然后程序开始运行，运行时会把之前的批次的数据缓存到checkpointPath，还会Driver的信息一并存下来。")]),t._v(" "),n("li",[t._v("如果程序中途停掉后，再次启动，依然会先去checkpointPath里找，看看有没有Driver的元数据信息，有就根据这些信息重启Driver，运行任务也会接着上次的进度来运行。")])])]),t._v(" "),n("h2",{attrs:{id:"sparkstreaming和sparksql整合"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparkstreaming和sparksql整合"}},[t._v("#")]),t._v(" SparkStreaming和SparkSQL整合")]),t._v(" "),n("h5",{attrs:{id:"为什么整合"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#为什么整合"}},[t._v("#")]),t._v(" 为什么整合？")]),t._v(" "),n("img",{attrs:{src:"sparkstreaming.assets/image-20200424040141974.png"}}),t._v(" "),n("h5",{attrs:{id:"代码开发-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#代码开发-2"}},[t._v("#")]),t._v(" 代码开发")]),t._v(" "),n("p",[t._v("pom.xml里面添加")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n     "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.spark"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n     "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("spark-sql_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n     "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.3.3"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("p",[t._v("代码开发")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("com"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kaikeba"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("log4j"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Level"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Logger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("SparkConf\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dstream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ReceiverInputDStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n  * sparkStreaming整合sparksql\n  */")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" SocketWordCountForeachRDDDataFrame "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    Logger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getLogger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"org"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Level"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ERROR"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// todo: 1、创建SparkConf对象")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkConf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" SparkConf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"NetworkWordCountForeachRDDDataFrame"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// todo: 2、创建StreamingContext对象")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo: 3、接受socket数据")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" socketTextStream"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" ReceiverInputDStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("socketTextStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9999")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo: 4、对数据进行处理")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" words"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" socketTextStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo: 5、对DStream进行处理，将RDD转换成DataFrame")]),t._v("\n      words"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreachRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n          "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取得到sparkSessin，由于将RDD转换成DataFrame需要用到SparkSession对象")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkSession"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" SparkSession "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("config"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrCreate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("sparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("implicits"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("_\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" dataFrame"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DataFrame "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"word"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//将dataFrame注册成表")]),t._v("\n         dataFrame"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createOrReplaceTempView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"words"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//统计每个单词出现的次数")]),t._v("\n         "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DataFrame "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select word,count(*) as count from words group by word"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n         "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//展示结果")]),t._v("\n        result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo: 6、开启流式计算")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("h2",{attrs:{id:"sparkstreaming容错"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparkstreaming容错"}},[t._v("#")]),t._v(" SparkStreaming容错")]),t._v(" "),n("h4",{attrs:{id:"sparkstreaming运行流程回顾"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparkstreaming运行流程回顾"}},[t._v("#")]),t._v(" SparkStreaming运行流程回顾")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1425),alt:"1567414277097"}})]),t._v(" "),n("h4",{attrs:{id:"executor失败"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#executor失败"}},[t._v("#")]),t._v(" Executor失败")]),t._v(" "),n("blockquote",[n("p",[t._v("在==Receiver接收到了数据之后，会将数据复制一份到其它的Executor的内存中==。")]),t._v(" "),n("p",[t._v('比如，在使用ssc.socketTextStream("node01",9999)接收数据时，默认会将数据复制一份到其它的Executor内存中，是因为该方法有一个缺省参数：storageLevel=StorageLevel.MEMORY_AND_DISK_2。')]),t._v(" "),n("p",[t._v("在两台机器的内存中，==如果一台机器上的Executor挂了，立即切换到另一台机器上的Executor，这种方式一般情况下非常可靠且没有切换时间==。")]),t._v(" "),n("p",[t._v("Tasks和Receiver自动的重启，不需要做任何的配置")]),t._v(" "),n("img",{attrs:{src:"sparkstreaming.assets/1567414655887-1584924078479.png"}})]),t._v(" "),n("h4",{attrs:{id:"driver失败"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#driver失败"}},[t._v("#")]),t._v(" Driver失败")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1426),alt:"1567414739556"}})]),t._v(" "),n("p",[t._v("用checkpoint机制恢复失败的Driver。每个Job生成之前进行checkpoint，在Job生成之后再进行checkpoint，如果出错的话就从checkpoint中恢复。")]),t._v(" "),n("p",[t._v("定期的将Driver信息写入到HDFS中。")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1427),alt:"1567414846715"}})]),t._v(" "),n("h6",{attrs:{id:"步骤一-设置自动重启driver程序"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#步骤一-设置自动重启driver程序"}},[t._v("#")]),t._v(" 步骤一：设置自动重启Driver程序")]),t._v(" "),n("p",[n("strong",[t._v("Standalone：")])]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("在spark-submit中增加以下两个参数：\n--deploy-mode cluster\n--supervise "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#失败后是否重启Driver")]),t._v("\n\n使用示例：\nspark-submit "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--master spark://node01:7077 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--deploy-mode cluster "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--supervise "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--class com.kaikeba.streaming.Demo "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--executor-memory 1g "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--total-executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\noriginal-sparkStreamingStudy-1.0-SNAPSHOT.jar \n")])])]),n("p",[n("strong",[t._v("Yarn：")])]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("在spark-submit中增加以下参数：\n--deploy-mode cluster\n在yarn配置中设置yarn.resourcemanager.am.max-attemps参数 ,默认为2，表示允许Driver挂掉之后重启的允许失败的次数，例如：\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("property"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("yarn.resourcemanager.am.max-attempts"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("/name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),n("span",{pre:!0,attrs:{class:"token operator"}},[n("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[t._v("4")]),t._v("<")]),t._v("/value"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("  \n  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("description"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    The maximum number of application master execution attempts.\n  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("/description"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("/property"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n\n\n使用示例：\nspark-submit "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--master "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("yarn")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--deploy-mode cluster "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--class com.kaikeba.streaming.Demo "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--executor-memory 1g "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--total-executor-cores "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\noriginal-sparkStreamingStudy-1.0-SNAPSHOT.jar \n")])])]),n("blockquote",[n("p",[t._v("提交后，==Driver的进程名称是DriverWrapper==")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1428),alt:"image-20200424042337680"}})]),t._v(" "),n("p",[t._v("在后面若想要测试Driver挂掉后的重启时，可以通过kill -9将Driver程序停掉。")])]),t._v(" "),n("h6",{attrs:{id:"步骤二-设置hdfs的checkpoint目录"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#步骤二-设置hdfs的checkpoint目录"}},[t._v("#")]),t._v(" 步骤二：设置HDFS的checkpoint目录")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("streamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setCheckpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hdfsDirectory"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n")])])]),n("h6",{attrs:{id:"步骤三-代码实现"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#步骤三-代码实现"}},[t._v("#")]),t._v(" 步骤三：代码实现")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Function to create and setup a new StreamingContext")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" functionToCreateContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" StreamingContext "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// new context")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" lines "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("socketTextStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// create DStreams")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n  ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("checkpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("checkpointDirectory"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// set checkpoint directory")]),t._v("\n  ssc\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Get StreamingContext from checkpoint data or create a new one")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" context "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrCreate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("checkpointDirectory"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" functionToCreateContext _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Do additional setup on context that needs to be done,")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// irrespective of whether it is being started or restarted")]),t._v("\ncontext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Start the context")]),t._v("\ncontext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ncontext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h4",{attrs:{id:"数据丢失如何处理"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#数据丢失如何处理"}},[t._v("#")]),t._v(" 数据丢失如何处理")]),t._v(" "),n("blockquote",[n("p",[t._v("利用WAL把数据写入到HDFS中")]),t._v(" "),n("img",{attrs:{src:"sparkstreaming.assets/1567415902458.png"}}),t._v(" "),n("p",[t._v("步骤一：设置checkpoint目录")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v("streamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setCheckpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hdfsDirectory"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("步骤二：开启WAL日志")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v('sparkConf.set("spark.streaming.receiver.writeAheadLog.enable", "true")\n')])])]),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("WAL使用在文件系统和数据库中用于数据操作的持久性，先把数据写到一个持久化的日志中，然后对数据做操作，如果操作过程中系统挂了，恢复的时候可以重新读取日志文件再次进行操作。\n\n对于像kafka和flume这些使用接收器来接收数据的数据源。接收器作为一个长时间的任务运行在executor中，负责从数据源接收数据，如果数据源支持的话，向数据源确认接收到数据，然后把数据存储在executor的内存中，然后在exector上运行任务处理这些数据。\n\n如果wal启用了，所有接收到的数据会保存到一个日志文件中去（HDFS), 这样保存接收数据的持久性，此外，如果只有在数据写入到log中之后接收器才向数据源确认，这样driver重启后那些保存在内存中但是没有写入到log中的数据将会重新发送，这两点保证的数据的无丢失。\n")])])]),n("p",[t._v("步骤三：需要reliable receiver")]),t._v(" "),n("p",[t._v("==如果Receiver接收到数据后，备份到HDFS或磁盘中的数据也丢失了，这时候怎么办？这时候我们就需要一个可靠的数据源了，何为可靠？可靠就是如果我数据丢失了，我依然能够重新去数据源获取数据。==")]),t._v(" "),n("p",[t._v("比如==Kafka就可以实现这个==，kafka可以记住消费数据的偏移量offset。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("当数据写完了WAL后，才告诉数据源数据已经消费，对于没有告诉数据源的数据，可以从数据源中重新消费数据\n")])])]),n("p",[t._v("步骤四：取消备份")]),t._v(" "),n("p",[t._v("开启了WAL日志后，可以把storageLevel设为StorageLevel.MEMORY_AND_DISK了。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("使用StorageLevel.MEMORY_AND_DISK_SER来存储数据源，不需要后缀为2的策略了，因为HDFS已经是多副本了。\n")])])]),n("p",[n("img",{attrs:{src:s(1429),alt:"1567416495877"}})]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("Reliable Receiver   : 当数据接收到，并且已经备份存储后，再发送回执给数据源\nUnreliable Receiver : 不发送回执给数据源\n")])])])]),t._v(" "),n("h4",{attrs:{id:"当一个task很慢容错"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#当一个task很慢容错"}},[t._v("#")]),t._v(" 当一个task很慢容错")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1430),alt:"1567417919912"}})]),t._v(" "),n("p",[t._v("开启推测机制：")]),t._v(" "),n("ol",[n("li",[t._v("设置spark.speculation=true后，会开启推测机制，每隔一段时间来检查有哪些正在运行的task需要重新调度，时间间隔默认为：spark.speculation.interval=100ms。")]),t._v(" "),n("li",[t._v("假设总的task有10个，成功的task的数量 > 0.75 * 10（spark.speculation.quantile=0.75），且正在运行的task的运行时间 > 1.5 * 成功运行task的平均时间（spark.speculation.multiplier=1.5），则这个正在运行的task需要重新等待调度。")]),t._v(" "),n("li",[t._v("开启其它的task来运行这些task,此时会有多个task同时做着同样的任务，谁先完成就用谁的。")])]),t._v(" "),n("p",[n("img",{attrs:{src:s(1431),alt:"Task推测机制"}})]),t._v(" "),n("p",[t._v("注意：")]),t._v(" "),n("p",[t._v("在分布式环境中导致某个Task执行缓慢的情况有很多，负载不均、程序bug、资源不均、数据倾斜等，而且这些情况在分布式任务计算环境中是常态。==Speculative Task这种以空间换时间的思路对计算资源是种压榨，同时如果Speculative Task本身也变成了Slow Task会导致情况进一步恶化==。")]),t._v(" "),n("h2",{attrs:{id:"sparkstreaming语义"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparkstreaming语义"}},[t._v("#")]),t._v(" SparkStreaming语义")]),t._v(" "),n("p",[t._v("有三种语义：")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("(1) At most once  一条记录要么被处理一次，要么没有被处理\n\n(2) At least once 一条记录可能被处理一次或者多次，可能会重复处理\n\n(3) Exactly once 一条记录只被处理一次\n")])])]),n("h2",{attrs:{id:"sparkstreaming与kafka整合"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparkstreaming与kafka整合"}},[t._v("#")]),t._v(" SparkStreaming与Kafka整合")]),t._v(" "),n("p",[t._v("SparkStreaming整合Kafka官方文档：http://spark.apache.org/docs/2.3.3/streaming-kafka-integration.html")]),t._v(" "),n("p",[t._v("Kafka在0.8和0.10（1.0）版本提供了新的消费者Api,可以进行与sparkStreaming的整合。0.8版本的已经过时了，而且在spark在2.3.0版本后，已经不再支持kafka 0.8。")]),t._v(" "),n("p",[t._v("对于spark-streaming-kafka-0-8，支持Receiver Dstream和Direct Dstream(直连)")]),t._v(" "),n("p",[t._v("对于spark-streaming-kafka-0-10，不再支持Receiver Dstream了。")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1432),alt:"image-20200424142427376"}})]),t._v(" "),n("p",[t._v("因为我们使用的是kafka 1.0，spark 2.3.3,所以选择spark-streaming-kafka-0-10。")]),t._v(" "),n("p",[t._v("点击spark-streaming-kafka-0-10，查看整合方式，如下，只需要添加依赖即可。")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1433),alt:"image-20200424143312397"}})]),t._v(" "),n("p",[t._v("kafka-0.8: 默认消费消息的偏移量是保存在zk集群上，默认自动提交偏移量到zk上")]),t._v(" "),n("p",[t._v("kafka-0.10：默认消费消息的偏移量是保存在kafka集群内置的topic中，默认自动提交偏移量到kafka集群上")]),t._v(" "),n("h2",{attrs:{id:"整合案例1-sparkstreaming与kafka-0-8-receiver-不推荐"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#整合案例1-sparkstreaming与kafka-0-8-receiver-不推荐"}},[t._v("#")]),t._v(" 整合案例1：sparkStreaming与Kafka-0-8(Receiver) 不推荐")]),t._v(" "),n("blockquote",[n("p",[t._v("此方法使用Receiver接收数据。==Receiver是使用Kafka高级消费者API实现的==。与所有接收器一样，从Kafka通过Receiver接收的数据存储在Spark执行器中，然后由Spark Streaming启动的作业处理数据。")]),t._v(" "),n("p",[t._v("但是在默认配置下，此方法可能会在失败时丢失数据（请参阅"),n("a",{attrs:{href:"http://spark.apache.org/docs/2.3.3/streaming-programming-guide.html#receiver-reliability",target:"_blank",rel:"noopener noreferrer"}},[t._v("接收器可靠性"),n("OutboundLink")],1),t._v("）。")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1434),alt:"image-20200424154359505"}})]),t._v(" "),n("p",[t._v("==为确保零数据丢失，必须在Spark Streaming中另外启用Write Ahead Logs==（在Spark 1.2中引入）。这将同步保存所有收到的Kafka将数据写入分布式文件系统（例如HDFS）上的预写日志，以便在发生故障时可以恢复所有数据，但是==性能不好==。")]),t._v(" "),n("p",[t._v("==性能不好的原因：==")]),t._v(" "),n("ol",[n("li",[t._v("Receiver只是一个线程，只是用一个Receiver去消费kafka一个topic的多个分区的数据，无疑是压力很大的。")]),t._v(" "),n("li",[t._v("WAL预写日志需要将数据写入到HDFS中，性能也会受到影响。")])]),t._v(" "),n("p",[t._v("==Receiver-Based Approach示意图：==")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1435),alt:"image-20200424170120758"}})])]),t._v(" "),n("h5",{attrs:{id:"第一步-添加pom依赖"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第一步-添加pom依赖"}},[t._v("#")]),t._v(" 第一步：添加pom依赖：")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n       "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.spark"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n       "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("spark-streaming-kafka-0-8_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n       "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.3.3"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("        \n")])])]),n("h5",{attrs:{id:"第二步-启动kafka集群及创建topic"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第二步-启动kafka集群及创建topic"}},[t._v("#")]),t._v(" 第二步：启动kafka集群及创建topic")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node01 ~"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("sh")]),t._v(" bin/kafkaCluster.sh start\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node01 ~"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ kafka-topics.sh --create --partitions "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(" --replication-factor "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" --topic KStreaming --zookeeper node01:2181,node02:2181,node03:2181\n")])])]),n("h5",{attrs:{id:"第三步-开发程序"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第三步-开发程序"}},[t._v("#")]),t._v(" 第三步：开发程序：")]),t._v(" "),n("p",[t._v("核心代码：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kafka"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("_\n\n "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" kafkaStream "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" KafkaUtils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("streamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n     "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("ZK quorum"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("consumer group id"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("per"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("topic number of Kafka partitions to "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("consume")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("代码开发：sparkStreaming使用kafka 0.8API基于recevier来接受消息")]),t._v(" "),n("p",[t._v("0.8 的kafka的offset是保存在zookeeper集群上的。所以要指定zookeeper集群地址。")]),t._v(" "),n("p",[t._v('注意：Kafka中的topic的partition，与Spark中的RDD的partition是没有关系的。所以，在KafkaUtils.createStream()中，提高partition的数量，==只会在Receiver中增加一个读取partition的线程的数量。不会增加Spark处理数据的并行度==。如：val topics=Map("KStreaming"->1)')]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("log4j"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Level"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Logger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dstream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ReceiverInputDStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kafka"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("KafkaUtils\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" KafkaStreaming "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    Logger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getLogger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"org"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Level"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ERROR"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark.streaming.receiver.writeAheadLog.enable"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"true"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("checkpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hdfs://node01:8020/ckKafka"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//WAL预写日志，将数据写到HDFS上")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//接收kafka数据")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" zkQuorum"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01:2181,node02:2181,node03:2181"')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" groupId"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"g1"')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" topics"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"KStreaming"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//1代表给定1个线程去消费数据")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("ReceiverInputDStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n      KafkaUtils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("zkQuorum"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("groupId"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("topics"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取接收到的topic数据的value(不需要key)")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h5",{attrs:{id:"第四步-运行程序-往topic生成数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#第四步-运行程序-往topic生成数据"}},[t._v("#")]),t._v(" 第四步：运行程序，往topic生成数据")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node01 ~"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ kafka-console-producer.sh --broker-list node01:9092,node02:9092,node03:9092 --topic KStreaming\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("hadoop hadoop flink\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("hadoop spark\n")])])]),n("p",[t._v("查看IDEA输出信息：")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("-------------------------------------------\nTime: 1587715986000 ms\n-------------------------------------------\n(flink,1)\n(hadoop,2)\n-------------------------------------------\nTime: 1587715996000 ms\n-------------------------------------------\n(spark,1)\n(hadoop,1)\n")])])]),n("h2",{attrs:{id:"direct介绍-推荐"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#direct介绍-推荐"}},[t._v("#")]),t._v(" Direct介绍(推荐)")]),t._v(" "),n("blockquote",[n("p",[t._v("这种新的不基于Receiver的直接方式，是在Spark 1.3中引入的，从而能够确保更加健壮的机制。")]),t._v(" "),n("p",[t._v("替代掉使用Receiver来接收数据后，这种方式==会周期性地查询Kafka，来获得每个topic+partition的最新的offset，从而定义每个batch的offset的范围==。")]),t._v(" "),n("p",[t._v("==当处理数据的job启动时，就会使用Kafka的简单consumer api来获取Kafka指定offset范围的数据。==")]),t._v(" "),n("p",[t._v("Direct Approach示意图：")]),t._v(" "),n("img",{attrs:{src:"sparkstreaming.assets/image-20200424164335533.png"}}),t._v(" "),n("p",[t._v("这种方式有如下优点：")]),t._v(" "),n("p",[t._v("1、简化并行读取：")]),t._v(" "),n("p",[t._v("如果要读取多个partition，不需要创建多个输入DStream然后对它们进行union操作。Spark会创建跟Kafka partition一样多的RDD partition，并且会并行从Kafka中读取数据。所以在==Kafka partition和RDD partition之间，有一个一对一的映射关系==。")]),t._v(" "),n("p",[t._v("2、高性能")]),t._v(" "),n("p",[t._v("如果要保证零数据丢失，在基于receiver的方式中，需要开启WAL机制。这种方式其实效率低下，因为数据实际上被复制了两份，Kafka自己本身就有高可靠的机制，会对数据复制一份，而这里又会复制一份到WAL中。==而基于direct的方式，不依赖Receiver，不需要开启WAL机制，只要Kafka中作了数据的复制，那么就可以通过Kafka的副本进行恢复。==")]),t._v(" "),n("p",[t._v("3、一次且仅一次的事务机制")]),t._v(" "),n("p",[t._v("基于receiver的方式，是使用Kafka的高阶API来在ZooKeeper中保存消费过的数据的offset的。这是消费Kafka数据的传统方式。基于receiver的方式配合着WAL机制可以保证数据零丢失的高可靠性，但是==却无法保证数据被处理一次且仅一次==，可能会处理两次。因为==Spark和ZooKeeper之间可能是不同步的，比如说已经被处理的数据，如果自动提交偏移量失败，则会导致重复处理数据==。")]),t._v(" "),n("p",[t._v("使用Direct方式的话，是自己去管理偏移量+幂等/事务来实现exactly-once语义。")]),t._v(" "),n("p",[t._v("4、降低资源")]),t._v(" "),n("p",[t._v("==Direct不需要Receivers，其申请的Executors全部参与到计算任务中==；而Receiver-based则需要专门的Receivers来读取Kafka数据且不参与计算。因此相同的资源申请，Direct 能够支持更大的业务。")]),t._v(" "),n("p",[t._v("5、降低内存")]),t._v(" "),n("p",[t._v("==Receiver-based的Receiver与其他Exectuor是异步的==，并持续不断接收数据，对于小业务量的场景还好，如果遇到大业务量时，需要提高Receiver的内存，但是参与计算的Executor并无需那么多的内存。而Direct 因为没有Receiver，而是在计算时读取数据，然后直接计算，所以对内存的要求很低。实际应用中我们可以把原先的10G降至现在的2-4G左右。")]),t._v(" "),n("p",[t._v("6、鲁棒性更好")]),t._v(" "),n("p",[t._v("Receiver-based方法需要Receivers来异步持续不断的读取数据，因此遇到网络、存储负载等因素，导致实时任务出现堆积，但Receivers却还在持续读取数据，此种情况很容易导致计算崩溃。==Direct 则没有这种顾虑，其Driver在触发batch计算任务时，才会读取数据并计算。队列出现堆积并不会引起程序的失败。==")])]),t._v(" "),n("h2",{attrs:{id:"整合案例2-sparkstreaming与kafka-0-8-direct"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#整合案例2-sparkstreaming与kafka-0-8-direct"}},[t._v("#")]),t._v(" 整合案例2：SparkStreaming与Kafka-0-8(Direct)")]),t._v(" "),n("ul",[n("li",[n("p",[t._v("支持0.8版本，或者更高的版本")])]),t._v(" "),n("li",[n("p",[t._v("pom.xml文件添加内容如下：")])])]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n       "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.spark"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n       "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("spark-streaming-kafka-0-8_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n       "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.3.3"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("  \n")])])]),n("p",[t._v("代码演示：")]),t._v(" "),n("ul",[n("li",[t._v("sparkStreaming使用kafka 0.8API基于Direct直连来接受消息")]),t._v(" "),n("li",[t._v("spark direct API接收kafka消息，从而不需要经过zookeeper，直接从broker上获取信息。")])]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("com"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("jimmy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("kafka"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("serializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("StringDecoder\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("log4j"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Level"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Logger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dstream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" InputDStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kafka"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("KafkaUtils\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" KafkaStreaming "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    Logger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getLogger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"org"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Level"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ERROR"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("checkpoint"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hdfs://node01:8020/ckKafka"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//接收kafka数据")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" kafkaParams"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"metadata.broker.list"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01:9092,node02:9092,node03:9092"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"group.id"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"g1"')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" topics"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Set"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"KStreaming"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("InputDStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("KafkaUtils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createDirectStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("StringDecoder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("StringDecoder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("kafkaParams"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("topics"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//千万不要导错StringDecoder所在的包")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取接收到的topic数据的value(不需要key)")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data2"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("DStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("data2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("运行sparkStreaming程序，启动生产者，往topic写数据：")]),t._v(" "),n("div",{staticClass:"language-sh extra-class"},[n("pre",{pre:!0,attrs:{class:"language-sh"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("hadoop@node01 ~"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("$ kafka-console-producer.sh --broker-list node01:9092,node02:9092,node03:9092 --topic KStreaming\n")])])]),n("p",[t._v("要想保证数据不丢失，最简单的就是靠checkpoint的机制，但是==checkpoint机制有个特点，如果代码升级了，checkpoint机制就失效了。所以如果想实现数据不丢失，那么就需要自己管理offset==。")]),t._v(" "),n("h2",{attrs:{id:"整合案例3-sparkstreaming与kafka-0-10-direct"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#整合案例3-sparkstreaming与kafka-0-10-direct"}},[t._v("#")]),t._v(" 整合案例3：SparkStreaming与Kafka-0-10(Direct)")]),t._v(" "),n("ul",[n("li",[n("p",[t._v("支持0.10版本，或者更高的版本（推荐使用这个版本）")])]),t._v(" "),n("li",[n("p",[t._v("pom.xml文件添加内容如下：")])])]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[t._v("   "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.spark"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("spark-streaming-kafka-0-10_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("2.3.3"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n   "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("ul",[n("li",[t._v("代码演示：")])]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kafka"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("clients"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("consumer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("ConsumerRecord\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kafka"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("common"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("serialization"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("StringDeserializer\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("log4j"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Level"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Logger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("RDD\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dstream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("InputDStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kafka010"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("CanCommitOffsets"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ConsumerStrategies"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" HasOffsetRanges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" KafkaUtils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" LocationStrategies"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" KafkaStreaming "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    Logger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getLogger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"org"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Level"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ERROR"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conf"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Demo"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//接收kafka数据")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" kafkaParams"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bootstrap.servers"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01:9092,node02:9092,node03:9092"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"group.id"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"g1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"key.deserializer"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" classOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("StringDeserializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"value.deserializer"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" classOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("StringDeserializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"enable.auto.commit"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"false"')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" topic"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Set"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"KStreaming"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("InputDStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("ConsumerRecord"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n      KafkaUtils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createDirectStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      LocationStrategies"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PreferConsistent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      ConsumerStrategies"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Subscribe"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("topic"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("kafkaParams"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取接收到的topic数据的value(不需要key)")]),t._v("\n    data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreachRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" dataRDD"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      dataRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("line"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("line"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取偏移量并提交到kafka中")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" offsetRange"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("asInstanceOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("HasOffsetRanges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("offsetRanges\n      data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("asInstanceOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("CanCommitOffsets"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("commitAsync"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("offsetRange"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("h2",{attrs:{id:"解决sparkstreaming与kafka0-8版本整合数据丢失问题"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#解决sparkstreaming与kafka0-8版本整合数据丢失问题"}},[t._v("#")]),t._v(" 解决SparkStreaming与Kafka0.8版本整合数据丢失问题")]),t._v(" "),n("p",[t._v("一般对于企业来说，无论是使用哪一套api去消费kafka的数据，都是设置手动提交偏移量。")]),t._v(" "),n("p",[t._v("如果是自动提交偏移量（默认60s提交一次）这里可能会出现问题：")]),t._v(" "),n("p",[t._v("（1）数据处理失败了，自动提交的偏移量，会出现数据的丢失。")]),t._v(" "),n("p",[t._v("（2）数据处理成功了，自动提交偏移量失败，会出现数据的重复处理。")]),t._v(" "),n("p",[t._v("自动提交偏移量的风险比较高，一般都使用手动提交偏移量，这里我们可以操作什么时候去提交偏移量，==把偏移量的提交交给消费者程序自己去维护==。")]),t._v(" "),n("p",[t._v("方案设计如下：")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1436),alt:"kafka08SaveOffset2ZK"}})]),t._v(" "),n("p",[t._v("代码开发，手动把偏移量存入Zookeeper，解决数据丢失问题。")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("com"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kaikeba"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kafka")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("kafka"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("common"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("TopicAndPartition\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("kafka"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("MessageAndMetadata\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("kafka"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("serializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("StringDecoder\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("kafka"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("utils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("ZKGroupTopicDirs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ZkUtils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("I0Itec"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("zkclient"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ZkClient\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("SparkConf\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("RDD\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dstream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("InputDStream\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kafka"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("HasOffsetRanges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" KafkaUtils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n  * 使用直连方式 SparkStreaming连接kafka0.8获取数据\n  * 手动将偏移量数据保存到zookeeper中\n  */")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" KafkaManagerOffset08 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo:1、创建SparkConf 提交到集群中运行 不要设置master参数")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"KafkaManagerOffset08"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[4]"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo: 2、设置SparkStreaming，并设定间隔时间")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo:3、指定相关参数")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//指定组名")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" groupID "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"consumer-kaikeba"')]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//指定消费者的topic名字")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" topic "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"wordcount"')]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//指定kafka的broker地址")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" brokerList "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01:9092,node02:9092,node03:9092"')]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//指定zookeeper的地址，用来存放数据偏移量数据，也可以使用Redis MySQL等")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" zkQuorum "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01:2181,node02:2181,node03:2181"')]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//创建Stream时使用的topic名字集合，SparkStreaming可同时消费多个topic")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" topics"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Set"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Set"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("topic"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//创建一个 ZKGroupTopicDirs 对象，就是用来指定在zk中的存储目录，用来保存数据偏移量")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" topicDirs "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" ZKGroupTopicDirs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("groupID"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" topic"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('//获取 zookeeper 中的路径 "/consumers/consumer-kaikeba/offsets/wordcount"')]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" zkTopicPath "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" topicDirs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("consumerOffsetDir\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//构造一个zookeeper的客户端 用来读写偏移量数据")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" zkClient "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" ZkClient"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("zkQuorum"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//准备kafka的参数")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" kafkaParams "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"metadata.broker.list"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" brokerList"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"group.id"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" groupID"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"enable.auto.commit"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"false"')]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo:4、定义kafkaStream流")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" kafkaStream"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" InputDStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),t._v("\n\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo:5、获取指定的zk节点的子节点个数")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" childrenNum "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" getZkChildrenNum"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("zkClient"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("zkTopicPath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo:6、判断是否保存过数据 根据子节点的数量是否为0")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("childrenNum "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//构造一个map集合用来存放数据偏移量信息")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" fromOffsets"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("TopicAndPartition"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//遍历子节点")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("<-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" until childrenNum"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取子节点  /consumers/consumer-kaikeba/offsets/wordcount/0")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" partitionOffset"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" zkClient"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("readData"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"$zkTopicPath/$i"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// /wordcount-----0")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" tp "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TopicAndPartition"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("topic"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取数据偏移量  将不同分区内的数据偏移量保存到map集合中")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//  wordcount/0 -> 1001")]),t._v("\n        fromOffsets "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tp "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" partitionOffset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toLong"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 泛型中 key：kafka中的key   value：hello tom hello jerry")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//创建函数 解析数据 转换为（topic_name, message）的元组")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" messageHandler "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mmd"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" MessageAndMetadata"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mmd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("topic"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mmd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("message"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo:7、利用底层的API创建DStream 采用直连的方式(之前已经消费了，从指定的位置消费)")]),t._v("\n       kafkaStream "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" KafkaUtils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createDirectStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StringDecoder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StringDecoder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" kafkaParams"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fromOffsets"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" messageHandler"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo:7、利用底层的API创建DStream 采用直连的方式(之前没有消费，这是第一次读取数据)")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//zk中没有子节点数据 就是第一次读取数据 直接创建直连对象")]),t._v("\n      kafkaStream "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" KafkaUtils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createDirectStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StringDecoder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StringDecoder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" kafkaParams"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" topics"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo:8、直接操作kafkaStream")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//依次迭代DStream中的kafkaRDD 只有kafkaRDD才可以强转为HasOffsetRanges  从中获取数据偏移量信息")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//之后是操作的RDD 不能够直接操作DStream 因为调用Transformation方法之后就不是kafkaRDD了获取不了偏移量信息")]),t._v("\n\n    kafkaStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreachRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("kafkaRDD "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//强转为HasOffsetRanges 获取offset偏移量数据")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" offsetRanges "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" kafkaRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("asInstanceOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("HasOffsetRanges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("offsetRanges\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取数据")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" lines"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("kafkaRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo：9、接下来就是对RDD进行操作 触发action")]),t._v("\n      lines"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreachPartition"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("patition "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        patition"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//todo: 10、手动提交偏移量到zk集群上")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("o "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("<-")]),t._v(" offsetRanges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//拼接zk路径   /consumers/consumer-kaikeba/offsets/wordcount/0")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" zkPath "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" s"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"${topicDirs.consumerOffsetDir}/${o.partition}"')]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//将 partition 的偏移量数据 offset 保存到zookeeper中")]),t._v("\n        ZkUtils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("updatePersistentPath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("zkClient"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" zkPath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" o"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("untilOffset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toString"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//开启SparkStreaming 并等待退出")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n    * 获取zk节点上的子节点的个数\n    * @param zkClient\n    * @param zkTopicPath\n    * @return\n    */")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" getZkChildrenNum"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("zkClient"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("ZkClient"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("zkTopicPath"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//查询该路径下是否有子节点，即是否有分区读取数据记录的读取的偏移量")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// /consumers/consumer-kaikeba/offsets/wordcount/0")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// /consumers/consumer-kaikeba/offsets/wordcount/1")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// /consumers/consumer-kaikeba/offsets/wordcount/2")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//子节点的个数")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" childrenNum"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" zkClient"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("countChildren"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("zkTopicPath"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    childrenNum\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])]),n("h2",{attrs:{id:"sparkstreaming应用程序如何保证exactly-once"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparkstreaming应用程序如何保证exactly-once"}},[t._v("#")]),t._v(" SparkStreaming应用程序如何保证Exactly-Once")]),t._v(" "),n("p",[t._v("牢记实现Exactly-Once思路：")]),t._v(" "),n("blockquote",[n("p",[t._v("==一个流式计算如果想要保证Exactly-Once，那么首先要满足下面三点要求：==")]),t._v(" "),n("p",[t._v("（1）Source支持Replay。---》Source的数据支持重新发送，kafka就可以")]),t._v(" "),n("p",[t._v("（2）流计算引擎本身处理能保证Exactly-Once。 ---》sparkstreaming可以")]),t._v(" "),n("p",[t._v("（3）Sink支持幂等或事务更新 ---》幂等是一个数学概念，f(f(x))=f(x),比如mysql表执行一个更新的sql语句，把老王的银行卡金额设为100，这个更新无论更新多少次，银行卡金额都是100。")]),t._v(" "),n("p",[t._v("也就是说如果要想让一个SparkStreaming的程序保证Exactly-Once,那么从如下三个角度出发")]),t._v(" "),n("p",[t._v("（1）接收数据:从Source中接收数据。")]),t._v(" "),n("p",[t._v("（2）转换数据:用DStream和RDD算子转换。")]),t._v(" "),n("p",[t._v("（3）储存数据:将结果保存至外部系统。")]),t._v(" "),n("p",[t._v("如果SparkStreaming程序需要实现Exactly-Once语义，那么每一个步骤都要保证Exactly-Once。")]),t._v(" "),n("p",[t._v("==实现数据被处理且只被处理一次的sink的方式：==")]),t._v(" "),n("p",[t._v("（1）需要实现数据结果保存与偏移量保存操作在同一个事务中，要么同时成功，要么就都失败。失败了会回滚。事务操作可以在foreachRDD()时进行。如果数据写入失败，或者offset保存失败，那么这一批次数据都将失败并且回滚。")]),t._v(" "),n("p",[t._v("（2）或者实现幂等。")])]),t._v(" "),n("h6",{attrs:{id:"案例演示"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#案例演示"}},[t._v("#")]),t._v(" 案例演示")]),t._v(" "),n("p",[t._v("pom.xml添加内容如下")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[t._v("       "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.scalikejdbc"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("scalikejdbc_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("3.1.0"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- https://mvnrepository.com/artifact/org.scalikejdbc/scalikejdbc-config --\x3e")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.scalikejdbc"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("scalikejdbc-config_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("3.1.0"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("mysql"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("mysql-connector-java"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("5.1.39"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("p",[t._v("代码开发")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kafka"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("common"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("TopicPartition\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kafka"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("common"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("serialization"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("StringDeserializer\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("SparkConf\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("SparkSession\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kafka010"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("ConsumerStrategies"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" HasOffsetRanges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" KafkaUtils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" LocationStrategies"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("slf4j"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("LoggerFactory\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("scalikejdbc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("ConnectionPool"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DB"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n  *    SparkStreaming EOS:\n  *      Input:Kafka\n  *      Process:Spark Streaming\n  *      Output:Mysql\n  *\n  *      保证EOS:\n  *        1、偏移量自己管理，即enable.auto.commit=false,这里保存在Mysql中\n  *        2、使用createDirectStream\n  *        3、事务输出: 结果存储与Offset提交在Driver端同一Mysql事务中\n  */")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("object")]),t._v(" SparkStreamingEOSKafkaMysqlAtomic "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@transient")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lazy")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" logger "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LoggerFactory"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getLogger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getClass"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Unit")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" topic"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"topic1"')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" group"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark_app1"')]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//Kafka配置")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" kafkaParams"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Object"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bootstrap.servers"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node1:6667,node2:6667,node3:6667"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"key.deserializer"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" classOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("StringDeserializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"value.deserializer"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" classOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("StringDeserializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"auto.offset.reset"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"latest"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"enable.auto.commit"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" java"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lang"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Boolean")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"group.id"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" group"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//在Driver端创建数据库连接池")]),t._v("\n    ConnectionPool"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("singleton"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbc:mysql://node3:3306/bigdata"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getClass"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getSimpleName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("replace"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"$"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" ssc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" StreamingContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("Seconds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//1)初次启动或重启时,从指定的Partition、Offset构建TopicPartition")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//2)运行过程中,每个Partition、Offset保存在内部currentOffsets = Map[TopicPartition, Long]()变量中")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//3)后期Kafka Topic分区动扩展,在运行过程中不能自动感知")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" initOffset"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("DB"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("readOnly"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implicit")]),t._v(" session"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      sql"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select `partition`,offset from kafka_topic_offset where topic =${topic} and `group`=${group}"')]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("item"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" TopicPartition"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("topic"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"partition"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"offset"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apply"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toMap\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//CreateDirectStream")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//从指定的Topic、Partition、Offset开始消费")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sourceDStream "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("KafkaUtils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createDirectStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      LocationStrategies"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PreferConsistent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      ConsumerStrategies"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Assign"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("initOffset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keys"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("kafkaParams"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("initOffset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    sourceDStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreachRDD"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isEmpty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" offsetRanges "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("asInstanceOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("HasOffsetRanges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("offsetRanges\n        offsetRanges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("offsetRange"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          logger"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("info"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Topic: ${offsetRange.topic},Group: ${group},Partition: ${offsetRange.partition},fromOffset: ${offsetRange.fromOffset},untilOffset: ${offsetRange.untilOffset}"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//统计分析")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//将结果收集到Driver端")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkSession "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("builder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("config"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getOrCreate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("sparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("implicits"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("_\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" dataFrame "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("json"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rdd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDS"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        dataFrame"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createOrReplaceTempView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tmpTable"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sparkSession"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sql"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n            |select\n            |   --每分钟\n            |   eventTimeMinute,\n            |   --每种语言\n            |   language,\n            |   -- 次数\n            |   count(1) pv,\n            |   -- 人数\n            |   count(distinct(userID)) uv\n            |from(\n            |   select *, substr(eventTime,0,16) eventTimeMinute from tmpTable\n            |) as tmp group by eventTimeMinute,language\n          """')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stripMargin\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//在Driver端存储数据、提交Offset")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//结果存储与Offset提交在同一事务中原子执行")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//这里将偏移量保存在Mysql中")]),t._v("\n        DB"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("localTx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implicit")]),t._v(" session"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n          "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//结果存储")]),t._v("\n          result"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("row"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            sql"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n            insert into twitter_pv_uv (eventTimeMinute, language,pv,uv)\n            value (\n                ${row.getAs[String]("eventTimeMinute")},\n                ${row.getAs[String]("language")},\n                ${row.getAs[Long]("pv")},\n                ${row.getAs[Long]("uv")}\n                )\n            on duplicate key update pv=pv,uv=uv\n          """')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apply"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n          "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//Offset提交")]),t._v("\n          offsetRanges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("foreach"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("offsetRange"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" affectedRows "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sql"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n          update kafka_topic_offset set offset = ${offsetRange.untilOffset}\n          where\n            topic = ${topic}\n            and `group` = ${group}\n            and `partition` = ${offsetRange.partition}\n            and offset = ${offsetRange.fromOffset}\n          """')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apply"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("affectedRows "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n              "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throw")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Exception"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""Commit Kafka Topic: ${topic} Offset Faild!"""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h2",{attrs:{id:"sparkstreaming调优"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparkstreaming调优"}},[t._v("#")]),t._v(" SparkStreaming调优")]),t._v(" "),n("h4",{attrs:{id:"调整blockreceiver的数量"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#调整blockreceiver的数量"}},[t._v("#")]),t._v(" 调整BlockReceiver的数量")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1437),alt:"1567325066744"}})]),t._v(" "),n("p",[t._v("案例演示：")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" kafkaStream "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("  \n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sparkStreamingConsumerGroup "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark-streaming-consumer-group"')]),t._v("  \n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" kafkaParams "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("  \n    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"zookeeper.connect"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"node01:2181,node02:2181,node03:2181"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  \n    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"group.id"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark-streaming-test"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" inputTopic "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"test"')]),t._v("  \n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" numPartitionsOfInputTopic "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("  \n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" streams "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" to "),n("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("numPartitionsOfInputTopic")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" map  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("x "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("  \n    KafkaUtils"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createStream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" kafkaParams"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inputTopic "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("      StorageLevel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("MEMORY_ONLY_SER"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("  \n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" unifiedStream "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ssc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("union"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("streams"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \n")])])]),n("h4",{attrs:{id:"_4调整block的数量"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4调整block的数量"}},[t._v("#")]),t._v(" 4调整Block的数量")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("batchInterval : 触发批处理的时间间隔\nblockInterval :将接收到的数据生成Block的时间间隔，spark.streaming.blockInterval(默认是200ms)，那么，BlockRDD的分区数 = batchInterval / blockInterval，即一个Block就是RDD的一个分区，就是一个task\n比如，batchInterval是2秒，而blockInterval是200ms，那么task数为10，如果task的数量太少，比一个executor的core数还少的话，那么可以减少blockInterval，blockInterval最好不要小于50ms，太小的话导致task数太多，那么launch task的时间久多了\n")])])]),n("h5",{attrs:{id:"_4-3-调整receiver的接受速率"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-调整receiver的接受速率"}},[t._v("#")]),t._v(" 4.3 调整Receiver的接受速率")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("pps:permits per second 每秒允许接受的数据量(QPS -> queries per second)\nSpark Streaming默认的PPS是没有限制的,可以通过参数spark.streaming.receiver.maxRate来控制，默认是Long.Maxvalue\n")])])]),n("h5",{attrs:{id:"_4-4-调整数据处理的并行度"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-4-调整数据处理的并行度"}},[t._v("#")]),t._v(" 4.4 调整数据处理的并行度")]),t._v(" "),n("p",[n("strong",[t._v("BlockRDD的分区数")])]),t._v(" "),n("p",[t._v("a. 通过Receiver接受数据的特点决定")]),t._v(" "),n("p",[t._v("b. 也可以自己通过repartition设置")]),t._v(" "),n("p",[n("strong",[t._v("ShuffleRDD的分区数")])]),t._v(" "),n("p",[t._v("a. 默认的分区数为spark.default.parallelism(core的大小)")]),t._v(" "),n("p",[t._v("b. 通过我们自己设置决定")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" wordCounts "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" words"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" a "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" b"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" HashPartitioner"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h5",{attrs:{id:"_4-5-数据的序列化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-5-数据的序列化"}},[t._v("#")]),t._v(" 4.5 数据的序列化")]),t._v(" "),n("p",[t._v("SparkStreaming两种需要序列化的数据：\na. 输入的数据：默认是以"),n("a",{attrs:{href:"http://spark.apache.org/docs/latest/api/scala/index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("StorageLevel.MEMORY_AND_DISK_SER_2"),n("OutboundLink")],1),t._v("的形式存储在executor上的内存中\nb. 缓存的数据：默认是以"),n("a",{attrs:{href:"http://spark.apache.org/docs/latest/api/scala/index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("StorageLevel.MEMORY_ONLY_SER"),n("OutboundLink")],1),t._v("的形式存储的内存中\n使用Kryo序列化机制，比Java序列化机制性能好")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" conf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkConf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setMaster"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setAppName"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"spark.serializer"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"org.apache.spark.serializer.KryoSerializer"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nconf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("registerKryoClasses"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("classOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("MyClass1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" classOf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("MyClass2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" SparkContext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h5",{attrs:{id:"_4-6-内存调优"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-6-内存调优"}},[t._v("#")]),t._v(" 4.6 内存调优")]),t._v(" "),n("ul",[n("li",[t._v("需要内存大小")])]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("和transformation的类型有关，如果使用的是updateStateByKey，Window这样的算子，那么内存就要设置得偏大。\n")])])]),n("ul",[n("li",[t._v("数据存储级别")])]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("如果把接收到的数据设置的存储级别是MEMORY_DISK这种级别，也就是说如果内存不够可以把数据存储到磁盘上，其实性能还是不好的，性能最好的就是所有的数据都在内存里面，所以如果在资源允许的情况下，把内存调大一点，让所有的数据都存在内存里面。\n")])])]),n("h5",{attrs:{id:"_4-7-output-operations性能"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-7-output-operations性能"}},[t._v("#")]),t._v(" 4.7 Output Operations性能")]),t._v(" "),n("ul",[n("li",[t._v("保存结果到外部的存储介质中，比如mysql/hbase数据库\n"),n("ul",[n("li",[t._v("使用高性能的算子操作实现")])])])]),t._v(" "),n("p",[n("img",{attrs:{src:s(1438),alt:"1585058900250"}})]),t._v(" "),n("p",[n("img",{attrs:{src:s(1439),alt:"1585058915092"}})]),t._v(" "),n("h5",{attrs:{id:"_4-8-backpressure-压力反馈"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-8-backpressure-压力反馈"}},[t._v("#")]),t._v(" 4.8 Backpressure(压力反馈)")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1440),alt:"1567327168554"}})]),t._v(" "),n("p",[n("img",{attrs:{src:s(1441),alt:"1567327191622"}})]),t._v(" "),n("p",[t._v("Feedback Loop : 动态使得Streaming app从unstable状态回到stable状态")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1442),alt:"1567327216060"}})]),t._v(" "),n("p",[t._v("从Spark1.5版本开始：==spark.streaming.backpressure.enabled = true==")]),t._v(" "),n("h5",{attrs:{id:"_4-9-elastic-scaling-资源动态分配"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-9-elastic-scaling-资源动态分配"}},[t._v("#")]),t._v(" 4.9 Elastic Scaling(资源动态分配)")]),t._v(" "),n("p",[t._v("动态分配资源：")]),t._v(" "),n("p",[t._v("批处理动态的决定这个application中需要多少个Executors：")]),t._v(" "),n("ol",[n("li",[t._v("当一个Executor空闲的时候，将这个Executor杀掉")]),t._v(" "),n("li",[t._v("当task太多的时候，动态的启动Executors")])]),t._v(" "),n("p",[t._v("Streaming分配Executor的原则是比对 process time / batchInterval 的比率")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1443),alt:"1567327351927"}})]),t._v(" "),n("p",[t._v("如果延迟了，那么就自动增加资源")]),t._v(" "),n("p",[n("img",{attrs:{src:s(1444),alt:"1567327385166"}})]),t._v(" "),n("p",[n("img",{attrs:{src:s(1445),alt:"1567327412253"}})]),t._v(" "),n("p",[t._v("从Spark2.0有这个功能，开启资源动态分配： ==spark.streaming.dynamicAllocation.enabled = true==")]),t._v(" "),n("h5",{attrs:{id:"_4-10-数据倾斜调优"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-10-数据倾斜调优"}},[t._v("#")]),t._v(" 4.10  数据倾斜调优")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("因为SparkStreaming的底层就是RDD，之前我们讲SparkCore的所有的数据倾斜的调优策略（见SparkCore调优）都适合于SparkStreaming，大家一定要灵活掌握，这个在实际开发的工作当中用得频率较高，各位同学面试的时候也可以从这个角度跟面试官聊。\t\n")])])]),n("h2",{attrs:{id:"总结"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("简单聊一下sparkStreaming程序。\n\n后期进入到企业之后，如果用到sparkStreaming消费kafka的数据，建议大家使用Direct直连方式的api的处理。它是有一些有点。如果你想实现exactly-once，可以实现幂等或者是事务去控制。去开发对应的代码.\n\n\n开发步骤：\n（1）在本地开发好程序（指定master为local），做测试，目的：为了测试代码的业务功能逻辑对不对\n（2）可以稍微改造一下程序（master不在为local）,把程序打成jar包提交到spark集群中运行\n\n\n有一个问题需要探讨一下：\n一个sparkStreaming程序到底给定多少计算资源是比较合理？\n假设实时处理程序的批处理时间间隔为5s。什么情况才叫资源比较合理？\n首先你要知道针对于实时处理程序来什么情况才叫合理？\n-----需要在当前批次时间间隔内，就要上一个批次时间产生的数据处理完成----------\n说白了就是这里需要在5s之内就把上一个5s的数据处理完成。\n如果处理的时间大于了批处理时间间隔，这里会出现数据的积压，任务延迟比较高\n\n\n可以来几组资源参数做测试：\n(1) --executor-memory  2g   --total-executor-core 10\n(2) --executor-memory  2g   --total-executor-core 20\n(3) --executor-memory  5g   --total-executor-core 20\n\n\n把程序提交到集群之后可以通过master的web页面观察任务运行的相关信息。\nspark-submit  \\\n--master spark://node01:7077  \\\n--class com.kaikeba.streaming.kafka.KafkaDirect10 \\\n--executor-memory 1g \\\n--total-executor-cores 4 \\\nsparkStreamingStudy-1.0-SNAPSHOT.jar \n")])])]),n("h2",{attrs:{id:"sparkstreaming高频面试题"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#sparkstreaming高频面试题"}},[t._v("#")]),t._v(" ==sparkStreaming高频面试题！！！！！！==")]),t._v(" "),n("h5",{attrs:{id:"_1、你们公司有多少个实时任务"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1、你们公司有多少个实时任务"}},[t._v("#")]),t._v(" 1、你们公司有多少个实时任务？")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("20-50个任务就可以了\n")])])]),n("h5",{attrs:{id:"_2、你们是如何保证数据不丢失的-代码怎么的-架构是什么"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2、你们是如何保证数据不丢失的-代码怎么的-架构是什么"}},[t._v("#")]),t._v(" 2、你们是如何保证数据不丢失的, 代码怎么的？架构是什么？")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("kafka 0.8\nkafka 0.10\n")])])]),n("h5",{attrs:{id:"_3、你们的任务多久是一个批次"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3、你们的任务多久是一个批次"}},[t._v("#")]),t._v(" 3、你们的任务多久是一个批次？")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("5秒、10秒、30秒、1分钟都是可以的\n")])])]),n("h5",{attrs:{id:"_4、一个批次里面大约有多少条数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4、一个批次里面大约有多少条数据"}},[t._v("#")]),t._v(" 4、一个批次里面大约有多少条数据？")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("8000条左右\n")])])]),n("h5",{attrs:{id:"_5、你的整个任务一天计算多少条数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_5、你的整个任务一天计算多少条数据"}},[t._v("#")]),t._v(" 5、你的整个任务一天计算多少条数据？")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("估算一下，2/8法则算一下\n")])])]),n("h5",{attrs:{id:"_6、一条消息多大"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_6、一条消息多大"}},[t._v("#")]),t._v(" 6、一条消息多大？")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("10KB左右\n")])])]),n("h5",{attrs:{id:"_7、你在处理实时任务的过程中遇到了什么问题吗-☆☆☆☆☆"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_7、你在处理实时任务的过程中遇到了什么问题吗-☆☆☆☆☆"}},[t._v("#")]),t._v(" 7、你在处理实时任务的过程中遇到了什么问题吗？（☆☆☆☆☆）")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("一定不能说没有，但是也不能说有些比较低级的问题\n举个例子，比如说之前处理的业务代码会出现数据丢失，现在不丢失了\n或者是任务延迟了，因为发送了数据倾斜，导致在规定的时间内数据没有处理完，导致调度延迟，内存损耗完。\n\n怎么解决的？可以使用之前的数据倾斜方法去处理解决。\n")])])]),n("h5",{attrs:{id:"_8、你们公司用的kafka是哪个版本-什么版本的sparkstreaming"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_8、你们公司用的kafka是哪个版本-什么版本的sparkstreaming"}},[t._v("#")]),t._v(" 8、你们公司用的kafka是哪个版本，什么版本的sparkStreaming?")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("1.0版本的kafka\n2.3.3版本的sparkStreaming\n")])])]),n("h5",{attrs:{id:"_9、你们公司是如何管理实时任务的"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_9、你们公司是如何管理实时任务的"}},[t._v("#")]),t._v(" 9、你们公司是如何管理实时任务的？")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("可以说出一个思路就可以了\n")])])]),n("h5",{attrs:{id:"_10、如何保证一次语义-☆☆☆☆☆"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_10、如何保证一次语义-☆☆☆☆☆"}},[t._v("#")]),t._v(" 10、如何保证一次语义？（☆☆☆☆☆）")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("不一定说要写代码，需要提供相关的思路即可\n")])])]),n("h2",{attrs:{id:"知识扩展-scalikejdbc"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#知识扩展-scalikejdbc"}},[t._v("#")]),t._v(" 知识扩展-ScalikeJDBC")]),t._v(" "),n("h4",{attrs:{id:"_1、什么是scalikejdbc"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1、什么是scalikejdbc"}},[t._v("#")]),t._v(" 1、什么是ScalikeJDBC")]),t._v(" "),n("p",[t._v("ScalikeJDBC是Scala开发人员基于SQL的简洁数据库访问库。")]),t._v(" "),n("p",[t._v("该库自然包装JDBC API，为您提供易于使用且非常灵活的API。")]),t._v(" "),n("p",[t._v("更重要的是，QueryDSL使您的代码类型安全且可重用。")]),t._v(" "),n("p",[t._v("ScalikeJDBC是一个实用且适合生产的产品。 将此库用于实际项目.")]),t._v(" "),n("h4",{attrs:{id:"_2、idea项目中导入相关库"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2、idea项目中导入相关库"}},[t._v("#")]),t._v(" 2、IDEA项目中导入相关库")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- https://mvnrepository.com/artifact/org.scalikejdbc/scalikejdbc --\x3e")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.scalikejdbc"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("scalikejdbc_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("3.1.0"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- https://mvnrepository.com/artifact/org.scalikejdbc/scalikejdbc-config --\x3e")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.scalikejdbc"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("scalikejdbc-config_2.11"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("3.1.0"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('\x3c!-- mysql " mysql-connector-java --\x3e')]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("mysql"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("mysql-connector-java"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("5.1.38"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("h4",{attrs:{id:"_3、数据库操作"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3、数据库操作"}},[t._v("#")]),t._v(" 3、数据库操作")]),t._v(" "),n("h5",{attrs:{id:"_3-1-数据库连接配置信息"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-数据库连接配置信息"}},[t._v("#")]),t._v(" 3.1 数据库连接配置信息")]),t._v(" "),n("ul",[n("li",[t._v("在IDEA的resources文件夹下创建application.conf")])]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#mysql的连接配置信息")]),t._v("\ndb.default.driver"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"com.mysql.jdbc.Driver"')]),t._v("\ndb.default.url"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbc:mysql://node03:3306/spark"')]),t._v("\ndb.default.user"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"root"')]),t._v("\ndb.default.password"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"123456"')]),t._v("\n")])])]),n("ul",[n("li",[t._v("scalikeJDBC默认加载default配置，或者使用自定义配置")])]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#mysql的连接配置信息")]),t._v("\ndb.fred.driver"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"com.mysql.jdbc.Driver"')]),t._v("\ndb.fred.url"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbc:mysql://node03:3306/spark"')]),t._v("\ndb.fred.user"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"root"')]),t._v("\ndb.fred.password"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"123456"')]),t._v("\n")])])]),n("h5",{attrs:{id:"_3-2-加载数据配置信息"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-加载数据配置信息"}},[t._v("#")]),t._v(" 3.2 加载数据配置信息")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//默认加载default配置信息")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DBs")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("setup")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//加载自定义的fred配置信息")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DBs")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("setup")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("'fred"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h5",{attrs:{id:"_3-3-查询数据库并封装数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-查询数据库并封装数据"}},[t._v("#")]),t._v(" 3.3 查询数据库并封装数据")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//配置mysql")]),t._v("\nDBs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setup"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//查询数据并返回单个列，并将列数据封装到集合中")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" list "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DB"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("readOnly"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implicit")]),t._v(" session "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("\n  SQL"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select content from post"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rs "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" \n    rs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"content"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apply"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("<-")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" Users"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nickName"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n  * 查询数据库，并将数据封装成对象，并返回一个集合\n  */")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//配置mysql")]),t._v("\nDBs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setup"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token symbol"}},[t._v("'fred")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//查询数据并返回单个列，并将列数据封装到集合中")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" users "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" NamedDB"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token symbol"}},[t._v("'fred")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("readOnly"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implicit")]),t._v(" session "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("\n  SQL"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select * from users"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rs "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("\n  Users"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("rs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" rs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    rs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("string"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"nickName"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apply"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("<-")]),t._v(" users"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  println"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h5",{attrs:{id:"_3-4-插入数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-插入数据"}},[t._v("#")]),t._v(" 3.4 插入数据")]),t._v(" "),n("h6",{attrs:{id:"_3-4-1-autocommit"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-1-autocommit"}},[t._v("#")]),t._v(" 3.4.1 AutoCommit")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("/**\n  * 插入数据，使用AutoCommit\n  * @return\n  */\nval insertResult "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DB.autoCommit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("implicit session "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n  SQL"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"insert into users(name, nickName) values(?,?)"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(".bind"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"test01"')]),t._v(", "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"test01"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    .update"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(".apply"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("insertResult"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h6",{attrs:{id:"_3-4-2-插入返回主键标识"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-2-插入返回主键标识"}},[t._v("#")]),t._v(" 3.4.2 插入返回主键标识")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n  * 插入数据，并返回主键\n  * @return\n  */")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" id "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DB"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("localTx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implicit")]),t._v(" session "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("\n  SQL"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"insert into users(name, nickName, sex) values(?,?,?)"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bind"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"test"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"000"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"male"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("updateAndReturnGeneratedKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"nickName"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apply"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("id"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h6",{attrs:{id:"_3-4-3-事务插入"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-3-事务插入"}},[t._v("#")]),t._v(" 3.4.3 事务插入")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n  * 使用事务插入数据库\n  * @return\n  */")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" tx "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DB"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("localTx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implicit")]),t._v(" session "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("\n  SQL"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"insert into users(name, nickName, sex) values(?,?,?)"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bind"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"test"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"haha"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"male"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apply"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//下一行会报错，用于测试")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" s "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" \n  SQL"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"insert into users(name, nickName, sex) values(?,?,?)"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bind"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"test01"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"haha01"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"male01"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apply"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprintln"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tx = ${tx}"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h6",{attrs:{id:"_3-4-4-更新数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-4-更新数据"}},[t._v("#")]),t._v(" 3.4.4 更新数据")]),t._v(" "),n("div",{staticClass:"language-scala extra-class"},[n("pre",{pre:!0,attrs:{class:"language-scala"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n  * 更新数据\n  * @return\n  */")]),t._v("\nDB"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("localTx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implicit")]),t._v(" session "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v("\n  SQL"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"update users set nickName = ?"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bind"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"xiaoming"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apply"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);a.default=e.exports}}]);