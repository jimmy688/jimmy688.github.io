<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>个人博客 | JiiiiG</title>
    <meta name="generator" content="VuePress 1.8.0">
    
    <meta name="description" content="自是年少，韶华倾负">
    
    <link rel="preload" href="/assets/css/0.styles.420b7c1f.css" as="style"><link rel="preload" href="/assets/js/app.fdd7a502.js" as="script"><link rel="preload" href="/assets/js/16.375b747e.js" as="script"><link rel="preload" href="/assets/js/18.5d2371a4.js" as="script"><link rel="prefetch" href="/assets/js/10.bbd38b9e.js"><link rel="prefetch" href="/assets/js/11.f49fc7d3.js"><link rel="prefetch" href="/assets/js/12.c5d97aa1.js"><link rel="prefetch" href="/assets/js/13.426d0224.js"><link rel="prefetch" href="/assets/js/14.1f257a58.js"><link rel="prefetch" href="/assets/js/15.be29bb6a.js"><link rel="prefetch" href="/assets/js/17.d02cdd8b.js"><link rel="prefetch" href="/assets/js/19.038919a3.js"><link rel="prefetch" href="/assets/js/2.d6257727.js"><link rel="prefetch" href="/assets/js/20.b3582e09.js"><link rel="prefetch" href="/assets/js/21.0c1e826b.js"><link rel="prefetch" href="/assets/js/22.91bff1a5.js"><link rel="prefetch" href="/assets/js/23.faacea60.js"><link rel="prefetch" href="/assets/js/24.69816497.js"><link rel="prefetch" href="/assets/js/25.c9fcaa62.js"><link rel="prefetch" href="/assets/js/26.d28c3abe.js"><link rel="prefetch" href="/assets/js/27.1518da7d.js"><link rel="prefetch" href="/assets/js/28.748a5581.js"><link rel="prefetch" href="/assets/js/29.775019f1.js"><link rel="prefetch" href="/assets/js/3.141002a4.js"><link rel="prefetch" href="/assets/js/30.74e7c570.js"><link rel="prefetch" href="/assets/js/31.190b11f2.js"><link rel="prefetch" href="/assets/js/32.d8f4f116.js"><link rel="prefetch" href="/assets/js/33.c489bc81.js"><link rel="prefetch" href="/assets/js/34.db609d51.js"><link rel="prefetch" href="/assets/js/35.ad3402e6.js"><link rel="prefetch" href="/assets/js/36.45f11923.js"><link rel="prefetch" href="/assets/js/37.b47e0576.js"><link rel="prefetch" href="/assets/js/38.58b934a2.js"><link rel="prefetch" href="/assets/js/39.e4d6bcdf.js"><link rel="prefetch" href="/assets/js/4.e9b44388.js"><link rel="prefetch" href="/assets/js/40.555106bc.js"><link rel="prefetch" href="/assets/js/41.4387ceb1.js"><link rel="prefetch" href="/assets/js/42.9bd4aea0.js"><link rel="prefetch" href="/assets/js/43.587e7966.js"><link rel="prefetch" href="/assets/js/44.80285763.js"><link rel="prefetch" href="/assets/js/45.f978da77.js"><link rel="prefetch" href="/assets/js/46.d93e3f2e.js"><link rel="prefetch" href="/assets/js/47.c15bd2aa.js"><link rel="prefetch" href="/assets/js/48.cb55fa72.js"><link rel="prefetch" href="/assets/js/49.d0f4e454.js"><link rel="prefetch" href="/assets/js/5.b90b80cb.js"><link rel="prefetch" href="/assets/js/50.112e8260.js"><link rel="prefetch" href="/assets/js/51.a66bcd03.js"><link rel="prefetch" href="/assets/js/52.0c7cbfb1.js"><link rel="prefetch" href="/assets/js/53.67ef240b.js"><link rel="prefetch" href="/assets/js/54.2c2d082d.js"><link rel="prefetch" href="/assets/js/55.88f19a20.js"><link rel="prefetch" href="/assets/js/56.c726e920.js"><link rel="prefetch" href="/assets/js/57.eaee47c5.js"><link rel="prefetch" href="/assets/js/58.ac15a3ac.js"><link rel="prefetch" href="/assets/js/59.64bdc849.js"><link rel="prefetch" href="/assets/js/6.7eea74ff.js"><link rel="prefetch" href="/assets/js/7.a1370e98.js"><link rel="prefetch" href="/assets/js/8.2e898240.js"><link rel="prefetch" href="/assets/js/9.a2439994.js">
    <link rel="stylesheet" href="/assets/css/0.styles.420b7c1f.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">个人博客 | JiiiiG</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  主页
</a></div><div class="nav-item"><a href="/linux/linux常用命令/01linux常用命令01.html" class="nav-link">
  Linux
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="大数据" class="dropdown-title"><span class="title">大数据</span> <span class="arrow down"></span></button> <button type="button" aria-label="大数据" class="mobile-dropdown-title"><span class="title">大数据</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/hadoop/01hadoop环境搭建/01搭建hadoop集群.html" class="nav-link">
  hadoop
</a></li><li class="dropdown-item"><!----> <a href="/hbase/hbase.html" class="nav-link">
  hbase
</a></li><li class="dropdown-item"><!----> <a href="/flink/flink.html" class="nav-link">
  flink
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程语言" class="dropdown-title"><span class="title">编程语言</span> <span class="arrow down"></span></button> <button type="button" aria-label="编程语言" class="mobile-dropdown-title"><span class="title">编程语言</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/sparkstreaming/.html" class="nav-link">
  java
</a></li></ul></div></div> <a href="https://github.com/MaLunan/press" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  主页
</a></div><div class="nav-item"><a href="/linux/linux常用命令/01linux常用命令01.html" class="nav-link">
  Linux
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="大数据" class="dropdown-title"><span class="title">大数据</span> <span class="arrow down"></span></button> <button type="button" aria-label="大数据" class="mobile-dropdown-title"><span class="title">大数据</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/hadoop/01hadoop环境搭建/01搭建hadoop集群.html" class="nav-link">
  hadoop
</a></li><li class="dropdown-item"><!----> <a href="/hbase/hbase.html" class="nav-link">
  hbase
</a></li><li class="dropdown-item"><!----> <a href="/flink/flink.html" class="nav-link">
  flink
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程语言" class="dropdown-title"><span class="title">编程语言</span> <span class="arrow down"></span></button> <button type="button" aria-label="编程语言" class="mobile-dropdown-title"><span class="title">编程语言</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/sparkstreaming/.html" class="nav-link">
  java
</a></li></ul></div></div> <a href="https://github.com/MaLunan/press" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><p>大数据实时技术框架发展</p> <blockquote><p>(1)storm:</p> <p>​	它是一个实时的处理框架，可以实现来一条数据就处理一条数据，实时性非常高，但吞吐量很低。</p> <p>​	已经被淘汰了。</p> <p>(2)sparkstreaming:</p> <p>​	它不能算是实时的处理引擎，其本质是批处理，只不过由于要处理的数据是源源不断的，并且每个		批次非常小，然后处理起来很快，让我们感觉有实时的效果。是微批处理。</p> <p>​	从严格意义来说，sparkstreaming并不是一个实时处理框架，可以理解是准实时的。</p> <p>​	特性：实时性不高，吞吐量比较高。</p> <p>(2)flink:</p> <p>​	它是真正意义上的实时处理框架，来一条数据就处理一条数据，它的实时性非常高，吞吐量也非常		高。是未来大数据的发展方向。</p></blockquote> <h2 id="sparkstreaming简介"><a href="#sparkstreaming简介" class="header-anchor">#</a> SparkStreaming简介</h2> <p>SparkStreaming是对于Spark核心API的拓展，从而<strong>支持对于实时数据流的可拓展，高吞吐量和容错性流处理</strong>。数据可以由多个源取得，例如：Kafka，Flume，Twitter，ZeroMQ，Kinesis或者TCP接口，同时可以使用由如map，reduce，join和window这样的高层接口描述的复杂算法进行处理。最终，处理过的数据可以被推送到文件系统，数据库和HDFS。</p> <p>数据从Kafka上获得时，我们可以把SparkStreaming理解成Kafka的消费者程序。</p> <p><img src="/assets/img/streaming-arch-1608485794544.645c1861.png" alt="Spark Streaming"></p> <p>Spark Streaming 是基于spark的流式批处理引擎，其<strong>基本原理是把输入数据以某一时间间隔批量的处理，当批处理间隔缩短到秒级时，便可以用于处理实时数据流。</strong></p> <p>流式：源源不断地数据流入</p> <p>流式批处理：一批批的数据源源不断地流入</p> <p><img src="/assets/img/image-20200422150253653-1608485794544.4653d71a.png" alt="image-20200422150253653"></p> <h2 id="sparkstreaming架构流程"><a href="#sparkstreaming架构流程" class="header-anchor">#</a> SparkStreaming架构流程</h2> <p><img src="/assets/img/sparkStreaming架构流程-1608485794544.e466e465.png" alt="sparkStreaming架构流程"></p> <ol><li>将sparkstreaming程序打成jar包，提交到spark集群。</li> <li>SparkStreaming就是一个application，需要创建流式处理的上下文对象StreamingContext,该StreamingContext内部会封装一个sparkContext,sparkContext是运行在Driver之上。根据不同的运行模式，在对应的服务器构建一个Driver。</li> <li>==Driver端发送Receiver（接收器）对象到某个executor进程==中，receiver是用来接收数据源的数据的，默认只有一个，可以配置多个，Receiver会占用一个线程。</li> <li>==Receiver会把接收到的一条条数据封装成一个个block==，然后把这些block数据写入到当前executor的内存中。==默认是每200ms之内接收的数据就是一个block，通过设置block-interval来改变这个值。==</li> <li>Receiver把接收到的数据块block的信息通知给Driver。这里会有向Driver端申请资源的步骤，暂时省略，跟之前学习spark时讲的申请资源流程大致一样。</li> <li>申请好资源后，会在不同的机器节点启动其它的executor，executor里面也会有task,一个task(线程）将会处理一个block块的数据。</li> <li>==Driver端根据一定的时间间隔，把这些block块组成一个RDD==，然后对这些RDD进行处理。==其中一个block就是RDD中的1个partition，一个partition对应1个task任务==。默认的批处理时间间隔batch-size=1s,</li> <li>按照批处理时间间隔和产生block的时间间隔的默认值，可以知道：每隔1s就会生成一个job,这个job对应的RDD的分区数为1s/200ms=5个。</li></ol> <h2 id="sparkstreaming程序入口"><a href="#sparkstreaming程序入口" class="header-anchor">#</a> SparkStreaming程序入口</h2> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;NetworkWordCount&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> ssc <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>conf<span class="token punctuation">,</span> Seconds<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">//或者</span>
<span class="token keyword">val</span> ssc <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">,</span> Seconds<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="什么是dstream"><a href="#什么是dstream" class="header-anchor">#</a> 什么是DStream</h2> <p>==离散数据流或者DStream是SparkStreaming提供的基本抽象==。其表现数据的连续流，这个输入数据流可以来自于源，也可以来自于转换输入流产生的已处理数据流。==内部而言，一个DStream以一系列连续的RDDs所展现==，这些RDD是Spark对于不变的，分布式数据集的抽象。一个DStream中的每个RDD都包含来自一定间隔的数据，如下图：</p> <p><img src="/assets/img/streaming-dstream-1608485794544.fabdf95b.png" alt=""></p> <p>==在DStream上使用的任何操作都会转换为针对底层RDD的操作，每一次对Dstream的处理都是针对当前批次生成的RDD数据==。例如：之前那个将行的流转变为词流的例子中，flatMap操作应用于行DStream的每个RDD上 从而产生words DStream的RDD。如下图：</p> <p><img src="/assets/img/streaming-dstream-ops-1608485794544.ecc85f84.png" alt="Spark Streaming"></p> <p><img src="/assets/img/DStream逻辑图-1608485794544.90b9e380.png" alt="DStream逻辑图"></p> <h2 id="dstream算子操作"><a href="#dstream算子操作" class="header-anchor">#</a> DStream算子操作</h2> <h4 id="transformations"><a href="#transformations" class="header-anchor">#</a> Transformations</h4> <p>==实现把一个DStream转换生成一个新的DStream，延迟加载不会触发任务的执行==</p> <table><thead><tr><th><strong>Transformation</strong></th> <th><strong>Meaning</strong></th></tr></thead> <tbody><tr><td>map(func)</td> <td>对DStream中的各个元素进行func函数操作，然后返回一个新的DStream</td></tr> <tr><td>flatMap(func)</td> <td>与map方法类似，只不过各个输入项可以被输出为零个或多个输出项</td></tr> <tr><td>filter(func)</td> <td>过滤出所有函数func返回值为true的DStream元素并返回一个新的DStream</td></tr> <tr><td>repartition(numPartitions)</td> <td>增加或减少DStream中的分区数，从而改变DStream的并行度</td></tr> <tr><td>union(otherStream)</td> <td>将源DStream和输入参数为otherDStream的元素合并，并返回一个新的DStream.</td></tr> <tr><td>count()</td> <td>通过对DStream中的各个RDD中的元素进行计数，然后返回只有一个元素的RDD构成的DStream</td></tr> <tr><td>reduce(func)</td> <td>对源DStream中的各个RDD中的元素利用func进行聚合操作，然后返回只有一个元素的RDD构成的新的DStream.</td></tr> <tr><td>countByValue()</td> <td>对于元素类型为K的DStream，返回一个元素为（K,Long）键值对形式的新的DStream，Long对应的值为源DStream中各个RDD的key出现的次数</td></tr> <tr><td>reduceByKey(func, [numTasks])</td> <td>利用func函数对源DStream中的key进行聚合操作，然后返回新的（K，V）对构成的DStream</td></tr> <tr><td>join(otherStream, [numTasks])</td> <td>输入为（K,V)、（K,W）类型的DStream，返回一个新的（K，（V，W））类型的DStream</td></tr> <tr><td>cogroup(otherStream, [numTasks])</td> <td>输入为（K,V)、（K,W）类型的DStream，返回一个新的 (K, Seq[V], Seq[W]) 元组类型的DStream</td></tr> <tr><td>transform(func)</td> <td>通过RDD-to-RDD函数作用于DStream中的各个RDD，可以是任意的RDD操作，从而返回一个新的RDD</td></tr> <tr><td>updateStateByKey(func)</td> <td>根据key的之前状态值和key的新值，对key进行更新，返回一个新状态的DStream</td></tr> <tr><td>reduceByKeyAndWindow</td> <td>窗口函数操作，实现按照window窗口大小来进行计算</td></tr></tbody></table> <h4 id="output-operations"><a href="#output-operations" class="header-anchor">#</a> Output Operations</h4> <p>输出算子操作，==触发任务的真正运行==</p> <table><thead><tr><th>Output Operation</th> <th>Meaning</th></tr></thead> <tbody><tr><td>print()</td> <td>打印到控制台</td></tr> <tr><td>saveAsTextFiles(prefix, [suffix])</td> <td>保存流的内容为文本文件，文件名为&quot;prefix-TIME_IN_MS[.suffix]&quot;.</td></tr> <tr><td>saveAsObjectFiles(prefix, [suffix])</td> <td>保存流的内容为SequenceFile，文件名为 &quot;prefix-TIME_IN_MS[.suffix]&quot;.</td></tr> <tr><td>saveAsHadoopFiles(prefix, [suffix])</td> <td>保存流的内容为hadoop文件，文件名为 &quot;prefix-TIME_IN_MS[.suffix]&quot;.</td></tr> <tr><td>foreachRDD(func)</td> <td>对Dstream里面的每个RDD执行func</td></tr></tbody></table> <h2 id="数据源-socket"><a href="#数据源-socket" class="header-anchor">#</a> 数据源--socket</h2> <h4 id="需求"><a href="#需求" class="header-anchor">#</a> 需求</h4> <p>使用sparkStreaming实时接收socket数据，实现单词计数</p> <h4 id="业务处理流程图"><a href="#业务处理流程图" class="header-anchor">#</a> 业务处理流程图</h4> <p><img src="/assets/img/1582444394566-1608485794544.a62380ac.png" alt="1582444394566"></p> <h4 id="安装并开启socket服务"><a href="#安装并开启socket服务" class="header-anchor">#</a> 安装并开启socket服务</h4> <p>首先在linux服务器node01上用yum 安装nc工具，==nc命令是netcat命令的简称==,它是用来设置路由器。我们可以利用它向某个端口发送数据。</p> <div class="language-shell extra-class"><pre class="language-shell"><code>yum -y <span class="token function">install</span> <span class="token function">nc</span>
</code></pre></div><p>执行命令向指定的端口发送数据(模拟socket)</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token function">nc</span> -lk <span class="token number">9999</span> 
</code></pre></div><h4 id="pom-xml配置"><a href="#pom-xml配置" class="header-anchor">#</a> pom.xml配置</h4> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>properties</span><span class="token punctuation">&gt;</span></span> <span class="token comment">&lt;!--注意这里，设置了version,在后面就可以引用这些值了，如${scala.version}--&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scala.version</span><span class="token punctuation">&gt;</span></span>2.11.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scala.version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>spark.version</span><span class="token punctuation">&gt;</span></span>2.3.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>spark.version</span><span class="token punctuation">&gt;</span></span> 
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>properties</span><span class="token punctuation">&gt;</span></span>

 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.scala-lang<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>scala-library<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${scala.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>  <span class="token comment">&lt;!--2.11.8--&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-streaming_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${spark.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span> <span class="token comment">&lt;!--2.3.3--&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>

 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>sourceDirectory</span><span class="token punctuation">&gt;</span></span>src/main/scala<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>sourceDirectory</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>testSourceDirectory</span><span class="token punctuation">&gt;</span></span>src/test/scala<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>testSourceDirectory</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>net.alchim31.maven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>scala-maven-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.2.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>compile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>testCompile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>args</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span><span class="token punctuation">&gt;</span></span>-dependencyfile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>arg</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span><span class="token punctuation">&gt;</span></span>${project.build.directory}/.scala_dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>arg</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>args</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>maven-shade-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.4.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">&gt;</span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>shade<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>filters</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>filter</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifact</span><span class="token punctuation">&gt;</span></span>*:*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifact</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>excludes</span><span class="token punctuation">&gt;</span></span>
                                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>META-INF/*.SF<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>META-INF/*.DSA<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>META-INF/*.RSA<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>excludes</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>filter</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>filters</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>transformers</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>transformer</span> <span class="token attr-name">implementation</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">&quot;</span>org.apache.maven.plugins.shade.resource.ManifestResourceTransformer<span class="token punctuation">&quot;</span></span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mainClass</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mainClass</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>transformer</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>transformers</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><h4 id="开发sparkstreaming程序"><a href="#开发sparkstreaming程序" class="header-anchor">#</a> 开发sparkStreaming程序</h4> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>jimmy<span class="token punctuation">.</span>streaming</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span>ReceiverInputDStream
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> MySocket <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> conf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;socketDemo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;warn&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> ssc<span class="token operator">=</span><span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sc<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> value<span class="token operator">:</span>ReceiverInputDStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> ssc<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">&quot;node01&quot;</span><span class="token punctuation">,</span> <span class="token number">9999</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> result<span class="token operator">=</span>value<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">=&gt;</span>x<span class="token operator">+</span>y<span class="token punctuation">)</span>
    result<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>

    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">//开启流式计算</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">//这个表示程序不会停止运行，除非手动中断</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><h4 id="运行程序"><a href="#运行程序" class="header-anchor">#</a> 运行程序</h4> <p>运行上面的Scala程序后，在node01上模拟socket以不同的速度发送数据，输入一些单词，空格隔开（要跟代码设置的分隔符一致），如下图：</p> <p><img src="/assets/img/image-20200423000846608-1608485794544.c5978fae.png" alt="image-20200423000846608"></p> <p>然后观察IDEA的程序运行界面，会出现类似下面格式的输出信息，每隔1000ms(1s)就会打印一次信息，可以结合sparkstreaming架构流程来分析。</p> <div class="language- extra-class"><pre class="language-text"><code>-------------------------------------------
Time: 1587571532000 ms
-------------------------------------------
(spark,2)
(hadoop,4)
-------------------------------------------
Time: 1587571533000 ms
-------------------------------------------
(,1)
(spark,5)
(hadoop,10)

-------------------------------------------
Time: 1587571534000 ms
-------------------------------------------

-------------------------------------------
Time: 1587571535000 ms
-------------------------------------------

-------------------------------------------
Time: 1587571536000 ms
-------------------------------------------
</code></pre></div><h4 id="思考问题"><a href="#思考问题" class="header-anchor">#</a> 思考问题</h4> <p>思考一个问题：在sparkstreaming中，能不能只设置一个线程来运行，如setMaster(&quot;local[1]&quot;)。</p> <p>答案是不可以，因为Receiver本身就占用了一个线程，一个CPU同一时间只能运行一个线程，只设置一个CPU的话，Receiver线程会一直占用着这个cpu，所以没有cpu去执行计算任务。</p> <h4 id="剖析"><a href="#剖析" class="header-anchor">#</a> 剖析</h4> <p>==每一个DStream只负责计算当前批次产生的数据，之前批次的数据，计算完成之后就不存在了。==</p> <p><img src="/assets/img/image-20200423003440585-1608485794544.9aa78933.png" alt="image-20200423003440585"></p> <h2 id="数据源-hdfs"><a href="#数据源-hdfs" class="header-anchor">#</a> 数据源--HDFS</h2> <h4 id="需求-2"><a href="#需求-2" class="header-anchor">#</a> 需求</h4> <p>通过sparkStreaming监控hdfs上的目录，有新的文件产生，就把数据拉取过来进行处理</p> <h4 id="业务处理流程图-2"><a href="#业务处理流程图-2" class="header-anchor">#</a> 业务处理流程图</h4> <p><img src="/assets/img/1582444992866-1608485794544.ad6e1770.png" alt="1582444992866"></p> <h4 id="创建监听目录"><a href="#创建监听目录" class="header-anchor">#</a> 创建监听目录</h4> <div class="language- extra-class"><pre class="language-text"><code>hdfs dfs -mkdir /dataStreamingDemo
</code></pre></div><h4 id="代码开发"><a href="#代码开发" class="header-anchor">#</a> 代码开发</h4> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>jimmy<span class="token punctuation">.</span>streaming</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Level<span class="token punctuation">,</span> Logger<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span>ReceiverInputDStream
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> MySocket <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    Logger<span class="token punctuation">.</span>getLogger<span class="token punctuation">(</span><span class="token string">&quot;org&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setLevel<span class="token punctuation">(</span>Level<span class="token punctuation">.</span>ERROR<span class="token punctuation">)</span>
    <span class="token keyword">val</span> conf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;socketDemo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;warn&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> ssc<span class="token operator">=</span><span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sc<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> value <span class="token operator">=</span> ssc<span class="token punctuation">.</span>textFileStream<span class="token punctuation">(</span><span class="token string">&quot;hdfs://node01:8020/dataStreamingDemo&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> result<span class="token operator">=</span>value<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">=&gt;</span>x<span class="token operator">+</span>y<span class="token punctuation">)</span>
    result<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>

    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">//开启流式计算</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">//这个表示程序不会停止运行，除非手动中断</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><blockquote><p>注意：</p> <ol><li></li></ol></blockquote> <h4 id="运行程序-2"><a href="#运行程序-2" class="header-anchor">#</a> 运行程序</h4> <p>创建数据文件：</p> <div class="language- extra-class"><pre class="language-text"><code>vi /tmp/words.txt

hadoop spark spark
flume flink hadoop hadoop
</code></pre></div><p>运行sparkStreaming程序,然后上传文件到hdfs的/dataStreamingDemo目录</p> <div class="language- extra-class"><pre class="language-text"><code>hdfs dfs -put /tmp/words.txt /dataStreamingDemo
</code></pre></div><p>观察IDEA程序运行界面，输出结果大致如下：</p> <div class="language- extra-class"><pre class="language-text"><code>Time: 1587583799000 ms
-------------------------------------------

-------------------------------------------
Time: 1587583800000 ms
-------------------------------------------
(flink,1)
(spark,2)
(hadoop,3)
(flume,1)

-------------------------------------------
Time: 1587583801000 ms
-------------------------------------------

-------------------------------------------
</code></pre></div><h4 id="报错问题"><a href="#报错问题" class="header-anchor">#</a> 报错问题</h4> <p>程序之前运行时，报错：<a href="https://www.cnblogs.com/dongxiucai/p/10245896.html" target="_blank" rel="noopener noreferrer">Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: org/apache/hadoop/fs/CanUnbuffer<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>这可能是因为pom依赖添加了hbase依赖的原因，导致出现一些异常，将hbase的依赖删掉就可以正常运行了。或者可以尝试将hbase的依赖放在hadoop依赖的后面。</p> <p>在该程序中，正确的pom.xml的配置如下：</p> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>properties</span><span class="token punctuation">&gt;</span></span> <span class="token comment">&lt;!--注意这里，设置了version,在后面就可以引用这些值了，如${scala.version}--&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scala.version</span><span class="token punctuation">&gt;</span></span>2.11.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scala.version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>spark.version</span><span class="token punctuation">&gt;</span></span>2.3.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>spark.version</span><span class="token punctuation">&gt;</span></span> 
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>properties</span><span class="token punctuation">&gt;</span></span>

 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.scala-lang<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>scala-library<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${scala.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>  <span class="token comment">&lt;!--2.11.8--&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-streaming_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${spark.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span> <span class="token comment">&lt;!--2.3.3--&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>

 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>sourceDirectory</span><span class="token punctuation">&gt;</span></span>src/main/scala<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>sourceDirectory</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>testSourceDirectory</span><span class="token punctuation">&gt;</span></span>src/test/scala<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>testSourceDirectory</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>net.alchim31.maven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>scala-maven-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.2.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>compile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>testCompile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>args</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span><span class="token punctuation">&gt;</span></span>-dependencyfile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>arg</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span><span class="token punctuation">&gt;</span></span>${project.build.directory}/.scala_dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>arg</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>args</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>maven-shade-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.4.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">&gt;</span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>shade<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>filters</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>filter</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifact</span><span class="token punctuation">&gt;</span></span>*:*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifact</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>excludes</span><span class="token punctuation">&gt;</span></span>
                                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>META-INF/*.SF<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>META-INF/*.DSA<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>META-INF/*.RSA<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>excludes</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>filter</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>filters</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>transformers</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>transformer</span> <span class="token attr-name">implementation</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">&quot;</span>org.apache.maven.plugins.shade.resource.ManifestResourceTransformer<span class="token punctuation">&quot;</span></span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mainClass</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mainClass</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>transformer</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>transformers</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><h2 id="自定义数据源todo"><a href="#自定义数据源todo" class="header-anchor">#</a> 自定义数据源TODO</h2> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">/**
  * 自定义一个Receiver，这个Receiver从socket中接收数据
  * 使用方式：nc -lk 8888
  */</span>
<span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>kaikeba<span class="token punctuation">.</span>streaming</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token punctuation">{</span>BufferedReader<span class="token punctuation">,</span> InputStreamReader<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>net<span class="token punctuation">.</span></span>Socket
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>charset<span class="token punctuation">.</span></span>StandardCharsets

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span>SparkConf
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>internal<span class="token punctuation">.</span></span>Logging
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>storage<span class="token punctuation">.</span></span>StorageLevel
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token punctuation">{</span>DStream<span class="token punctuation">,</span> ReceiverInputDStream<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>receiver<span class="token punctuation">.</span></span>Receiver

<span class="token comment">/**
  * 自定义数据源
  */</span>
<span class="token keyword">object</span> CustomReceiver <span class="token punctuation">{</span>

  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
   Logger<span class="token punctuation">.</span>getLogger<span class="token punctuation">(</span><span class="token string">&quot;org&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setLevel<span class="token punctuation">(</span>Level<span class="token punctuation">.</span>ERROR<span class="token punctuation">)</span>

    <span class="token comment">// todo: 1、创建SparkConf对象</span>
    <span class="token keyword">val</span> sparkConf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
                                              <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;CustomReceiver&quot;</span><span class="token punctuation">)</span>
                                              <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">// todo: 2、创建StreamingContext对象</span>
    <span class="token keyword">val</span> ssc <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//todo: 3、调用 receiverStream api，将自定义的Receiver传进去</span>
   <span class="token keyword">val</span> receiverStream <span class="token operator">=</span> ssc<span class="token punctuation">.</span>receiverStream<span class="token punctuation">(</span><span class="token keyword">new</span> CustomReceiver<span class="token punctuation">(</span><span class="token string">&quot;node01&quot;</span><span class="token punctuation">,</span><span class="token number">8888</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//todo: 4、对数据进行处理</span>
    <span class="token keyword">val</span> result<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> receiverStream
                                                      <span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                                                      <span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                                                      <span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>
    <span class="token comment">//todo: 5、打印结果</span>
    result<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//todo: 6、开启流式计算</span>
    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>

<span class="token punctuation">}</span>

<span class="token comment">/**
  * 自定义source数据源
  * @param host
  * @param port
  */</span>
<span class="token keyword">class</span> CustomReceiver<span class="token punctuation">(</span>host<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>port<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> Receiver<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>StorageLevel<span class="token punctuation">.</span>MEMORY_AND_DISK_SER<span class="token punctuation">)</span> <span class="token keyword">with</span> Logging<span class="token punctuation">{</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> onStart<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span><span class="token punctuation">{</span>
    <span class="token comment">//启动一个线程，开始接受数据</span>
      <span class="token keyword">new</span> Thread<span class="token punctuation">(</span><span class="token string">&quot;socket receiver&quot;</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
        <span class="token keyword">override</span> <span class="token keyword">def</span> run<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
            receive<span class="token punctuation">(</span><span class="token punctuation">)</span>
          <span class="token punctuation">}</span>
      <span class="token punctuation">}</span><span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

  <span class="token comment">/** Create a socket connection and receive data until receiver is stopped */</span>
  <span class="token keyword">private</span> <span class="token keyword">def</span> receive<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">var</span> socket<span class="token operator">:</span> Socket <span class="token operator">=</span> <span class="token keyword">null</span>
    <span class="token keyword">var</span> userInput<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token keyword">null</span>
    <span class="token keyword">try</span> <span class="token punctuation">{</span>
      logInfo<span class="token punctuation">(</span><span class="token string">&quot;Connecting to &quot;</span> <span class="token operator">+</span> host <span class="token operator">+</span> <span class="token string">&quot;:&quot;</span> <span class="token operator">+</span> port<span class="token punctuation">)</span>
      socket <span class="token operator">=</span> <span class="token keyword">new</span> Socket<span class="token punctuation">(</span>host<span class="token punctuation">,</span> port<span class="token punctuation">)</span>
      logInfo<span class="token punctuation">(</span><span class="token string">&quot;Connected to &quot;</span> <span class="token operator">+</span> host <span class="token operator">+</span> <span class="token string">&quot;:&quot;</span> <span class="token operator">+</span> port<span class="token punctuation">)</span>
      <span class="token keyword">val</span> reader <span class="token operator">=</span> <span class="token keyword">new</span> BufferedReader<span class="token punctuation">(</span>
        <span class="token keyword">new</span> InputStreamReader<span class="token punctuation">(</span>socket<span class="token punctuation">.</span>getInputStream<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> StandardCharsets<span class="token punctuation">.</span>UTF_8<span class="token punctuation">)</span><span class="token punctuation">)</span>

      userInput <span class="token operator">=</span> reader<span class="token punctuation">.</span>readLine<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token keyword">while</span><span class="token punctuation">(</span><span class="token operator">!</span>isStopped <span class="token operator">&amp;&amp;</span> userInput <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        store<span class="token punctuation">(</span>userInput<span class="token punctuation">)</span>
        userInput <span class="token operator">=</span> reader<span class="token punctuation">.</span>readLine<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
      reader<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
      socket<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
      logInfo<span class="token punctuation">(</span><span class="token string">&quot;Stopped receiving&quot;</span><span class="token punctuation">)</span>
      restart<span class="token punctuation">(</span><span class="token string">&quot;Trying to connect again&quot;</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">{</span>
      <span class="token keyword">case</span> e<span class="token operator">:</span> java<span class="token punctuation">.</span>net<span class="token punctuation">.</span>ConnectException <span class="token keyword">=&gt;</span>
        restart<span class="token punctuation">(</span><span class="token string">&quot;Error connecting to &quot;</span> <span class="token operator">+</span> host <span class="token operator">+</span> <span class="token string">&quot;:&quot;</span> <span class="token operator">+</span> port<span class="token punctuation">,</span> e<span class="token punctuation">)</span>
      <span class="token keyword">case</span> t<span class="token operator">:</span> Throwable <span class="token keyword">=&gt;</span>
        restart<span class="token punctuation">(</span><span class="token string">&quot;Error receiving data&quot;</span><span class="token punctuation">,</span> t<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

  <span class="token keyword">override</span> <span class="token keyword">def</span> onStop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span><span class="token punctuation">{</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><h2 id="集群运行sparkstreaming程序"><a href="#集群运行sparkstreaming程序" class="header-anchor">#</a> 集群运行sparkStreaming程序</h2> <p>自己开发wordcount程序，然后打包上传到集群，并打开任务运行界面，查看一下任务运行情况。</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>jimmy<span class="token punctuation">.</span>streaming</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Level<span class="token punctuation">,</span> Logger<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> MySocket <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    Logger<span class="token punctuation">.</span>getLogger<span class="token punctuation">(</span><span class="token string">&quot;org&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setLevel<span class="token punctuation">(</span>Level<span class="token punctuation">.</span>ERROR<span class="token punctuation">)</span>
    <span class="token keyword">val</span> conf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;socketDemo&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;warn&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> ssc<span class="token operator">=</span><span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sc<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> value <span class="token operator">=</span> ssc<span class="token punctuation">.</span>textFileStream<span class="token punctuation">(</span>args<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> result<span class="token operator">=</span>value<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">=&gt;</span>x<span class="token operator">+</span>y<span class="token punctuation">)</span>
    result<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>

    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">//开启流式计算</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">//这个表示程序不会停止运行，除非手动中断</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>运行jar包</p> <div class="language-sh extra-class"><pre class="language-sh"><code>spark-submit --class com.jimmy.streaming.MySocket --master spark://node01:7077 --executor-memory 1g --total-executor-cores <span class="token number">2</span> originaMySparkDemo-1.0-SNAPSHOT.jar /dataStreamingDemo
</code></pre></div><p>上传文件到监听目录:</p> <div class="language- extra-class"><pre class="language-text"><code>hdfs dfs -put /tmp/words.txt /dataStreamingDemo/
</code></pre></div><p>观察效果：</p> <p><img src="/assets/img/image-20200423035855381-1608485794544.a4195a90.png" alt="image-20200423035855381"></p> <p>查看sparkStreaming的任务运行界面，可以看到一些图表等：</p> <p><img src="/assets/img/image-20200423035950826-1608485794544.e88692d4.png" alt="image-20200423035950826"></p> <p>查看Executors，可以发现，driver运行在node01上</p> <p><img src="/assets/img/image-20200423040120447-1608485794545.1bc0ac38.png" alt="image-20200423040120447"></p> <h2 id="transformation-高级算子"><a href="#transformation-高级算子" class="header-anchor">#</a> Transformation 高级算子</h2> <h4 id="updatestatebykey-统计分析所有批次"><a href="#updatestatebykey-统计分析所有批次" class="header-anchor">#</a> updateStateByKey——统计分析所有批次</h4> <p>需求: sparkStreaming接受socket数据实现所有批次的单词次数累加</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>jimmy<span class="token punctuation">.</span>streaming</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> UpdateDemo <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> sparkconf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkconf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> ssc<span class="token operator">=</span><span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sc<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;warn&quot;</span><span class="token punctuation">)</span>

    ssc<span class="token punctuation">.</span>checkpoint<span class="token punctuation">(</span><span class="token string">&quot;hdfs://node01:8020/ck&quot;</span><span class="token punctuation">)</span>  <span class="token comment">//缓存历史批次的数据</span>

    <span class="token keyword">val</span> data<span class="token operator">=</span>ssc<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">&quot;node01&quot;</span><span class="token punctuation">,</span><span class="token number">9999</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> result<span class="token operator">=</span>data<span class="token punctuation">.</span>updateStateByKey<span class="token punctuation">(</span>myUpdateFunc<span class="token punctuation">)</span>

    result<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

  <span class="token keyword">def</span> myUpdateFunc<span class="token punctuation">(</span>currentValue<span class="token operator">:</span>Seq<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">,</span>historyValues<span class="token operator">:</span>Option<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span>Option<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token punctuation">{</span>
    <span class="token keyword">val</span> newValue<span class="token operator">=</span>currentValue<span class="token punctuation">.</span>sum<span class="token operator">+</span>historyValues<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    Some<span class="token punctuation">(</span>newValue<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>源码分析：</p> <blockquote><p>查看updateStateByKey的源码如下：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">def</span> updateStateByKey<span class="token punctuation">[</span>S<span class="token operator">:</span> ClassTag<span class="token punctuation">]</span><span class="token punctuation">(</span>
   updateFunc<span class="token operator">:</span> <span class="token punctuation">(</span>Seq<span class="token punctuation">[</span>V<span class="token punctuation">]</span><span class="token punctuation">,</span> Option<span class="token punctuation">[</span>S<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> Option<span class="token punctuation">[</span>S<span class="token punctuation">]</span><span class="token punctuation">,</span>
   numPartitions<span class="token operator">:</span> <span class="token builtin">Int</span>
 <span class="token punctuation">)</span><span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> S<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ssc<span class="token punctuation">.</span>withScope <span class="token punctuation">{</span>
 updateStateByKey<span class="token punctuation">(</span>updateFunc<span class="token punctuation">,</span> defaultPartitioner<span class="token punctuation">(</span>numPartitions<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre></div><p>从源码可知，该算子需要传入一个函数：(Seq[V], Option[S]) =&gt; Option[S],所以我们需要自己自定义一个符合参数类型要求的函数：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">def</span> myUpdateFunc<span class="token punctuation">(</span>currentValue<span class="token operator">:</span>Seq<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">,</span>historyValues<span class="token operator">:</span>Option<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span>Option<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token punctuation">{</span>
 <span class="token keyword">val</span> newValue<span class="token operator">=</span>currentValue<span class="token punctuation">.</span>sum<span class="token operator">+</span>historyValues<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
 Some<span class="token punctuation">(</span>newValue<span class="token punctuation">)</span>  <span class="token comment">//将单词在所有批次出现的总次数</span>
<span class="token punctuation">}</span>
</code></pre></div><ol><li>这个myUpdateFunc函数传入updateStateByKey后，将会依次作用于所有批次的不同单词。</li> <li>currentValue:当前批次中==每一个单词出现的所有的1的集合==，如List(1,1,1,1),对该集合进行.sum操作就可以获得某个单词在当前批次出现的次数。</li> <li>historyValues:之前批次中==每个单词出现的总次数==,Option类型表示存在或者不存在。Some表示存在有值，None表示没有</li></ol></blockquote> <p>运行程序：</p> <blockquote><p>1、启动socket服务，nc -lk 9999，运行sparkStreaming程序</p> <p>2、socket发送hadoop hadoop hadoop hadoop,此时程序界面显示如下，可以发现，打印的信息是所有批次的综合</p> <div class="language- extra-class"><pre class="language-text"><code>-------------------------------------------
Time: 1587634964000 ms
-------------------------------------------
(hadoop,4)

-------------------------------------------
Time: 1587634966000 ms
-------------------------------------------
(hadoop,4)

-------------------------------------------
Time: 1587634968000 ms
-------------------------------------------
(hadoop,4)
</code></pre></div><p>3、socket继续发送flink spark hadoop，此时程序界面显示如下，可以发现，当前批次与历史批次的数据进行了汇总再输出</p> <div class="language- extra-class"><pre class="language-text"><code>-------------------------------------------
Time: 1587634980000 ms
-------------------------------------------
(flink,1)
(spark,1)
(hadoop,5)

-------------------------------------------
Time: 1587634982000 ms
-------------------------------------------
(flink,1)
(spark,1)
(hadoop,5)
</code></pre></div></blockquote> <h4 id="mapwithstate-统计分析所有批次"><a href="#mapwithstate-统计分析所有批次" class="header-anchor">#</a> mapWithState——统计分析所有批次</h4> <p>mapWithState也是可以实现所有批次的累加，但是它相对于updateStateByKey，==性能更高==。</p> <p>需求: sparkStreaming接受socket数据实现所有批次的单词次数累加</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>jimmy<span class="token punctuation">.</span>streaming</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token punctuation">{</span>DStream<span class="token punctuation">,</span> MapWithStateDStream<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Durations<span class="token punctuation">,</span> Seconds<span class="token punctuation">,</span> State<span class="token punctuation">,</span> StateSpec<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">,</span> Time<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> mapDemo1 <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> sparkconf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkconf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> ssc<span class="token operator">=</span><span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sc<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;warn&quot;</span><span class="token punctuation">)</span>

    ssc<span class="token punctuation">.</span>checkpoint<span class="token punctuation">(</span><span class="token string">&quot;hdfs://node01:8020/ck2&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">//定义一个用于初始化的RDD</span>
    <span class="token keyword">val</span> initRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ssc<span class="token punctuation">.</span>sparkContext<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">&quot;hadoop&quot;</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">&quot;spark&quot;</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> data<span class="token operator">:</span>DStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>ssc<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">&quot;node01&quot;</span><span class="token punctuation">,</span><span class="token number">9999</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> MyStateSpec<span class="token operator">=</span>StateSpec<span class="token punctuation">.</span>function<span class="token punctuation">(</span><span class="token punctuation">(</span>time<span class="token operator">:</span>Time<span class="token punctuation">,</span>key<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>currentValue<span class="token operator">:</span>Option<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">,</span>historyState<span class="token operator">:</span>State<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
      <span class="token keyword">val</span> newValue<span class="token operator">=</span>currentValue<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">+</span>historyState<span class="token punctuation">.</span>getOption<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
      <span class="token keyword">val</span> output<span class="token operator">=</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span>newValue<span class="token punctuation">)</span>
      <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token operator">!</span>historyState<span class="token punctuation">.</span>isTimingOut<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
        historyState<span class="token punctuation">.</span>update<span class="token punctuation">(</span>newValue<span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
      Some<span class="token punctuation">(</span>output<span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>initialState<span class="token punctuation">(</span>initRDD<span class="token punctuation">)</span><span class="token punctuation">.</span>timeout<span class="token punctuation">(</span>Durations<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> result<span class="token operator">:</span>MapWithStateDStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>data<span class="token punctuation">.</span>mapWithState<span class="token punctuation">(</span>MyStateSpec<span class="token punctuation">)</span>

    result<span class="token punctuation">.</span>stateSnapshots<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>源码分析：</p> <blockquote><p>查看mapWithState的源码，如下：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">def</span> mapWithState<span class="token punctuation">[</span>StateType<span class="token operator">:</span> ClassTag<span class="token punctuation">,</span> MappedType<span class="token operator">:</span> ClassTag<span class="token punctuation">]</span><span class="token punctuation">(</span>
   spec<span class="token operator">:</span> StateSpec<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">,</span> StateType<span class="token punctuation">,</span> MappedType<span class="token punctuation">]</span>
 <span class="token punctuation">)</span><span class="token operator">:</span> MapWithStateDStream<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">,</span> StateType<span class="token punctuation">,</span> MappedType<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
 <span class="token keyword">new</span> MapWithStateDStreamImpl<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">,</span> StateType<span class="token punctuation">,</span> MappedType<span class="token punctuation">]</span><span class="token punctuation">(</span>
   <span class="token keyword">self</span><span class="token punctuation">,</span>
   spec<span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>StateSpecImpl<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">,</span> StateType<span class="token punctuation">,</span> MappedType<span class="token punctuation">]</span><span class="token punctuation">]</span>
 <span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre></div><p>mapWithState算子需要一个参数：spec: StateSpec[K, V, StateType, MappedType]</p> <p>StateSpec是一个object，里面有一个function方法，这个方法可以返回一个StateSpec[KeyType, ValueType, StateType, MappedType]，正好是mapWithState算子需要的参数类型，源码如下：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">object</span> StateSpec <span class="token punctuation">{</span>

<span class="token keyword">def</span> function<span class="token punctuation">[</span>KeyType<span class="token punctuation">,</span> ValueType<span class="token punctuation">,</span> StateType<span class="token punctuation">,</span> MappedType<span class="token punctuation">]</span><span class="token punctuation">(</span>
   mappingFunction<span class="token operator">:</span> <span class="token punctuation">(</span>Time<span class="token punctuation">,</span> KeyType<span class="token punctuation">,</span> Option<span class="token punctuation">[</span>ValueType<span class="token punctuation">]</span><span class="token punctuation">,</span> State<span class="token punctuation">[</span>StateType<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> Option<span class="token punctuation">[</span>MappedType<span class="token punctuation">]</span>
 <span class="token punctuation">)</span><span class="token operator">:</span> StateSpec<span class="token punctuation">[</span>KeyType<span class="token punctuation">,</span> ValueType<span class="token punctuation">,</span> StateType<span class="token punctuation">,</span> MappedType<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
 ClosureCleaner<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>mappingFunction<span class="token punctuation">,</span> checkSerializable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
 <span class="token keyword">new</span> StateSpecImpl<span class="token punctuation">(</span>mappingFunction<span class="token punctuation">)</span>
<span class="token punctuation">}</span>

</code></pre></div><p>function方法需要一个函数作为参数：mappingFunction: (Time, KeyType, Option[ValueType], State[StateType]) =&gt; Option[MappedType]</p> <p>下面是代码中自己定义function方法的代码：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> MyStateSpec<span class="token operator">=</span>StateSpec<span class="token punctuation">.</span>function<span class="token punctuation">(</span><span class="token punctuation">(</span>time<span class="token operator">:</span>Time<span class="token punctuation">,</span>key<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>currentValue<span class="token operator">:</span>Option<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">,</span>historyState<span class="token operator">:</span>State<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
   <span class="token keyword">val</span> newValue<span class="token operator">=</span>currentValue<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">+</span>historyState<span class="token punctuation">.</span>getOption<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
   <span class="token keyword">val</span> output<span class="token operator">=</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span>newValue<span class="token punctuation">)</span>
   <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token operator">!</span>historyState<span class="token punctuation">.</span>isTimingOut<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
     historyState<span class="token punctuation">.</span>update<span class="token punctuation">(</span>newValue<span class="token punctuation">)</span>
   <span class="token punctuation">}</span>
   Some<span class="token punctuation">(</span>output<span class="token punctuation">)</span>
 <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>initialState<span class="token punctuation">(</span>initRDD<span class="token punctuation">)</span><span class="token punctuation">.</span>timeout<span class="token punctuation">(</span>Durations<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>key:String是单词，currentValue:Option[Int]是该单词在当前批次的出现次数，historyState:State[Int]是历史批次的次数，封装在State里面。</p> <p>使用Some封装output，返回出去。</p> <p>.initialState(initRDD)用于进行初始化，initRDD是自己定义的。</p> <p>.timeout(Durations.seconds(5))表示如果某个单词（key)超过5s没有出现，该key及其状态state将会被移除掉。</p> <p>historyState.update(newValue)是用来更新历史批次的state的，if(!historyState.isTimingOut())表示如果某单词（key)超时没有出现，就不更新其state了。</p> <p>==在这里，打印时，最好使用result.stateSnapshots().print()方式而不是result.print()==</p> <p>单纯使用print()的效果是下面这样的：</p> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token punctuation">(</span>flink,1<span class="token punctuation">)</span>
<span class="token punctuation">(</span>hadoop,11<span class="token punctuation">)</span>
<span class="token punctuation">(</span>hadoop,12<span class="token punctuation">)</span> <span class="token comment">#单词的次数加1就会打印一次，不太好。</span>
</code></pre></div></blockquote> <p>运行程序：</p> <blockquote><p>1、打开socket,nc -lk 9999,运行程序，一开始输出结果如下：</p> <div class="language- extra-class"><pre class="language-text"><code>-------------------------------------------
Time: 1587654820000 ms
-------------------------------------------
(spark,20)
(hadoop,10)
</code></pre></div><p>2、socket发送数据：hadoop hadoop，输出如下，可以看到，hadoop在初始值10的基础上加了2，并且spark在5s之后被移除了。</p> <div class="language- extra-class"><pre class="language-text"><code>-------------------------------------------
Time: 1587654834000 ms
-------------------------------------------
(spark,20)
(hadoop,12)

-------------------------------------------
Time: 1587654836000 ms
-------------------------------------------
(spark,20)
(hadoop,12)

-------------------------------------------
Time: 1587654838000 ms
-------------------------------------------
(hadoop,12)
</code></pre></div></blockquote> <h4 id="transform-对dstream中的rdd进行操作"><a href="#transform-对dstream中的rdd进行操作" class="header-anchor">#</a> transform——对DStream中的RDD进行操作</h4> <p>需求: 获取每一个批次中单词出现次数最多的前3位</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span>DStream
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> sparkconf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkconf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> ssc<span class="token operator">=</span><span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sc<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;warn&quot;</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>checkpoint<span class="token punctuation">(</span><span class="token string">&quot;hdfs://node01:8020/ck2&quot;</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> data<span class="token operator">:</span>DStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>ssc<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">&quot;node01&quot;</span><span class="token punctuation">,</span><span class="token number">9999</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
      flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>
    <span class="token keyword">val</span> result<span class="token operator">:</span>DStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>data<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>rdd<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
      <span class="token keyword">val</span> sortrdd<span class="token operator">=</span>rdd<span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>_2<span class="token punctuation">,</span><span class="token boolean">false</span><span class="token punctuation">)</span>
      <span class="token keyword">val</span> top3<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span>sortrdd<span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
      println<span class="token punctuation">(</span><span class="token string">&quot;=====top3结果====&quot;</span><span class="token punctuation">)</span>
      top3<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
      println<span class="token punctuation">(</span><span class="token string">&quot;=====top3结果====&quot;</span><span class="token punctuation">)</span>
      println<span class="token punctuation">(</span><span class="token string">&quot;原始数据:&quot;</span><span class="token punctuation">)</span>
      <span class="token comment">//不能将top3作为结果	返回，因为不是RDD[(String, Int)]类型</span>
      sortrdd
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    result<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>运行结果：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>top3结果<span class="token operator">==</span><span class="token operator">==</span>
<span class="token punctuation">(</span>hadoop<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>flink<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>spark<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>top3结果<span class="token operator">==</span><span class="token operator">==</span>
原始数据<span class="token operator">:</span>
<span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span>
Time<span class="token operator">:</span> <span class="token number">1587660264000</span> ms
<span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span>
<span class="token punctuation">(</span>hadoop<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>flink<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>spark<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>hive<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>flume<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="window操作"><a href="#window操作" class="header-anchor">#</a> Window操作</h4> <p>如果这样设置：val ssc=new StreamingContext(sc,Seconds(2))，就代表每隔2s处理2s的数据，那么现在的需求是：实现每隔4秒统计6秒的数据。</p> <p>注意：每隔2s处理2s的数据是在处理速度足够快的基础上的，不一定2s就能处理2s的数据，如果2s内处理不完依然会阻塞。</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span>DStream
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo1 <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> sparkconf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkconf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> ssc<span class="token operator">=</span><span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sc<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;warn&quot;</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>checkpoint<span class="token punctuation">(</span><span class="token string">&quot;hdfs://node01:8020/ck2&quot;</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> data<span class="token operator">:</span>DStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>ssc<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">&quot;node01&quot;</span><span class="token punctuation">,</span><span class="token number">9999</span><span class="token punctuation">)</span><span class="token punctuation">.</span>               
      flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> result<span class="token operator">=</span>data<span class="token punctuation">.</span>reduceByKeyAndWindow<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">,</span>y<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token keyword">=&gt;</span>x<span class="token operator">+</span>y<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    result<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><blockquote><p>查看reduceByKeyAndWindow的源码：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">def</span> reduceByKeyAndWindow<span class="token punctuation">(</span>
   reduceFunc<span class="token operator">:</span> <span class="token punctuation">(</span>V<span class="token punctuation">,</span> V<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> V<span class="token punctuation">,</span>
   windowDuration<span class="token operator">:</span> Duration<span class="token punctuation">,</span>
   slideDuration<span class="token operator">:</span> Duration
 <span class="token punctuation">)</span><span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ssc<span class="token punctuation">.</span>withScope <span class="token punctuation">{</span>
 reduceByKeyAndWindow<span class="token punctuation">(</span>reduceFunc<span class="token punctuation">,</span> windowDuration<span class="token punctuation">,</span> 
                      slideDuration<span class="token punctuation">,</span> defaultPartitioner<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre></div><p>该方法需要三个参数：
reduceFunc: (V, V) =&gt; V,  ---&gt; 就是一个函数
windowDuration: Duration, ---&gt; 窗口的大小(时间单位)，该窗口会包含N个批次的数据
slideDuration: Duration   ---&gt; 滑动窗口的时间间隔，表示每隔多久计算一次</p> <p>以代码中的Seconds(6),Seconds(4)为例，==这样做有个弊端：有些数据可能被重复处理了。因此，我们通常将窗口的大小与滑动窗口的时间间隔设置为一致，如Seconds(4),Seconds(4)==</p> <img src="sparkstreaming.assets/image-20200424015743703.png"> <p>运行结果如下,可以看到，数据是每隔4s会被处理一次。</p> <div class="language- extra-class"><pre class="language-text"><code>-------------------------------------------
Time: 1587662178000 ms
-------------------------------------------

-------------------------------------------
Time: 1587662182000 ms
-------------------------------------------

-------------------------------------------
Time: 1587662186000 ms
-------------------------------------------

-------------------------------------------
Time: 1587662190000 ms
-------------------------------------------
(hive,2)
(flink,4)
(spark,4)
(hadoop,6)
(flume,2)
</code></pre></div></blockquote> <h2 id="output-算子"><a href="#output-算子" class="header-anchor">#</a> Output 算子</h2> <h4 id="foreachrdd"><a href="#foreachrdd" class="header-anchor">#</a> foreachRDD</h4> <p>需求：将WordCount案例中得到的结果通过foreachRDD保存结果到mysql中</p> <p>在node03登录mysql,创建test database,table wordcount</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">create</span> <span class="token keyword">database</span> test<span class="token punctuation">;</span>
<span class="token keyword">use</span> test<span class="token punctuation">;</span>
<span class="token keyword">create</span> tabel wordcount<span class="token punctuation">(</span>word <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">,</span>count <span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><p>添加pom依赖：</p> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>mysql<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>mysql-connector-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>5.1.38<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><p>开发代码，一共有4个方案：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>jimmy<span class="token punctuation">.</span>streaming</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span>DriverManager

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span>DStream
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo1 <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> sparkconf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkconf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> ssc<span class="token operator">=</span><span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sc<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;warn&quot;</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> data<span class="token operator">:</span>DStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>ssc<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">&quot;node01&quot;</span><span class="token punctuation">,</span><span class="token number">9999</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
      flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>

    <span class="token comment">//===============方案1：会出错====================</span>
    data<span class="token punctuation">.</span>foreachRDD<span class="token punctuation">(</span>rdd<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
      <span class="token comment">//注意这里创建的对象都是在Driver端!!!</span>
      <span class="token keyword">val</span> conne<span class="token operator">=</span>DriverManager<span class="token punctuation">.</span>getConnection<span class="token punctuation">(</span><span class="token string">&quot;jdbc:mysql://node03:3306/test&quot;</span><span class="token punctuation">,</span>
        <span class="token string">&quot;root&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;123456&quot;</span><span class="token punctuation">)</span>
      <span class="token keyword">val</span> statement<span class="token operator">=</span>conne<span class="token punctuation">.</span>prepareStatement<span class="token punctuation">(</span>
        <span class="token string">&quot;insert into wordcount(word,count) values(?,?)&quot;</span><span class="token punctuation">)</span>
      rdd<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>record<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
        <span class="token comment">//这一块代码的执行是在executor端，需要进行网络传输，会出现task not serializable异常</span>
        statement<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>record<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
        statement<span class="token punctuation">.</span>setInt<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>record<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>
        statement<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
        statement<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        conne<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment">//===============方案2：性能较低====================</span>
    data<span class="token punctuation">.</span>foreachRDD<span class="token punctuation">(</span>rdd<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
      rdd<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>record<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
        <span class="token keyword">val</span> conne<span class="token operator">=</span>DriverManager<span class="token punctuation">.</span>getConnection<span class="token punctuation">(</span><span class="token string">&quot;jdbc:mysql://node03:3306/test&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;root&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;123456&quot;</span><span class="token punctuation">)</span>
        <span class="token keyword">val</span> statement<span class="token operator">=</span>conne<span class="token punctuation">.</span>prepareStatement<span class="token punctuation">(</span>s<span class="token string">&quot;insert into wordcount(word,count) values(?,?)&quot;</span><span class="token punctuation">)</span>
        statement<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>record<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
        statement<span class="token punctuation">.</span>setInt<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>record<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>
        statement<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
        statement<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        conne<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment">//===============方案3：性能高(推荐）====================</span>
    data<span class="token punctuation">.</span>foreachRDD<span class="token punctuation">(</span>rdd<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
      rdd<span class="token punctuation">.</span>foreachPartition<span class="token punctuation">(</span>iter<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
        <span class="token keyword">val</span> conne<span class="token operator">=</span>DriverManager<span class="token punctuation">.</span>getConnection<span class="token punctuation">(</span><span class="token string">&quot;jdbc:mysql://node03:3306/test&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;root&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;123456&quot;</span><span class="token punctuation">)</span>
        <span class="token keyword">val</span> statement<span class="token operator">=</span>conne<span class="token punctuation">.</span>prepareStatement<span class="token punctuation">(</span>s<span class="token string">&quot;insert into wordcount(word,count) values(?,?)&quot;</span><span class="token punctuation">)</span>
        conne<span class="token punctuation">.</span>setAutoCommit<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span> <span class="token comment">//关闭自动提交！！！</span>

        iter<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>record<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
          statement<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>record<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
          statement<span class="token punctuation">.</span>setInt<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>record<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>
          statement<span class="token punctuation">.</span>addBatch<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">//添加到一个批次</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span>

        statement<span class="token punctuation">.</span>executeBatch<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">//批量提交该分区所有数据</span>
        statement<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        conne<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment">//===============方案4：性能更高====================</span>
    data<span class="token punctuation">.</span>foreachRDD<span class="token punctuation">(</span>rdd<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
      rdd<span class="token punctuation">.</span>foreachPartition<span class="token punctuation">(</span>iter<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
        <span class="token keyword">val</span> conne<span class="token operator">=</span>DriverManager<span class="token punctuation">.</span>getConnection<span class="token punctuation">(</span><span class="token string">&quot;jdbc:mysql://node03:3306/test&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;root&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;123456&quot;</span><span class="token punctuation">)</span>
        <span class="token keyword">val</span> statement<span class="token operator">=</span>conne<span class="token punctuation">.</span>prepareStatement<span class="token punctuation">(</span>s<span class="token string">&quot;insert into wordcount(word,count) values(?,?)&quot;</span><span class="token punctuation">)</span>
        iter<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>record<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
          statement<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>record<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
          statement<span class="token punctuation">.</span>setInt<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>record<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>
          statement<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span>
        statement<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        conne<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>
  
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    data<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p>运行结果：</p> <div class="language-sql extra-class"><pre class="language-sql"><code>mysql<span class="token operator">&gt;</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> wordcount<span class="token punctuation">;</span>
<span class="token operator">+</span><span class="token comment">--------+-------+</span>
<span class="token operator">|</span> word   <span class="token operator">|</span> count <span class="token operator">|</span>
<span class="token operator">+</span><span class="token comment">--------+-------+</span>
<span class="token operator">|</span> hive   <span class="token operator">|</span>     <span class="token number">1</span> <span class="token operator">|</span>
<span class="token operator">|</span> flink  <span class="token operator">|</span>     <span class="token number">2</span> <span class="token operator">|</span>
<span class="token operator">|</span> spark  <span class="token operator">|</span>     <span class="token number">2</span> <span class="token operator">|</span>
<span class="token operator">|</span> hadoop <span class="token operator">|</span>     <span class="token number">3</span> <span class="token operator">|</span>
<span class="token operator">|</span> flume  <span class="token operator">|</span>     <span class="token number">1</span> <span class="token operator">|</span>
<span class="token operator">+</span><span class="token comment">--------+-------+</span>
</code></pre></div><h2 id="checkpoint"><a href="#checkpoint" class="header-anchor">#</a> Checkpoint</h2> <p>checkpoint不仅仅可以保存运算结果中的数据，还可以存储Driver端的信息</p> <p>==通过checkpoint可以实现Driver端的高可用==</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>jimmy<span class="token punctuation">.</span>streaming</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> DemoCheckpoint <span class="token punctuation">{</span>
  <span class="token keyword">val</span> checkpointPath<span class="token operator">=</span><span class="token string">&quot;hdfs://node01:8020/ckDir&quot;</span>

  <span class="token keyword">def</span> MycreatingFunc<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>StreamingContext<span class="token operator">=</span><span class="token punctuation">{</span>
    <span class="token keyword">val</span> sparkconf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkconf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> ssc<span class="token operator">=</span><span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sc<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;warn&quot;</span><span class="token punctuation">)</span>

    ssc<span class="token punctuation">.</span>checkpoint<span class="token punctuation">(</span>checkpointPath<span class="token punctuation">)</span>  <span class="token comment">//缓存历史批次的数据</span>

    <span class="token keyword">val</span> data<span class="token operator">=</span>ssc<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">&quot;node01&quot;</span><span class="token punctuation">,</span><span class="token number">9999</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
      flatMap<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> result<span class="token operator">=</span>data<span class="token punctuation">.</span>updateStateByKey<span class="token punctuation">(</span>myUpdateFunc<span class="token punctuation">)</span>
    result<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc
  <span class="token punctuation">}</span>

  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> ssc<span class="token operator">=</span>StreamingContext<span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span>checkpointPath<span class="token punctuation">,</span>MycreatingFunc<span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

  <span class="token keyword">def</span> myUpdateFunc<span class="token punctuation">(</span>currentValue<span class="token operator">:</span>Seq<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">,</span>historyValues<span class="token operator">:</span>Option<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span>Option<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token punctuation">{</span>
    <span class="token keyword">val</span> newValue<span class="token operator">=</span>currentValue<span class="token punctuation">.</span>sum<span class="token operator">+</span>historyValues<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    Some<span class="token punctuation">(</span>newValue<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>运行测试</p> <blockquote><p>运行程序，socket发送数据: hadoop flink,输出信息如下：</p> <div class="language- extra-class"><pre class="language-text"><code>-------------------------------------------
Time: 1587670986000 ms
-------------------------------------------
(flink,1)
(hadoop,1)
</code></pre></div><p>此时，==终止程序的运行，然后重新启动程序==，继续socket发送数据hadoop flink,  观察输出：</p> <div class="language- extra-class"><pre class="language-text"><code>-------------------------------------------
Time: 1587670988000 ms
-------------------------------------------
(flink,2)
(hadoop,2)
</code></pre></div><p>可以发现，即使程序中途停止运行了，当程序重新启动时，依然能够接着上次的结果继续运行计算。</p> <p>==Checkpoint实现Driver的高可用的原理：==</p> <ol><li>val ssc=StreamingContext.getOrCreate(checkpointPath,MycreatingFunc)尝试创建StreamingContext时，==先去checkpointPath里找，看看有没有Driver的元数据信息，没有的话就根据MycreatingFunc方法来获取一个StreamingContext==</li> <li>然后程序开始运行，运行时会把之前的批次的数据缓存到checkpointPath，还会Driver的信息一并存下来。</li> <li>如果程序中途停掉后，再次启动，依然会先去checkpointPath里找，看看有没有Driver的元数据信息，有就根据这些信息重启Driver，运行任务也会接着上次的进度来运行。</li></ol></blockquote> <h2 id="sparkstreaming和sparksql整合"><a href="#sparkstreaming和sparksql整合" class="header-anchor">#</a> SparkStreaming和SparkSQL整合</h2> <h5 id="为什么整合"><a href="#为什么整合" class="header-anchor">#</a> 为什么整合？</h5> <img src="sparkstreaming.assets/image-20200424040141974.png"> <h5 id="代码开发-2"><a href="#代码开发-2" class="header-anchor">#</a> 代码开发</h5> <p>pom.xml里面添加</p> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-sql_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.3.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><p>代码开发</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>kaikeba<span class="token punctuation">.</span>streaming</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Level<span class="token punctuation">,</span> Logger<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span>SparkConf
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{</span>DataFrame<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token punctuation">{</span>DStream<span class="token punctuation">,</span> ReceiverInputDStream<span class="token punctuation">}</span>

<span class="token comment">/**
  * sparkStreaming整合sparksql
  */</span>
<span class="token keyword">object</span> SocketWordCountForeachRDDDataFrame <span class="token punctuation">{</span>

  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    Logger<span class="token punctuation">.</span>getLogger<span class="token punctuation">(</span><span class="token string">&quot;org&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setLevel<span class="token punctuation">(</span>Level<span class="token punctuation">.</span>ERROR<span class="token punctuation">)</span>

    <span class="token comment">// todo: 1、创建SparkConf对象</span>
    <span class="token keyword">val</span> sparkConf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;NetworkWordCountForeachRDDDataFrame&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">// todo: 2、创建StreamingContext对象</span>
    <span class="token keyword">val</span> ssc <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//todo: 3、接受socket数据</span>
    <span class="token keyword">val</span> socketTextStream<span class="token operator">:</span> ReceiverInputDStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> ssc<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">&quot;node01&quot;</span><span class="token punctuation">,</span><span class="token number">9999</span><span class="token punctuation">)</span>

    <span class="token comment">//todo: 4、对数据进行处理</span>
    <span class="token keyword">val</span> words<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> socketTextStream<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//todo: 5、对DStream进行处理，将RDD转换成DataFrame</span>
      words<span class="token punctuation">.</span>foreachRDD<span class="token punctuation">(</span>rdd<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>

          <span class="token comment">//获取得到sparkSessin，由于将RDD转换成DataFrame需要用到SparkSession对象</span>
        <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>config<span class="token punctuation">(</span>rdd<span class="token punctuation">.</span>sparkContext<span class="token punctuation">.</span>getConf<span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_
        <span class="token keyword">val</span> dataFrame<span class="token operator">:</span> DataFrame <span class="token operator">=</span> rdd<span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token string">&quot;word&quot;</span><span class="token punctuation">)</span>

        <span class="token comment">//将dataFrame注册成表</span>
         dataFrame<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">&quot;words&quot;</span><span class="token punctuation">)</span>

        <span class="token comment">//统计每个单词出现的次数</span>
         <span class="token keyword">val</span> result<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select word,count(*) as count from words group by word&quot;</span><span class="token punctuation">)</span>

         <span class="token comment">//展示结果</span>
        result<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

      <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment">//todo: 6、开启流式计算</span>
    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>


  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><h2 id="sparkstreaming容错"><a href="#sparkstreaming容错" class="header-anchor">#</a> SparkStreaming容错</h2> <h4 id="sparkstreaming运行流程回顾"><a href="#sparkstreaming运行流程回顾" class="header-anchor">#</a> SparkStreaming运行流程回顾</h4> <p><img src="/assets/img/1567414277097-1584924072316-1608485794545.5a6af600.png" alt="1567414277097"></p> <h4 id="executor失败"><a href="#executor失败" class="header-anchor">#</a> Executor失败</h4> <blockquote><p>在==Receiver接收到了数据之后，会将数据复制一份到其它的Executor的内存中==。</p> <p>比如，在使用ssc.socketTextStream(&quot;node01&quot;,9999)接收数据时，默认会将数据复制一份到其它的Executor内存中，是因为该方法有一个缺省参数：storageLevel=StorageLevel.MEMORY_AND_DISK_2。</p> <p>在两台机器的内存中，==如果一台机器上的Executor挂了，立即切换到另一台机器上的Executor，这种方式一般情况下非常可靠且没有切换时间==。</p> <p>Tasks和Receiver自动的重启，不需要做任何的配置</p> <img src="sparkstreaming.assets/1567414655887-1584924078479.png"></blockquote> <h4 id="driver失败"><a href="#driver失败" class="header-anchor">#</a> Driver失败</h4> <p><img src="/assets/img/1567414739556-1584924084233-1608485794545.a8320463.png" alt="1567414739556"></p> <p>用checkpoint机制恢复失败的Driver。每个Job生成之前进行checkpoint，在Job生成之后再进行checkpoint，如果出错的话就从checkpoint中恢复。</p> <p>定期的将Driver信息写入到HDFS中。</p> <p><img src="/assets/img/1567414846715-1584924092832-1608485794545.f2b16e22.png" alt="1567414846715"></p> <h6 id="步骤一-设置自动重启driver程序"><a href="#步骤一-设置自动重启driver程序" class="header-anchor">#</a> 步骤一：设置自动重启Driver程序</h6> <p><strong>Standalone：</strong></p> <div class="language-shell extra-class"><pre class="language-shell"><code>在spark-submit中增加以下两个参数：
--deploy-mode cluster
--supervise <span class="token comment">#失败后是否重启Driver</span>

使用示例：
spark-submit <span class="token punctuation">\</span>
--master spark://node01:7077 <span class="token punctuation">\</span>
--deploy-mode cluster <span class="token punctuation">\</span>
--supervise <span class="token punctuation">\</span>
--class com.kaikeba.streaming.Demo <span class="token punctuation">\</span>
--executor-memory 1g <span class="token punctuation">\</span>
--total-executor-cores <span class="token number">2</span> <span class="token punctuation">\</span>
original-sparkStreamingStudy-1.0-SNAPSHOT.jar 
</code></pre></div><p><strong>Yarn：</strong></p> <div class="language-shell extra-class"><pre class="language-shell"><code>在spark-submit中增加以下参数：
--deploy-mode cluster
在yarn配置中设置yarn.resourcemanager.am.max-attemps参数 ,默认为2，表示允许Driver挂掉之后重启的允许失败的次数，例如：

<span class="token operator">&lt;</span>property<span class="token operator">&gt;</span>
  <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>yarn.resourcemanager.am.max-attempts<span class="token operator">&lt;</span>/name<span class="token operator">&gt;</span>
  <span class="token operator">&lt;</span>value<span class="token operator">&gt;</span><span class="token operator"><span class="token file-descriptor important">4</span>&lt;</span>/value<span class="token operator">&gt;</span>  
  <span class="token operator">&lt;</span>description<span class="token operator">&gt;</span>
    The maximum number of application master execution attempts.
  <span class="token operator">&lt;</span>/description<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/property<span class="token operator">&gt;</span>


使用示例：
spark-submit <span class="token punctuation">\</span>
--master <span class="token function">yarn</span> <span class="token punctuation">\</span>
--deploy-mode cluster <span class="token punctuation">\</span>
--class com.kaikeba.streaming.Demo <span class="token punctuation">\</span>
--executor-memory 1g <span class="token punctuation">\</span>
--total-executor-cores <span class="token number">2</span> <span class="token punctuation">\</span>
original-sparkStreamingStudy-1.0-SNAPSHOT.jar 
</code></pre></div><blockquote><p>提交后，==Driver的进程名称是DriverWrapper==</p> <p><img src="/assets/img/image-20200424042337680-1608485794545.2a3408cf.png" alt="image-20200424042337680"></p> <p>在后面若想要测试Driver挂掉后的重启时，可以通过kill -9将Driver程序停掉。</p></blockquote> <h6 id="步骤二-设置hdfs的checkpoint目录"><a href="#步骤二-设置hdfs的checkpoint目录" class="header-anchor">#</a> 步骤二：设置HDFS的checkpoint目录</h6> <div class="language-scala extra-class"><pre class="language-scala"><code>streamingContext<span class="token punctuation">.</span>setCheckpoint<span class="token punctuation">(</span>hdfsDirectory<span class="token punctuation">)</span> 
</code></pre></div><h6 id="步骤三-代码实现"><a href="#步骤三-代码实现" class="header-anchor">#</a> 步骤三：代码实现</h6> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">// Function to create and setup a new StreamingContext</span>
<span class="token keyword">def</span> functionToCreateContext<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> StreamingContext <span class="token operator">=</span> <span class="token punctuation">{</span>
  <span class="token keyword">val</span> ssc <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>   <span class="token comment">// new context</span>
  <span class="token keyword">val</span> lines <span class="token operator">=</span> ssc<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token comment">// create DStreams</span>
  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
  ssc<span class="token punctuation">.</span>checkpoint<span class="token punctuation">(</span>checkpointDirectory<span class="token punctuation">)</span>   <span class="token comment">// set checkpoint directory</span>
  ssc
<span class="token punctuation">}</span>

<span class="token comment">// Get StreamingContext from checkpoint data or create a new one</span>
<span class="token keyword">val</span> context <span class="token operator">=</span> StreamingContext<span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span>checkpointDirectory<span class="token punctuation">,</span> functionToCreateContext _<span class="token punctuation">)</span>

<span class="token comment">// Do additional setup on context that needs to be done,</span>
<span class="token comment">// irrespective of whether it is being started or restarted</span>
context<span class="token punctuation">.</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

<span class="token comment">// Start the context</span>
context<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
context<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="数据丢失如何处理"><a href="#数据丢失如何处理" class="header-anchor">#</a> 数据丢失如何处理</h4> <blockquote><p>利用WAL把数据写入到HDFS中</p> <img src="sparkstreaming.assets/1567415902458.png"> <p>步骤一：设置checkpoint目录</p> <div class="language-scala extra-class"><pre class="language-scala"><code>streamingContext<span class="token punctuation">.</span>setCheckpoint<span class="token punctuation">(</span>hdfsDirectory<span class="token punctuation">)</span>
</code></pre></div><p>步骤二：开启WAL日志</p> <div class="language- extra-class"><pre class="language-text"><code>sparkConf.set(&quot;spark.streaming.receiver.writeAheadLog.enable&quot;, &quot;true&quot;)
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>WAL使用在文件系统和数据库中用于数据操作的持久性，先把数据写到一个持久化的日志中，然后对数据做操作，如果操作过程中系统挂了，恢复的时候可以重新读取日志文件再次进行操作。

对于像kafka和flume这些使用接收器来接收数据的数据源。接收器作为一个长时间的任务运行在executor中，负责从数据源接收数据，如果数据源支持的话，向数据源确认接收到数据，然后把数据存储在executor的内存中，然后在exector上运行任务处理这些数据。

如果wal启用了，所有接收到的数据会保存到一个日志文件中去（HDFS), 这样保存接收数据的持久性，此外，如果只有在数据写入到log中之后接收器才向数据源确认，这样driver重启后那些保存在内存中但是没有写入到log中的数据将会重新发送，这两点保证的数据的无丢失。
</code></pre></div><p>步骤三：需要reliable receiver</p> <p>==如果Receiver接收到数据后，备份到HDFS或磁盘中的数据也丢失了，这时候怎么办？这时候我们就需要一个可靠的数据源了，何为可靠？可靠就是如果我数据丢失了，我依然能够重新去数据源获取数据。==</p> <p>比如==Kafka就可以实现这个==，kafka可以记住消费数据的偏移量offset。</p> <div class="language- extra-class"><pre class="language-text"><code>当数据写完了WAL后，才告诉数据源数据已经消费，对于没有告诉数据源的数据，可以从数据源中重新消费数据
</code></pre></div><p>步骤四：取消备份</p> <p>开启了WAL日志后，可以把storageLevel设为StorageLevel.MEMORY_AND_DISK了。</p> <div class="language- extra-class"><pre class="language-text"><code>使用StorageLevel.MEMORY_AND_DISK_SER来存储数据源，不需要后缀为2的策略了，因为HDFS已经是多副本了。
</code></pre></div><p><img src="/assets/img/1567416495877-1608485794545.1417b123.png" alt="1567416495877"></p> <div class="language- extra-class"><pre class="language-text"><code>Reliable Receiver   : 当数据接收到，并且已经备份存储后，再发送回执给数据源
Unreliable Receiver : 不发送回执给数据源
</code></pre></div></blockquote> <h4 id="当一个task很慢容错"><a href="#当一个task很慢容错" class="header-anchor">#</a> 当一个task很慢容错</h4> <p><img src="/assets/img/1567417919912-1608485794545.3d4219f6.png" alt="1567417919912"></p> <p>开启推测机制：</p> <ol><li>设置spark.speculation=true后，会开启推测机制，每隔一段时间来检查有哪些正在运行的task需要重新调度，时间间隔默认为：spark.speculation.interval=100ms。</li> <li>假设总的task有10个，成功的task的数量 &gt; 0.75 * 10（spark.speculation.quantile=0.75），且正在运行的task的运行时间 &gt; 1.5 * 成功运行task的平均时间（spark.speculation.multiplier=1.5），则这个正在运行的task需要重新等待调度。</li> <li>开启其它的task来运行这些task,此时会有多个task同时做着同样的任务，谁先完成就用谁的。</li></ol> <p><img src="/assets/img/Task推测机制-1608485794545.4bc9a959.png" alt="Task推测机制"></p> <p>注意：</p> <p>在分布式环境中导致某个Task执行缓慢的情况有很多，负载不均、程序bug、资源不均、数据倾斜等，而且这些情况在分布式任务计算环境中是常态。==Speculative Task这种以空间换时间的思路对计算资源是种压榨，同时如果Speculative Task本身也变成了Slow Task会导致情况进一步恶化==。</p> <h2 id="sparkstreaming语义"><a href="#sparkstreaming语义" class="header-anchor">#</a> SparkStreaming语义</h2> <p>有三种语义：</p> <div class="language- extra-class"><pre class="language-text"><code>(1) At most once  一条记录要么被处理一次，要么没有被处理

(2) At least once 一条记录可能被处理一次或者多次，可能会重复处理

(3) Exactly once 一条记录只被处理一次
</code></pre></div><h2 id="sparkstreaming与kafka整合"><a href="#sparkstreaming与kafka整合" class="header-anchor">#</a> SparkStreaming与Kafka整合</h2> <p>SparkStreaming整合Kafka官方文档：http://spark.apache.org/docs/2.3.3/streaming-kafka-integration.html</p> <p>Kafka在0.8和0.10（1.0）版本提供了新的消费者Api,可以进行与sparkStreaming的整合。0.8版本的已经过时了，而且在spark在2.3.0版本后，已经不再支持kafka 0.8。</p> <p>对于spark-streaming-kafka-0-8，支持Receiver Dstream和Direct Dstream(直连)</p> <p>对于spark-streaming-kafka-0-10，不再支持Receiver Dstream了。</p> <p><img src="/assets/img/image-20200424142427376-1608485794545.3b646446.png" alt="image-20200424142427376"></p> <p>因为我们使用的是kafka 1.0，spark 2.3.3,所以选择spark-streaming-kafka-0-10。</p> <p>点击spark-streaming-kafka-0-10，查看整合方式，如下，只需要添加依赖即可。</p> <p><img src="/assets/img/image-20200424143312397-1608485794545.0a5a9a90.png" alt="image-20200424143312397"></p> <p>kafka-0.8: 默认消费消息的偏移量是保存在zk集群上，默认自动提交偏移量到zk上</p> <p>kafka-0.10：默认消费消息的偏移量是保存在kafka集群内置的topic中，默认自动提交偏移量到kafka集群上</p> <h2 id="整合案例1-sparkstreaming与kafka-0-8-receiver-不推荐"><a href="#整合案例1-sparkstreaming与kafka-0-8-receiver-不推荐" class="header-anchor">#</a> 整合案例1：sparkStreaming与Kafka-0-8(Receiver) 不推荐</h2> <blockquote><p>此方法使用Receiver接收数据。==Receiver是使用Kafka高级消费者API实现的==。与所有接收器一样，从Kafka通过Receiver接收的数据存储在Spark执行器中，然后由Spark Streaming启动的作业处理数据。</p> <p>但是在默认配置下，此方法可能会在失败时丢失数据（请参阅<a href="http://spark.apache.org/docs/2.3.3/streaming-programming-guide.html#receiver-reliability" target="_blank" rel="noopener noreferrer">接收器可靠性<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>）。</p> <p><img src="/assets/img/image-20200424154359505-1608485794545.f66632ba.png" alt="image-20200424154359505"></p> <p>==为确保零数据丢失，必须在Spark Streaming中另外启用Write Ahead Logs==（在Spark 1.2中引入）。这将同步保存所有收到的Kafka将数据写入分布式文件系统（例如HDFS）上的预写日志，以便在发生故障时可以恢复所有数据，但是==性能不好==。</p> <p>==性能不好的原因：==</p> <ol><li>Receiver只是一个线程，只是用一个Receiver去消费kafka一个topic的多个分区的数据，无疑是压力很大的。</li> <li>WAL预写日志需要将数据写入到HDFS中，性能也会受到影响。</li></ol> <p>==Receiver-Based Approach示意图：==</p> <p><img src="/assets/img/image-20200424170120758-1608485794545.0f8715ff.png" alt="image-20200424170120758"></p></blockquote> <h5 id="第一步-添加pom依赖"><a href="#第一步-添加pom依赖" class="header-anchor">#</a> 第一步：添加pom依赖：</h5> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-streaming-kafka-0-8_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.3.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>        
</code></pre></div><h5 id="第二步-启动kafka集群及创建topic"><a href="#第二步-启动kafka集群及创建topic" class="header-anchor">#</a> 第二步：启动kafka集群及创建topic</h5> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token punctuation">[</span>hadoop@node01 ~<span class="token punctuation">]</span>$ <span class="token function">sh</span> bin/kafkaCluster.sh start
<span class="token punctuation">[</span>hadoop@node01 ~<span class="token punctuation">]</span>$ kafka-topics.sh --create --partitions <span class="token number">3</span> --replication-factor <span class="token number">2</span> --topic KStreaming --zookeeper node01:2181,node02:2181,node03:2181
</code></pre></div><h5 id="第三步-开发程序"><a href="#第三步-开发程序" class="header-anchor">#</a> 第三步：开发程序：</h5> <p>核心代码：</p> <div class="language-scala extra-class"><pre class="language-scala"><code> <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span>_

 <span class="token keyword">val</span> kafkaStream <span class="token operator">=</span> KafkaUtils<span class="token punctuation">.</span>createStream<span class="token punctuation">(</span>streamingContext<span class="token punctuation">,</span>
     <span class="token punctuation">[</span>ZK quorum<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>consumer group id<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>per<span class="token operator">-</span>topic number of Kafka partitions to <span class="token namespace">consume</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p>代码开发：sparkStreaming使用kafka 0.8API基于recevier来接受消息</p> <p>0.8 的kafka的offset是保存在zookeeper集群上的。所以要指定zookeeper集群地址。</p> <p>注意：Kafka中的topic的partition，与Spark中的RDD的partition是没有关系的。所以，在KafkaUtils.createStream()中，提高partition的数量，==只会在Receiver中增加一个读取partition的线程的数量。不会增加Spark处理数据的并行度==。如：val topics=Map(&quot;KStreaming&quot;-&gt;1)</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Level<span class="token punctuation">,</span> Logger<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token punctuation">{</span>DStream<span class="token punctuation">,</span> ReceiverInputDStream<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span>KafkaUtils
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> KafkaStreaming <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    Logger<span class="token punctuation">.</span>getLogger<span class="token punctuation">(</span><span class="token string">&quot;org&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setLevel<span class="token punctuation">(</span>Level<span class="token punctuation">.</span>ERROR<span class="token punctuation">)</span>
    <span class="token keyword">val</span> conf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>set<span class="token punctuation">(</span><span class="token string">&quot;spark.streaming.receiver.writeAheadLog.enable&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> ssc<span class="token operator">=</span><span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sc<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    ssc<span class="token punctuation">.</span>checkpoint<span class="token punctuation">(</span><span class="token string">&quot;hdfs://node01:8020/ckKafka&quot;</span><span class="token punctuation">)</span>  <span class="token comment">//WAL预写日志，将数据写到HDFS上</span>

    <span class="token comment">//接收kafka数据</span>
    <span class="token keyword">val</span> zkQuorum<span class="token operator">=</span><span class="token string">&quot;node01:2181,node02:2181,node03:2181&quot;</span>
    <span class="token keyword">val</span> groupId<span class="token operator">=</span><span class="token string">&quot;g1&quot;</span>
    <span class="token keyword">val</span> topics<span class="token operator">=</span>Map<span class="token punctuation">(</span><span class="token string">&quot;KStreaming&quot;</span><span class="token operator">-&gt;</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment">//1代表给定1个线程去消费数据</span>
    <span class="token keyword">val</span> data<span class="token operator">:</span>ReceiverInputDStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>
      KafkaUtils<span class="token punctuation">.</span>createStream<span class="token punctuation">(</span>ssc<span class="token punctuation">,</span>zkQuorum<span class="token punctuation">,</span>groupId<span class="token punctuation">,</span>topics<span class="token punctuation">)</span>

    <span class="token comment">//获取接收到的topic数据的value(不需要key)</span>
    <span class="token keyword">val</span> data2<span class="token operator">:</span>DStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token operator">=</span>data<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>
    <span class="token keyword">val</span> result<span class="token operator">=</span>data2<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>

    result<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><h5 id="第四步-运行程序-往topic生成数据"><a href="#第四步-运行程序-往topic生成数据" class="header-anchor">#</a> 第四步：运行程序，往topic生成数据</h5> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token punctuation">[</span>hadoop@node01 ~<span class="token punctuation">]</span>$ kafka-console-producer.sh --broker-list node01:9092,node02:9092,node03:9092 --topic KStreaming

<span class="token operator">&gt;</span>hadoop hadoop flink
<span class="token operator">&gt;</span>hadoop spark
</code></pre></div><p>查看IDEA输出信息：</p> <div class="language- extra-class"><pre class="language-text"><code>-------------------------------------------
Time: 1587715986000 ms
-------------------------------------------
(flink,1)
(hadoop,2)
-------------------------------------------
Time: 1587715996000 ms
-------------------------------------------
(spark,1)
(hadoop,1)
</code></pre></div><h2 id="direct介绍-推荐"><a href="#direct介绍-推荐" class="header-anchor">#</a> Direct介绍(推荐)</h2> <blockquote><p>这种新的不基于Receiver的直接方式，是在Spark 1.3中引入的，从而能够确保更加健壮的机制。</p> <p>替代掉使用Receiver来接收数据后，这种方式==会周期性地查询Kafka，来获得每个topic+partition的最新的offset，从而定义每个batch的offset的范围==。</p> <p>==当处理数据的job启动时，就会使用Kafka的简单consumer api来获取Kafka指定offset范围的数据。==</p> <p>Direct Approach示意图：</p> <img src="sparkstreaming.assets/image-20200424164335533.png"> <p>这种方式有如下优点：</p> <p>1、简化并行读取：</p> <p>如果要读取多个partition，不需要创建多个输入DStream然后对它们进行union操作。Spark会创建跟Kafka partition一样多的RDD partition，并且会并行从Kafka中读取数据。所以在==Kafka partition和RDD partition之间，有一个一对一的映射关系==。</p> <p>2、高性能</p> <p>如果要保证零数据丢失，在基于receiver的方式中，需要开启WAL机制。这种方式其实效率低下，因为数据实际上被复制了两份，Kafka自己本身就有高可靠的机制，会对数据复制一份，而这里又会复制一份到WAL中。==而基于direct的方式，不依赖Receiver，不需要开启WAL机制，只要Kafka中作了数据的复制，那么就可以通过Kafka的副本进行恢复。==</p> <p>3、一次且仅一次的事务机制</p> <p>基于receiver的方式，是使用Kafka的高阶API来在ZooKeeper中保存消费过的数据的offset的。这是消费Kafka数据的传统方式。基于receiver的方式配合着WAL机制可以保证数据零丢失的高可靠性，但是==却无法保证数据被处理一次且仅一次==，可能会处理两次。因为==Spark和ZooKeeper之间可能是不同步的，比如说已经被处理的数据，如果自动提交偏移量失败，则会导致重复处理数据==。</p> <p>使用Direct方式的话，是自己去管理偏移量+幂等/事务来实现exactly-once语义。</p> <p>4、降低资源</p> <p>==Direct不需要Receivers，其申请的Executors全部参与到计算任务中==；而Receiver-based则需要专门的Receivers来读取Kafka数据且不参与计算。因此相同的资源申请，Direct 能够支持更大的业务。</p> <p>5、降低内存</p> <p>==Receiver-based的Receiver与其他Exectuor是异步的==，并持续不断接收数据，对于小业务量的场景还好，如果遇到大业务量时，需要提高Receiver的内存，但是参与计算的Executor并无需那么多的内存。而Direct 因为没有Receiver，而是在计算时读取数据，然后直接计算，所以对内存的要求很低。实际应用中我们可以把原先的10G降至现在的2-4G左右。</p> <p>6、鲁棒性更好</p> <p>Receiver-based方法需要Receivers来异步持续不断的读取数据，因此遇到网络、存储负载等因素，导致实时任务出现堆积，但Receivers却还在持续读取数据，此种情况很容易导致计算崩溃。==Direct 则没有这种顾虑，其Driver在触发batch计算任务时，才会读取数据并计算。队列出现堆积并不会引起程序的失败。==</p></blockquote> <h2 id="整合案例2-sparkstreaming与kafka-0-8-direct"><a href="#整合案例2-sparkstreaming与kafka-0-8-direct" class="header-anchor">#</a> 整合案例2：SparkStreaming与Kafka-0-8(Direct)</h2> <ul><li><p>支持0.8版本，或者更高的版本</p></li> <li><p>pom.xml文件添加内容如下：</p></li></ul> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-streaming-kafka-0-8_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.3.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>  
</code></pre></div><p>代码演示：</p> <ul><li>sparkStreaming使用kafka 0.8API基于Direct直连来接受消息</li> <li>spark direct API接收kafka消息，从而不需要经过zookeeper，直接从broker上获取信息。</li></ul> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>jimmy<span class="token punctuation">.</span>streaming</span>

<span class="token keyword">import</span> <span class="token namespace">kafka<span class="token punctuation">.</span>serializer<span class="token punctuation">.</span></span>StringDecoder
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Level<span class="token punctuation">,</span> Logger<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token punctuation">{</span>DStream<span class="token punctuation">,</span> InputDStream<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span>KafkaUtils
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> KafkaStreaming <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    Logger<span class="token punctuation">.</span>getLogger<span class="token punctuation">(</span><span class="token string">&quot;org&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setLevel<span class="token punctuation">(</span>Level<span class="token punctuation">.</span>ERROR<span class="token punctuation">)</span>
    <span class="token keyword">val</span> conf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> ssc<span class="token operator">=</span><span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sc<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>checkpoint<span class="token punctuation">(</span><span class="token string">&quot;hdfs://node01:8020/ckKafka&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">//接收kafka数据</span>
    <span class="token keyword">val</span> kafkaParams<span class="token operator">=</span>Map<span class="token punctuation">(</span>
      <span class="token string">&quot;metadata.broker.list&quot;</span><span class="token operator">-&gt;</span><span class="token string">&quot;node01:9092,node02:9092,node03:9092&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;group.id&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;g1&quot;</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">val</span> topics<span class="token operator">=</span>Set<span class="token punctuation">(</span><span class="token string">&quot;KStreaming&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> data<span class="token operator">:</span>InputDStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>KafkaUtils<span class="token punctuation">.</span>createDirectStream<span class="token punctuation">[</span>
      <span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">,</span>StringDecoder<span class="token punctuation">,</span>StringDecoder<span class="token punctuation">]</span><span class="token punctuation">(</span>ssc<span class="token punctuation">,</span>kafkaParams<span class="token punctuation">,</span>topics<span class="token punctuation">)</span>
      <span class="token comment">//千万不要导错StringDecoder所在的包</span>

    <span class="token comment">//获取接收到的topic数据的value(不需要key)</span>
    <span class="token keyword">val</span> data2<span class="token operator">:</span>DStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token operator">=</span>data<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>
    <span class="token keyword">val</span> result<span class="token operator">=</span>data2<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>

    result<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>运行sparkStreaming程序，启动生产者，往topic写数据：</p> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token punctuation">[</span>hadoop@node01 ~<span class="token punctuation">]</span>$ kafka-console-producer.sh --broker-list node01:9092,node02:9092,node03:9092 --topic KStreaming
</code></pre></div><p>要想保证数据不丢失，最简单的就是靠checkpoint的机制，但是==checkpoint机制有个特点，如果代码升级了，checkpoint机制就失效了。所以如果想实现数据不丢失，那么就需要自己管理offset==。</p> <h2 id="整合案例3-sparkstreaming与kafka-0-10-direct"><a href="#整合案例3-sparkstreaming与kafka-0-10-direct" class="header-anchor">#</a> 整合案例3：SparkStreaming与Kafka-0-10(Direct)</h2> <ul><li><p>支持0.10版本，或者更高的版本（推荐使用这个版本）</p></li> <li><p>pom.xml文件添加内容如下：</p></li></ul> <div class="language-xml extra-class"><pre class="language-xml"><code>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-streaming-kafka-0-10_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.3.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><ul><li>代码演示：</li></ul> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span>ConsumerRecord
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span>StringDeserializer
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Level<span class="token punctuation">,</span> Logger<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token punctuation">{</span>InputDStream<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>kafka010<span class="token punctuation">.</span></span><span class="token punctuation">{</span>CanCommitOffsets<span class="token punctuation">,</span> ConsumerStrategies<span class="token punctuation">,</span> HasOffsetRanges<span class="token punctuation">,</span> KafkaUtils<span class="token punctuation">,</span> LocationStrategies<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> KafkaStreaming <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    Logger<span class="token punctuation">.</span>getLogger<span class="token punctuation">(</span><span class="token string">&quot;org&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setLevel<span class="token punctuation">(</span>Level<span class="token punctuation">.</span>ERROR<span class="token punctuation">)</span>
    <span class="token keyword">val</span> conf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> ssc<span class="token operator">=</span><span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sc<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//接收kafka数据</span>
    <span class="token keyword">val</span> kafkaParams<span class="token operator">=</span>Map<span class="token punctuation">(</span>
      <span class="token string">&quot;bootstrap.servers&quot;</span> <span class="token operator">-&gt;</span><span class="token string">&quot;node01:9092,node02:9092,node03:9092&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;group.id&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;g1&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;key.deserializer&quot;</span> <span class="token operator">-&gt;</span> classOf<span class="token punctuation">[</span>StringDeserializer<span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token string">&quot;value.deserializer&quot;</span> <span class="token operator">-&gt;</span> classOf<span class="token punctuation">[</span>StringDeserializer<span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token string">&quot;enable.auto.commit&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;false&quot;</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">val</span> topic<span class="token operator">=</span>Set<span class="token punctuation">(</span><span class="token string">&quot;KStreaming&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> data<span class="token operator">:</span>InputDStream<span class="token punctuation">[</span>ConsumerRecord<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">=</span>
      KafkaUtils<span class="token punctuation">.</span>createDirectStream<span class="token punctuation">(</span>
      ssc<span class="token punctuation">,</span>
      LocationStrategies<span class="token punctuation">.</span>PreferConsistent<span class="token punctuation">,</span>
      ConsumerStrategies<span class="token punctuation">.</span>Subscribe<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span>kafkaParams<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//获取接收到的topic数据的value(不需要key)</span>
    data<span class="token punctuation">.</span>foreachRDD<span class="token punctuation">(</span>rdd<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
      <span class="token keyword">val</span> dataRDD<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token operator">=</span>rdd<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>value<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      dataRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>line<span class="token keyword">=&gt;</span>println<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token comment">//获取偏移量并提交到kafka中</span>
      <span class="token keyword">val</span> offsetRange<span class="token operator">=</span>rdd<span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>HasOffsetRanges<span class="token punctuation">]</span><span class="token punctuation">.</span>offsetRanges
      data<span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>CanCommitOffsets<span class="token punctuation">]</span><span class="token punctuation">.</span>commitAsync<span class="token punctuation">(</span>offsetRange<span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><h2 id="解决sparkstreaming与kafka0-8版本整合数据丢失问题"><a href="#解决sparkstreaming与kafka0-8版本整合数据丢失问题" class="header-anchor">#</a> 解决SparkStreaming与Kafka0.8版本整合数据丢失问题</h2> <p>一般对于企业来说，无论是使用哪一套api去消费kafka的数据，都是设置手动提交偏移量。</p> <p>如果是自动提交偏移量（默认60s提交一次）这里可能会出现问题：</p> <p>（1）数据处理失败了，自动提交的偏移量，会出现数据的丢失。</p> <p>（2）数据处理成功了，自动提交偏移量失败，会出现数据的重复处理。</p> <p>自动提交偏移量的风险比较高，一般都使用手动提交偏移量，这里我们可以操作什么时候去提交偏移量，==把偏移量的提交交给消费者程序自己去维护==。</p> <p>方案设计如下：</p> <p><img src="/assets/img/kafka08SaveOffset2ZK-1608485794545.64dd9c48.png" alt="kafka08SaveOffset2ZK"></p> <p>代码开发，手动把偏移量存入Zookeeper，解决数据丢失问题。</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>kaikeba<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>kafka</span>

<span class="token keyword">import</span> <span class="token namespace">kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span></span>TopicAndPartition
<span class="token keyword">import</span> <span class="token namespace">kafka<span class="token punctuation">.</span>message<span class="token punctuation">.</span></span>MessageAndMetadata
<span class="token keyword">import</span> <span class="token namespace">kafka<span class="token punctuation">.</span>serializer<span class="token punctuation">.</span></span>StringDecoder
<span class="token keyword">import</span> <span class="token namespace">kafka<span class="token punctuation">.</span>utils<span class="token punctuation">.</span></span><span class="token punctuation">{</span>ZKGroupTopicDirs<span class="token punctuation">,</span> ZkUtils<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span></span>I0Itec<span class="token punctuation">.</span>zkclient<span class="token punctuation">.</span>ZkClient
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span>SparkConf
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span>InputDStream
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token punctuation">{</span>HasOffsetRanges<span class="token punctuation">,</span> KafkaUtils<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>


<span class="token comment">/**
  * 使用直连方式 SparkStreaming连接kafka0.8获取数据
  * 手动将偏移量数据保存到zookeeper中
  */</span>
<span class="token keyword">object</span> KafkaManagerOffset08 <span class="token punctuation">{</span>

  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>

    <span class="token comment">//todo:1、创建SparkConf 提交到集群中运行 不要设置master参数</span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;KafkaManagerOffset08&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[4]&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">//todo: 2、设置SparkStreaming，并设定间隔时间</span>
    <span class="token keyword">val</span> ssc <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>conf<span class="token punctuation">,</span> Seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//todo:3、指定相关参数</span>

        <span class="token comment">//指定组名</span>
        <span class="token keyword">val</span> groupID <span class="token operator">=</span> <span class="token string">&quot;consumer-kaikeba&quot;</span>
        <span class="token comment">//指定消费者的topic名字</span>
        <span class="token keyword">val</span> topic <span class="token operator">=</span> <span class="token string">&quot;wordcount&quot;</span>
        <span class="token comment">//指定kafka的broker地址</span>
        <span class="token keyword">val</span> brokerList <span class="token operator">=</span> <span class="token string">&quot;node01:9092,node02:9092,node03:9092&quot;</span>

        <span class="token comment">//指定zookeeper的地址，用来存放数据偏移量数据，也可以使用Redis MySQL等</span>
        <span class="token keyword">val</span> zkQuorum <span class="token operator">=</span> <span class="token string">&quot;node01:2181,node02:2181,node03:2181&quot;</span>

        <span class="token comment">//创建Stream时使用的topic名字集合，SparkStreaming可同时消费多个topic</span>
        <span class="token keyword">val</span> topics<span class="token operator">:</span> Set<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Set<span class="token punctuation">(</span>topic<span class="token punctuation">)</span>

        <span class="token comment">//创建一个 ZKGroupTopicDirs 对象，就是用来指定在zk中的存储目录，用来保存数据偏移量</span>
        <span class="token keyword">val</span> topicDirs <span class="token operator">=</span> <span class="token keyword">new</span> ZKGroupTopicDirs<span class="token punctuation">(</span>groupID<span class="token punctuation">,</span> topic<span class="token punctuation">)</span>

        <span class="token comment">//获取 zookeeper 中的路径 &quot;/consumers/consumer-kaikeba/offsets/wordcount&quot;</span>
        <span class="token keyword">val</span> zkTopicPath <span class="token operator">=</span> topicDirs<span class="token punctuation">.</span>consumerOffsetDir

        <span class="token comment">//构造一个zookeeper的客户端 用来读写偏移量数据</span>
        <span class="token keyword">val</span> zkClient <span class="token operator">=</span> <span class="token keyword">new</span> ZkClient<span class="token punctuation">(</span>zkQuorum<span class="token punctuation">)</span>

        <span class="token comment">//准备kafka的参数</span>
        <span class="token keyword">val</span> kafkaParams <span class="token operator">=</span> Map<span class="token punctuation">(</span>
          <span class="token string">&quot;metadata.broker.list&quot;</span> <span class="token operator">-&gt;</span> brokerList<span class="token punctuation">,</span>
          <span class="token string">&quot;group.id&quot;</span> <span class="token operator">-&gt;</span> groupID<span class="token punctuation">,</span>
          <span class="token string">&quot;enable.auto.commit&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;false&quot;</span>
        <span class="token punctuation">)</span>


    <span class="token comment">//todo:4、定义kafkaStream流</span>
    <span class="token keyword">var</span> kafkaStream<span class="token operator">:</span> InputDStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span>


    <span class="token comment">//todo:5、获取指定的zk节点的子节点个数</span>
    <span class="token keyword">val</span> childrenNum <span class="token operator">=</span> getZkChildrenNum<span class="token punctuation">(</span>zkClient<span class="token punctuation">,</span>zkTopicPath<span class="token punctuation">)</span>


    <span class="token comment">//todo:6、判断是否保存过数据 根据子节点的数量是否为0</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>childrenNum <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>

      <span class="token comment">//构造一个map集合用来存放数据偏移量信息</span>
      <span class="token keyword">var</span> fromOffsets<span class="token operator">:</span> Map<span class="token punctuation">[</span>TopicAndPartition<span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span> <span class="token operator">=</span> Map<span class="token punctuation">(</span><span class="token punctuation">)</span>

      <span class="token comment">//遍历子节点</span>
      <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token keyword">&lt;-</span> <span class="token number">0</span> until childrenNum<span class="token punctuation">)</span> <span class="token punctuation">{</span>

        <span class="token comment">//获取子节点  /consumers/consumer-kaikeba/offsets/wordcount/0</span>
        <span class="token keyword">val</span> partitionOffset<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> zkClient<span class="token punctuation">.</span>readData<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>s<span class="token string">&quot;$zkTopicPath/$i&quot;</span><span class="token punctuation">)</span>
        <span class="token comment">// /wordcount-----0</span>
        <span class="token keyword">val</span> tp <span class="token operator">=</span> TopicAndPartition<span class="token punctuation">(</span>topic<span class="token punctuation">,</span> i<span class="token punctuation">)</span>

        <span class="token comment">//获取数据偏移量  将不同分区内的数据偏移量保存到map集合中</span>
        <span class="token comment">//  wordcount/0 -&gt; 1001</span>
        fromOffsets <span class="token operator">+=</span> <span class="token punctuation">(</span>tp <span class="token operator">-&gt;</span> partitionOffset<span class="token punctuation">.</span>toLong<span class="token punctuation">)</span>
      <span class="token punctuation">}</span>

      <span class="token comment">// 泛型中 key：kafka中的key   value：hello tom hello jerry</span>
      <span class="token comment">//创建函数 解析数据 转换为（topic_name, message）的元组</span>
      <span class="token keyword">val</span> messageHandler <span class="token operator">=</span> <span class="token punctuation">(</span>mmd<span class="token operator">:</span> MessageAndMetadata<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>mmd<span class="token punctuation">.</span>topic<span class="token punctuation">,</span> mmd<span class="token punctuation">.</span>message<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

      <span class="token comment">//todo:7、利用底层的API创建DStream 采用直连的方式(之前已经消费了，从指定的位置消费)</span>
       kafkaStream <span class="token operator">=</span> KafkaUtils<span class="token punctuation">.</span>createDirectStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> StringDecoder<span class="token punctuation">,</span> StringDecoder<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">(</span>ssc<span class="token punctuation">,</span> kafkaParams<span class="token punctuation">,</span> fromOffsets<span class="token punctuation">,</span> messageHandler<span class="token punctuation">)</span>

    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
      <span class="token comment">//todo:7、利用底层的API创建DStream 采用直连的方式(之前没有消费，这是第一次读取数据)</span>
      <span class="token comment">//zk中没有子节点数据 就是第一次读取数据 直接创建直连对象</span>
      kafkaStream <span class="token operator">=</span> KafkaUtils<span class="token punctuation">.</span>createDirectStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> StringDecoder<span class="token punctuation">,</span> StringDecoder<span class="token punctuation">]</span><span class="token punctuation">(</span>ssc<span class="token punctuation">,</span> kafkaParams<span class="token punctuation">,</span> topics<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>

    <span class="token comment">//todo:8、直接操作kafkaStream</span>
    <span class="token comment">//依次迭代DStream中的kafkaRDD 只有kafkaRDD才可以强转为HasOffsetRanges  从中获取数据偏移量信息</span>
    <span class="token comment">//之后是操作的RDD 不能够直接操作DStream 因为调用Transformation方法之后就不是kafkaRDD了获取不了偏移量信息</span>

    kafkaStream<span class="token punctuation">.</span>foreachRDD<span class="token punctuation">(</span>kafkaRDD <span class="token keyword">=&gt;</span> <span class="token punctuation">{</span>
      <span class="token comment">//强转为HasOffsetRanges 获取offset偏移量数据</span>
      <span class="token keyword">val</span> offsetRanges <span class="token operator">=</span> kafkaRDD<span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>HasOffsetRanges<span class="token punctuation">]</span><span class="token punctuation">.</span>offsetRanges

      <span class="token comment">//获取数据</span>
      <span class="token keyword">val</span> lines<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span>kafkaRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>

      <span class="token comment">//todo：9、接下来就是对RDD进行操作 触发action</span>
      lines<span class="token punctuation">.</span>foreachPartition<span class="token punctuation">(</span>patition <span class="token keyword">=&gt;</span> <span class="token punctuation">{</span>
        patition<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> println<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>

      <span class="token comment">//todo: 10、手动提交偏移量到zk集群上</span>
      <span class="token keyword">for</span> <span class="token punctuation">(</span>o <span class="token keyword">&lt;-</span> offsetRanges<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">//拼接zk路径   /consumers/consumer-kaikeba/offsets/wordcount/0</span>
        <span class="token keyword">val</span> zkPath <span class="token operator">=</span> s<span class="token string">&quot;${topicDirs.consumerOffsetDir}/${o.partition}&quot;</span>

        <span class="token comment">//将 partition 的偏移量数据 offset 保存到zookeeper中</span>
        ZkUtils<span class="token punctuation">.</span>updatePersistentPath<span class="token punctuation">(</span>zkClient<span class="token punctuation">,</span> zkPath<span class="token punctuation">,</span> o<span class="token punctuation">.</span>untilOffset<span class="token punctuation">.</span>toString<span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment">//开启SparkStreaming 并等待退出</span>
    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>

  <span class="token comment">/**
    * 获取zk节点上的子节点的个数
    * @param zkClient
    * @param zkTopicPath
    * @return
    */</span>
  <span class="token keyword">def</span> getZkChildrenNum<span class="token punctuation">(</span>zkClient<span class="token operator">:</span>ZkClient<span class="token punctuation">,</span>zkTopicPath<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span><span class="token builtin">Int</span> <span class="token operator">=</span><span class="token punctuation">{</span>

    <span class="token comment">//查询该路径下是否有子节点，即是否有分区读取数据记录的读取的偏移量</span>
    <span class="token comment">// /consumers/consumer-kaikeba/offsets/wordcount/0</span>
    <span class="token comment">// /consumers/consumer-kaikeba/offsets/wordcount/1</span>
    <span class="token comment">// /consumers/consumer-kaikeba/offsets/wordcount/2</span>

    <span class="token comment">//子节点的个数</span>
    <span class="token keyword">val</span> childrenNum<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> zkClient<span class="token punctuation">.</span>countChildren<span class="token punctuation">(</span>zkTopicPath<span class="token punctuation">)</span>

    childrenNum
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><h2 id="sparkstreaming应用程序如何保证exactly-once"><a href="#sparkstreaming应用程序如何保证exactly-once" class="header-anchor">#</a> SparkStreaming应用程序如何保证Exactly-Once</h2> <p>牢记实现Exactly-Once思路：</p> <blockquote><p>==一个流式计算如果想要保证Exactly-Once，那么首先要满足下面三点要求：==</p> <p>（1）Source支持Replay。---》Source的数据支持重新发送，kafka就可以</p> <p>（2）流计算引擎本身处理能保证Exactly-Once。 ---》sparkstreaming可以</p> <p>（3）Sink支持幂等或事务更新 ---》幂等是一个数学概念，f(f(x))=f(x),比如mysql表执行一个更新的sql语句，把老王的银行卡金额设为100，这个更新无论更新多少次，银行卡金额都是100。</p> <p>也就是说如果要想让一个SparkStreaming的程序保证Exactly-Once,那么从如下三个角度出发</p> <p>（1）接收数据:从Source中接收数据。</p> <p>（2）转换数据:用DStream和RDD算子转换。</p> <p>（3）储存数据:将结果保存至外部系统。</p> <p>如果SparkStreaming程序需要实现Exactly-Once语义，那么每一个步骤都要保证Exactly-Once。</p> <p>==实现数据被处理且只被处理一次的sink的方式：==</p> <p>（1）需要实现数据结果保存与偏移量保存操作在同一个事务中，要么同时成功，要么就都失败。失败了会回滚。事务操作可以在foreachRDD()时进行。如果数据写入失败，或者offset保存失败，那么这一批次数据都将失败并且回滚。</p> <p>（2）或者实现幂等。</p></blockquote> <h6 id="案例演示"><a href="#案例演示" class="header-anchor">#</a> 案例演示</h6> <p>pom.xml添加内容如下</p> <div class="language-xml extra-class"><pre class="language-xml"><code>       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.scalikejdbc<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>scalikejdbc_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
  <span class="token comment">&lt;!-- https://mvnrepository.com/artifact/org.scalikejdbc/scalikejdbc-config --&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.scalikejdbc<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>scalikejdbc-config_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>mysql<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>mysql-connector-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>5.1.39<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><p>代码开发</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span></span>TopicPartition
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span>StringDeserializer
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span>SparkConf
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span>SparkSession
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>kafka010<span class="token punctuation">.</span></span><span class="token punctuation">{</span>ConsumerStrategies<span class="token punctuation">,</span> HasOffsetRanges<span class="token punctuation">,</span> KafkaUtils<span class="token punctuation">,</span> LocationStrategies<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>slf4j<span class="token punctuation">.</span></span>LoggerFactory
<span class="token keyword">import</span> <span class="token namespace">scalikejdbc<span class="token punctuation">.</span></span><span class="token punctuation">{</span>ConnectionPool<span class="token punctuation">,</span> DB<span class="token punctuation">,</span> _<span class="token punctuation">}</span>
<span class="token comment">/**
  *    SparkStreaming EOS:
  *      Input:Kafka
  *      Process:Spark Streaming
  *      Output:Mysql
  *
  *      保证EOS:
  *        1、偏移量自己管理，即enable.auto.commit=false,这里保存在Mysql中
  *        2、使用createDirectStream
  *        3、事务输出: 结果存储与Offset提交在Driver端同一Mysql事务中
  */</span>
<span class="token keyword">object</span> SparkStreamingEOSKafkaMysqlAtomic <span class="token punctuation">{</span>
  <span class="token annotation punctuation">@transient</span> <span class="token keyword">lazy</span> <span class="token keyword">val</span> logger <span class="token operator">=</span> LoggerFactory<span class="token punctuation">.</span>getLogger<span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>getClass<span class="token punctuation">)</span>

  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>

    <span class="token keyword">val</span> topic<span class="token operator">=</span><span class="token string">&quot;topic1&quot;</span>
    <span class="token keyword">val</span> group<span class="token operator">=</span><span class="token string">&quot;spark_app1&quot;</span>

    <span class="token comment">//Kafka配置</span>
    <span class="token keyword">val</span> kafkaParams<span class="token operator">=</span> Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> Object<span class="token punctuation">]</span><span class="token punctuation">(</span>
      <span class="token string">&quot;bootstrap.servers&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;node1:6667,node2:6667,node3:6667&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;key.deserializer&quot;</span> <span class="token operator">-&gt;</span> classOf<span class="token punctuation">[</span>StringDeserializer<span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token string">&quot;value.deserializer&quot;</span> <span class="token operator">-&gt;</span> classOf<span class="token punctuation">[</span>StringDeserializer<span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token string">&quot;auto.offset.reset&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;latest&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;enable.auto.commit&quot;</span> <span class="token operator">-&gt;</span> <span class="token punctuation">(</span><span class="token boolean">false</span><span class="token operator">:</span> java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span><span class="token builtin">Boolean</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token string">&quot;group.id&quot;</span> <span class="token operator">-&gt;</span> group<span class="token punctuation">)</span>

    <span class="token comment">//在Driver端创建数据库连接池</span>
    ConnectionPool<span class="token punctuation">.</span>singleton<span class="token punctuation">(</span><span class="token string">&quot;jdbc:mysql://node3:3306/bigdata&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>getClass<span class="token punctuation">.</span>getSimpleName<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">&quot;$&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> ssc <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>conf<span class="token punctuation">,</span>Seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//1)初次启动或重启时,从指定的Partition、Offset构建TopicPartition</span>
    <span class="token comment">//2)运行过程中,每个Partition、Offset保存在内部currentOffsets = Map[TopicPartition, Long]()变量中</span>
    <span class="token comment">//3)后期Kafka Topic分区动扩展,在运行过程中不能自动感知</span>
    <span class="token keyword">val</span> initOffset<span class="token operator">=</span>DB<span class="token punctuation">.</span>readOnly<span class="token punctuation">(</span><span class="token keyword">implicit</span> session<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
      sql<span class="token string">&quot;select `partition`,offset from kafka_topic_offset where topic =${topic} and `group`=${group}&quot;</span>
        <span class="token punctuation">.</span>map<span class="token punctuation">(</span>item<span class="token keyword">=&gt;</span> <span class="token keyword">new</span> TopicPartition<span class="token punctuation">(</span>topic<span class="token punctuation">,</span> item<span class="token punctuation">.</span>get<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">&quot;partition&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">-&gt;</span> item<span class="token punctuation">.</span>get<span class="token punctuation">[</span><span class="token builtin">Long</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">&quot;offset&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span>list<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toMap
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment">//CreateDirectStream</span>
    <span class="token comment">//从指定的Topic、Partition、Offset开始消费</span>
    <span class="token keyword">val</span> sourceDStream <span class="token operator">=</span>KafkaUtils<span class="token punctuation">.</span>createDirectStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>
      ssc<span class="token punctuation">,</span>
      LocationStrategies<span class="token punctuation">.</span>PreferConsistent<span class="token punctuation">,</span>
      ConsumerStrategies<span class="token punctuation">.</span>Assign<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>initOffset<span class="token punctuation">.</span>keys<span class="token punctuation">,</span>kafkaParams<span class="token punctuation">,</span>initOffset<span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    sourceDStream<span class="token punctuation">.</span>foreachRDD<span class="token punctuation">(</span>rdd<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
      <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>rdd<span class="token punctuation">.</span>isEmpty<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
        <span class="token keyword">val</span> offsetRanges <span class="token operator">=</span> rdd<span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>HasOffsetRanges<span class="token punctuation">]</span><span class="token punctuation">.</span>offsetRanges
        offsetRanges<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>offsetRange<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
          logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span>s<span class="token string">&quot;Topic: ${offsetRange.topic},Group: ${group},Partition: ${offsetRange.partition},fromOffset: ${offsetRange.fromOffset},untilOffset: ${offsetRange.untilOffset}&quot;</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span>

        <span class="token comment">//统计分析</span>
        <span class="token comment">//将结果收集到Driver端</span>
        <span class="token keyword">val</span> sparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">.</span>config<span class="token punctuation">(</span>rdd<span class="token punctuation">.</span>sparkContext<span class="token punctuation">.</span>getConf<span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_
        <span class="token keyword">val</span> dataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span>rdd<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>value<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toDS<span class="token punctuation">)</span>
        dataFrame<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">&quot;tmpTable&quot;</span><span class="token punctuation">)</span>
        <span class="token keyword">val</span> result<span class="token operator">=</span>sparkSession<span class="token punctuation">.</span>sql<span class="token punctuation">(</span>
          <span class="token triple-quoted-string string">&quot;&quot;&quot;
            |select
            |   --每分钟
            |   eventTimeMinute,
            |   --每种语言
            |   language,
            |   -- 次数
            |   count(1) pv,
            |   -- 人数
            |   count(distinct(userID)) uv
            |from(
            |   select *, substr(eventTime,0,16) eventTimeMinute from tmpTable
            |) as tmp group by eventTimeMinute,language
          &quot;&quot;&quot;</span><span class="token punctuation">.</span>stripMargin
        <span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment">//在Driver端存储数据、提交Offset</span>
        <span class="token comment">//结果存储与Offset提交在同一事务中原子执行</span>
        <span class="token comment">//这里将偏移量保存在Mysql中</span>
        DB<span class="token punctuation">.</span>localTx<span class="token punctuation">(</span><span class="token keyword">implicit</span> session<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>

          <span class="token comment">//结果存储</span>
          result<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>row<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
            sql<span class="token triple-quoted-string string">&quot;&quot;&quot;
            insert into twitter_pv_uv (eventTimeMinute, language,pv,uv)
            value (
                ${row.getAs[String](&quot;eventTimeMinute&quot;)},
                ${row.getAs[String](&quot;language&quot;)},
                ${row.getAs[Long](&quot;pv&quot;)},
                ${row.getAs[Long](&quot;uv&quot;)}
                )
            on duplicate key update pv=pv,uv=uv
          &quot;&quot;&quot;</span><span class="token punctuation">.</span>update<span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token punctuation">)</span>
          <span class="token punctuation">}</span><span class="token punctuation">)</span>

          <span class="token comment">//Offset提交</span>
          offsetRanges<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>offsetRange<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
            <span class="token keyword">val</span> affectedRows <span class="token operator">=</span> sql<span class="token triple-quoted-string string">&quot;&quot;&quot;
          update kafka_topic_offset set offset = ${offsetRange.untilOffset}
          where
            topic = ${topic}
            and `group` = ${group}
            and `partition` = ${offsetRange.partition}
            and offset = ${offsetRange.fromOffset}
          &quot;&quot;&quot;</span><span class="token punctuation">.</span>update<span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token keyword">if</span> <span class="token punctuation">(</span>affectedRows <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
              <span class="token keyword">throw</span> <span class="token keyword">new</span> Exception<span class="token punctuation">(</span>s<span class="token triple-quoted-string string">&quot;&quot;&quot;Commit Kafka Topic: ${topic} Offset Faild!&quot;&quot;&quot;</span><span class="token punctuation">)</span>
            <span class="token punctuation">}</span>
          <span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

<span class="token punctuation">}</span>
</code></pre></div><h2 id="sparkstreaming调优"><a href="#sparkstreaming调优" class="header-anchor">#</a> SparkStreaming调优</h2> <h4 id="调整blockreceiver的数量"><a href="#调整blockreceiver的数量" class="header-anchor">#</a> 调整BlockReceiver的数量</h4> <p><img src="/assets/img/1567325066744-1608485794545.b042984f.png" alt="1567325066744"></p> <p>案例演示：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> kafkaStream <span class="token operator">=</span> <span class="token punctuation">{</span>  
  <span class="token keyword">val</span> sparkStreamingConsumerGroup <span class="token operator">=</span> <span class="token string">&quot;spark-streaming-consumer-group&quot;</span>  
  <span class="token keyword">val</span> kafkaParams <span class="token operator">=</span> Map<span class="token punctuation">(</span>  
    <span class="token string">&quot;zookeeper.connect&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;node01:2181,node02:2181,node03:2181&quot;</span><span class="token punctuation">,</span>  
    <span class="token string">&quot;group.id&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;spark-streaming-test&quot;</span><span class="token punctuation">)</span>  
  <span class="token keyword">val</span> inputTopic <span class="token operator">=</span> <span class="token string">&quot;test&quot;</span>  
  <span class="token keyword">val</span> numPartitionsOfInputTopic <span class="token operator">=</span> <span class="token number">3</span>  
  <span class="token keyword">val</span> streams <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> to <span class="token namespace">numPartitionsOfInputTopic</span><span class="token punctuation">)</span> map  <span class="token punctuation">{</span>x <span class="token keyword">=&gt;</span>  
    KafkaUtils<span class="token punctuation">.</span>createStream<span class="token punctuation">(</span>ssc<span class="token punctuation">,</span> kafkaParams<span class="token punctuation">,</span> Map<span class="token punctuation">(</span>inputTopic <span class="token operator">-&gt;</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      StorageLevel<span class="token punctuation">.</span>MEMORY_ONLY_SER<span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>  
  <span class="token punctuation">}</span>  
  <span class="token keyword">val</span> unifiedStream <span class="token operator">=</span> ssc<span class="token punctuation">.</span>union<span class="token punctuation">(</span>streams<span class="token punctuation">)</span>  
</code></pre></div><h4 id="_4调整block的数量"><a href="#_4调整block的数量" class="header-anchor">#</a> 4调整Block的数量</h4> <div class="language- extra-class"><pre class="language-text"><code>batchInterval : 触发批处理的时间间隔
blockInterval :将接收到的数据生成Block的时间间隔，spark.streaming.blockInterval(默认是200ms)，那么，BlockRDD的分区数 = batchInterval / blockInterval，即一个Block就是RDD的一个分区，就是一个task
比如，batchInterval是2秒，而blockInterval是200ms，那么task数为10，如果task的数量太少，比一个executor的core数还少的话，那么可以减少blockInterval，blockInterval最好不要小于50ms，太小的话导致task数太多，那么launch task的时间久多了
</code></pre></div><h5 id="_4-3-调整receiver的接受速率"><a href="#_4-3-调整receiver的接受速率" class="header-anchor">#</a> 4.3 调整Receiver的接受速率</h5> <div class="language- extra-class"><pre class="language-text"><code>pps:permits per second 每秒允许接受的数据量(QPS -&gt; queries per second)
Spark Streaming默认的PPS是没有限制的,可以通过参数spark.streaming.receiver.maxRate来控制，默认是Long.Maxvalue
</code></pre></div><h5 id="_4-4-调整数据处理的并行度"><a href="#_4-4-调整数据处理的并行度" class="header-anchor">#</a> 4.4 调整数据处理的并行度</h5> <p><strong>BlockRDD的分区数</strong></p> <p>a. 通过Receiver接受数据的特点决定</p> <p>b. 也可以自己通过repartition设置</p> <p><strong>ShuffleRDD的分区数</strong></p> <p>a. 默认的分区数为spark.default.parallelism(core的大小)</p> <p>b. 通过我们自己设置决定</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> wordCounts <span class="token operator">=</span> words<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>a<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> b<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> a <span class="token operator">+</span> b<span class="token punctuation">,</span> <span class="token keyword">new</span> HashPartitioner<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h5 id="_4-5-数据的序列化"><a href="#_4-5-数据的序列化" class="header-anchor">#</a> 4.5 数据的序列化</h5> <p>SparkStreaming两种需要序列化的数据：
a. 输入的数据：默认是以<a href="http://spark.apache.org/docs/latest/api/scala/index.html" target="_blank" rel="noopener noreferrer">StorageLevel.MEMORY_AND_DISK_SER_2<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>的形式存储在executor上的内存中
b. 缓存的数据：默认是以<a href="http://spark.apache.org/docs/latest/api/scala/index.html" target="_blank" rel="noopener noreferrer">StorageLevel.MEMORY_ONLY_SER<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>的形式存储的内存中
使用Kryo序列化机制，比Java序列化机制性能好</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
conf<span class="token punctuation">.</span>set<span class="token punctuation">(</span><span class="token string">&quot;spark.serializer&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;org.apache.spark.serializer.KryoSerializer&quot;</span><span class="token punctuation">)</span>
conf<span class="token punctuation">.</span>registerKryoClasses<span class="token punctuation">(</span>Array<span class="token punctuation">(</span>classOf<span class="token punctuation">[</span>MyClass1<span class="token punctuation">]</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>MyClass2<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
</code></pre></div><h5 id="_4-6-内存调优"><a href="#_4-6-内存调优" class="header-anchor">#</a> 4.6 内存调优</h5> <ul><li>需要内存大小</li></ul> <div class="language- extra-class"><pre class="language-text"><code>和transformation的类型有关，如果使用的是updateStateByKey，Window这样的算子，那么内存就要设置得偏大。
</code></pre></div><ul><li>数据存储级别</li></ul> <div class="language- extra-class"><pre class="language-text"><code>如果把接收到的数据设置的存储级别是MEMORY_DISK这种级别，也就是说如果内存不够可以把数据存储到磁盘上，其实性能还是不好的，性能最好的就是所有的数据都在内存里面，所以如果在资源允许的情况下，把内存调大一点，让所有的数据都存在内存里面。
</code></pre></div><h5 id="_4-7-output-operations性能"><a href="#_4-7-output-operations性能" class="header-anchor">#</a> 4.7 Output Operations性能</h5> <ul><li>保存结果到外部的存储介质中，比如mysql/hbase数据库
<ul><li>使用高性能的算子操作实现</li></ul></li></ul> <p><img src="/assets/img/1585058900250-1608485794545.098bf077.png" alt="1585058900250"></p> <p><img src="/assets/img/1585058915092-1608485794545.4f21ba92.png" alt="1585058915092"></p> <h5 id="_4-8-backpressure-压力反馈"><a href="#_4-8-backpressure-压力反馈" class="header-anchor">#</a> 4.8 Backpressure(压力反馈)</h5> <p><img src="/assets/img/1567327168554-1608485794545.45fc942e.png" alt="1567327168554"></p> <p><img src="/assets/img/1567327191622-1608485794545.79783499.png" alt="1567327191622"></p> <p>Feedback Loop : 动态使得Streaming app从unstable状态回到stable状态</p> <p><img src="/assets/img/1567327216060-1608485794545.1a3bdc95.png" alt="1567327216060"></p> <p>从Spark1.5版本开始：==spark.streaming.backpressure.enabled = true==</p> <h5 id="_4-9-elastic-scaling-资源动态分配"><a href="#_4-9-elastic-scaling-资源动态分配" class="header-anchor">#</a> 4.9 Elastic Scaling(资源动态分配)</h5> <p>动态分配资源：</p> <p>批处理动态的决定这个application中需要多少个Executors：</p> <ol><li>当一个Executor空闲的时候，将这个Executor杀掉</li> <li>当task太多的时候，动态的启动Executors</li></ol> <p>Streaming分配Executor的原则是比对 process time / batchInterval 的比率</p> <p><img src="/assets/img/1567327351927-1608485794545.165c3b8b.png" alt="1567327351927"></p> <p>如果延迟了，那么就自动增加资源</p> <p><img src="/assets/img/1567327385166-1608485794545.7363d307.png" alt="1567327385166"></p> <p><img src="/assets/img/1567327412253-1608485794545.4547d784.png" alt="1567327412253"></p> <p>从Spark2.0有这个功能，开启资源动态分配： ==spark.streaming.dynamicAllocation.enabled = true==</p> <h5 id="_4-10-数据倾斜调优"><a href="#_4-10-数据倾斜调优" class="header-anchor">#</a> 4.10  数据倾斜调优</h5> <div class="language- extra-class"><pre class="language-text"><code>因为SparkStreaming的底层就是RDD，之前我们讲SparkCore的所有的数据倾斜的调优策略（见SparkCore调优）都适合于SparkStreaming，大家一定要灵活掌握，这个在实际开发的工作当中用得频率较高，各位同学面试的时候也可以从这个角度跟面试官聊。	
</code></pre></div><h2 id="总结"><a href="#总结" class="header-anchor">#</a> 总结</h2> <div class="language- extra-class"><pre class="language-text"><code>简单聊一下sparkStreaming程序。

后期进入到企业之后，如果用到sparkStreaming消费kafka的数据，建议大家使用Direct直连方式的api的处理。它是有一些有点。如果你想实现exactly-once，可以实现幂等或者是事务去控制。去开发对应的代码.


开发步骤：
（1）在本地开发好程序（指定master为local），做测试，目的：为了测试代码的业务功能逻辑对不对
（2）可以稍微改造一下程序（master不在为local）,把程序打成jar包提交到spark集群中运行


有一个问题需要探讨一下：
一个sparkStreaming程序到底给定多少计算资源是比较合理？
假设实时处理程序的批处理时间间隔为5s。什么情况才叫资源比较合理？
首先你要知道针对于实时处理程序来什么情况才叫合理？
-----需要在当前批次时间间隔内，就要上一个批次时间产生的数据处理完成----------
说白了就是这里需要在5s之内就把上一个5s的数据处理完成。
如果处理的时间大于了批处理时间间隔，这里会出现数据的积压，任务延迟比较高


可以来几组资源参数做测试：
(1) --executor-memory  2g   --total-executor-core 10
(2) --executor-memory  2g   --total-executor-core 20
(3) --executor-memory  5g   --total-executor-core 20


把程序提交到集群之后可以通过master的web页面观察任务运行的相关信息。
spark-submit  \
--master spark://node01:7077  \
--class com.kaikeba.streaming.kafka.KafkaDirect10 \
--executor-memory 1g \
--total-executor-cores 4 \
sparkStreamingStudy-1.0-SNAPSHOT.jar 
</code></pre></div><h2 id="sparkstreaming高频面试题"><a href="#sparkstreaming高频面试题" class="header-anchor">#</a> ==sparkStreaming高频面试题！！！！！！==</h2> <h5 id="_1、你们公司有多少个实时任务"><a href="#_1、你们公司有多少个实时任务" class="header-anchor">#</a> 1、你们公司有多少个实时任务？</h5> <div class="language- extra-class"><pre class="language-text"><code>20-50个任务就可以了
</code></pre></div><h5 id="_2、你们是如何保证数据不丢失的-代码怎么的-架构是什么"><a href="#_2、你们是如何保证数据不丢失的-代码怎么的-架构是什么" class="header-anchor">#</a> 2、你们是如何保证数据不丢失的, 代码怎么的？架构是什么？</h5> <div class="language- extra-class"><pre class="language-text"><code>kafka 0.8
kafka 0.10
</code></pre></div><h5 id="_3、你们的任务多久是一个批次"><a href="#_3、你们的任务多久是一个批次" class="header-anchor">#</a> 3、你们的任务多久是一个批次？</h5> <div class="language- extra-class"><pre class="language-text"><code>5秒、10秒、30秒、1分钟都是可以的
</code></pre></div><h5 id="_4、一个批次里面大约有多少条数据"><a href="#_4、一个批次里面大约有多少条数据" class="header-anchor">#</a> 4、一个批次里面大约有多少条数据？</h5> <div class="language- extra-class"><pre class="language-text"><code>8000条左右
</code></pre></div><h5 id="_5、你的整个任务一天计算多少条数据"><a href="#_5、你的整个任务一天计算多少条数据" class="header-anchor">#</a> 5、你的整个任务一天计算多少条数据？</h5> <div class="language- extra-class"><pre class="language-text"><code>估算一下，2/8法则算一下
</code></pre></div><h5 id="_6、一条消息多大"><a href="#_6、一条消息多大" class="header-anchor">#</a> 6、一条消息多大？</h5> <div class="language- extra-class"><pre class="language-text"><code>10KB左右
</code></pre></div><h5 id="_7、你在处理实时任务的过程中遇到了什么问题吗-☆☆☆☆☆"><a href="#_7、你在处理实时任务的过程中遇到了什么问题吗-☆☆☆☆☆" class="header-anchor">#</a> 7、你在处理实时任务的过程中遇到了什么问题吗？（☆☆☆☆☆）</h5> <div class="language- extra-class"><pre class="language-text"><code>一定不能说没有，但是也不能说有些比较低级的问题
举个例子，比如说之前处理的业务代码会出现数据丢失，现在不丢失了
或者是任务延迟了，因为发送了数据倾斜，导致在规定的时间内数据没有处理完，导致调度延迟，内存损耗完。

怎么解决的？可以使用之前的数据倾斜方法去处理解决。
</code></pre></div><h5 id="_8、你们公司用的kafka是哪个版本-什么版本的sparkstreaming"><a href="#_8、你们公司用的kafka是哪个版本-什么版本的sparkstreaming" class="header-anchor">#</a> 8、你们公司用的kafka是哪个版本，什么版本的sparkStreaming?</h5> <div class="language- extra-class"><pre class="language-text"><code>1.0版本的kafka
2.3.3版本的sparkStreaming
</code></pre></div><h5 id="_9、你们公司是如何管理实时任务的"><a href="#_9、你们公司是如何管理实时任务的" class="header-anchor">#</a> 9、你们公司是如何管理实时任务的？</h5> <div class="language- extra-class"><pre class="language-text"><code>可以说出一个思路就可以了
</code></pre></div><h5 id="_10、如何保证一次语义-☆☆☆☆☆"><a href="#_10、如何保证一次语义-☆☆☆☆☆" class="header-anchor">#</a> 10、如何保证一次语义？（☆☆☆☆☆）</h5> <div class="language- extra-class"><pre class="language-text"><code>不一定说要写代码，需要提供相关的思路即可
</code></pre></div><h2 id="知识扩展-scalikejdbc"><a href="#知识扩展-scalikejdbc" class="header-anchor">#</a> 知识扩展-ScalikeJDBC</h2> <h4 id="_1、什么是scalikejdbc"><a href="#_1、什么是scalikejdbc" class="header-anchor">#</a> 1、什么是ScalikeJDBC</h4> <p>ScalikeJDBC是Scala开发人员基于SQL的简洁数据库访问库。</p> <p>该库自然包装JDBC API，为您提供易于使用且非常灵活的API。</p> <p>更重要的是，QueryDSL使您的代码类型安全且可重用。</p> <p>ScalikeJDBC是一个实用且适合生产的产品。 将此库用于实际项目.</p> <h4 id="_2、idea项目中导入相关库"><a href="#_2、idea项目中导入相关库" class="header-anchor">#</a> 2、IDEA项目中导入相关库</h4> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token comment">&lt;!-- https://mvnrepository.com/artifact/org.scalikejdbc/scalikejdbc --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.scalikejdbc<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>scalikejdbc_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token comment">&lt;!-- https://mvnrepository.com/artifact/org.scalikejdbc/scalikejdbc-config --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.scalikejdbc<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>scalikejdbc-config_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token comment">&lt;!-- mysql &quot; mysql-connector-java --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>mysql<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>mysql-connector-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>5.1.38<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><h4 id="_3、数据库操作"><a href="#_3、数据库操作" class="header-anchor">#</a> 3、数据库操作</h4> <h5 id="_3-1-数据库连接配置信息"><a href="#_3-1-数据库连接配置信息" class="header-anchor">#</a> 3.1 数据库连接配置信息</h5> <ul><li>在IDEA的resources文件夹下创建application.conf</li></ul> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#mysql的连接配置信息</span>
db.default.driver<span class="token operator">=</span><span class="token string">&quot;com.mysql.jdbc.Driver&quot;</span>
db.default.url<span class="token operator">=</span><span class="token string">&quot;jdbc:mysql://node03:3306/spark&quot;</span>
db.default.user<span class="token operator">=</span><span class="token string">&quot;root&quot;</span>
db.default.password<span class="token operator">=</span><span class="token string">&quot;123456&quot;</span>
</code></pre></div><ul><li>scalikeJDBC默认加载default配置，或者使用自定义配置</li></ul> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#mysql的连接配置信息</span>
db.fred.driver<span class="token operator">=</span><span class="token string">&quot;com.mysql.jdbc.Driver&quot;</span>
db.fred.url<span class="token operator">=</span><span class="token string">&quot;jdbc:mysql://node03:3306/spark&quot;</span>
db.fred.user<span class="token operator">=</span><span class="token string">&quot;root&quot;</span>
db.fred.password<span class="token operator">=</span><span class="token string">&quot;123456&quot;</span>
</code></pre></div><h5 id="_3-2-加载数据配置信息"><a href="#_3-2-加载数据配置信息" class="header-anchor">#</a> 3.2 加载数据配置信息</h5> <div class="language-java extra-class"><pre class="language-java"><code><span class="token comment">//默认加载default配置信息</span>
<span class="token class-name">DBs</span><span class="token punctuation">.</span><span class="token function">setup</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">//加载自定义的fred配置信息</span>
<span class="token class-name">DBs</span><span class="token punctuation">.</span><span class="token function">setup</span><span class="token punctuation">(</span>'fred<span class="token punctuation">)</span>
</code></pre></div><h5 id="_3-3-查询数据库并封装数据"><a href="#_3-3-查询数据库并封装数据" class="header-anchor">#</a> 3.3 查询数据库并封装数据</h5> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">//配置mysql</span>
DBs<span class="token punctuation">.</span>setup<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">//查询数据并返回单个列，并将列数据封装到集合中</span>
<span class="token keyword">val</span> list <span class="token operator">=</span> DB<span class="token punctuation">.</span>readOnly<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token keyword">implicit</span> session <span class="token keyword">=&gt;</span>
  SQL<span class="token punctuation">(</span><span class="token string">&quot;select content from post&quot;</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>map<span class="token punctuation">(</span>rs <span class="token keyword">=&gt;</span> 
    rs<span class="token punctuation">.</span>string<span class="token punctuation">(</span><span class="token string">&quot;content&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>list<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token keyword">for</span><span class="token punctuation">(</span>s <span class="token keyword">&lt;-</span> list<span class="token punctuation">)</span><span class="token punctuation">{</span>
  println<span class="token punctuation">(</span>s<span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre></div><div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">case</span> <span class="token keyword">class</span> Users<span class="token punctuation">(</span>id<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span> name<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span> nickName<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">)</span>

<span class="token comment">/**
  * 查询数据库，并将数据封装成对象，并返回一个集合
  */</span>
<span class="token comment">//配置mysql</span>
DBs<span class="token punctuation">.</span>setup<span class="token punctuation">(</span><span class="token symbol">'fred</span><span class="token punctuation">)</span>

<span class="token comment">//查询数据并返回单个列，并将列数据封装到集合中</span>
<span class="token keyword">val</span> users <span class="token operator">=</span> NamedDB<span class="token punctuation">(</span><span class="token symbol">'fred</span><span class="token punctuation">)</span><span class="token punctuation">.</span>readOnly<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token keyword">implicit</span> session <span class="token keyword">=&gt;</span>
  SQL<span class="token punctuation">(</span><span class="token string">&quot;select * from users&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>rs <span class="token keyword">=&gt;</span>
  Users<span class="token punctuation">(</span>rs<span class="token punctuation">.</span>string<span class="token punctuation">(</span><span class="token string">&quot;id&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> rs<span class="token punctuation">.</span>string<span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    rs<span class="token punctuation">.</span>string<span class="token punctuation">(</span><span class="token string">&quot;nickName&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>list<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> <span class="token punctuation">(</span>u <span class="token keyword">&lt;-</span> users<span class="token punctuation">)</span><span class="token punctuation">{</span>
  println<span class="token punctuation">(</span>u<span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre></div><h5 id="_3-4-插入数据"><a href="#_3-4-插入数据" class="header-anchor">#</a> 3.4 插入数据</h5> <h6 id="_3-4-1-autocommit"><a href="#_3-4-1-autocommit" class="header-anchor">#</a> 3.4.1 AutoCommit</h6> <div class="language-shell extra-class"><pre class="language-shell"><code>/**
  * 插入数据，使用AutoCommit
  * @return
  */
val insertResult <span class="token operator">=</span> DB.autoCommit<span class="token punctuation">(</span><span class="token punctuation">{</span>implicit session <span class="token operator">=</span><span class="token operator">&gt;</span>
  SQL<span class="token punctuation">(</span><span class="token string">&quot;insert into users(name, nickName) values(?,?)&quot;</span><span class="token punctuation">)</span>.bind<span class="token punctuation">(</span><span class="token string">&quot;test01&quot;</span>, <span class="token string">&quot;test01&quot;</span><span class="token punctuation">)</span>
    .update<span class="token punctuation">(</span><span class="token punctuation">)</span>.apply<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
println<span class="token punctuation">(</span>insertResult<span class="token punctuation">)</span>
</code></pre></div><h6 id="_3-4-2-插入返回主键标识"><a href="#_3-4-2-插入返回主键标识" class="header-anchor">#</a> 3.4.2 插入返回主键标识</h6> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">/**
  * 插入数据，并返回主键
  * @return
  */</span>
<span class="token keyword">val</span> id <span class="token operator">=</span> DB<span class="token punctuation">.</span>localTx<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token keyword">implicit</span> session <span class="token keyword">=&gt;</span>
  SQL<span class="token punctuation">(</span><span class="token string">&quot;insert into users(name, nickName, sex) values(?,?,?)&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token string">&quot;test&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;000&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;male&quot;</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>updateAndReturnGeneratedKey<span class="token punctuation">(</span><span class="token string">&quot;nickName&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
println<span class="token punctuation">(</span>id<span class="token punctuation">)</span>
</code></pre></div><h6 id="_3-4-3-事务插入"><a href="#_3-4-3-事务插入" class="header-anchor">#</a> 3.4.3 事务插入</h6> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">/**
  * 使用事务插入数据库
  * @return
  */</span>
<span class="token keyword">val</span> tx <span class="token operator">=</span> DB<span class="token punctuation">.</span>localTx<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token keyword">implicit</span> session <span class="token keyword">=&gt;</span>
  SQL<span class="token punctuation">(</span><span class="token string">&quot;insert into users(name, nickName, sex) values(?,?,?)&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token string">&quot;test&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;haha&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;male&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token comment">//下一行会报错，用于测试</span>
  <span class="token keyword">var</span> s <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token number">0</span> 
  SQL<span class="token punctuation">(</span><span class="token string">&quot;insert into users(name, nickName, sex) values(?,?,?)&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token string">&quot;test01&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;haha01&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;male01&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
println<span class="token punctuation">(</span>s<span class="token string">&quot;tx = ${tx}&quot;</span><span class="token punctuation">)</span>
</code></pre></div><h6 id="_3-4-4-更新数据"><a href="#_3-4-4-更新数据" class="header-anchor">#</a> 3.4.4 更新数据</h6> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">/**
  * 更新数据
  * @return
  */</span>
DB<span class="token punctuation">.</span>localTx<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token keyword">implicit</span> session <span class="token keyword">=&gt;</span>
  SQL<span class="token punctuation">(</span><span class="token string">&quot;update users set nickName = ?&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>bind<span class="token punctuation">(</span><span class="token string">&quot;xiaoming&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre></div></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/MaLunan/press/edit/dev-mln/docs/sparkstreaming/sparkstreaming.md" target="_blank" rel="noopener noreferrer">在GitHub 上编辑此页！</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="last-updated"><span class="prefix">上次更新时间:</span> <span class="time">1/19/2021, 1:41:59 AM</span></div></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.fdd7a502.js" defer></script><script src="/assets/js/16.375b747e.js" defer></script><script src="/assets/js/18.5d2371a4.js" defer></script>
  </body>
</html>
