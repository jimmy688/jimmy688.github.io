<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>个人博客 | JiiiiG</title>
    <meta name="generator" content="VuePress 1.8.0">
    
    <meta name="description" content="自是年少，韶华倾负">
    
    <link rel="preload" href="/assets/css/0.styles.420b7c1f.css" as="style"><link rel="preload" href="/assets/js/app.fdd7a502.js" as="script"><link rel="preload" href="/assets/js/16.375b747e.js" as="script"><link rel="preload" href="/assets/js/4.e9b44388.js" as="script"><link rel="prefetch" href="/assets/js/10.bbd38b9e.js"><link rel="prefetch" href="/assets/js/11.f49fc7d3.js"><link rel="prefetch" href="/assets/js/12.c5d97aa1.js"><link rel="prefetch" href="/assets/js/13.426d0224.js"><link rel="prefetch" href="/assets/js/14.1f257a58.js"><link rel="prefetch" href="/assets/js/15.be29bb6a.js"><link rel="prefetch" href="/assets/js/17.d02cdd8b.js"><link rel="prefetch" href="/assets/js/18.5d2371a4.js"><link rel="prefetch" href="/assets/js/19.038919a3.js"><link rel="prefetch" href="/assets/js/2.d6257727.js"><link rel="prefetch" href="/assets/js/20.b3582e09.js"><link rel="prefetch" href="/assets/js/21.0c1e826b.js"><link rel="prefetch" href="/assets/js/22.91bff1a5.js"><link rel="prefetch" href="/assets/js/23.faacea60.js"><link rel="prefetch" href="/assets/js/24.69816497.js"><link rel="prefetch" href="/assets/js/25.c9fcaa62.js"><link rel="prefetch" href="/assets/js/26.d28c3abe.js"><link rel="prefetch" href="/assets/js/27.1518da7d.js"><link rel="prefetch" href="/assets/js/28.748a5581.js"><link rel="prefetch" href="/assets/js/29.775019f1.js"><link rel="prefetch" href="/assets/js/3.141002a4.js"><link rel="prefetch" href="/assets/js/30.74e7c570.js"><link rel="prefetch" href="/assets/js/31.190b11f2.js"><link rel="prefetch" href="/assets/js/32.d8f4f116.js"><link rel="prefetch" href="/assets/js/33.c489bc81.js"><link rel="prefetch" href="/assets/js/34.db609d51.js"><link rel="prefetch" href="/assets/js/35.ad3402e6.js"><link rel="prefetch" href="/assets/js/36.45f11923.js"><link rel="prefetch" href="/assets/js/37.b47e0576.js"><link rel="prefetch" href="/assets/js/38.58b934a2.js"><link rel="prefetch" href="/assets/js/39.e4d6bcdf.js"><link rel="prefetch" href="/assets/js/40.555106bc.js"><link rel="prefetch" href="/assets/js/41.4387ceb1.js"><link rel="prefetch" href="/assets/js/42.9bd4aea0.js"><link rel="prefetch" href="/assets/js/43.587e7966.js"><link rel="prefetch" href="/assets/js/44.80285763.js"><link rel="prefetch" href="/assets/js/45.f978da77.js"><link rel="prefetch" href="/assets/js/46.d93e3f2e.js"><link rel="prefetch" href="/assets/js/47.c15bd2aa.js"><link rel="prefetch" href="/assets/js/48.cb55fa72.js"><link rel="prefetch" href="/assets/js/49.d0f4e454.js"><link rel="prefetch" href="/assets/js/5.b90b80cb.js"><link rel="prefetch" href="/assets/js/50.112e8260.js"><link rel="prefetch" href="/assets/js/51.a66bcd03.js"><link rel="prefetch" href="/assets/js/52.0c7cbfb1.js"><link rel="prefetch" href="/assets/js/53.67ef240b.js"><link rel="prefetch" href="/assets/js/54.2c2d082d.js"><link rel="prefetch" href="/assets/js/55.88f19a20.js"><link rel="prefetch" href="/assets/js/56.c726e920.js"><link rel="prefetch" href="/assets/js/57.eaee47c5.js"><link rel="prefetch" href="/assets/js/58.ac15a3ac.js"><link rel="prefetch" href="/assets/js/59.64bdc849.js"><link rel="prefetch" href="/assets/js/6.7eea74ff.js"><link rel="prefetch" href="/assets/js/7.a1370e98.js"><link rel="prefetch" href="/assets/js/8.2e898240.js"><link rel="prefetch" href="/assets/js/9.a2439994.js">
    <link rel="stylesheet" href="/assets/css/0.styles.420b7c1f.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">个人博客 | JiiiiG</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  主页
</a></div><div class="nav-item"><a href="/linux/linux常用命令/01linux常用命令01.html" class="nav-link">
  Linux
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="大数据" class="dropdown-title"><span class="title">大数据</span> <span class="arrow down"></span></button> <button type="button" aria-label="大数据" class="mobile-dropdown-title"><span class="title">大数据</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/hadoop/01hadoop环境搭建/01搭建hadoop集群.html" class="nav-link">
  hadoop
</a></li><li class="dropdown-item"><!----> <a href="/hbase/hbase.html" class="nav-link">
  hbase
</a></li><li class="dropdown-item"><!----> <a href="/flink/flink.html" class="nav-link">
  flink
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程语言" class="dropdown-title"><span class="title">编程语言</span> <span class="arrow down"></span></button> <button type="button" aria-label="编程语言" class="mobile-dropdown-title"><span class="title">编程语言</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/spark/.html" class="nav-link">
  java
</a></li></ul></div></div> <a href="https://github.com/MaLunan/press" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  主页
</a></div><div class="nav-item"><a href="/linux/linux常用命令/01linux常用命令01.html" class="nav-link">
  Linux
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="大数据" class="dropdown-title"><span class="title">大数据</span> <span class="arrow down"></span></button> <button type="button" aria-label="大数据" class="mobile-dropdown-title"><span class="title">大数据</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/hadoop/01hadoop环境搭建/01搭建hadoop集群.html" class="nav-link">
  hadoop
</a></li><li class="dropdown-item"><!----> <a href="/hbase/hbase.html" class="nav-link">
  hbase
</a></li><li class="dropdown-item"><!----> <a href="/flink/flink.html" class="nav-link">
  flink
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程语言" class="dropdown-title"><span class="title">编程语言</span> <span class="arrow down"></span></button> <button type="button" aria-label="编程语言" class="mobile-dropdown-title"><span class="title">编程语言</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/spark/.html" class="nav-link">
  java
</a></li></ul></div></div> <a href="https://github.com/MaLunan/press" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><p>课前准备</p> <p>安装好对应版本的hadoop集群</p> <p>安装好对应版本的zookeeper集群</p> <h2 id="课堂主题"><a href="#课堂主题" class="header-anchor">#</a> 课堂主题</h2> <p>本堂课主要围绕 <strong>spark的基础知识点</strong> 进行讲解。主要包括以下几个方面</p> <ol><li>spark核心概念</li> <li>spark集群架构</li> <li>spark集群安装部署</li> <li>spark-shell的使用</li> <li>通过IDEA开发spark程序</li> <li>RDD弹性分布式数据集的概念</li> <li>RDD弹性分布式数据集的五大属性</li> <li>RDD弹性分布式数据集的算子操作分类</li> <li>RDD弹性分布式数据集的算子操作练习</li> <li>RDD弹性分布式数据集的依赖关系</li> <li>RDD弹性分布式数据集的lineage血统机制</li> <li>RDD弹性分布式数据集的缓存机制</li> <li>spark任务的DAG有向无环图的构建</li> <li>spark任务如何划分stage</li> <li>spark的任务调度流程</li> <li>spark的运行架构</li> <li>基于wordcount程序剖析spark任务提交、划分、调度流程</li></ol> <h2 id="spark是什么"><a href="#spark是什么" class="header-anchor">#</a> spark是什么</h2> <p>&quot;Apache Spark&quot; is a unified analytics engine for large-scale data processing.</p> <p>spark是针对于大规模数据处理的统一分析引擎</p> <p>spark是在Hadoop基础上的改进，是UC Berkeley AMP lab所开源的类Hadoop MapReduce的通用的并行计算框架，Spark基于map reduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。</p> <p>spark是基于内存计算框架，计算速度非常之快，但是它仅仅只是涉及到计算，并没有涉及到数据的存储，后期需要使用spark对接外部的数据源，比如hdfs。</p> <p>注意：spark只做计算不做存储</p> <h2 id="spark的四大特性"><a href="#spark的四大特性" class="header-anchor">#</a> spark的四大特性</h2> <p>查看官网可以了解spark的四大特性，spark官网地址：http://spark.apache.org/</p> <h4 id="速度快"><a href="#速度快" class="header-anchor">#</a> 速度快</h4> <p>spark运行速度相对于hadoop提高100倍,见下图：</p> <p>Apache Spark使用最先进的DAG调度程序，查询优化程序和物理执行引擎，实现批量和流式数据的高性能。</p> <p><img src="/assets/img/image-20200414153227594.48c5d190.png" alt="image-20200414153227594"></p> <h5 id="spark比mr快的2个主要原因-面试题"><a href="#spark比mr快的2个主要原因-面试题" class="header-anchor">#</a> spark比MR快的2个主要原因（面试题）</h5> <h6 id="_1、基于内存"><a href="#_1、基于内存" class="header-anchor">#</a> 1、基于内存</h6> <p>mapreduce任务后期再计算的时候，每一个job的输出结果会落地到磁盘，后续有其他的job需要依赖于前面job的输出结果，这个时候就需要进行大量的磁盘io操作。性能就比较低。</p> <p>spark任务后期再计算的时候，job的输出结果可以保存在内存中，后续有其他的job需要依赖于前面job的输出结果，这个时候就直接从内存中获取得到，避免了磁盘io操作，性能比较高</p> <p>对于spark程序和mapreduce程序都会产生shuffle阶段，在shuffle阶段中它们产生的数据都会落地到磁盘。</p> <h6 id="_2、进程与线程"><a href="#_2、进程与线程" class="header-anchor">#</a> 2、进程与线程</h6> <p>mapreduce任务以进程的方式运行在yarn集群中，比如程序中有100个MapTask，一个task就需要一个进程，这些task要运行就需要开启100个进程。</p> <p>spark任务以线程的方式运行在进程中，比如程序中有100个MapTask，后期一个task就对应一个线程，这里就不再是进程，这些task需要运行，这里可以极端一点：只需要开启1个进程，在这个进程中启动100个线程就可以了。</p> <p>进程中可以启动很多个线程，而开启一个进程与开启一个线程需要的时间和调度代价是不一样。 开启一个进程需要的时间远远大于开启一个线程。</p> <h4 id="易用性"><a href="#易用性" class="header-anchor">#</a> 易用性</h4> <p>可以通过 java/scala/python/R/SQL等不同语言快速去编写spark程序</p> <p><img src="/assets/img/image-20200414153247802.047676e1.png" alt="image-20200414153247802"></p> <h4 id="通用性"><a href="#通用性" class="header-anchor">#</a> 通用性</h4> <p>spark框架不在是一个简单的框架，可以把spark理解成一个spark生态系统，它内部是包含了很多模块，基于不同的应用场景可以选择对应的模块去使用，见下图：</p> <ol><li>sparksql：通过sql去开发spark程序做一些离线分析</li> <li>sparkStreaming：主要是用来解决公司有实时计算的这种场景</li> <li>Mlib：它封装了一些机器学习的算法库</li> <li>Graphx：图计算</li></ol> <p><img src="/assets/img/image-20200414153311063.9e358597.png" alt="image-20200414153311063"></p> <h4 id="兼容性"><a href="#兼容性" class="header-anchor">#</a> 兼容性</h4> <p>spark程序就是一个计算逻辑程序，这个任务要运行就需要计算资源（内存、cpu、磁盘），哪里可以给当前这个任务提供计算资源，就可以把spark程序提交到哪里去运行。</p> <p>目前主要的运行方式是下面的standAlone和yarn。</p> <p>**standAlone：**它是spark自带的独立运行模式，整个任务的资源分配由spark集群的老大Master负责</p> <p>**yarn：**可以把spark程序提交到yarn中运行，整个任务的资源分配由yarn中的老大ResourceManager负责</p> <p>mesos：它也是apache开源的一个类似于yarn的资源调度平台</p> <p><img src="/assets/img/image-20200414153331693.bb28a70b.png" alt="image-20200414153331693"></p> <h2 id="spark集群架构-重要"><a href="#spark集群架构-重要" class="header-anchor">#</a> spark集群架构（重要）</h2> <p><img src="/assets/img/spark.62d0f0f0.png" alt="spark"></p> <ul><li>Driver：执行客户端写好的main方法，它会构建一个名叫SparkContext对象，该对象是所有spark程序的执行入口</li> <li>Application：就是一个spark的应用程序，它是包含了客户端的代码和任务运行的资源信息</li> <li>ClusterManager：给程序提供计算资源的外部服务,在不同的运行平台，ClusterManager也不同，主要有以下3种：
<ul><li>standAlone：它是spark自带的集群模式，整个任务的资源分配由spark集群的老大Master负责</li> <li>yarn：可以把spark程序提交到yarn中运行，整个任务的资源分配由yarn中的老大ResourceManager负责</li> <li>mesos：它也是apache开源的一个类似于yarn的资源调度平台。</li></ul></li> <li>Master：它是整个spark集群的主节点，负责任务资源的分配</li> <li>Worker：它是整个spark集群的从节点，负责任务计算的节点</li> <li>Executor：它是一个进程，它会在worker节点启动该进程（计算资源），一个worker节点可以有多个Executor进程</li> <li>Task：spark任务是以task线程的方式运行在worker节点对应的executor进程中</li></ul> <h2 id="spark集群安装部署"><a href="#spark集群安装部署" class="header-anchor">#</a> spark集群安装部署</h2> <p>搭建spark集群要事先搭建好zookeeper集群，spark会依赖zookeeper集群来实现Master的高可用。</p> <h4 id="第一步-下载安装包"><a href="#第一步-下载安装包" class="header-anchor">#</a> 第一步：下载安装包</h4> <p>下载安装包：spark-2.3.3-bin-hadoop2.7.tgz</p> <p>下载地址：</p> <p>https://archive.apache.org/dist/spark/spark-2.3.3/spark-2.3.3-bin-hadoop2.7.tgz</p> <h4 id="第二步-解压安装包"><a href="#第二步-解压安装包" class="header-anchor">#</a> 第二步：解压安装包</h4> <p>上传安装包到node01,解压，修改名称：</p> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token builtin class-name">cd</span> /kkb/soft
rz

<span class="token function">tar</span> -zxvf /kkb/soft/spark-2.3.3-bin-hadoop2.7.tgz -C /kkb/install/
<span class="token builtin class-name">cd</span> /kkb/install
<span class="token function">mv</span> spark-2.3.3-bin-hadoop2.7 spark
</code></pre></div><h4 id="第三步-修改配置文件"><a href="#第三步-修改配置文件" class="header-anchor">#</a> 第三步：修改配置文件</h4> <p>进入到spark的安装目录下对应的conf文件夹</p> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token builtin class-name">cd</span> /kkb/install/spark/conf
<span class="token function">mv</span> spark-env.sh.template spark-env.sh
<span class="token function">vim</span> spark-env.sh
</code></pre></div><p>添加下面内容</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#配置java的环境变量</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/kkb/install/jdk1.8.0_141
<span class="token comment">#配置zk相关信息</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_DAEMON_JAVA_OPTS</span><span class="token operator">=</span><span class="token string">&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER  -Dspark.deploy.zookeeper.url=node01:2181,node02:2181,node03:2181  -Dspark.deploy.zookeeper.dir=/spark&quot;</span>
</code></pre></div><p>说明：</p> <ol><li>-Dspark.deploy.recoveryMode=ZOOKEEPER 指定spark的恢复模式为ZOOKEEPER</li> <li>-Dspark.deploy.zookeeper.url=node01:2181,node02:2181,node03:2181指定zookeeper集群的地址</li> <li>-Dspark.deploy.zookeeper.dir=/spark&quot; 指定spark在zookeeper中创建的节点（文件），随便设置一个名字即可</li></ol> <p>设定spark的从节点：</p> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token function">mv</span> slaves.template slaves
<span class="token function">vim</span> slaves 
</code></pre></div><div class="language-sh extra-class"><pre class="language-sh"><code><span class="token comment">#指定spark集群的worker节点</span>
node02
node03
</code></pre></div><h4 id="第四步-分发安装目录到其他机器"><a href="#第四步-分发安装目录到其他机器" class="header-anchor">#</a> 第四步：分发安装目录到其他机器</h4> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token function">scp</span> -r /kkb/install/spark node02:/kkb/install
<span class="token function">scp</span> -r /kkb/install/spark node03:/kkb/install
</code></pre></div><h4 id="第五步-修改spark环境变量"><a href="#第五步-修改spark环境变量" class="header-anchor">#</a> 第五步：修改spark环境变量</h4> <p>所有节点修改/etc/profile</p> <div class="language- extra-class"><pre class="language-text"><code>sudo vim /etc/profile
</code></pre></div><div class="language-shell extra-class"><pre class="language-shell"><code><span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_HOME</span><span class="token operator">=</span>/kkb/install/spark
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$SPARK_HOME</span>/bin:<span class="token variable">$SPARK_HOME</span>/sbin
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>source /etc/profile
</code></pre></div><h2 id="spark集群的启动和停止"><a href="#spark集群的启动和停止" class="header-anchor">#</a> spark集群的启动和停止</h2> <p>必须先启动zookeeper集群</p> <h4 id="启动spark"><a href="#启动spark" class="header-anchor">#</a> 启动spark</h4> <p>在任意一台服务器来执行下列脚本（条件：需要任意2台机器之间实现ssh免密登录），</p> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token variable">$SPARK_HOME</span>/sbin/start-all.sh
</code></pre></div><p>在哪里启动这个脚本，就会在当前该机器启动一个Master进程，整个集群的worker进程的启动由slaves文件决定</p> <p>后期可以在其他机器单独在启动master,实现高可用：</p> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token variable">$SPARK_HOME</span>/sbin/start-master.sh
</code></pre></div><p>验证是否成功开启：</p> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token punctuation">[</span>hadoop@node01 conf<span class="token punctuation">]</span>$ xcall jps
************<span class="token operator">=</span> node01 jps ************<span class="token operator">=</span>
<span class="token number">7892</span> Jps
<span class="token number">7610</span> QuorumPeerMain
<span class="token number">7739</span> Master
************<span class="token operator">=</span> node02 jps ************<span class="token operator">=</span>
<span class="token number">7857</span> Master
<span class="token number">7941</span> Jps
<span class="token number">7751</span> Worker
<span class="token number">7611</span> QuorumPeerMain
************<span class="token operator">=</span> node03 jps ************<span class="token operator">=</span>
<span class="token number">7921</span> Jps
<span class="token number">7802</span> Worker
<span class="token number">7643</span> QuorumPeerMain
</code></pre></div><h4 id="停止spark"><a href="#停止spark" class="header-anchor">#</a> 停止spark</h4> <p>在处于active Master主节点执行</p> <div class="language- extra-class"><pre class="language-text"><code>$SPARK_HOME/sbin/stop-all.sh
</code></pre></div><p>在处于standBy Master主节点执行</p> <div class="language- extra-class"><pre class="language-text"><code>$SPARK_HOME/sbin/stop-master.sh
</code></pre></div><h2 id="spark高可用思考问题"><a href="#spark高可用思考问题" class="header-anchor">#</a> spark高可用思考问题</h2> <p>问题思考：</p> <p>1、如何恢复到上一次活着master挂掉之前的状态?</p> <div class="language- extra-class"><pre class="language-text"><code>在高可用模式下，整个spark集群就有很多个master，其中只有一个master被zk选举成活着的master，其他的多个master都处于standby，同时把整个spark集群的元数据信息通过zk中节点进行保存。

后期如果活着的master挂掉。首先zk会感知到活着的master挂掉，下面开始在多个处于standby中的master进行选举，再次产生一个活着的master，这个活着的master会读取保存在zk节点中的spark集群元数据信息，恢复到上一次master的状态。整个过程在恢复的时候经历过了很多个不同的阶段，每个阶段都需要一定时间，最终恢复到上个活着的master的状态，整个恢复过程一般需要1-2分钟。
</code></pre></div><p>2、在master的恢复阶段对任务的影响?</p> <div class="language- extra-class"><pre class="language-text"><code>a）对已经运行的任务是没有任何影响
   由于该任务正在运行，说明它已经拿到了计算资源，这个时候就不需要master。
   	  
b) 对即将要提交的任务是有影响
  由于该任务需要有计算资源，这个时候会找活着的master去申请计算资源，由于没有一个活着的master,该任务是获取不到计算资源，也就是任务无法运行。
</code></pre></div><p><img src="/assets/img/image-20200414175158839.c699e51e.png" alt="image-20200414175158839"></p> <h2 id="spark集群的web管理界面"><a href="#spark集群的web管理界面" class="header-anchor">#</a> spark集群的web管理界面</h2> <p>当启动好spark集群之后，可以访问这样一个地址：http://...:8080</p> <p>比如说，如果node01/node02都启动了Master,则可以访问地址：http://node01:8080和http://node02:8080</p> <p>可以通过这个web界面观察到很多信息</p> <ul><li>整个spark集群的详细信息</li> <li>整个spark集群总的资源信息</li> <li>整个spark集群已经使用的资源信息</li> <li>整个spark集群还剩的资源信息</li> <li>整个spark集群正在运行的任务信息</li> <li>整个spark集群已经完成的任务信息</li></ul> <p>node01：</p> <p><img src="/assets/img/image-20200414172049366.4e524e62.png" alt="image-20200414172049366"></p> <p>node02:</p> <p><img src="/assets/img/image-20200414172114655.4a6e7e96.png" alt="image-20200414172114655"></p> <p>整个spark集群的计算资源是把所有worker节点的资源进行累加，下面是老师的截图：</p> <p><img src="/assets/img/image-20200414172533211.519ada93.png" alt="image-20200414172533211"></p> <h2 id="初识spark程序"><a href="#初识spark程序" class="header-anchor">#</a> 初识spark程序</h2> <h4 id="普通模式提交-指定活着的master地址"><a href="#普通模式提交-指定活着的master地址" class="header-anchor">#</a> 普通模式提交 (指定活着的master地址)</h4> <p>指定的必须是alive状态的Master地址，否则会执行失败。</p> <div class="language- extra-class"><pre class="language-text"><code>cd /kkb/install/spark
</code></pre></div><div class="language-shell extra-class"><pre class="language-shell"><code>bin/spark-submit <span class="token punctuation">\</span>
--class org.apache.spark.examples.SparkPi <span class="token punctuation">\</span>
--master spark://node01:7077 <span class="token punctuation">\</span>
--executor-memory 1G <span class="token punctuation">\</span>
--total-executor-cores <span class="token number">2</span> <span class="token punctuation">\</span>
examples/jars/spark-examples_2.11-2.3.3.jar <span class="token punctuation">\</span>
<span class="token number">10</span>


<span class="token comment">####参数说明</span>
--class：指定包含main方法的主类
--master：指定spark集群master地址
--executor-memory：指定任务在运行的时候需要的每一个executor内存大小
--total-executor-cores： 指定任务在运行的时候需要总的cpu核数
examples/jars/spark-examples_2.11-2.3.3.jar :是spark程序打包成的jar包,spark提供的计算圆周率的测试包
<span class="token number">10</span> ：spark程序要用到的参数
</code></pre></div><p>运行结果查看：</p> <p><img src="/assets/img/image-20200414175405614.55fced14.png" alt="image-20200414175405614"></p> <p><img src="/assets/img/image-20200414175505390.021e8a4e.png" alt="image-20200414175505390"></p> <h4 id="高可用模式提交-集群有很多个master"><a href="#高可用模式提交-集群有很多个master" class="header-anchor">#</a> 高可用模式提交 (集群有很多个master）</h4> <p>当Master有多个的时候，上面的提交方式就显得很麻烦了，因为要找到alive状态的Master很费时间。</p> <p>企业中，一般都是固定几台机器来启动Master,然后使用高可用模式提交，这个模式会<strong>轮询</strong>尝试连接Master列表中的Master,连接成功了就将spark程序提交上去。</p> <div class="language-shell extra-class"><pre class="language-shell"><code>bin/spark-submit <span class="token punctuation">\</span>
--class org.apache.spark.examples.SparkPi <span class="token punctuation">\</span>
--master spark://node01:7077,node02:7077,node03:7077 <span class="token punctuation">\</span>
--executor-memory 1G <span class="token punctuation">\</span>
--total-executor-cores <span class="token number">2</span> <span class="token punctuation">\</span>
examples/jars/spark-examples_2.11-2.3.3.jar <span class="token punctuation">\</span>
<span class="token number">10</span>

spark集群中有很多个master，并不知道哪一个master是活着的master，即使你知道哪一个master是活着的master，它也有可能下一秒就挂掉，这里就可以把所有master都罗列出来
--master spark://node01:7077,node02:7077,node03:7077

后期程序会轮训整个master列表，最终找到活着的master，然后向它申请计算资源，最后运行程序。
</code></pre></div><h2 id="spark-shell使用"><a href="#spark-shell使用" class="header-anchor">#</a> spark-shell使用</h2> <h4 id="运行spark-shell-master-local-n-读取本地文件"><a href="#运行spark-shell-master-local-n-读取本地文件" class="header-anchor">#</a> 运行spark-shell --master local[N] 读取本地文件</h4> <p>选项说明：</p> <ul><li>local 表示程序在本地进行计算，跟spark集群目前没有任何关系</li> <li>N  它是一个正整数，表示使用N个线程参与任务计算</li> <li>local[N] 表示本地采用N个线程计算任务</li></ul> <p>spark-shell --master local[2]</p> <ul><li>默认会产生一个SparkSubmit进程</li></ul> <p>示例： 读取本地文件进行单词统计</p> <h6 id="第一步-创建文件"><a href="#第一步-创建文件" class="header-anchor">#</a> 第一步：创建文件</h6> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token punctuation">[</span>hadoop@node01 ~<span class="token punctuation">]</span>$ <span class="token builtin class-name">cd</span> /tmp
<span class="token punctuation">[</span>hadoop@node01 tmp<span class="token punctuation">]</span>$ <span class="token function">vi</span> words.txt
hadoop spark spark
flume flink hadoop hadoop
</code></pre></div><h6 id="第二步-开启spark-shell"><a href="#第二步-开启spark-shell" class="header-anchor">#</a> 第二步：开启spark-shell</h6> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token punctuation">[</span>hadoop<span class="token annotation punctuation">@node01</span> <span class="token operator">~</span><span class="token punctuation">]</span>$ spark<span class="token operator">-</span>shell <span class="token operator">--</span>master local<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
<span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">14</span> <span class="token number">18</span><span class="token operator">:</span><span class="token number">15</span><span class="token operator">:</span><span class="token number">00</span> WARN  NativeCodeLoader<span class="token operator">:</span><span class="token number">62</span> <span class="token operator">-</span> Unable to <span class="token namespace">load</span> native<span class="token operator">-</span>hadoop library <span class="token keyword">for</span> your platform<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> using builtin<span class="token operator">-</span>java classes where applicable
Setting default log level to <span class="token string">&quot;WARN&quot;</span><span class="token punctuation">.</span>
To adjust logging level use sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span>newLevel<span class="token punctuation">)</span><span class="token punctuation">.</span> For SparkR<span class="token punctuation">,</span> use setLogLevel<span class="token punctuation">(</span>newLevel<span class="token punctuation">)</span><span class="token punctuation">.</span>
Spark context Web UI available at http<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>node01<span class="token operator">:</span><span class="token number">4040</span>
Spark context available as <span class="token string">'sc'</span> <span class="token punctuation">(</span>master <span class="token operator">=</span> local<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> app id <span class="token operator">=</span> local<span class="token operator">-</span><span class="token number">1586859312537</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
Spark session available as <span class="token string">'spark'</span><span class="token punctuation">.</span>
Welcome to
      ____              __
     <span class="token operator">/</span> __<span class="token operator">/</span>__  ___ _____<span class="token operator">/</span> <span class="token operator">/</span>__
    _\ \<span class="token operator">/</span> _ \<span class="token operator">/</span> _ `<span class="token operator">/</span> __<span class="token operator">/</span>  <span class="token symbol">'_</span><span class="token operator">/</span>
   <span class="token operator">/</span>___<span class="token operator">/</span> <span class="token punctuation">.</span>__<span class="token operator">/</span>\_<span class="token punctuation">,</span>_<span class="token operator">/</span>_<span class="token operator">/</span> <span class="token operator">/</span>_<span class="token operator">/</span>\_\   version <span class="token number">2.3</span><span class="token number">.3</span>
      <span class="token operator">/</span>_<span class="token operator">/</span>
         
Using Scala version <span class="token number">2.11</span><span class="token number">.8</span> <span class="token punctuation">(</span>Java HotSpot<span class="token punctuation">(</span>TM<span class="token punctuation">)</span> <span class="token number">64</span><span class="token operator">-</span>Bit Server VM<span class="token punctuation">,</span> Java <span class="token number">1.8</span><span class="token number">.0</span>_141<span class="token punctuation">)</span>
Type in expressions to <span class="token namespace">have</span> them evaluated<span class="token punctuation">.</span>
Type <span class="token operator">:</span>help <span class="token keyword">for</span> more information<span class="token punctuation">.</span>

scala<span class="token operator">&gt;</span> 
</code></pre></div><p>说明：</p> <ol><li>Spark context available as 'sc'，启动spark shell的时候，Spark context被初始化为了'sc'</li></ol> <h6 id="第三步-编写scala程序"><a href="#第三步-编写scala程序" class="header-anchor">#</a> 第三步：编写scala程序</h6> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;file:///tmp/words.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">=&gt;</span>x<span class="token operator">+</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span>collect
res0<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>flink<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>spark<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>hadoop<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>flume<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">//可以简写成下面：</span>
sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;file:///tmp/words.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span><span class="token punctuation">.</span>collect
</code></pre></div><p>说明：</p> <ol><li>sc.textFile()——加载数据  大致格式：hadoop spark spark</li> <li>flatMap(x=&gt;x.split(&quot; &quot;))——扁平化： 大致格式：List(hadoop,spark,spark)</li> <li>map(x=&gt;(x,1))——映射 大致格式：List((hadoop,1),(spark,1),(spark,1))</li> <li>reduceByKey((x,y)=&gt;x+y)——按Key聚合  大致格式：(hadoop,List(1,1))-----&gt;(hadoop,2)</li> <li>collect——收集打印</li> <li>结果是被装在Array里面的</li></ol> <h4 id="运行spark-shell-master-local-n-读取hdfs上文件"><a href="#运行spark-shell-master-local-n-读取hdfs上文件" class="header-anchor">#</a> 运行spark-shell --master local[N] 读取HDFS上文件</h4> <h6 id="spark整合hdfs"><a href="#spark整合hdfs" class="header-anchor">#</a> spark整合HDFS</h6> <p>在node01上修改配置文件</p> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token function">vi</span> /kkb/install/spark/conf/spark-env.sh 
</code></pre></div><div class="language-shell extra-class"><pre class="language-shell"><code><span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_CONF_DIR</span><span class="token operator">=</span>/kkb/install/hadoop-2.6.0-cdh5.14.2/etc/hadoop
</code></pre></div><p>分发到其他节点</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token function">sudo</span> <span class="token function">scp</span> spark-env.sh node02:/kkb/install/spark/conf
<span class="token function">sudo</span> <span class="token function">scp</span> spark-env.sh node03:/kkb/install/spark/conf
</code></pre></div><p>示例：读取HDFS文件进行单词统计</p> <h6 id="第一步-将文件上传到hdfs"><a href="#第一步-将文件上传到hdfs" class="header-anchor">#</a> 第一步：将文件上传到hdfs</h6> <p>开启hadoop</p> <div class="language- extra-class"><pre class="language-text"><code>hadoop.sh start
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>hdfs dfs -put /tmp/words.txt /
</code></pre></div><h6 id="第二步-开启spark-shell-2"><a href="#第二步-开启spark-shell-2" class="header-anchor">#</a> 第二步：开启spark shell</h6> <div class="language- extra-class"><pre class="language-text"><code>spark-shell --master local[2]
</code></pre></div><h6 id="第三步-编写spark程序"><a href="#第三步-编写spark程序" class="header-anchor">#</a> 第三步：编写spark程序</h6> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;hdfs://node01:8020/words.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span><span class="token punctuation">.</span>collect
res5<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>flink<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>spark<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>hadoop<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>flume<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">//简写：</span>
sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/words.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span><span class="token punctuation">.</span>collect
</code></pre></div><h4 id="运行spark-shell-指定集群中活着master"><a href="#运行spark-shell-指定集群中活着master" class="header-anchor">#</a> 运行spark-shell 指定集群中活着master</h4> <p>上面的--local方式是本地运行的，没有使用到spark集群，当使用--master指定alive状态的master时就是使用spark集群来运行了。</p> <p>开启spark shell</p> <div class="language-sh extra-class"><pre class="language-sh"><code>spark-shell --master spark://node01:7077 --executor-memory 1g  --total-executor-cores <span class="token number">2</span>

--master spark://node01:7077  <span class="token comment">#指定活着的master地址</span>
--executor-memory 1g    <span class="token comment">#指定每一个executor进程的内存大小</span>
--total-executor-cores <span class="token number">4</span>    <span class="token comment">#指定总的executor进程cpu核数</span>
</code></pre></div><p>开启spark shell，访问web端，会显示（local方式运行spark shell时是不会显示的）：</p> <p><img src="/assets/img/image-20200414194201687.1cc47e96.png" alt="image-20200414194201687"></p> <p>示例1：读取HDFS上文件进行单词统计</p> <div class="language-scala extra-class"><pre class="language-scala"><code>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;hdfs://node01:8020/words.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span><span class="token punctuation">.</span>collect

<span class="token comment">//实现读取hdfs上文件之后，需要把计算的结果保存到hdfs上</span>
sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/words.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span><span class="token punctuation">.</span>saveAsTextFile<span class="token punctuation">(</span><span class="token string">&quot;/out&quot;</span><span class="token punctuation">)</span>
</code></pre></div><p>示例2：读取HDFS上文件进行单词统计并将结果保存到HDFS</p> <div class="language-scala extra-class"><pre class="language-scala"><code>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;hdfs://node01:8020/words.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span><span class="token punctuation">.</span>saveAsTextFile<span class="token punctuation">(</span><span class="token string">&quot;hdfs://node01:8020/spark_out&quot;</span><span class="token punctuation">)</span>
</code></pre></div><p>查看保存到HDFS的结果,结果被存放到两个文件中：</p> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token punctuation">[</span>hadoop@node01 tmp<span class="token punctuation">]</span>$ hdfs dfs -ls /spark_out
Found <span class="token number">3</span> items
-rw-r--r--   <span class="token number">3</span> hadoop supergroup          <span class="token number">0</span> <span class="token number">2020</span>-04-14 <span class="token number">19</span>:46 /spark_out/_SUCCESS
-rw-r--r--   <span class="token number">3</span> hadoop supergroup         <span class="token number">10</span> <span class="token number">2020</span>-04-14 <span class="token number">19</span>:46 /spark_out/part-00000
-rw-r--r--   <span class="token number">3</span> hadoop supergroup         <span class="token number">31</span> <span class="token number">2020</span>-04-14 <span class="token number">19</span>:46 /spark_out/part-00001
<span class="token punctuation">[</span>hadoop@node01 tmp<span class="token punctuation">]</span>$ hdfs dfs -cat /spark_out/part-00000
<span class="token punctuation">(</span>flink,1<span class="token punctuation">)</span>
<span class="token punctuation">[</span>hadoop@node01 tmp<span class="token punctuation">]</span>$ hdfs dfs -cat /spark_out/part-00001
<span class="token punctuation">(</span>spark,2<span class="token punctuation">)</span>
<span class="token punctuation">(</span>hadoop,3<span class="token punctuation">)</span>
<span class="token punctuation">(</span>flume,1<span class="token punctuation">)</span>

<span class="token comment">#为什么结果会保存到两个文件中？后面会讲</span>
</code></pre></div><h2 id="通过idea开发spark程序"><a href="#通过idea开发spark程序" class="header-anchor">#</a> 通过IDEA开发spark程序</h2> <h4 id="构建maven工程"><a href="#构建maven工程" class="header-anchor">#</a> 构建maven工程</h4> <h6 id="创建src-main-scala-和-src-test-scala-目录"><a href="#创建src-main-scala-和-src-test-scala-目录" class="header-anchor">#</a> 创建src/main/scala 和 src/test/scala 目录</h6> <p><img src="/assets/img/1568613632045.bf4edee5.png" alt="1568613632045"></p> <h6 id="添加pom依赖"><a href="#添加pom依赖" class="header-anchor">#</a> 添加pom依赖</h6> <p>说明：</p> <ol><li>创建maven工程后，设定maven为自己安装的maven，并在确保settings.xml里面设置了镜像地址为阿里云</li> <li>如果下载不下来scala-maven-plugin或者maven-shade-plugin，则自己去网上搜索下载，然后存放到本地仓库repository的对应目录，没有对应的目录就自己创建。</li> <li>比如，import不了scala-maven-plugin，那就将从网上下载的plugin的jar包存放到以下目录：E:\BaiduNetdiskDownload\repository\net\alchim31\maven\scala-maven-plugin</li> <li>下载maven依赖的好网址：https://mvnrepository.com/</li></ol> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-core_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.3.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>


 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>sourceDirectory</span><span class="token punctuation">&gt;</span></span>src/main/scala<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>sourceDirectory</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>testSourceDirectory</span><span class="token punctuation">&gt;</span></span>src/test/scala<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>testSourceDirectory</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>net.alchim31.maven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>scala-maven-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.2.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>compile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>testCompile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>args</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span><span class="token punctuation">&gt;</span></span>-dependencyfile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>arg</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>arg</span><span class="token punctuation">&gt;</span></span>${project.build.directory}/.scala_dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>arg</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>args</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>maven-shade-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.4.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">&gt;</span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>shade<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>filters</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>filter</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifact</span><span class="token punctuation">&gt;</span></span>*:*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifact</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>excludes</span><span class="token punctuation">&gt;</span></span>
                                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>META-INF/*.SF<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>META-INF/*.DSA<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>META-INF/*.RSA<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>excludes</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>filter</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>filters</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>transformers</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>transformer</span> <span class="token attr-name">implementation</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">&quot;</span>org.apache.maven.plugins.shade.resource.ManifestResourceTransformer<span class="token punctuation">&quot;</span></span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mainClass</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mainClass</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>transformer</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>transformers</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">&gt;</span></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><h4 id="spark单词统计-scala-本地运行"><a href="#spark单词统计-scala-本地运行" class="header-anchor">#</a> spark单词统计（scala/本地运行)</h4> <p>在windows创建文件&quot;F:\test\aa.txt&quot;</p> <div class="language- extra-class"><pre class="language-text"><code>hadoop spark spark
flume hadoop flink
hive spark hadoop
spark hbase
</code></pre></div><p>创建object,代码开发：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> SparkWordCount <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    
    <span class="token comment">//构建sparkConf对象 设置application名称和master地址</span>
    <span class="token keyword">val</span> sConf<span class="token operator">:</span>SparkConf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;WordCount&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    
    
    <span class="token comment">//构建sparkContext对象,该对象非常重要，它是所有spark程序的执行入口</span>
    <span class="token comment">// 它内部会构建DAGScheduler和 TaskScheduler对象</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sConf<span class="token punctuation">)</span>
      
    <span class="token comment">//设置日志输出级别</span>
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;warn&quot;</span><span class="token punctuation">)</span>
    
    <span class="token comment">//读取数据文件</span>
    <span class="token keyword">val</span> data<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;F:\\test\\aa.txt&quot;</span><span class="token punctuation">)</span>
    
    <span class="token comment">//切分每一行，获取所有单词</span>
    <span class="token keyword">val</span> words<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token operator">=</span>data<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment">//每个单词计为1</span>
    <span class="token keyword">val</span> wordAndOne<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>words<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment">//将相同单词出现的1累加</span>
    <span class="token keyword">val</span> res<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>wordAndOne<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">=&gt;</span>x<span class="token operator">+</span>y<span class="token punctuation">)</span>
    
    <span class="token comment">//按照单词出现的次数降序排列  第二个参数默认是true表示升序，设置为false表示降序</span>
    <span class="token keyword">val</span> res_sort<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>res<span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>_2<span class="token punctuation">,</span><span class="token boolean">false</span><span class="token punctuation">)</span>
    
    <span class="token comment">//收集数据</span>
    <span class="token keyword">val</span> res_coll<span class="token operator">:</span>Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>res_sort<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
      
    <span class="token comment">//打印</span>
    res_coll<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
      
    <span class="token comment">//关闭spark Context</span>
    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p>运行输出结果为：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token punctuation">(</span>spark<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>hadoop<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>hive<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>flink<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>flume<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>hbase<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="spark单词统计-scala-集群运行"><a href="#spark单词统计-scala-集群运行" class="header-anchor">#</a> spark单词统计（scala/集群运行)</h4> <p>集群运行与本地运行的代码开发很接近，本次集群运行相对于上面的本地运行代码，修改的地方有：</p> <ol><li>new SparkConf().setAppName(&quot;WordCount&quot;)没有加.setMaster(&quot;local[2]&quot;)</li> <li>sc.textFile(args(0))数据输入路径采用动态传参</li> <li>不再有数据收集,即.collect()</li> <li>res_sort.saveAsTextFile(args(1))结果输出路径采用动态传参</li></ol> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> SparkWordCount <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> sConf<span class="token operator">:</span>SparkConf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;WordCount&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sConf<span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;warn&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> data<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span>args<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> words<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token operator">=</span>data<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> wordAndOne<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>words<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> res<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>wordAndOne<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">=&gt;</span>x<span class="token operator">+</span>y<span class="token punctuation">)</span>
    <span class="token keyword">val</span> res_sort<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>res<span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>_2<span class="token punctuation">,</span><span class="token boolean">false</span><span class="token punctuation">)</span>
    res_sort<span class="token punctuation">.</span>saveAsTextFile<span class="token punctuation">(</span>args<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>打成jar包提交到集群中运行</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token punctuation">[</span>hadoop@node01 tmp<span class="token punctuation">]</span>$ spark-submit --master spark://node01:7077,node02:7077 <span class="token punctuation">\</span>
--class SparkWordCount <span class="token punctuation">\</span>
--executor-memory 1g <span class="token punctuation">\</span>
--total-executor-cores <span class="token number">2</span> <span class="token punctuation">\</span>
/tmp/original-MySparkDemo-1.0-SNAPSHOT.jar <span class="token punctuation">\</span>
/words.txt /spark_out1
</code></pre></div><p>说明：</p> <ol><li>运行jar包前，要先创建好数据文件/words.txt</li> <li>/words.txt指的是hdfs的路径（因为之前spark整合了hdfs)</li> <li>/out也是hdfs的路径</li> <li>/tmp/original-MySparkDemo-1.0-SNAPSHOT.jar是linux的本地路径</li></ol> <h4 id="spark单词统计-java-本地运行-todo"><a href="#spark单词统计-java-本地运行-todo" class="header-anchor">#</a> spark单词统计（JAVA/本地运行)TODO</h4> <p>代码开发</p> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>kaikeba</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token class-name">SparkConf</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span></span><span class="token class-name">JavaPairRDD</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span></span><span class="token class-name">JavaRDD</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span></span><span class="token class-name">JavaSparkContext</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>function<span class="token punctuation">.</span></span><span class="token class-name">FlatMapFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>function<span class="token punctuation">.</span></span><span class="token class-name">Function2</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>function<span class="token punctuation">.</span></span><span class="token class-name">PairFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">scala<span class="token punctuation">.</span></span><span class="token class-name">Tuple2</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Arrays</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Iterator</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">List</span><span class="token punctuation">;</span>

<span class="token comment">//todo: 利用java语言开发spark的单词统计程序</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">JavaWordCount</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">//1、创建SparkConf对象</span>
        <span class="token class-name">SparkConf</span> sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">&quot;JavaWordCount&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//2、构建JavaSparkContext对象</span>
        <span class="token class-name">JavaSparkContext</span> jsc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">JavaSparkContext</span><span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//3、读取数据文件</span>
        <span class="token class-name">JavaRDD</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> data <span class="token operator">=</span> jsc<span class="token punctuation">.</span><span class="token function">textFile</span><span class="token punctuation">(</span><span class="token string">&quot;E:\\words.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//4、切分每一行获取所有的单词   scala:  data.flatMap(x=&gt;x.split(&quot; &quot;))</span>
        <span class="token class-name">JavaRDD</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> wordsJavaRDD <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlatMapFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">public</span> <span class="token class-name">Iterator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> <span class="token function">call</span><span class="token punctuation">(</span><span class="token class-name">String</span> line<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
                <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> words <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">return</span> <span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">iterator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//5、每个单词计为1    scala:  wordsJavaRDD.map(x=&gt;(x,1))</span>
        <span class="token class-name">JavaPairRDD</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> wordAndOne <span class="token operator">=</span> wordsJavaRDD<span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">PairFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">public</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> <span class="token function">call</span><span class="token punctuation">(</span><span class="token class-name">String</span> word<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
                <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//6、相同单词出现的1累加    scala:  wordAndOne.reduceByKey((x,y)=&gt;x+y)</span>
        <span class="token class-name">JavaPairRDD</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> result <span class="token operator">=</span> wordAndOne<span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Function2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">public</span> <span class="token class-name">Integer</span> <span class="token function">call</span><span class="token punctuation">(</span><span class="token class-name">Integer</span> v1<span class="token punctuation">,</span> <span class="token class-name">Integer</span> v2<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
                <span class="token keyword">return</span> v1 <span class="token operator">+</span> v2<span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//按照单词出现的次数降序 (单词，次数)  --&gt;(次数,单词).sortByKey----&gt; (单词，次数)</span>
        <span class="token class-name">JavaPairRDD</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> reverseJavaRDD <span class="token operator">=</span> result<span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">PairFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">public</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> <span class="token function">call</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> t<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
                <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>t<span class="token punctuation">.</span>_2<span class="token punctuation">,</span> t<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">JavaPairRDD</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> sortedRDD <span class="token operator">=</span> reverseJavaRDD<span class="token punctuation">.</span><span class="token function">sortByKey</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">PairFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">public</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> <span class="token function">call</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> t<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{</span>
                <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>t<span class="token punctuation">.</span>_2<span class="token punctuation">,</span> t<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//7、收集打印</span>
        <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> finalResult <span class="token operator">=</span> sortedRDD<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> t <span class="token operator">:</span> finalResult<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;单词：&quot;</span><span class="token operator">+</span>t<span class="token punctuation">.</span>_1 <span class="token operator">+</span><span class="token string">&quot;\t次数：&quot;</span><span class="token operator">+</span>t<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        jsc<span class="token punctuation">.</span><span class="token function">stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><h2 id="spark学习推荐"><a href="#spark学习推荐" class="header-anchor">#</a> spark学习推荐</h2> <p>看书：《图解spark》</p> <p>看spark官网：http://spark.apache.org/</p> <h2 id="spark补充1"><a href="#spark补充1" class="header-anchor">#</a> spark补充1</h2> <p>用yarn运行spark程序,而不是用Master运行时，就跟spark集群没多大关系了。</p> <p>spark程序和MapReduce程序一样，本质上都是一个java程序，都有自己的计算逻辑，用yarn运行spark程序时，提交job的方式还是spark-submit,spark程序的计算还是在内存中，很多东西都不变，只是将Master换成了yarn。</p> <p>yarn可理解成一个资源统一调度框架，不仅仅可以为MapReduce任务分配资源，还可以为spark等任务分配计算资源。</p> <h2 id="rdd"><a href="#rdd" class="header-anchor">#</a> RDD</h2> <h3 id="rdd是什么"><a href="#rdd是什么" class="header-anchor">#</a> RDD是什么</h3> <p>RDD（Resilient Distributed Dataset）叫做<strong>弹性分布式数据集</strong>，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合。<strong>RDD是spark core的底层核心</strong>。</p> <ul><li><strong>Dataset</strong>:就是一个集合，存储很多数据.</li> <li><strong>Distributed</strong>：它内部的元素进行了分布式存储，方便于后期进行分布式计算.</li> <li><strong>Resilient</strong>：表示弹性，rdd的数据是可以保存在内存或者是磁盘中.</li></ul> <h3 id="rdd的五大属性-重要"><a href="#rdd的五大属性-重要" class="header-anchor">#</a> RDD的五大属性（重要）</h3> <p>ctrl+左击查看RDD的部分源码（如果看不了就download source),源码中对RDD的描述如下：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">/**
 * A Resilient Distributed Dataset (RDD), the basic abstraction in Spark. Represents an immutable,
 * partitioned collection of elements that can be operated on in parallel. This class contains the
 * basic operations available on all RDDs, such as `map`, `filter`, and `persist`. In addition,
 * [[org.apache.spark.rdd.PairRDDFunctions]] contains operations available only on RDDs of key-value
 * pairs, such as `groupByKey` and `join`;
 * [[org.apache.spark.rdd.DoubleRDDFunctions]] contains operations available only on RDDs of
 * Doubles; and
 * [[org.apache.spark.rdd.SequenceFileRDDFunctions]] contains operations available on RDDs that
 * can be saved as SequenceFiles.
 * All operations are automatically available on any RDD of the right type (e.g. RDD[(Int, Int)])
 * through implicit.
 *
 * Internally, each RDD is characterized by five main properties:
 *
 *  - A list of partitions
 *  - A function for computing each split
 *  - A list of dependencies on other RDDs
 *  - Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)
 *  - Optionally, a list of preferred locations to compute each split on (e.g. block locations for
 *    an HDFS file)
 *
 * All of the scheduling and execution in Spark is done based on these methods, allowing each RDD
 * to implement its own way of computing itself. Indeed, users can implement custom RDDs (e.g. for
 * reading data from a new storage system) by overriding these functions. Please refer to the
 * &lt;a href=&quot;http://people.csail.mit.edu/matei/papers/2012/nsdi_spark.pdf&quot;&gt;Spark paper&lt;/a&gt;
 * for more details on RDD internals.
 */</span>
</code></pre></div><p>从上面源码中，可以得到RDD的五大属性：</p> <h4 id="属性1-a-list-of-partitions"><a href="#属性1-a-list-of-partitions" class="header-anchor">#</a> 属性1：A list of partitions</h4> <p>一个分区列表，这里表示一个rdd有很多分区，每一个分区内部是包含了该RDD的部分数据，spark中任务是以task线程的方式运行， 一个分区就对应一个task线程。</p> <p><img src="/assets/img/image-20200415130448439.1b2a2653.png" alt="image-20200415130448439"></p> <p>用户可以在创建RDD时指定RDD的分区个数，如果没有指定，那么就会采用默认值。</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd<span class="token operator">=</span>sparkContext<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/words.txt&quot;</span><span class="token punctuation">)</span>
</code></pre></div><p>分区数的默认值的计算公式如下：</p> <div class="language-scala extra-class"><pre class="language-scala"><code>RDD的分区数<span class="token operator">=</span>max<span class="token punctuation">(</span>文件的block个数，defaultMinPartitions<span class="token punctuation">)</span>
<span class="token comment">//通过Spark Context读取hdfs上的文件来计算分区数</span>
</code></pre></div><h4 id="属性2-a-function-for-computing-each-split"><a href="#属性2-a-function-for-computing-each-split" class="header-anchor">#</a> 属性2：A function for computing each split</h4> <p>一个计算每个分区的函数，这里表示Spark中RDD的计算是以分区为单位的，每个RDD都会实现compute计算函数以达到这个目的.</p> <h4 id="属性3-a-list-of-dependencies-on-other-rdds"><a href="#属性3-a-list-of-dependencies-on-other-rdds" class="header-anchor">#</a> 属性3：A list of dependencies on other RDDs</h4> <p>一个rdd会依赖于其他多个rdd，这里涉及到rdd与rdd之间的依赖关系，spark任务的容错机制就是根据这个特性（血统）而来。</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/words.txt&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd2<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token operator">=</span>rdd1<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd3<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>rdd2<span class="token punctuation">.</span>Map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">val</span> rdd6<span class="token operator">=</span>rdd4<span class="token punctuation">.</span>join<span class="token punctuation">(</span>rdd5<span class="token punctuation">)</span>
</code></pre></div><p>rdd2依赖于rdd1,而rdd3依赖于rdd2</p> <p>rdd6依赖于rdd4、rdd5</p> <h4 id="属性4-optionally-a-partitioner-for-key-value-rdds-e-g-to-say-that-the-rdd-is-hash-partitioned"><a href="#属性4-optionally-a-partitioner-for-key-value-rdds-e-g-to-say-that-the-rdd-is-hash-partitioned" class="header-anchor">#</a> 属性4：Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)</h4> <p>一个Partitioner，即RDD的分区函数（可选项）</p> <p>当前Spark中实现了两种类型的分区函数，</p> <ol><li>基于哈希的HashPartitioner，(key.hashcode % 分区数= 分区号)。它是默认值</li> <li>基于范围的RangePartitioner。</li></ol> <p>什么会有Partitioner?</p> <ol><li>只有对于key-value的RDD(RDD[(String, Int)]),并且产生shuffle，才会有Partitioner，</li> <li>非key-value的RDD(RDD[String])的Parititioner的值是None。</li></ol> <p>Option类型：可以表示有值或者没有值，它有2个子类：</p> <ol><li>Some：表示封装了值</li> <li>None：表示没有值</li></ol> <h4 id="属性5-optionally-a-list-of-preferred-locations-to-compute-each-split-on-e-g-block-locations-for-an-hdfs-file"><a href="#属性5-optionally-a-list-of-preferred-locations-to-compute-each-split-on-e-g-block-locations-for-an-hdfs-file" class="header-anchor">#</a> 属性5：Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)</h4> <p>一个列表，存储每个Partition的优先位置(可选项)，这里涉及到数据的本地性，数据块位置最优。</p> <p>spark任务在调度的时候会优先考虑存有数据的节点开启计算任务，减少数据的网络传输，提升计算效率。</p> <p><img src="/assets/img/image-20200415133258993.7ac58233.png" alt="image-20200415133258993"></p> <h3 id="基于spark的单词统计程序剖析rdd的五大属性"><a href="#基于spark的单词统计程序剖析rdd的五大属性" class="header-anchor">#</a> 基于spark的单词统计程序剖析rdd的五大属性</h3> <h5 id="需求"><a href="#需求" class="header-anchor">#</a> 需求</h5> <div class="language- extra-class"><pre class="language-text"><code>HDFS上有一个大小为300M的文件，通过spark实现文件单词统计，最后把结果数据保存到HDFS上
</code></pre></div><h5 id="要执行的代码"><a href="#要执行的代码" class="header-anchor">#</a> 要执行的代码</h5> <div class="language-scala extra-class"><pre class="language-scala"><code>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/words.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span><span class="token punctuation">.</span>saveAsTextFile<span class="token punctuation">(</span><span class="token string">&quot;/out&quot;</span><span class="token punctuation">)</span>
</code></pre></div><h5 id="流程分析"><a href="#流程分析" class="header-anchor">#</a> 流程分析</h5> <h6 id="大致流程"><a href="#大致流程" class="header-anchor">#</a> 大致流程：</h6> <p><img src="/assets/img/image-20200415140940717.0dbe4c3f.png" alt="image-20200415140940717"></p> <h6 id="每个rdd的解释"><a href="#每个rdd的解释" class="header-anchor">#</a> 每个rdd的解释：</h6> <p><img src="/assets/img/image-20200415141032695.3c38f9fe.png" alt="image-20200415141032695"></p> <h6 id="完整图"><a href="#完整图" class="header-anchor">#</a> 完整图：</h6> <p><img src="/assets/img/image-20200415141636967.592e7cbe.png" alt="image-20200415141636967"></p> <h6 id="partitioner的解析"><a href="#partitioner的解析" class="header-anchor">#</a> partitioner的解析：</h6> <p>rdd1,rdd2,rdd3的partitioner都是None，经过shuffle，rdd4的partitioner为HashPartitioner。</p> <p><img src="/assets/img/image-20200415141443569.a6145eda.png" alt="image-20200415141443569"></p> <p><img src="/assets/img/image-20200415141529095.0c23b06a.png" alt="image-20200415141529095"></p> <h5 id="为什么计算小文件会生成两个结果文件"><a href="#为什么计算小文件会生成两个结果文件" class="header-anchor">#</a> 为什么计算小文件会生成两个结果文件？</h5> <p>通过上面的流程分析，可以知道，<strong>加载一个文件时，文件的block个数就是默认的分区个数</strong>，而一个分区对应生成一个结果文件。</p> <p>那为什么我们之前计算words.txt这么一个只有1个block的小文件时，会生成2个结果文件？按道理不是1个才对？</p> <p>这跟加载数据文件的textFile()方法的参数有关，首先来看一下textFile()的源码：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">def</span> textFile<span class="token punctuation">(</span>
      path<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span>
      minPartitions<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> defaultMinPartitions<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> withScope <span class="token punctuation">{</span>
    assertNotStopped<span class="token punctuation">(</span><span class="token punctuation">)</span>
    hadoopFile<span class="token punctuation">(</span>path<span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>TextInputFormat<span class="token punctuation">]</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>LongWritable<span class="token punctuation">]</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>Text<span class="token punctuation">]</span><span class="token punctuation">,</span>
      minPartitions<span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>pair <span class="token keyword">=&gt;</span> pair<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>toString<span class="token punctuation">)</span><span class="token punctuation">.</span>setName<span class="token punctuation">(</span>path<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
</code></pre></div><p>可以看到，textFile方法，有两个参数,path和minPartitions，而我们之前使用的时候，只填了一个参数，如：val data:RDD[String]=sc.textFile(args(0))</p> <p>这样的话，最小分区数minPartitions就会使用默认值defaultMinPartitions，再来看一下defaultMinPartitions的源码：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">def</span> defaultMinPartitions<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> math<span class="token punctuation">.</span>min<span class="token punctuation">(</span>defaultParallelism<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
</code></pre></div><p>defaultMinPartitions是一个方法，返回值是math.min(defaultParallelism, 2)</p> <p>defaultParallelism是默认并行度，一般是大于2的数，所以math.min(defaultParallelism, 2)=2</p> <p>因此，最小分区数minPartitions=2，这就是计算分析小文件会生成2个文件的原因。</p> <h3 id="拓展-并行与并发"><a href="#拓展-并行与并发" class="header-anchor">#</a> 拓展：并行与并发</h3> <h4 id="并发"><a href="#并发" class="header-anchor">#</a> 并发</h4> <p>并发（Concurrent），在操作系统中，是指一个时间段中有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理机上运行。</p> <p>并发不是真正意义上的“同时进行”，只是CPU把一个时间段划分成几个时间片段（时间区间），然后在这几个时间区间之间来回切换，由于CPU处理的速度非常快，只要时间间隔处理得当，即可让用户感觉是多个应用程序同时在进行。如：打游戏和听音乐两件事情在<strong>同一个时间段内</strong>都是在同一台电脑上完成了<strong>从开始到结束的动作</strong>。那么，就可以说听音乐和打游戏是并发的。</p> <h4 id="并行"><a href="#并行" class="header-anchor">#</a> 并行</h4> <p>并行（Parallel），当系统有一个以上CPU时，当一个CPU执行一个进程时，另一个CPU可以执行另一个进程，两个进程互不抢占CPU资源，可以同时进行，这种方式我们称之为并行(Parallel)。</p> <p>其实决定并行的因素不是CPU的数量，而是CPU的核心数量，比如一个CPU多个核也可以并行。</p> <h4 id="并行与并发示意图"><a href="#并行与并发示意图" class="header-anchor">#</a> 并行与并发示意图</h4> <p>如下图所示：（并发与并发示意图）</p> <p><img src="/assets/img/1628624-20190505161932608-1136050215.6e44701f.jpg" alt="img">**</p> <p>所以，并发是在一段时间内宏观上多个程序同时运行，并行是在某一时刻，真正有多个程序在运行。</p> <h4 id="并行和并发的区别"><a href="#并行和并发的区别" class="header-anchor">#</a> 并行和并发的区别</h4> <ol><li><p>并发，指的是多个事情，在同一时间段内同时发生了。</p></li> <li><p>并行，指的是多个事情，在同一时间点上同时发生了。</p></li> <li><p>并发的多个任务之间是互相抢占资源的。</p></li> <li><p>并行的多个任务之间是不互相抢占资源的。</p></li></ol> <p>只有在多CPU或者一个CPU多核的情况中，才会发生并行。否则，看似同时发生的事情，其实都是并发执行的。</p> <h4 id="spark的并行"><a href="#spark的并行" class="header-anchor">#</a> spark的并行</h4> <p>一个文件有多个block,一个block对应一个分区，一个分区就会对应一个task,一个task对应一个线程，多个线程并行运行：</p> <p>以上面的300M的文件的计算为例，分析spark中的并行：</p> <p>并行运行1：</p> <p><img src="/assets/img/image-20200415154218150.d5088665.png" alt="image-20200415154218150"></p> <p>并行运行2：</p> <p><img src="/assets/img/image-20200415154545940.d8e964cd.png" alt="image-20200415154545940"></p> <h3 id="rdd的创建方式"><a href="#rdd的创建方式" class="header-anchor">#</a> RDD的创建方式</h3> <p>RDD的创建方式有3种：</p> <p>1、通过已经存在的scala集合去构建，前期做一些测试用到的比较多</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1<span class="token operator">=</span>sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">//parallelize可以添加第2个参数，是分区的数量</span>
<span class="token keyword">val</span> rdd2<span class="token operator">=</span>sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token string">&quot;hadoop&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;hive&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;spark&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd3<span class="token operator">=</span>sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">//parallelize表示并行化</span>
</code></pre></div><p>无论传入的是什么，元素最终都是用Array封装的：</p> <p><img src="/assets/img/image-20200415155327297.988fa4aa.png" alt="image-20200415155327297"></p> <p>2、加载外部的数据源去构建</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/words.txt&quot;</span><span class="token punctuation">)</span>
</code></pre></div><p>3、从已经存在的rdd进行转换生成一个新的rdd</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd2<span class="token operator">=</span>rdd1<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd3<span class="token operator">=</span>rdd2<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="rdd的算子"><a href="#rdd的算子" class="header-anchor">#</a> RDD的算子</h2> <p>算子可以理解成RDD的一些方法。</p> <p>RDD的算子可以分为2类：</p> <p>1、transformation（转换）</p> <ul><li>根据已经存在的rdd转换生成一个新的rdd,  它是延迟加载，它不会立即执行</li> <li>例如： map / flatMap / reduceByKey 等</li></ul> <p>2、action (动作)</p> <ul><li>它会真正触发任务的运行，将rdd的计算的结果数据返回给Driver端，或者是保存结果数据到外部存储介质中</li> <li>例如：collect / saveAsTextFile 等</li></ul> <h3 id="rdd常见的算子操作说明-重要"><a href="#rdd常见的算子操作说明-重要" class="header-anchor">#</a> RDD常见的算子操作说明(重要)</h3> <h4 id="transformation算子"><a href="#transformation算子" class="header-anchor">#</a> transformation算子</h4> <table><thead><tr><th><strong>转换</strong></th> <th><strong>含义</strong></th></tr></thead> <tbody><tr><td><strong>map(func)</strong></td> <td>返回一个新的RDD，该RDD由每一个输入元素经过func函数转换后组成</td></tr> <tr><td><strong>filter(func)</strong></td> <td>返回一个新的RDD，该RDD由经过func函数计算后返回值为true的输入元素组成</td></tr> <tr><td><strong>flatMap(func)</strong></td> <td>类似于map，但是每一个输入元素可以被映射为0或多个输出元素（所以func应该返回一个序列，而不是单一元素）</td></tr> <tr><td><strong>mapPartitions(func)</strong></td> <td>类似于map，但独立地在RDD的每一个分片上运行，因此在类型为T的RDD上运行时，func的函数类型必须是Iterator[T] =&gt; Iterator[U]</td></tr> <tr><td><strong>mapPartitionsWithIndex(func)</strong></td> <td>类似于mapPartitions，但func带有一个整数参数表示分片的索引值，因此在类型为T的RDD上运行时，func的函数类型必须是(Int, Interator[T]) =&gt; Iterator[U]</td></tr> <tr><td><strong>union(otherDataset)</strong></td> <td>对源RDD和参数RDD求并集后返回一个新的RDD</td></tr> <tr><td><strong>intersection(otherDataset)</strong></td> <td>对源RDD和参数RDD求交集后返回一个新的RDD</td></tr> <tr><td><strong>distinct([numTasks]))</strong></td> <td>对源RDD进行去重后返回一个新的RDD</td></tr> <tr><td><strong>groupByKey([numTasks])</strong></td> <td>在一个(K,V)的RDD上调用，返回一个(K, Iterator[V])的RDD</td></tr> <tr><td><strong>reduceByKey(func, [numTasks])</strong></td> <td>在一个(K,V)的RDD上调用，返回一个(K,V)的RDD，使用指定的reduce函数，将相同key的值聚合到一起，与groupByKey类似，reduce任务的个数可以通过第二个可选的参数来设置</td></tr> <tr><td><strong>sortByKey([ascending], [numTasks])</strong></td> <td>在一个(K,V)的RDD上调用，K必须实现Ordered接口，返回一个按照key进行排序的(K,V)的RDD</td></tr> <tr><td><strong>sortBy(func,[ascending], [numTasks])</strong></td> <td>与sortByKey类似，但是更灵活</td></tr> <tr><td><strong>join(otherDataset, [numTasks])</strong></td> <td>在类型为(K,V)和(K,W)的RDD上调用，返回一个相同key对应的所有元素对在一起的(K,(V,W))的RDD</td></tr> <tr><td><strong>cogroup(otherDataset, [numTasks])</strong></td> <td>在类型为(K,V)和(K,W)的RDD上调用，返回一个(K,<code>(Iterable&lt;V&gt;,Iterable&lt;W&gt;))</code>类型的RDD</td></tr> <tr><td><strong>coalesce(numPartitions)</strong></td> <td>减少 RDD 的分区数到指定值。</td></tr> <tr><td><strong>repartition(numPartitions)</strong></td> <td>重新给 RDD 分区</td></tr> <tr><td><strong>repartitionAndSortWithinPartitions(partitioner)</strong></td> <td>重新给 RDD 分区，并且每个分区内以记录的 key 排序</td></tr></tbody></table> <h4 id="action算子"><a href="#action算子" class="header-anchor">#</a> action算子</h4> <table><thead><tr><th><strong>动作</strong></th> <th><strong>含义</strong></th></tr></thead> <tbody><tr><td><strong>reduce(func)</strong></td> <td>reduce将RDD中元素前两个传给输入函数，产生一个新的return值，新产生的return值与RDD中下一个元素（第三个元素）组成两个元素，再被传给输入函数，直到最后只有一个值为止。</td></tr> <tr><td><strong>collect()</strong></td> <td>在驱动程序中，以数组的形式返回数据集的所有元素</td></tr> <tr><td><strong>count()</strong></td> <td>返回RDD的元素个数</td></tr> <tr><td><strong>first()</strong></td> <td>返回RDD的第一个元素（类似于take(1)）</td></tr> <tr><td><strong>take(n)</strong></td> <td>返回一个由数据集的前n个元素组成的数组</td></tr> <tr><td><strong>takeOrdered(n, [ordering])</strong></td> <td>返回自然顺序或者自定义顺序的前 n 个元素</td></tr> <tr><td><strong>saveAsTextFile(path)</strong></td> <td>将数据集的元素以textfile的形式保存到HDFS文件系统或者其他支持的文件系统，对于每个元素，Spark将会调用toString方法，将它装换为文件中的文本</td></tr> <tr><td><strong>saveAsSequenceFile(path)</strong></td> <td>将数据集中的元素以Hadoop sequencefile的格式保存到指定的目录下，可以使HDFS或者其他Hadoop支持的文件系统。</td></tr> <tr><td><strong>saveAsObjectFile(path)</strong></td> <td>将数据集的元素，以 Java 序列化的方式保存到指定的目录下</td></tr> <tr><td><strong>countByKey()</strong></td> <td>针对(K,V)类型的RDD，返回一个(K,Int)的map，表示每一个key对应的元素个数。</td></tr> <tr><td><strong>foreach(func)</strong></td> <td>在数据集的每一个元素上，运行函数func</td></tr> <tr><td><strong>foreachPartition(func)</strong></td> <td>在数据集的每一个分区上，运行函数func</td></tr></tbody></table> <h4 id="map与mappartitions的区别-面试题"><a href="#map与mappartitions的区别-面试题" class="header-anchor">#</a> map与mapPartitions的区别（面试题）</h4> <ol><li>map含义：返回一个新的RDD，该RDD由每一个输入元素经过func函数转换后组成</li> <li>mapPartitions含义：类似于map，但独立地在RDD的每一个分片上运行，因此在类型为T的RDD上运行时，func的函数类型必须是Iterator[T] =&gt; Iterator[U]</li> <li>map是对rdd中的每一个元素进行操作，mapPartitions是对rdd中的每一个分区/task的迭代器进行操作</li> <li>两者最终实现的效果都是一样的，但是实现的过程不一样。</li></ol> <p>MapPartitions的优点：</p> <p>如果是普通的map，比如一个partition中有1万条数据，那么你的function要执行和计算1万次。</p> <p><strong>使用MapPartitions操作之后，一个task仅仅会执行一次function</strong>，function一次接收所有的partition数据。只要执行一次就可以了，性能比较高。</p> <p>如果在map过程中需要频繁创建额外的对象(例如将rdd中的数据通过jdbc写入数据库,map需要为每个元素创建一个链接而mapPartition为每个partition创建一个链接),则mapPartitions效率比map高的多。</p> <p>SparkSql或DataFrame默认会对程序进行mapPartition的优化。</p> <p>MapPartitions的缺点：</p> <p>如果是普通的map操作，一次function的执行就处理一条数据；那么如果内存不够用的情况下， 比如处理了1千条数据了，那么这个时候内存不够了，那么就可以将已经处理完的1千条数据从内存里面垃圾回收掉，或者用其他方法，腾出空间来吧。</p> <p>所以说普通的<strong>map操作通常不会导致内存的OOM（Out Of Memory)异常</strong>。</p> <p>但是MapPartitions操作，对于大量数据来说，比如甚至一个partition，100万数据，一次传入一个function以后，那么可能一下子内存不够，但是又没有办法去腾出内存空间来，可能就OOM，内存溢出。</p> <h4 id="foreach与foreachpartition的区别-面试题"><a href="#foreach与foreachpartition的区别-面试题" class="header-anchor">#</a> foreach与foreachPartition的区别（面试题）</h4> <p>与map VS mapPartitions类似</p> <h2 id="面试题1"><a href="#面试题1" class="header-anchor">#</a> 面试题1</h2> <p><img src="/assets/img/image-20200417025522744.3076c3d3.png" alt="image-20200417025522744"></p> <h2 id="rdd常用的算子操作演示"><a href="#rdd常用的算子操作演示" class="header-anchor">#</a> RDD常用的算子操作演示</h2> <p>为了方便前期的测试和学习，可以使用spark-shell进行演示</p> <div class="language-shell extra-class"><pre class="language-shell"><code>spark-shell --master local<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
</code></pre></div><h4 id="_1-map"><a href="#_1-map" class="header-anchor">#</a> 1 map</h4> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> rdd1<span class="token operator">=</span>sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> rdd2<span class="token operator">=</span>rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span>
scala<span class="token operator">&gt;</span> rdd2<span class="token punctuation">.</span>collect
res4<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">)</span>  
</code></pre></div><h4 id="_2-filter"><a href="#_2-filter" class="header-anchor">#</a> 2 filter</h4> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">//把rdd1中大于5的元素进行过滤</span>
rdd1<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> x <span class="token operator">&gt;</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect
</code></pre></div><h4 id="_3-flatmap"><a href="#_3-flatmap" class="header-anchor">#</a> 3 flatMap</h4> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span>	<span class="token string">&quot;a b c&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;d e f&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;h i j&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">//获取rdd1中元素的每一个字母</span>
rdd1<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect
</code></pre></div><h4 id="_4-intersection、union"><a href="#_4-intersection、union" class="header-anchor">#</a> 4 intersection、union</h4> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">//求交集</span>
scala<span class="token operator">&gt;</span> rdd1<span class="token punctuation">.</span>intersection<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span><span class="token punctuation">.</span>collect
res7<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>  

<span class="token comment">//求并集</span>
scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> rdd5<span class="token operator">=</span>rdd1<span class="token punctuation">.</span>union<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span>
scala<span class="token operator">&gt;</span> rdd5<span class="token punctuation">.</span>collect
res6<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="_5-distinct"><a href="#_5-distinct" class="header-anchor">#</a> 5 distinct</h4> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">//去重</span>
rdd1<span class="token punctuation">.</span>distinct
</code></pre></div><h4 id="_6-join、groupbykey"><a href="#_6-join、groupbykey" class="header-anchor">#</a> 6 join、groupByKey</h4> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">&quot;tom&quot;</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;jerry&quot;</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;kitty&quot;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">&quot;jerry&quot;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;tom&quot;</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;shuke&quot;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">//求join</span>
<span class="token keyword">val</span> rdd3 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>join<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span>
rdd3<span class="token punctuation">.</span>collect
res8<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>tom<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>jerry<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">//求并集</span>
<span class="token keyword">val</span> rdd4 <span class="token operator">=</span> rdd1 union rdd2
rdd4<span class="token punctuation">.</span>groupByKey<span class="token punctuation">.</span>collect
res11<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>tom<span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>jerry<span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>shuke<span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>kitty<span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="_7-cogroup"><a href="#_7-cogroup" class="header-anchor">#</a> 7 cogroup</h4> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">&quot;tom&quot;</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;tom&quot;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;jerry&quot;</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;kitty&quot;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">&quot;jerry&quot;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;tom&quot;</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;jim&quot;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">//分组</span>
<span class="token keyword">val</span> rdd3 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>cogroup<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span>
rdd3<span class="token punctuation">.</span>collect
res12<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>Iterable<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span>jim<span class="token punctuation">,</span><span class="token punctuation">(</span>CompactBuffer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>tom<span class="token punctuation">,</span><span class="token punctuation">(</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>jerry<span class="token punctuation">,</span><span class="token punctuation">(</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>kitty<span class="token punctuation">,</span><span class="token punctuation">(</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="_8-reduce"><a href="#_8-reduce" class="header-anchor">#</a> 8 reduce</h4> <p>示例1：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">//reduce聚合</span>
<span class="token keyword">val</span> rdd2 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>reduce<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>
</code></pre></div><p>示例2：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd3 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token string">&quot;1&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;2&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;3&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;4&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;5&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

scala<span class="token operator">&gt;</span> rdd3<span class="token punctuation">.</span>reduce<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>
res18<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token number">12345</span>

scala<span class="token operator">&gt;</span> rdd3<span class="token punctuation">.</span>reduce<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>
res21<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token number">34512</span> <span class="token comment">//从12345变成了34512</span>
</code></pre></div><p>从上面示例2的代码块可知，同样的操作，出现了不同的结果。</p> <p>这是因为元素在不同的分区中，每一个分区都是一个独立的task线程去运行（多个分区并行运算）。这些task运行有先后关系。</p> <p>查看元素的分区情况：</p> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> rdd3<span class="token punctuation">.</span>partitions
res19<span class="token operator">:</span> Array<span class="token punctuation">[</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>Partition<span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>ParallelCollectionPartition<span class="token annotation punctuation">@c55</span><span class="token punctuation">,</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>ParallelCollectionPartition<span class="token annotation punctuation">@c56</span><span class="token punctuation">)</span>

scala<span class="token operator">&gt;</span> rdd3<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>length
res20<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">2</span>
</code></pre></div><h4 id="_9-reducebykey、sortbykey"><a href="#_9-reducebykey、sortbykey" class="header-anchor">#</a> 9 reduceByKey、sortByKey</h4> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">&quot;tom&quot;</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;jerry&quot;</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;kitty&quot;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token punctuation">(</span><span class="token string">&quot;shuke&quot;</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">&quot;jerry&quot;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;tom&quot;</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;shuke&quot;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;kitty&quot;</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd3 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>union<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span>

<span class="token comment">//按key进行聚合</span>
<span class="token keyword">val</span> rdd4 <span class="token operator">=</span> rdd3<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>
rdd4<span class="token punctuation">.</span>collect

<span class="token comment">//按value的降序排序</span>
<span class="token keyword">val</span> rdd5 <span class="token operator">=</span> rdd4<span class="token punctuation">.</span>map<span class="token punctuation">(</span>t <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>t<span class="token punctuation">.</span>_2<span class="token punctuation">,</span> t<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sortByKey<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>t <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>t<span class="token punctuation">.</span>_2<span class="token punctuation">,</span> t<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span>
rdd5<span class="token punctuation">.</span>collect
</code></pre></div><h4 id="_10-repartition、coalesce"><a href="#_10-repartition、coalesce" class="header-anchor">#</a> 10 repartition、coalesce</h4> <h6 id="两者使用区别"><a href="#两者使用区别" class="header-anchor">#</a> 两者使用区别</h6> <p>coalesce功能：改变分区数量，只能减少，不能增加</p> <p>repartition功能：改变分区数量，减少增加都可以</p> <p>coalesce示例：</p> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> rdd1<span class="token operator">=</span>sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>

scala<span class="token operator">&gt;</span> rdd1<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>length
res4<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">3</span>

<span class="token comment">//************=利用coalesce减少分区数量，成功****************************=</span>
scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> rdd2<span class="token operator">=</span>rdd1<span class="token punctuation">.</span>coalesce<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
rdd2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> CoalescedRDD<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> at coalesce at <span class="token generics"><span class="token punctuation">&lt;</span>console<span class="token punctuation">&gt;</span></span><span class="token operator">:</span><span class="token number">25</span>

scala<span class="token operator">&gt;</span> rdd2<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>length
res5<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">2</span>

scala<span class="token operator">&gt;</span> rdd1<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>length
res6<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">3</span>

<span class="token comment">//************=利用coalesce增加分区数量，失败****************************=</span>
scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> rdd3<span class="token operator">=</span>rdd1<span class="token punctuation">.</span>coalesce<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
rdd3<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> CoalescedRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at coalesce at <span class="token generics"><span class="token punctuation">&lt;</span>console<span class="token punctuation">&gt;</span></span><span class="token operator">:</span><span class="token number">25</span>

scala<span class="token operator">&gt;</span> rdd3<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>length
res7<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">3</span>

scala<span class="token operator">&gt;</span> rdd1<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>length
res8<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">3</span>

<span class="token comment">//************=利用repatriation增加分区数量，成功****************************=</span>
scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> rdd4<span class="token operator">=</span>rdd1<span class="token punctuation">.</span>repartition<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
rdd4<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span> at repartition at <span class="token generics"><span class="token punctuation">&lt;</span>console<span class="token punctuation">&gt;</span></span><span class="token operator">:</span><span class="token number">25</span>

scala<span class="token operator">&gt;</span> rdd4<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>length
res9<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">5</span>

scala<span class="token operator">&gt;</span> rdd1<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>length
res10<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">3</span>
</code></pre></div><p>为什么repartition可以增加分区数量，而coalesce不可以，两者又有什么区别，我们来看一下源码：</p> <p>repartition方法的源码（源码在RDD.scala搜索即可）：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">def</span> repartition<span class="token punctuation">(</span>numPartitions<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token keyword">implicit</span> ord<span class="token operator">:</span> Ordering<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> withScope <span class="token punctuation">{</span>
    coalesce<span class="token punctuation">(</span>numPartitions<span class="token punctuation">,</span> shuffle <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
</code></pre></div><p>从源码可以看出，repartition方法体调用了coalesce方法，该coalesce方法有2个参数，第2个参数是shuffle = true。再来看一下coalesce方法的源码：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">def</span> coalesce<span class="token punctuation">(</span>numPartitions<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> shuffle<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">,</span>
               partitionCoalescer<span class="token operator">:</span> Option<span class="token punctuation">[</span>PartitionCoalescer<span class="token punctuation">]</span> <span class="token operator">=</span> Option<span class="token punctuation">.</span>empty<span class="token punctuation">)</span>
              <span class="token punctuation">(</span><span class="token keyword">implicit</span> ord<span class="token operator">:</span> Ordering<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">)</span>
      <span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> withScope <span class="token punctuation">{</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span>
</code></pre></div><p>可看到，coalesce方法的第二个参数是shuffle，但是值却是false，这与repartition方法体里调用的coalesce参数值刚好相反。</p> <p>因此，可以推断出，repartition能够的增加分区的数量的根本原因是将shuffle参数设为了true。</p> <p>使用建议：因为shuffle是比较消耗资源的，所以如果要减少分区的数量时，尽量使用coalesce。</p> <h6 id="改变分区数量的应用场景举例"><a href="#改变分区数量的应用场景举例" class="header-anchor">#</a> 改变分区数量的应用场景举例：</h6> <p>要执行的操作：</p> <div class="language-scala extra-class"><pre class="language-scala"><code>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/words.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">=&gt;</span>x<span class="token operator">+</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span>saveAsTextFile<span class="token punctuation">(</span><span class="token string">&quot;/out&quot;</span><span class="token punctuation">)</span>
</code></pre></div><p>假如words.txt文件很大,那么会产生很多个分区，比如1000个分区，每个分区数据量可能有点小。</p> <p>如果直接保存数据到hdfs上，那么会产生很多个小文件(hdfs不适合处理小文件)。</p> <p>为了减少在hdfs生成的小文件数量，可以在saveAsTextFile(&quot;/out&quot;)之前添加一个步骤来减少分区数量，代码如下：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd4<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/words.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">=&gt;</span>x<span class="token operator">+</span>y<span class="token punctuation">)</span>

<span class="token keyword">val</span> rdd5<span class="token operator">=</span>rdd4<span class="token punctuation">.</span>coalesce<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>

rdd5<span class="token punctuation">.</span>saveAsTextFile<span class="token punctuation">(</span><span class="token string">&quot;/out&quot;</span><span class="token punctuation">)</span>
</code></pre></div><h6 id="有无shuffle的示意图"><a href="#有无shuffle的示意图" class="header-anchor">#</a> 有无shuffle的示意图：</h6> <p>可以看到，减少分区数量如果使用repartition会产生shuffle，shuffle阶段要进行计算分区号和交叉传送等操作，明显麻烦比无shuffle时麻烦很多，消耗资源。</p> <p><img src="/assets/img/image-20200415201224598.0d38e9a6.png" alt="image-20200415201224598"></p> <h4 id="_11-map、mappartitions、mappartitionswithindex"><a href="#_11-map、mappartitions、mappartitionswithindex" class="header-anchor">#</a> 11 map、mapPartitions、mapPartitionsWithIndex</h4> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1<span class="token operator">=</span>sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> x<span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect
rdd1<span class="token punctuation">.</span>mapPartitions<span class="token punctuation">(</span>iter <span class="token keyword">=&gt;</span> iter<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect

<span class="token comment">//map：用于遍历RDD,将函数f应用于每一个元素，返回新的RDD(transformation算子)。</span>
<span class="token comment">//mapPartitions:用于遍历操作RDD中的每一个分区，返回生成一个新的RDD（transformation算子）。</span>
</code></pre></div><p>总结：</p> <p>如果在映射的过程中需要频繁创建额外的对象，使用mapPartitions要比map高效</p> <p>比如，将RDD中的所有数据通过JDBC连接写入数据库，如果使用map函数，可能要为每一个元素都创建一个connection，这样开销很大，如果使用mapPartitions，那么只需要针对每一个分区建立一个connection。</p> <p>mapPartitionsWithIndex的使用：</p> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> rdd1<span class="token operator">=</span>sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span> at parallelize at <span class="token generics"><span class="token punctuation">&lt;</span>console<span class="token punctuation">&gt;</span></span><span class="token operator">:</span><span class="token number">24</span>

<span class="token comment">//index表示分区号  可以获取得到每一个元素属于哪一个分区</span>
scala<span class="token operator">&gt;</span> rdd1<span class="token punctuation">.</span>mapPartitionsWithIndex<span class="token punctuation">(</span><span class="token punctuation">(</span>index<span class="token punctuation">,</span>iter<span class="token punctuation">)</span><span class="token keyword">=&gt;</span>iter<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>index<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect
res11<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="_12-foreach、foreachpartition"><a href="#_12-foreach、foreachpartition" class="header-anchor">#</a> 12 foreach、foreachPartition</h4> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">//foreach实现对rdd1里的每一个元素乘10然后打印输出</span>
rdd1<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>println<span class="token punctuation">(</span>x <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">//foreachPartition实现对rdd1里的每一个元素乘10然后打印输出</span>
rdd1<span class="token punctuation">.</span>foreachPartition<span class="token punctuation">(</span>iter <span class="token keyword">=&gt;</span> iter<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>println<span class="token punctuation">(</span>x <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">//foreach:用于遍历RDD,将函数f应用于每一个元素，无返回值(action算子)。</span>
<span class="token comment">//foreachPartition: 用于遍历操作RDD中的每一个分区。无返回值(action算子)。</span>
</code></pre></div><p>总结：一般使用mapPartitions或者foreachPartition算子比map和foreach更加高效，推荐使用。</p> <hr> <p>-----------------------------录播分界线-----------------------------------------</p> <hr> <h2 id="案例1-使用java实现spark的wordcount"><a href="#案例1-使用java实现spark的wordcount" class="header-anchor">#</a> 案例1：使用Java实现spark的wordCount</h2> <h5 id="案例需求"><a href="#案例需求" class="header-anchor">#</a> 案例需求：</h5> <p>单词计数</p> <h5 id="第一步-创建maven工程-引入依赖"><a href="#第一步-创建maven工程-引入依赖" class="header-anchor">#</a> 第一步：创建maven工程，引入依赖</h5> <div class="language-xml extra-class"><pre class="language-xml"><code> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-core_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.3.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>

</code></pre></div><h5 id="第二步-代码开发"><a href="#第二步-代码开发" class="header-anchor">#</a> 第二步：代码开发</h5> <p>说明：</p> <ol><li>使用Java编写spark程序，其实跟scala的步骤是一样的，只不过写法有点变化而已。</li> <li>scala的RDD对应Java中的JavaRDD</li> <li>scala的SparkContext对应Java中的JavaSparkContext</li> <li>scala方法中的参数为函数时，在Java中要改成对象，因为Java是面向对象的，这是scala相对于Java非常不同的地方。</li> <li>编写spark程序的大致步骤如下：</li></ol> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span>SparkConf<span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span></span>JavaPairRDD<span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span></span>JavaRDD<span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span></span>JavaSparkContext<span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>function<span class="token punctuation">.</span></span>FlatMapFunction<span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>function<span class="token punctuation">.</span></span>Function2<span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>function<span class="token punctuation">.</span></span>PairFunction<span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">scala<span class="token punctuation">.</span></span>Tuple2<span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Arrays<span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Iterator<span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>List<span class="token punctuation">;</span>

public <span class="token keyword">class</span> MyJavaSpark <span class="token punctuation">{</span>
    public static void main<span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">//1、创建spark Conf</span>
        SparkConf sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;WordCount&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//2、创建spark Context</span>
        JavaSparkContext javaSparkContext <span class="token operator">=</span> <span class="token keyword">new</span> JavaSparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//3、读取数据</span>
        JavaRDD<span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> stringJavaRDD <span class="token operator">=</span> javaSparkContext<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;F:\\test\\aa.txt&quot;</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//4、切分每一行数据为一个个单词</span>
        <span class="token keyword">final</span> JavaRDD<span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> wordsRDD <span class="token operator">=</span> stringJavaRDD<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span><span class="token keyword">new</span> FlatMapFunction<span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            public Iterator<span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> call<span class="token punctuation">(</span><span class="token builtin">String</span> s<span class="token punctuation">)</span> throws Exception <span class="token punctuation">{</span>
                <span class="token builtin">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> s1 <span class="token operator">=</span> s<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">return</span> Arrays<span class="token punctuation">.</span>asList<span class="token punctuation">(</span>s1<span class="token punctuation">)</span><span class="token punctuation">.</span>iterator<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//5、每个单词计为1</span>
        JavaPairRDD<span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> wordAndOneRDD <span class="token operator">=</span> wordsRDD<span class="token punctuation">.</span>mapToPair<span class="token punctuation">(</span><span class="token keyword">new</span> PairFunction<span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            public Tuple2<span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> call<span class="token punctuation">(</span><span class="token builtin">String</span> s<span class="token punctuation">)</span> throws Exception <span class="token punctuation">{</span>
                <span class="token keyword">return</span> <span class="token keyword">new</span> Tuple2<span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//6、相同的单词累加1</span>
        JavaPairRDD<span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> resultRDD <span class="token operator">=</span> wordAndOneRDD<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token keyword">new</span> Function2<span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            public Integer call<span class="token punctuation">(</span>Integer v1<span class="token punctuation">,</span> Integer v2<span class="token punctuation">)</span> throws Exception <span class="token punctuation">{</span>
                <span class="token keyword">return</span> v1 <span class="token operator">+</span> v2<span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//7、收集数据</span>
        List<span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> collectRDD <span class="token operator">=</span> resultRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">//8、打印数据</span>
        <span class="token keyword">for</span><span class="token punctuation">(</span>Tuple2<span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> t<span class="token operator">:</span>collectRDD<span class="token punctuation">)</span><span class="token punctuation">{</span>
            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span>println<span class="token punctuation">(</span><span class="token string">&quot;单词：&quot;</span><span class="token operator">+</span>t<span class="token punctuation">.</span>_1<span class="token operator">+</span><span class="token string">&quot;次数：&quot;</span><span class="token operator">+</span>t<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        <span class="token comment">//9、关闭资源</span>
        javaSparkContext<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>运行结果为：</p> <div class="language- extra-class"><pre class="language-text"><code>单词：hive次数：1
单词：flink次数：1
单词：spark次数：4
单词：hadoop次数：3
单词：flume次数：1
单词：hbase次数：1
</code></pre></div><h2 id="案例2-实现点击流日志数据分析"><a href="#案例2-实现点击流日志数据分析" class="header-anchor">#</a> 案例2：实现点击流日志数据分析</h2> <p>点击流日志数据：用户在网站的浏览行为记录</p> <h5 id="案例数据"><a href="#案例数据" class="header-anchor">#</a> 案例数据</h5> <p>资料中的access.log文件，文件里一行数据的格式大致如下：</p> <div class="language- extra-class"><pre class="language-text"><code>60.208.6.156 - - [18/Sep/2013:06:49:48 +0000] &quot;GET /wp-content/uploads/2013/07/rcassandra.png HTTP/1.0&quot; 200 185524 &quot;http://cos.name/category/software/packages/&quot; &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36&quot;
</code></pre></div><ol><li>数据中的横杠-也是一个字段， 表示无</li> <li>一行数据代表一次访问。</li> <li>第1个字段是用户的ip地址</li></ol> <p><img src="/assets/img/image-20200415221704529.a5be946b.png" alt="image-20200415221704529"></p> <h5 id="统计pv"><a href="#统计pv" class="header-anchor">#</a> 统计PV</h5> <p>PV：页面浏览量，是网站各个网页被浏览的总次数。对应于access.log中的数据，一行数据就是一条浏览记录。</p> <p>因此，要获取PV，实质是要统计access.log文件中行数。</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> PV <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> sparkconf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;PV&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkconf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> data<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;E:\\LearningAll\\8-HadoopEcosystem-Video\\spark下载资料\\spark课程录播资料\\案例数据\\access.log&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> pv<span class="token operator">=</span>data<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    println<span class="token punctuation">(</span>pv<span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>运行结果为：</p> <div class="language- extra-class"><pre class="language-text"><code>14619
</code></pre></div><h5 id="统计uv"><a href="#统计uv" class="header-anchor">#</a> 统计UV</h5> <p>UV（Unique Visitor）是独立访客数。放在这里就是有多少个不同的ip地址的访客访问过网站，相同ip地址的访客，无论访问网站多少次，都只算入UV一次。</p> <p>因此，spark程序的大致步骤是：加载每一行数据，获取每一行数据的ip地址，对ip地址去重，然后统计ip数量。</p> <p>代码开发:</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> PV <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> sparkconf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;PV&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkconf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> data<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;E:\\LearningAll\\8-HadoopEcosystem-Video\\spark下载资料\\spark课程录播资料\\案例数据\\access.log&quot;</span><span class="token punctuation">)</span>
    <span class="token comment">//获取每一行的ip地址：</span>
    <span class="token keyword">val</span> rdd2<span class="token operator">=</span>data<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//去重：</span>
    <span class="token keyword">val</span> rdd3<span class="token operator">=</span>rdd2<span class="token punctuation">.</span>distinct<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> uv<span class="token operator">=</span>rdd3<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    println<span class="token punctuation">(</span>uv<span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>1050
</code></pre></div><h5 id="获取被访问的topn页面地址"><a href="#获取被访问的topn页面地址" class="header-anchor">#</a> 获取被访问的TopN页面地址</h5> <p>数据文件里每一行数据代表一次访问，每一行数据的第11个字段是被访问的页面地址，如</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token number">60.208</span><span class="token number">.6</span><span class="token number">.156</span> <span class="token operator">-</span> <span class="token operator">-</span> <span class="token punctuation">[</span><span class="token number">18</span><span class="token operator">/</span>Sep<span class="token operator">/</span><span class="token number">2013</span><span class="token operator">:</span><span class="token number">06</span><span class="token operator">:</span><span class="token number">49</span><span class="token operator">:</span><span class="token number">48</span> <span class="token operator">+</span><span class="token number">0000</span><span class="token punctuation">]</span> <span class="token string">&quot;GET /wp-content/uploads/2013/07/rcassandra.png HTTP/1.0&quot;</span> <span class="token number">200</span> <span class="token number">185524</span> <span class="token string">&quot;http://cos.name/category/software/packages/&quot;</span> <span class="token string">&quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36&quot;</span>
</code></pre></div><p>中的&quot;http://cos.name/category/software/packages/&quot;。</p> <p>但是，有些行的数据是不完整的，可能没有第11个字段，或者第11个字段的值是 &quot;-&quot; ，因此，我们首先要进行数据的处理，然后再分析数据。</p> <p>注意，&quot;-&quot;中的双引号是包括在数据里面的，千万别少写了，特别注意下面代码块中的第11行代码。</p> <p>代码开发</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> PV <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> sparkconf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;PV&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkconf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> data<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;E:\\LearningAll\\8-HadoopEcosystem-Video\\spark下载资料\\spark课程录播资料\\案例数据\\access.log&quot;</span><span class="token punctuation">)</span>
    <span class="token comment">//处理数据，使得每一行数据至少有11个字段</span>
    <span class="token keyword">val</span> data2<span class="token operator">=</span>data<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>length<span class="token operator">&gt;</span><span class="token number">10</span><span class="token punctuation">)</span>
    <span class="token comment">//处理数据，使得每一行数据的第11个字段都不为 &quot;-&quot;，注意，双引号也包括在里面</span>
    <span class="token keyword">val</span> data3<span class="token operator">=</span>data2<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token operator">!=</span><span class="token string">&quot;\&quot;-\&quot;&quot;</span><span class="token punctuation">)</span>
    <span class="token comment">//获取第11个字段</span>
    <span class="token keyword">val</span> rdd10<span class="token operator">=</span>data3<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//每个计1</span>
    <span class="token keyword">val</span> result1<span class="token operator">=</span>rdd10<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//统计</span>
    <span class="token keyword">val</span> result2<span class="token operator">=</span>result1<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>
    <span class="token comment">//排序</span>
    <span class="token keyword">val</span> sortRDD<span class="token operator">=</span>result2<span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>_2<span class="token punctuation">,</span><span class="token boolean">false</span><span class="token punctuation">)</span>
    <span class="token comment">//获取Top5</span>
    <span class="token keyword">val</span> finalRes<span class="token operator">=</span>sortRDD<span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
    <span class="token comment">//打印：</span>
    finalRes<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>运行结果为：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token punctuation">(</span><span class="token string">&quot;http://blog.fens.me/category/hadoop-action/&quot;</span><span class="token punctuation">,</span><span class="token number">547</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token string">&quot;http://blog.fens.me/&quot;</span><span class="token punctuation">,</span><span class="token number">377</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token string">&quot;http://blog.fens.me/wp-admin/post.php?post=2445&amp;action=edit&amp;message=10&quot;</span><span class="token punctuation">,</span><span class="token number">360</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token string">&quot;http://blog.fens.me/r-json-rjson/&quot;</span><span class="token punctuation">,</span><span class="token number">274</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token string">&quot;http://blog.fens.me/angularjs-webstorm-ide/&quot;</span><span class="token punctuation">,</span><span class="token number">271</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="案例3-读取文件数据写入到mysql表中"><a href="#案例3-读取文件数据写入到mysql表中" class="header-anchor">#</a> 案例3：读取文件数据写入到mysql表中</h2> <h5 id="创建maven工程"><a href="#创建maven工程" class="header-anchor">#</a> 创建maven工程</h5> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-core_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.3.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>mysql<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>mysql-connector-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>5.1.38<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><h5 id="案例数据-2"><a href="#案例数据-2" class="header-anchor">#</a> 案例数据</h5> <div class="language- extra-class"><pre class="language-text"><code>1,tony,18
2,xiaoqiang,20
3,xiaoming,15
4,laowang,45
</code></pre></div><h5 id="创建mysql表"><a href="#创建mysql表" class="header-anchor">#</a> 创建mysql表</h5> <p>在node03登录mysql,创建一个表，Person</p> <div class="language-sql extra-class"><pre class="language-sql"><code>mysql<span class="token operator">&gt;</span> <span class="token keyword">create</span> <span class="token keyword">database</span> demo1<span class="token punctuation">;</span>
mysql<span class="token operator">&gt;</span> <span class="token keyword">use</span> demo1
mysql<span class="token operator">&gt;</span> <span class="token keyword">create</span> <span class="token keyword">table</span> person<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span>age <span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre></div><h5 id="通过foreach算子实现"><a href="#通过foreach算子实现" class="header-anchor">#</a> 通过foreach算子实现</h5> <p>大致步骤：加载数据--》处理数据后将数据封装到RDD中--》foreach遍历数据，创建mysql连接，写入数据</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Connection<span class="token punctuation">,</span> DriverManager<span class="token punctuation">,</span> PreparedStatement<span class="token punctuation">}</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Data2MysqlForeach <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> sparkkconf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;ForeachMysql&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkkconf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> data<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;E:\\LearningAll\\8-HadoopEcosystem-Video\\spark下载资料\\spark课程录播资料\\案例数据\\person.txt&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> data2<span class="token operator">:</span>RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">=</span>data<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;,&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    data2<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>t<span class="token keyword">=&gt;</span> <span class="token punctuation">{</span>
      <span class="token keyword">var</span> conne<span class="token operator">:</span> Connection <span class="token operator">=</span> <span class="token keyword">null</span>
      <span class="token keyword">try</span> <span class="token punctuation">{</span>
        <span class="token comment">//创建连接</span>
        conne <span class="token operator">=</span> DriverManager<span class="token punctuation">.</span>getConnection<span class="token punctuation">(</span><span class="token string">&quot;jdbc:mysql://node03:3306/demo1&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;root&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;123456&quot;</span><span class="token punctuation">)</span>
        <span class="token comment">//定义sql语句，?是占位符</span>
        <span class="token keyword">val</span> sql1 <span class="token operator">=</span> <span class="token string">&quot;insert into person(id,name,age) values(?,?,?)&quot;</span>
        <span class="token comment">//获取prepareStatement对象，这个对象可以对sql语句进行预编译</span>
        <span class="token keyword">val</span> ps <span class="token operator">=</span> conne<span class="token punctuation">.</span>prepareStatement<span class="token punctuation">(</span>sql1<span class="token punctuation">)</span>
        <span class="token comment">//给sql语句的问号?赋值，1代表第一个问号，2代表第二个问号...</span>
        ps<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> t<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        ps<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> t<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        ps<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> t<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment">//执行sql语句</span>
        ps<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token keyword">catch</span> <span class="token punctuation">{</span>
        <span class="token keyword">case</span> ex<span class="token operator">:</span>Exception <span class="token keyword">=&gt;</span>println<span class="token punctuation">(</span>ex<span class="token punctuation">.</span>getMessage<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token keyword">finally</span> <span class="token punctuation">{</span>
        <span class="token keyword">if</span><span class="token punctuation">(</span>conne<span class="token operator">!=</span><span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">{</span>conne<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p>查看mysql的person表,如下，已经写入成功：</p> <div class="language-sql extra-class"><pre class="language-sql"><code>mysql<span class="token operator">&gt;</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> person<span class="token punctuation">;</span>
<span class="token operator">+</span><span class="token comment">------+-----------+------+</span>
<span class="token operator">|</span> id   <span class="token operator">|</span> name      <span class="token operator">|</span> age  <span class="token operator">|</span>
<span class="token operator">+</span><span class="token comment">------+-----------+------+</span>
<span class="token operator">|</span>    <span class="token number">4</span> <span class="token operator">|</span> laowang   <span class="token operator">|</span>   <span class="token number">45</span> <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">1</span> <span class="token operator">|</span> tony      <span class="token operator">|</span>   <span class="token number">18</span> <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">2</span> <span class="token operator">|</span> xiaoqiang <span class="token operator">|</span>   <span class="token number">20</span> <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">3</span> <span class="token operator">|</span> xiaoming  <span class="token operator">|</span>   <span class="token number">15</span> <span class="token operator">|</span>
<span class="token operator">+</span><span class="token comment">------+-----------+------+</span>
</code></pre></div><p>说明：</p> <ol><li>通过foreach算子来实现的话，观察代码，会发现，foreach每遍历一条数据，就会创建一个mysql连接，如果存在大量数据的话，无疑是很耗时的。</li> <li>从person表可看到，插入的数据的顺序并不是跟源数据一致的，这是因为受到了多个分区并行执行的影响。</li></ol> <h5 id="通过foreachpartition算子实现"><a href="#通过foreachpartition算子实现" class="header-anchor">#</a> 通过foreachPartition算子实现</h5> <p>通过foreachPartition来实现与foreach来实现的源代码差不多，只需要修改几个地方,代码如下：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Connection<span class="token punctuation">,</span> DriverManager<span class="token punctuation">,</span> PreparedStatement<span class="token punctuation">}</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Data2MysqlForeachPartition <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> sparkkconf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;ForeachMysql&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkkconf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> data<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;E:\\LearningAll\\8-HadoopEcosystem-Video\\spark下载资料\\spark课程录播资料\\案例数据\\person.txt&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> data2<span class="token operator">:</span>RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">=</span>data<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;,&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    data2<span class="token punctuation">.</span>foreachPartition<span class="token punctuation">(</span>iter<span class="token keyword">=&gt;</span> <span class="token punctuation">{</span>
      <span class="token keyword">var</span> conne<span class="token operator">:</span> Connection <span class="token operator">=</span> <span class="token keyword">null</span>
      <span class="token keyword">try</span> <span class="token punctuation">{</span>
        <span class="token comment">//创建连接</span>
        conne <span class="token operator">=</span> DriverManager<span class="token punctuation">.</span>getConnection<span class="token punctuation">(</span><span class="token string">&quot;jdbc:mysql://node03:3306/demo1&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;root&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;123456&quot;</span><span class="token punctuation">)</span>
        <span class="token comment">//定义sql语句，?是占位符</span>
        <span class="token keyword">val</span> sql1 <span class="token operator">=</span> <span class="token string">&quot;insert into person(id,name,age) values(?,?,?)&quot;</span>
        <span class="token comment">//获取prepareStatement对象，这个对象可以对sql语句进行预编译</span>
        <span class="token keyword">val</span> ps <span class="token operator">=</span> conne<span class="token punctuation">.</span>prepareStatement<span class="token punctuation">(</span>sql1<span class="token punctuation">)</span>
        <span class="token comment">//给sql语句的问号?赋值，1代表第一个问号，2代表第二个问号...</span>
        iter<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>t<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
          ps<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> t<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          ps<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> t<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          ps<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> t<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

          ps<span class="token punctuation">.</span>addBatch<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token comment">//执行sql语句</span>
        ps<span class="token punctuation">.</span>executeBatch<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token keyword">catch</span> <span class="token punctuation">{</span>
        <span class="token keyword">case</span> ex<span class="token operator">:</span>Exception <span class="token keyword">=&gt;</span>println<span class="token punctuation">(</span>ex<span class="token punctuation">.</span>getMessage<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token keyword">finally</span> <span class="token punctuation">{</span>
        <span class="token keyword">if</span><span class="token punctuation">(</span>conne<span class="token operator">!=</span><span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">{</span>conne<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p>再次查看person表：</p> <div class="language-sql extra-class"><pre class="language-sql"><code>mysql<span class="token operator">&gt;</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> person<span class="token punctuation">;</span>
<span class="token operator">+</span><span class="token comment">------+-----------+------+</span>
<span class="token operator">|</span> id   <span class="token operator">|</span> name      <span class="token operator">|</span> age  <span class="token operator">|</span>
<span class="token operator">+</span><span class="token comment">------+-----------+------+</span>
<span class="token operator">|</span>    <span class="token number">4</span> <span class="token operator">|</span> laowang   <span class="token operator">|</span>   <span class="token number">45</span> <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">1</span> <span class="token operator">|</span> tony      <span class="token operator">|</span>   <span class="token number">18</span> <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">2</span> <span class="token operator">|</span> xiaoqiang <span class="token operator">|</span>   <span class="token number">20</span> <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">3</span> <span class="token operator">|</span> xiaoming  <span class="token operator">|</span>   <span class="token number">15</span> <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">1</span> <span class="token operator">|</span> tony      <span class="token operator">|</span>   <span class="token number">18</span> <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">4</span> <span class="token operator">|</span> laowang   <span class="token operator">|</span>   <span class="token number">45</span> <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">2</span> <span class="token operator">|</span> xiaoqiang <span class="token operator">|</span>   <span class="token number">20</span> <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">3</span> <span class="token operator">|</span> xiaoming  <span class="token operator">|</span>   <span class="token number">15</span> <span class="token operator">|</span>
<span class="token operator">+</span><span class="token comment">------+-----------+------+</span>
</code></pre></div><h5 id="小结"><a href="#小结" class="header-anchor">#</a> 小结</h5> <ol><li><p>foreach算子实现获取得到一条一条的数据之后，然后进行获取对应的数据库连接，实现把数据插入到mysql表中，这里rdd中有N条数据，这里就需要与mysql数据库创建N次连接，它是比较浪费资源</p></li> <li><p>foreachPartition算子实现以分区为单位与mysql数据库来创建数据库连接，可以大大减少与mysql数据创建的连接数，有助于程序的性能提升。所以后期推荐大家使用foreachPartition算子</p></li></ol> <h2 id="案例4-读取文件数据写入到hbase表中"><a href="#案例4-读取文件数据写入到hbase表中" class="header-anchor">#</a> 案例4：读取文件数据写入到hbase表中</h2> <h5 id="案例数据-3"><a href="#案例数据-3" class="header-anchor">#</a> 案例数据</h5> <p>数据是资料中的users.dat文件，数据的大致格式如下，以::为分隔符，一共5个字段，分别是id,gender,age,position,code</p> <div class="language- extra-class"><pre class="language-text"><code>1::F::1::10::48067
2::M::56::16::70072
3::M::25::15::55117
4::M::45::7::02460
5::M::25::20::55455
6::F::50::9::55117
7::M::35::1::06810
</code></pre></div><h5 id="添加pom依赖-2"><a href="#添加pom依赖-2" class="header-anchor">#</a> 添加pom依赖</h5> <p>在之前案例的pom的基础上，添加以下依赖：</p> <div class="language-xml extra-class"><pre class="language-xml"><code>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.hbase<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>hbase-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.2.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><h5 id="创建hbase表"><a href="#创建hbase表" class="header-anchor">#</a> 创建hbase表</h5> <p>确保hbase、hadoop、zookeeper都正常开启，进入hbase shell，创建表person</p> <div class="language-sql extra-class"><pre class="language-sql"><code><span class="token keyword">start</span><span class="token operator">-</span>hbase<span class="token punctuation">.</span>sh

hbase shell

hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:<span class="token number">001</span>:<span class="token number">0</span><span class="token operator">&gt;</span> <span class="token keyword">create</span> <span class="token string">'person'</span><span class="token punctuation">,</span><span class="token string">'f1'</span><span class="token punctuation">,</span><span class="token string">'f2'</span>
</code></pre></div><h5 id="代码开发"><a href="#代码开发" class="header-anchor">#</a> 代码开发</h5> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span></span><span class="token punctuation">{</span>HBaseConfiguration<span class="token punctuation">,</span> TableName<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>client<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Connection<span class="token punctuation">,</span> ConnectionFactory<span class="token punctuation">,</span> Put<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Data2Hbase <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> sparkConf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;hbase&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> data<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;E:\\LearningAll\\8-HadoopEcosystem-Video\\spark下载资料\\spark课程录播资料\\案例数据\\users.dat&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> data2<span class="token operator">=</span>data<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;::&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    data2<span class="token punctuation">.</span>foreachPartition<span class="token punctuation">(</span>iter<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
      <span class="token keyword">var</span> conne<span class="token operator">:</span>Connection<span class="token operator">=</span><span class="token keyword">null</span>
      <span class="token keyword">try</span><span class="token punctuation">{</span>
        <span class="token keyword">val</span> conf<span class="token operator">=</span>HBaseConfiguration<span class="token punctuation">.</span>create<span class="token punctuation">(</span><span class="token punctuation">)</span>
        conf<span class="token punctuation">.</span>set<span class="token punctuation">(</span><span class="token string">&quot;hbase.zookeeper.quorum&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;node01:2181,node02:2181,node03:2181&quot;</span><span class="token punctuation">)</span>
        conne<span class="token operator">=</span>ConnectionFactory<span class="token punctuation">.</span>createConnection<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
        <span class="token keyword">val</span> tablePerson<span class="token operator">=</span>conne<span class="token punctuation">.</span>getTable<span class="token punctuation">(</span>TableName<span class="token punctuation">.</span>valueOf<span class="token punctuation">(</span><span class="token string">&quot;person&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        iter<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
          <span class="token keyword">val</span> put<span class="token operator">=</span><span class="token keyword">new</span> Put<span class="token punctuation">(</span>x<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          put<span class="token punctuation">.</span>addColumn<span class="token punctuation">(</span><span class="token string">&quot;f1&quot;</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">&quot;gender&quot;</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          put<span class="token punctuation">.</span>addColumn<span class="token punctuation">(</span><span class="token string">&quot;f1&quot;</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          put<span class="token punctuation">.</span>addColumn<span class="token punctuation">(</span><span class="token string">&quot;f1&quot;</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">&quot;position&quot;</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          put<span class="token punctuation">.</span>addColumn<span class="token punctuation">(</span><span class="token string">&quot;f1&quot;</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">&quot;code&quot;</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getBytes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          tablePerson<span class="token punctuation">.</span>put<span class="token punctuation">(</span>put<span class="token punctuation">)</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token keyword">catch</span> <span class="token punctuation">{</span>
        <span class="token keyword">case</span> ex<span class="token operator">:</span>Exception <span class="token keyword">=&gt;</span>println<span class="token punctuation">(</span>ex<span class="token punctuation">.</span>getMessage<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token keyword">finally</span> <span class="token punctuation">{</span><span class="token keyword">if</span> <span class="token punctuation">(</span>conne<span class="token operator">!=</span><span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">{</span>conne<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p>查看hbase中的person表，部分数据如下：</p> <div class="language-sh extra-class"><pre class="language-sh"><code>scan <span class="token string">'person'</span>                                                                                  
<span class="token number">999</span>                 <span class="token assign-left variable">column</span><span class="token operator">=</span>f1:age, <span class="token assign-left variable">timestamp</span><span class="token operator">=</span><span class="token number">1586981613489</span>, <span class="token assign-left variable">value</span><span class="token operator">=</span><span class="token number">25</span>                   
<span class="token number">999</span>                 <span class="token assign-left variable">column</span><span class="token operator">=</span>f1:code, <span class="token assign-left variable">timestamp</span><span class="token operator">=</span><span class="token number">1586981613489</span>, <span class="token assign-left variable">value</span><span class="token operator">=</span><span class="token number">62558</span>               
<span class="token number">999</span>                 <span class="token assign-left variable">column</span><span class="token operator">=</span>f1:gender, <span class="token assign-left variable">timestamp</span><span class="token operator">=</span><span class="token number">1586981613489</span>, <span class="token assign-left variable">value</span><span class="token operator">=</span>M                 
<span class="token number">999</span>                 <span class="token assign-left variable">column</span><span class="token operator">=</span>f1:position, <span class="token assign-left variable">timestamp</span><span class="token operator">=</span><span class="token number">1586981613489</span>, <span class="token assign-left variable">value</span><span class="token operator">=</span><span class="token number">15</span>   
</code></pre></div><h2 id="案例5-实现ip地址查询"><a href="#案例5-实现ip地址查询" class="header-anchor">#</a> 案例5：实现ip地址查询</h2> <h5 id="需求分析"><a href="#需求分析" class="header-anchor">#</a> 需求分析</h5> <p>在互联网中，我们经常会见到城市热点图这样的报表数据，例如在百度统计中，会统计今年的热门旅游城市、热门报考学校等，会将这样的信息显示在热点图中。</p> <p><img src="/assets/img/1579070050537.fd0aa8ad.png" alt="1579070050537"></p> <p>要想实现上面热点图效果，我们需要通过日志信息（运行商或者网站自己生成）和城市ip段信息来判断用户的ip段，统计热点经纬度。</p> <p>示意图：基站下放给用户可以上网的ip地址，通过这个ip地址就可以定位用户的坐标（经纬度）。</p> <p><img src="/assets/img/image-20200416043037480.03bbf87b.png" alt="image-20200416043037480"></p> <h5 id="案例数据-4"><a href="#案例数据-4" class="header-anchor">#</a> 案例数据</h5> <p>1、日志信息数据: 20090121000132.394251.http.format</p> <p>各字段分别表示：时间戳|ip地址|.......,只需要留意前2个字段</p> <p><img src="/assets/img/1579070153331.051eef8e.png" alt="1579070153331"></p> <p>2、城市ip段信息数据: ip.txt，类似于码表数据</p> <p>开始数字和结束数字分别是开始ip和结束ip经过算法计算得到的值。</p> <p><img src="/assets/img/1579070232110.bc07f573.png" alt="1579070232110"></p> <h5 id="开发思路"><a href="#开发思路" class="header-anchor">#</a> 开发思路</h5> <p>1、 加载城市ip段信息，获取ip起始数字和结束数字，经度，维度</p> <p>2、 加载日志数据，获取ip信息，然后使用相同的算法将ip转换为数字，和ip段比较</p> <p>3、 比较的时候采用二分法查找，找到对应的经度和维度</p> <p>4、 然后对经度和维度做单词计数</p> <h5 id="广播变量"><a href="#广播变量" class="header-anchor">#</a> 广播变量</h5> <p>在本次的ip案例中，要将日志数据中的每个ip都拿去跟城市ip信息数据进行匹配，为每个日志数据中的ip匹配对应的经纬度，而如果每个task都加载一份城市ip信息数据到内存中的话，无疑是非常消耗内存的，因此需要将城市ip信息数据封装在广播变量里，作为共享数据。</p> <p><img src="/assets/img/image-20200416123110870.c1348d79.png" alt="image-20200416123110870"></p> <h5 id="代码实现"><a href="#代码实现" class="header-anchor">#</a> 代码实现</h5> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> CityIp <span class="token punctuation">{</span>
  <span class="token keyword">def</span> ip2Long<span class="token punctuation">(</span>ip<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span><span class="token builtin">Long</span><span class="token operator">=</span><span class="token punctuation">{</span>
    <span class="token keyword">val</span> ipSpl<span class="token operator">:</span>Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token operator">=</span>ip<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;\\.&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">var</span> ipLong<span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token number">0L</span>
    <span class="token keyword">for</span><span class="token punctuation">(</span>i<span class="token keyword">&lt;-</span>ipSpl<span class="token punctuation">)</span><span class="token punctuation">{</span>
      ipLong<span class="token operator">=</span>i<span class="token punctuation">.</span>toLong <span class="token operator">|</span> ipLong<span class="token operator">&lt;&lt;</span><span class="token number">8L</span>
    <span class="token punctuation">}</span>
    ipLong
  <span class="token punctuation">}</span>
  <span class="token keyword">def</span> binarySearch<span class="token punctuation">(</span>ipLong<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> cityIp<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span><span class="token punctuation">{</span>
    <span class="token comment">//定义码表数组的起始下标：</span>
    <span class="token keyword">var</span> startIndex<span class="token operator">=</span><span class="token number">0</span>
    <span class="token comment">//定义码表数组的结束下标：</span>
    <span class="token keyword">var</span> endIndex<span class="token operator">=</span>cityIp<span class="token punctuation">.</span>length<span class="token operator">-</span><span class="token number">1</span>

    <span class="token keyword">while</span><span class="token punctuation">(</span>startIndex<span class="token operator">&lt;=</span>endIndex<span class="token punctuation">)</span><span class="token punctuation">{</span>
      <span class="token keyword">val</span> middleIndex<span class="token operator">=</span><span class="token punctuation">(</span>startIndex<span class="token operator">+</span>endIndex<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span>
      <span class="token comment">//如果正好满足中间的元组的IP数值</span>
      <span class="token keyword">if</span><span class="token punctuation">(</span>ipLong <span class="token operator">&gt;=</span> cityIp<span class="token punctuation">(</span>middleIndex<span class="token punctuation">)</span><span class="token punctuation">.</span>_1<span class="token punctuation">.</span>toLong <span class="token operator">&amp;&amp;</span> ipLong<span class="token operator">&lt;=</span>cityIp<span class="token punctuation">(</span>middleIndex<span class="token punctuation">)</span><span class="token punctuation">.</span>_2<span class="token punctuation">.</span>toLong<span class="token punctuation">)</span><span class="token punctuation">{</span>
        <span class="token keyword">return</span> middleIndex
      <span class="token punctuation">}</span>
      <span class="token keyword">if</span><span class="token punctuation">(</span>ipLong <span class="token operator">&gt;</span> cityIp<span class="token punctuation">(</span>middleIndex<span class="token punctuation">)</span><span class="token punctuation">.</span>_1<span class="token punctuation">.</span>toLong<span class="token punctuation">)</span><span class="token punctuation">{</span>
        startIndex<span class="token operator">=</span>middleIndex<span class="token operator">+</span><span class="token number">1</span>
      <span class="token punctuation">}</span>
      <span class="token keyword">if</span><span class="token punctuation">(</span>ipLong<span class="token operator">&lt;</span>cityIp<span class="token punctuation">(</span>middleIndex<span class="token punctuation">)</span><span class="token punctuation">.</span>_2<span class="token punctuation">.</span>toLong<span class="token punctuation">)</span><span class="token punctuation">{</span>
        endIndex<span class="token operator">=</span>middleIndex
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    <span class="token operator">-</span><span class="token number">1</span> <span class="token comment">//-1表示下标没有找到</span>
  <span class="token punctuation">}</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> sparkconf<span class="token operator">=</span><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;Ip&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span><span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkconf<span class="token punctuation">)</span>
    <span class="token comment">//加载ip码表数据</span>
    <span class="token keyword">val</span> ipData<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;E:\\LearningAll\\8-HadoopEcosystem-Video\\spark下载资料\\spark课程录播资料\\案例数据\\ip.txt&quot;</span><span class="token punctuation">)</span>
    <span class="token comment">//处理ip码表数据</span>
    <span class="token keyword">val</span> ipData2<span class="token operator">=</span>ipData<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;\\|&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">(</span>x<span class="token punctuation">.</span>length<span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">(</span>x<span class="token punctuation">.</span>length<span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//创建广播变量</span>
    <span class="token keyword">val</span> bdIP<span class="token operator">=</span>sc<span class="token punctuation">.</span>broadcast<span class="token punctuation">(</span>ipData2<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//加载运营商日志数据</span>
    <span class="token keyword">val</span> logData<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;E:\\LearningAll\\8-HadoopEcosystem-Video\\spark下载资料\\spark课程录播资料\\案例数据\\20090121000132.394251.http.format&quot;</span><span class="token punctuation">)</span>
    <span class="token comment">//处理运营商日志数据</span>
    <span class="token keyword">val</span> logIps<span class="token operator">=</span>logData<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;\\|&quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//遍历日志数据中的每个ip，将ip转为Long类型数值</span>
    <span class="token keyword">val</span> andOneRDD<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span>logIps<span class="token punctuation">.</span>mapPartitions<span class="token punctuation">(</span>iter<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
      <span class="token comment">//获取广播变量的数据</span>
      <span class="token keyword">val</span> cityIp<span class="token operator">:</span>Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span>bdIP<span class="token punctuation">.</span>value
      <span class="token comment">//遍历日志的ip，将ip转为数值</span>
      iter<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
        <span class="token keyword">val</span> ipLong<span class="token operator">=</span>ip2Long<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment">//获取ipLong在ip码表对应的索引数值（获取ipLong处在城市ipx信息表的第几行的ip数值区间）</span>
        <span class="token keyword">val</span> index<span class="token operator">:</span><span class="token builtin">Int</span><span class="token operator">=</span>binarySearch<span class="token punctuation">(</span>ipLong<span class="token punctuation">,</span>cityIp<span class="token punctuation">)</span><span class="token punctuation">.</span>toInt
        <span class="token comment">//获取下标对应的经纬度等信息</span>
        <span class="token keyword">val</span> resultJW<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">=</span>cityIp<span class="token punctuation">(</span>index<span class="token punctuation">)</span>
        <span class="token comment">//封装数据,作为返回值</span>
        <span class="token punctuation">(</span><span class="token punctuation">(</span>resultJW<span class="token punctuation">.</span>_3<span class="token punctuation">,</span>resultJW<span class="token punctuation">.</span>_4<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token comment">//相同的经纬度出现累加1</span>
    <span class="token keyword">val</span> finalResult<span class="token operator">=</span>andOneRDD<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>

    <span class="token comment">//打印数据：</span>
    finalResult<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p>运行结果为：</p> <div class="language- extra-class"><pre class="language-text"><code>((106.51107,106.51107),91)
((108.948024,108.948024),1824)
((114.502461,114.502461),383)
((106.27633,106.27633),36)
((102.712251,102.712251),126)
((107.08166,107.08166),29)
((116.405285,116.405285),1535)
((107.7601,107.7601),85)
((107.39007,107.39007),47)
((106.57434,106.57434),177)
((106.56347,106.56347),3)
((106.504962,106.504962),400)
</code></pre></div><h5 id="小结-2"><a href="#小结-2" class="header-anchor">#</a> 小结</h5> <p>该案例比较贴近实际的真实需求，含金量是比较高，这里使用了广播变量知识点、二分查询、ip地址转成Long类型数字，大家多多练习！掌握spark中的RDD编程。</p> <h2 id="spark程序的序列化问题"><a href="#spark程序的序列化问题" class="header-anchor">#</a> spark程序的序列化问题</h2> <h4 id="transformation操作为什么需要序列化"><a href="#transformation操作为什么需要序列化" class="header-anchor">#</a> transformation操作为什么需要序列化</h4> <p>spark是分布式执行引擎，其核心抽象是弹性分布式数据集RDD，其代表了分布在不同节点的数据。Spark的计算是在executor上分布式执行的，所以用户执行RDD的map，flatMap，reduceByKey等transformation 操作时可能有如下执行过程：</p> <ol><li>代码中对象在driver本地序列化</li> <li>对象序列化后传输到远程executor节点</li> <li>远程executor节点反序列化对象</li> <li>最终远程节点执行</li></ol> <p>这些操作要序列化的原因：</p> <p>我们知道，transformation这些算子都是要传入参数的，而且很多的参数都是函数，类似于闭包，闭包可简单理解成“定义在一个函数内部的函数”。</p> <p>假如说作为算子参数的函数是：x=&gt;(x,外部定义的对象或变量等)，外部定义的对象或变量等是在driver端创建的，那么如果作为算子参数的函数要使用外部的东西，就要从driver端拉取外部对象等过来到当前executor，从而使用。</p> <p>因此，对象在执行中需要序列化通过网络传输，则必须经过序列化过程。</p> <p><img src="/assets/img/image-20200416162320980.1ca863cf.png" alt="image-20200416162320980"></p> <h4 id="spark的任务序列化异常原因"><a href="#spark的任务序列化异常原因" class="header-anchor">#</a> spark的任务序列化异常原因</h4> <h5 id="报错的可能原因"><a href="#报错的可能原因" class="header-anchor">#</a> 报错的可能原因</h5> <p>在编写spark程序中，由于在map，foreachPartition等算子内部使用了外部定义的变量和函数，从而引发Task未序列化问题。</p> <p>然而spark算子在计算过程中使用外部变量在许多情形下确实在所难免，比如在filter算子根据外部指定的条件进行过滤，map根据相应的配置进行变换。</p> <p>经常会出现“org.apache.spark.SparkException: Task not serializable”这个错误，出现这个错误的原因可能是：</p> <ol><li>这些算子使用了外部的变量，但是这个变量不能序列化。</li> <li>当前类使用了“extends Serializable”声明支持序列化，但是由于某些字段不支持序列化，仍然会导致整个类序列化时出现问题，最终导致出现Task未序列化问题。</li></ol> <h5 id="示例1"><a href="#示例1" class="header-anchor">#</a> 示例1：</h5> <p>数据库连接定义在了foreachPartition算子外部，当算子内部要使用该连接时，就出现了序列化错误。这是因为这个数据库连接是在driver端构建的，而数据库连接没有实现序列化，无法传输到不同机器的executor，就报错了。</p> <p><img src="/assets/img/image-20200416163718819.cf388296.png" alt="image-20200416163718819"></p> <h5 id="示例2"><a href="#示例2" class="header-anchor">#</a> 示例2：</h5> <p>看下图，serialDemo是在object外部定义的类，虽然serialDemo extends Serializable实现序列化，但是，因为该类里面的数据库连接是conne是不支持序列化的，导致序列化不成功。虽然引用的是name变量，但还是报错了。</p> <p>如果函数中使用了该类对象的成员变量，该类除了要实现序列化之外，<strong>所有的成员变量必须要实现序列化</strong>。</p> <p><img src="/assets/img/image-20200416164933460.54034453.png" alt="image-20200416164933460"></p> <h4 id="spark中解决序列化问题的办法"><a href="#spark中解决序列化问题的办法" class="header-anchor">#</a> spark中解决序列化问题的办法</h4> <ol><li>如果函数中使用了该类对象，该类要实现序列化，序列化方法：class xxx extends Serializable{}</li> <li>如果函数中使用了该类对象的成员变量，该类除了要实现序列化之外，所有的成员变量必须要实现序列化</li> <li>对于不能序列化的成员变量使用**“@transient”**标注，告诉编译器不需要序列化</li> <li>也可将依赖的变量独立放到一个小的class中，让这个class支持序列化，这样做可以减少网络传输量，提高效率。</li> <li>可以把对象的创建直接在该函数中构建这样避免需要序列化</li></ol> <p>因此，遵从这些方法，将上面示例2中的代码改成如下就可以运行成功了：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Connection<span class="token punctuation">,</span> DriverManager<span class="token punctuation">,</span> PreparedStatement<span class="token punctuation">}</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">class</span> serialDemo <span class="token keyword">extends</span> Serializable <span class="token punctuation">{</span>
  <span class="token keyword">val</span> name<span class="token operator">:</span><span class="token builtin">String</span><span class="token operator">=</span><span class="token string">&quot;krystal&quot;</span>
  <span class="token annotation punctuation">@transient</span>
  <span class="token keyword">val</span> conne <span class="token operator">=</span> DriverManager<span class="token punctuation">.</span>getConnection<span class="token punctuation">(</span><span class="token string">&quot;jdbc:mysql://node03:3306/demo1&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;root&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;123456&quot;</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
<span class="token keyword">object</span> Data2MysqlForeachPartition <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> sparkkconf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;ForeachMysql&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkkconf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> rdd1<span class="token operator">=</span>sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sd<span class="token operator">=</span><span class="token keyword">new</span> serialDemo<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> rdd2<span class="token operator">=</span>rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>sd<span class="token punctuation">.</span>name<span class="token punctuation">)</span><span class="token punctuation">)</span>
    rdd2<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>运行结果为：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span>krystal<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>krystal<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>krystal<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>krystal<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span>krystal<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span>krystal<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span>krystal<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span>krystal<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">,</span>krystal<span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span>krystal<span class="token punctuation">)</span>
</code></pre></div><h2 id="spark-on-yarn"><a href="#spark-on-yarn" class="header-anchor">#</a> spark on yarn</h2> <p>spark程序可以提交到yarn中去运行，此时spark任务所需要的计算资源由yarn中的老大ResourceManager去分配</p> <p>官网资料地址: http://spark.apache.org/docs/2.3.3/running-on-yarn.html</p> <h4 id="环境准备"><a href="#环境准备" class="header-anchor">#</a> 环境准备</h4> <ol><li>安装hadoop集群</li> <li>安装spark环境</li></ol> <p>注意：</p> <p>这里不需要安装spark集群，只需要解压spark安装包到任意一台服务器，然后修改文件spark-env.sh:</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token comment">#指定java的环境变量</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/kkb/install/jdk1.8.0_141
<span class="token comment">#指定hadoop的配置文件目录</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_CONF_DIR</span><span class="token operator">=</span>/kkb/install/hadoop-2.6.0-cdh5.14.2/etc/hadoop
</code></pre></div><p>因为我们之前安装过了spark集群，包含了spark环境，所以我们不需要做任何操作</p> <h4 id="sparkonyarn模式"><a href="#sparkonyarn模式" class="header-anchor">#</a> sparkOnYarn模式</h4> <p>按照Spark应用程序中的driver分布方式不同，Spark on YARN有两种模式：</p> <ol><li>yarn-client模式</li> <li>yarn-cluster`模式</li></ol> <h5 id="yarn-cluster模式"><a href="#yarn-cluster模式" class="header-anchor">#</a> yarn-cluster模式</h5> <p>提交spark的测试程序到yarn运行：</p> <div class="language-shell extra-class"><pre class="language-shell"><code>spark-submit --class org.apache.spark.examples.SparkPi <span class="token punctuation">\</span>
--master <span class="token function">yarn</span> <span class="token punctuation">\</span>
--deploy-mode cluster <span class="token punctuation">\</span>
--driver-memory 1g <span class="token punctuation">\</span>
--executor-memory 1g <span class="token punctuation">\</span>
--executor-cores <span class="token number">1</span> <span class="token punctuation">\</span>
/kkb/install/spark/examples/jars/spark-examples_2.11-2.3.3.jar <span class="token punctuation">\</span>
<span class="token number">10</span>

<span class="token comment">#特别注意 </span>
	--master 的值是yarn
	--deploy-mode 的值是cluster，表示使用cluster模式运行
</code></pre></div><p>如果运行出现错误，可能是虚拟内存不足，可以添加参数</p> <p>vim yarn-site.xml</p> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token comment">&lt;!--容器是否会执行物理内存限制，默认为True--&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.pmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token comment">&lt;!--容器是否会执行虚拟内存限制，默认为True--&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.vmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><p>说明：</p> <p>1、使用cluster集群模式时，如果在运行中途，在运行窗口界面按ctrl+c是终止不了spark程序的运行的，虽然窗口不再有打印输出，但是程序还是在运行着的。如下：</p> <p><img src="/assets/img/image-20200416173857717.52abff73.png" alt="image-20200416173857717"></p> <p>2、ctrl+c停止打印输出后，我们去查看http://node01:8088/cluster的信息，发现该任务执行成功了：</p> <p><img src="/assets/img/image-20200416174244879.56d2cc16.png" alt="image-20200416174244879"></p> <p>3、点击该Application的ID，查看log,可看到运行结果：</p> <p><img src="/assets/img/image-20200416174653942.6f404951.png" alt="image-20200416174653942"></p> <p>4、即使不使用ctrl+c中断打印信息的输出，程序在运行完成后（state：Finished代表运行完成），在Linux的运行输出窗口依然是看不到Pi的结果输出的。这跟cluster模式运行有关。</p> <h5 id="yarn-client模式"><a href="#yarn-client模式" class="header-anchor">#</a> yarn-client模式</h5> <p>提交spark的测试程序到yarn运行：</p> <div class="language-shell extra-class"><pre class="language-shell"><code>spark-submit --class org.apache.spark.examples.SparkPi <span class="token punctuation">\</span>
--master <span class="token function">yarn</span> <span class="token punctuation">\</span>
--deploy-mode client <span class="token punctuation">\</span>
--driver-memory 1g <span class="token punctuation">\</span>
--executor-memory 1g <span class="token punctuation">\</span>
--executor-cores <span class="token number">1</span> <span class="token punctuation">\</span>
/kkb/install/spark/examples/jars/spark-examples_2.11-2.3.3.jar <span class="token punctuation">\</span>
<span class="token number">10</span>
</code></pre></div><p>说明：</p> <ol><li>在client模式下，如果ctrl+c中断了输出，等同于停止了程序的运行。</li> <li>在client模式下，可以在Linux的运行输出窗口看到Pi结果的输出</li></ol> <h4 id="两种模式的原理"><a href="#两种模式的原理" class="header-anchor">#</a> 两种模式的原理</h4> <p>首先来回顾以下MapReduce程序运行在yarn的大致流程：</p> <ol><li>客户端与ResourceManager进行通信，申请Application</li> <li>客户端提交jar包到hdfs</li> <li>RM向集群的某个NodeManager申请开启ApplicationMaster,该NM就启动一个Container，在该Container里面启动ApplicationMaster</li> <li>ApplicationMaster向RM申请在某些NodeManager启动容器，给task运行，然后NM就会启动一些Container给task运行</li></ol> <h5 id="yarn-cluster模式原理"><a href="#yarn-cluster模式原理" class="header-anchor">#</a> yarn-cluster模式原理：</h5> <p>结合yanr的工作机制,yarn-cluter模式执行spark程序的大致流程如下：</p> <ol><li>客户端提交Application到RM</li> <li>RM找到某个节点上NodeManager，申请Container来启动一个ApplicationMaster。</li> <li>ApplicationMaster启动后，会在内部构建一个spark context对象。SparkContext的底层调度器由taskScheduler变成了YarnClusterScheduler。</li> <li>在之前了解到，SparkContext对象是在Driver端的，因此，Driver端也是在该ApplicationMaster进程内部的。ApplicationMaster跟driver端捆绑在一起了，ApplicationMaster在哪里，driver端就在哪里。</li> <li>构建好SparkContext对象后，ApplicationMaster会向RM申请计算资源Container。</li> <li>然后在某些NodeManager节点上就会启动Container,在Container上启动executor</li> <li>最后，YarnClusterScheduler就会提交task到executor上运行</li></ol> <p>了解yarn-cluster模式的机制后，就可以理解：为什么ctrl+c终止客户端终端停止不了spark程序的运行了。</p> <p>这是因为Driver端跟客户端不在同一个节点，比如客户端在node01,而nodemanager和dirver都在node02。</p> <p><img src="/assets/img/image-20200416191119359.ade43fbe.png" alt="image-20200416191119359"></p> <h5 id="yarn-client模式原理"><a href="#yarn-client模式原理" class="header-anchor">#</a> yarn-client模式原理：</h5> <p>client模式与cluster模式的流程很相似，只不过是Driver端的位置发生了变化，Driver端跟客户端捆绑在了一起，YarnClusterScheduler也变成了YarnClientScheduler。</p> <p>因此，当使用client模式时，如果我们停掉了客户端终端，就相当于停掉了Driver端，导致程序运行失败。这也是我们输出日志显示不停地尝试连接Driver端的原因。</p> <p><img src="/assets/img/yarn-client.03504e03.png" alt="yarn-client"></p> <h4 id="两种模式的区别"><a href="#两种模式的区别" class="header-anchor">#</a> 两种模式的区别</h4> <p>yarn-cluster模式</p> <ul><li>spark程序的<strong>Driver程序在YARN中运行</strong>，运行结果不能在客户端显示，并且客户端可以在启动应用程序后消失应用的。</li> <li>最好运行那些将结果最终保存在外部存储介质（如HDFS、Redis、Mysql），客户端的终端显示的仅是作为YARN的job的简单运行状况。</li></ul> <p>yarn-client模式</p> <ul><li>spark程序的<strong>Driver运行在Client上</strong>，应用程序运行结果会在客户端显示，所有适合运行结果有输出的应用程序（如spark-shell）</li></ul> <p>总结</p> <ol><li>最大的区别就是Driver端的位置不一样。</li> <li>yarn-cluster: Driver端运行在yarn集群中，与ApplicationMaster进程在一起。</li> <li>yarn-client:  Driver端运行在提交任务的客户端,与ApplicationMaster进程没关系,经常用于进行测试</li></ol> <h2 id="collect-算子操作剖析"><a href="#collect-算子操作剖析" class="header-anchor">#</a> collect 算子操作剖析</h2> <p>collect算子操作的作用：</p> <ol><li>它是一个action操作，会触发任务的运行</li> <li>它会把RDD的数据进行收集之后，以数组的形式返回给Driver端</li></ol> <p><img src="/assets/img/collect.4a1391ec.png" alt="collect"></p> <p>总结：</p> <ol><li><p>默认Driver端的内存大小为1G，由参数 spark.driver.memory 设置。</p></li> <li><p>如果某个rdd的数据量超过了Driver端默认的1G内存，对rdd调用collect操作，这里会出现Driver端的内存溢出（OOM），所有这个<strong>collect操作存在一定的风险，实际开发代码一般不会使用</strong>。比如说rdd的数据量达到了10G，rdd.collect这个操作非常危险，很有可能出现driver端的内存不足</p></li> <li><p>广播变量也会占用Driver端一定的内存空间。</p></li> <li><p>实际企业中一般都会把该参数调大，比如5G/10G等。</p> <p>可以在代码中修改该参数，如下</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>set<span class="token punctuation">(</span><span class="token string">&quot;spark.driver.memory&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;5G&quot;</span><span class="token punctuation">)</span>
</code></pre></div></li></ol> <h2 id="spark任务中资源参数剖析"><a href="#spark任务中资源参数剖析" class="header-anchor">#</a> spark任务中资源参数剖析</h2> <p>通过开发工具开发好spark程序后达成jar包最后提交到集群中运行</p> <p>提交任务脚本如下</p> <div class="language-shell extra-class"><pre class="language-shell"><code>spark-submit <span class="token punctuation">\</span>
--master spark://node01:7077,node02:7077 <span class="token punctuation">\</span>
--class com.kaikeba.WordCountOnSpark <span class="token punctuation">\</span>
--executor-memory 1g  <span class="token punctuation">\</span>
--total-executor-cores <span class="token number">4</span> <span class="token punctuation">\</span>
original-spark_class03-1.0-SNAPSHOT.jar <span class="token punctuation">\</span>
/words.txt  /out
</code></pre></div><h4 id="executor-memory"><a href="#executor-memory" class="header-anchor">#</a> --executor-memory</h4> <ul><li>表示每一个executor进程需要的内存大小，它决定了后期操作数据的速度</li></ul> <div class="language- extra-class"><pre class="language-text"><code>比如说一个rdd的数据量大小为5g,这里给定的executor-memory为2g, 在这种情况下，内存是存储不下，它会把一部分数据保存在内存中，还有一部分数据保存在磁盘，后续需要用到该rdd的结果数据，可以从内存和磁盘中获取得到，这里就涉及到一定的磁盘io操作。

,这里给定的executor-memory为10g，这里数据就可以完全在内存中存储下，后续需要用到该rdd的数据，就可以直接从内存中获取，这样一来，避免了大量的磁盘io操作。性能得到提升。


在实际的工作，这里 --executor-memory 需要设置的大一点。
比如说10G/20G/30G等
</code></pre></div><h4 id="total-executor-cores"><a href="#total-executor-cores" class="header-anchor">#</a> --total-executor-cores</h4> <p>--total-executor-cores表示任务运行需要总的cpu核数，它决定了任务并行运行的粒度</p> <p>比如说要处理100个task，注意一个cpu在同一时间只能处理一个task线程。</p> <ol><li><p>如果给定的总的cpu核数是5个，这里就需要100/5=20个批次才可以把这100个task运行完成，如果平均每个task运行1分钟，这里最后一共运行20分钟。</p></li> <li><p>如果给定的总的cpu核数是20个，这里就需要100/20=5个批次才可以把这100个task运行完成，如果平均每个task运行1分钟，这里最后一共运行5分钟。</p></li> <li><p>如果如果给定的总的cpu核数是100个，这里就需要100/100=1个批次才可以把这100个task运行完成，如果平均每个task运行1分钟，这里最后一共运行1分钟。</p></li></ol> <p>在实际的生产环境中，--total-executor-cores 这个参数一般也会设置的大一点，比如说 30个/50个/100个</p> <p><img src="/assets/img/image-20200416204239271.112e3ee6.png" alt="image-20200416204239271"></p> <h4 id="总结"><a href="#总结" class="header-anchor">#</a> 总结</h4> <p>后期对于spark程序的优化，可以从这2个参数入手，无论你把哪一个参数调大，对程序运行的效率来说都会达到一定程度的提升，加大计算资源它是最直接、最有效果的优化手段。</p> <p>在计算资源有限的情况下，可以考虑其他方面，比如说代码层面，JVM层面等</p> <h2 id="spark的shuffle原理分析"><a href="#spark的shuffle原理分析" class="header-anchor">#</a> spark的shuffle原理分析</h2> <h4 id="shuffle概述"><a href="#shuffle概述" class="header-anchor">#</a> shuffle概述</h4> <p>Shuffle就是对数据进行重组，由于分布式计算的特性和要求，在实现细节上更加繁琐和复杂。</p> <p>在MapReduce框架，Shuffle是连接Map和Reduce之间的桥梁，Map阶段通过shuffle读取数据并输出到对应的Reduce；而Reduce阶段负责从Map端拉取数据并进行计算。</p> <p>在整个shuffle过程中，往往伴随着大量的磁盘和网络I/O。所以shuffle性能的高低也直接决定了整个程序的性能高低。<strong>Spark也会有自己的shuffle实现过程。</strong></p> <p>MapReduce Shuffle流程图：</p> <p><img src="/assets/img/mapreduce_shuffle.3d01431e.png" alt="mapreduce_shuffle"></p> <h4 id="spark中的shuffle介绍"><a href="#spark中的shuffle介绍" class="header-anchor">#</a> spark中的shuffle介绍</h4> <p>在DAG调度的过程中，Stage阶段的划分是根据是否有shuffle过程，也就是存在wide Dependency宽依赖的时候,需要进行shuffle,这时候会将作业job划分成多个Stage，每一个stage内部有很多可以并行运行的task。</p> <p>stage与stage之间的过程就是shuffle阶段，在Spark的中，负责shuffle过程的执行、计算和处理的组件主要就是ShuffleManager，也即shuffle管理器。ShuffleManager随着Spark的发展有两种实现的方式，分别为HashShuffleManager和SortShuffleManager，因此spark的Shuffle有Hash Shuffle和Sort Shuffle两种。</p> <h4 id="hashshuffle机制"><a href="#hashshuffle机制" class="header-anchor">#</a> HashShuffle机制</h4> <h5 id="hashshuffle概述"><a href="#hashshuffle概述" class="header-anchor">#</a> HashShuffle概述</h5> <p>在Spark 1.2以前，默认的shuffle计算引擎是HashShuffleManager。</p> <p>该ShuffleManager-HashShuffleManager有着一个非常严重的弊端，就是会产生大量的中间磁盘文件，进而由大量的磁盘IO操作影响了性能。因此在Spark 1.2以后的版本中，默认的ShuffleManager改成了SortShuffleManager。</p> <p>SortShuffleManager相较于HashShuffleManager来说，有了一定的改进。主要就在于每个Task在进行shuffle操作时，虽然也会产生较多的临时磁盘文件，但是最后会将所有的临时文件合并(merge)成一个磁盘文件，因此每个Task就只有一个磁盘文件。在下一个stage的shuffle read task拉取自己的数据时，只要根据索引读取每个磁盘文件中的部分数据即可。</p> <p>HashShuffleManager的运行机制主要分成两种:</p> <ol><li>一种是<strong>普通运行机制</strong></li> <li>另一种是<strong>合并的运行机制</strong>。合并机制主要是通过复用buffer来优化Shuffle过程中产生的小文件的数量。</li></ol> <p>Hash shuffle是不具有排序的Shuffle。</p> <h5 id="普通机制的hash-shuffle"><a href="#普通机制的hash-shuffle" class="header-anchor">#</a> 普通机制的Hash shuffle</h5> <p><img src="/assets/img/未优化的HashShuffle机制.1eb1d73a.png" alt="未优化的HashShuffle机制"></p> <p><strong>图解</strong></p> <p>这里我们先明确一个假设前提：每个Executor只有1个CPU core，也就是说，无论这个Executor上分配多少个task线程，同一时间都只能执行一个task线程。</p> <p>图中有3个ReduceTask，从ShuffleMapTask 开始那边各自把自己进行 Hash 计算(分区器：hash/numreduce取模)，分类出3个不同的类别，每个 ShuffleMapTask 都分成3种类别的数据，想把不同的数据汇聚然后计算出最终的结果，所以ReduceTask 会在属于自己类别的数据收集过来，汇聚成一个同类别的大集合，每1个ShuffleMapTask输出3份本地文件，这里有4个ShuffleMapTask，所以总共输出了4 x 3个分类文件 = 12个本地小文件。</p> <p><strong>shuffle Write阶段</strong></p> <p>主要就是在一个stage结束计算之后，为了下一个stage可以执行shuffle类的算子(比如reduceByKey，groupByKey)，而将每个task处理的数据按key进行“分区”。所谓“分区”，就是对相同的key执行hash算法，从而将相同key都写入同一个磁盘文件中，而每一个磁盘文件都只属于reduce端的stage的一个task。在将数据写入磁盘之前，会先将数据写入内存缓冲Buffer中，当内存缓冲填满之后，才会溢写到磁盘文件中去。</p> <p>那么每个执行shuffle write的task，要为下一个stage创建多少个磁盘文件呢? 很简单，下一个stage的task有多少个，当前stage的每个task就要创建多少份磁盘文件。比如下一个stage总共有100个task，那么当前stage的每个task都要创建100份磁盘文件。如果当前stage有50个task，总共有10个Executor，每个Executor执行5个Task，那么每个Executor上总共就要创建500个磁盘文件，所有Executor上会创建5000个磁盘文件。由此可见，未经优化的shuffle write操作所产生的磁盘文件的数量是极其惊人的。</p> <p><strong>shuffle Read阶段</strong></p> <p>shuffle read，通常就是一个stage刚开始时要做的事情。此时该stage的每一个task就需要将上一个stage的计算结果中的所有相同key，从各个节点上通过网络都拉取到自己所在的节点上，然后进行key的聚合或连接等操作。由于shuffle write的过程中，task给Reduce端的stage的每个task都创建了一个磁盘文件，因此shuffle read的过程中，每个task只要从上游stage的所有task所在节点上，拉取属于自己的那一个磁盘文件即可。</p> <p>shuffle read的拉取过程是一边拉取一边进行聚合的。每个shuffle read task都会有一个自己的buffer缓冲，每次都只能拉取与buffer缓冲相同大小的数据，然后通过内存中的一个Map进行聚合等操作。聚合完一批数据后，再拉取下一批数据，并放到buffer缓冲中进行聚合操作。以此类推，直到最后将所有数据到拉取完，并得到最终的结果。</p> <p><strong>注意</strong></p> <ol><li><p>buffer起到的是缓存作用，缓存能够加速写磁盘，提高计算的效率,shuffle write task buffer的默认大小32k,shuffle read task buffer的默认大小是48M。</p></li> <li><p>分区器：根据hash/numRedcue取模决定数据由几个Reduce处理，也决定了写入几个buffer中</p></li> <li><p>block file：磁盘小文件，从图中我们可以知道磁盘小文件的个数计算公式：
block file=M*R</p></li> <li><p>M为map task的数量，R为Reduce的数量，一般Reduce的数量等于buffer的数量，都是由分区器决定的</p></li></ol> <p><strong>Hash shuffle普通机制的问题</strong></p> <p>（1)Shuffle阶段在磁盘上会产生海量的小文件，建立通信和拉取数据的次数变多,此时会产生大量耗时低效的 IO 操作 (因为产生过多的小文件)</p> <p>（2)可能导致OOM，大量耗时低效的 IO 操作 ，导致写磁盘时的对象过多，读磁盘时候的对象也过多，这些对象存储在堆内存中，会导致堆内存不足，相应会导致频繁的GC，GC会导致OOM。由于内存中需要保存海量文件操作句柄和临时信息，如果数据处理的规模比较庞大的话，内存不可承受，会出现 OOM 等问题</p> <h5 id="合并机制的hash-shuffle"><a href="#合并机制的hash-shuffle" class="header-anchor">#</a> 合并机制的Hash shuffle</h5> <p>合并机制就是复用buffer缓冲区，开启合并机制的配置是spark.shuffle.consolidateFiles。该参数默认值为false，将其设置为true即可开启优化机制。</p> <p>通常来说，如果我们使用HashShuffleManager，那么都建议开启这个选项。</p> <p><img src="/assets/img/优化后的Shuffle机制.f34a54cc.png" alt="优化后的Shuffle机制"></p> <ul><li><strong>图解</strong></li></ul> <p>这里有6个这里有6个shuffleMapTask，数据类别还是分成3种类型，因为Hash算法会根据你的 Key 进行分类，在同一个进程中，无论是有多少过Task，都会把同样的Key放在同一个Buffer里，然后把Buffer中的数据写入以Core数量为单位的本地文件中，(一个Core只有一种类型的Key的数据)。</p> <p>每1个Task所在的进程中，分别写入共同进程中的3份本地文件，这里有6个shuffleMapTasks，所以总共输出是 2个Cores x 3个分类文件 = 6个本地小文件。</p> <ul><li><strong>注意</strong></li></ul> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token number">1</span>、启动HashShuffle的合并机制ConsolidatedShuffle的配置：
	spark.shuffle.consolidateFiles<span class="token operator">=</span>true

<span class="token number">2</span>、block <span class="token assign-left variable">file</span><span class="token operator">=</span>Core*R  <span class="token comment">#产生文件的数量</span>
	Core为CPU的核数，R为ReduceTask的数量
</code></pre></div><ul><li><strong>Hash shuffle合并机制的问题</strong></li></ul> <div class="language- extra-class"><pre class="language-text"><code>  	如果 Reducer 端的并行任务或者是数据分片过多的话则 Core * Reducer Task 依旧过大，也会产生很多小文件。
</code></pre></div><h4 id="sort-shuffle机制"><a href="#sort-shuffle机制" class="header-anchor">#</a> Sort shuffle机制</h4> <p>SortShuffleManager的运行机制主要分成两种，</p> <ul><li>一种是<strong>普通运行机制</strong></li> <li>另一种是<strong>bypass运行机制</strong></li></ul> <h5 id="sort-shuffle的普通机制"><a href="#sort-shuffle的普通机制" class="header-anchor">#</a> Sort shuffle的普通机制</h5> <p><img src="/assets/img/sortshuffle.15ced369.png" alt="sortshuffle"></p> <ul><li><strong>图解</strong></li></ul> <p>在该模式下，数据会先写入一个数据结构，聚合算子写入Map，一边通过Map局部聚合，一边写入内存。Join算子写入ArrayList直接写入内存中。然后需要判断是否达到阈值（5M），如果达到就会将内存数据结构的数据写入到磁盘，清空内存数据结构。</p> <p>在溢写磁盘前，先根据key进行排序，排序过后的数据，会分批写入到磁盘文件中。默认批次为10000条，数据会以每批一万条写入到磁盘文件。写入磁盘文件通过缓冲区溢写的方式，每次溢写都会产生一个磁盘文件，也就是说一个task过程会产生多个临时文件.</p> <p>最后在每个task中，将所有的临时文件合并，这就是merge过程，此过程将所有临时文件读取出来，一次写入到最终文件。意味着一个task的所有数据都在这一个文件中。同时单独写一份索引文件，标识下游各个task的数据在文件中的索引start offset和end offset。</p> <p>这样算来如果第一个stage 50个task，每个Executor执行一个task，那么无论下游有几个task，就需要50*2=100个磁盘文件。</p> <ul><li><strong>好处</strong></li></ul> <div class="language- extra-class"><pre class="language-text"><code>  1. 小文件明显变少了，一个task只生成一个file文件
  
  2. file文件整体有序，加上索引文件的辅助，查找变快，虽然排序浪费一些性能，但是查找变快很多
</code></pre></div><h5 id="bypass模式的sortshuffle"><a href="#bypass模式的sortshuffle" class="header-anchor">#</a> bypass模式的sortShuffle</h5> <p>bypass机制运行条件</p> <ul><li>shuffle map task数量小于spark.shuffle.sort.bypassMergeThreshold参数的值</li> <li>不是聚合类的shuffle算子（比如reduceByKey）</li></ul> <p><img src="/assets/img/bypasssortshuffle.88d96eac.png" alt="bypasssortshuffle"></p> <ul><li><strong>好处</strong></li></ul> <p>该机制与sortshuffle的普通机制相比，在shuffleMapTask不多的情况下，首先写的机制是不同，其次不会进行排序。这样就可以节约一部分性能开销。</p> <ul><li><strong>总结</strong></li></ul> <div class="language- extra-class"><pre class="language-text"><code>在shuffleMapTask数量小于默认值200时，启用bypass模式的sortShuffle(原因是数据量本身比较少，没必要进行sort全排序，因为数据量少本身查询速度就快，正好省了sort的那部分性能开销。)
 
 该机制与普通SortShuffleManager运行机制的不同在于：
    第一: 磁盘写机制不同；
    第二: 不会进行sort排序；
</code></pre></div><h2 id="spark-shuffle参数调优"><a href="#spark-shuffle参数调优" class="header-anchor">#</a> Spark Shuffle参数调优</h2> <p><strong>spark.shuffle.file.buffer</strong></p> <ul><li>默认值：32k</li> <li>参数说明：该参数用于设置shuffle write task的BufferedOutputStream的buffer缓冲大小。将数据写到磁盘文件之前，会先写入buffer缓冲中，待缓冲写满之后，才会溢写到磁盘。</li> <li>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如64k），从而减少shuffle write过程中溢写磁盘文件的次数，也就可以减少磁盘IO次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</li></ul> <p><strong>spark.reducer.maxSizeInFlight</strong></p> <ul><li>默认值：48m</li> <li>参数说明：该参数用于设置shuffle read task的buffer缓冲大小，而这个buffer缓冲决定了每次能够拉取多少数据。</li> <li>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如96m），从而减少拉取数据的次数，也就可以减少网络传输的次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</li></ul> <p><strong>spark.shuffle.io.maxRetries</strong></p> <ul><li>默认值：3</li> <li>参数说明：shuffle read task从shuffle write task所在节点拉取属于自己的数据时，如果因为网络异常导致拉取失败，是会自动进行重试的。该参数就代表了可以重试的最大次数。如果在指定次数之内拉取还是没有成功，就可能会导致作业执行失败。</li> <li>调优建议：对于那些包含了特别耗时的shuffle操作的作业，建议增加重试最大次数（比如60次），以避免由于JVM的full gc或者网络不稳定等因素导致的数据拉取失败。在实践中发现，对于针对超大数据量（数十亿~上百亿）的shuffle过程，调节该参数可以大幅度提升稳定性。</li></ul> <p><strong>spark.shuffle.io.retryWait</strong></p> <ul><li>默认值：5s</li> <li>参数说明：具体解释同上，该参数代表了每次重试拉取数据的等待间隔，默认是5s。</li> <li>调优建议：建议加大间隔时长（比如60s），以增加shuffle操作的稳定性。</li></ul> <p><strong>spark.shuffle.memoryFraction</strong>（Spark1.6是这个参数，1.6以后参数变了，具体参考上一讲Spark内存模型知识）</p> <ul><li>默认值：0.2</li> <li>参数说明：该参数代表了Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是20%。</li> <li>调优建议：在资源参数调优中讲解过这个参数。如果内存充足，而且很少使用持久化操作，建议调高这个比例，给shuffle read的聚合操作更多内存，以避免由于内存不足导致聚合过程中频繁读写磁盘。在实践中发现，合理调节该参数可以将性能提升10%左右。</li></ul> <p><strong>spark.shuffle.manager</strong></p> <ul><li>默认值：sort</li> <li>参数说明：该参数用于设置ShuffleManager的类型。Spark 1.5以后，有三个可选项：hash、sort和tungsten-sort。HashShuffleManager是Spark 1.2以前的默认选项，但是Spark 1.2以及之后的版本默认都是SortShuffleManager了。Spark1.6以后把hash方式给移除了，tungsten-sort与sort类似，但是使用了tungsten计划中的堆外内存管理机制，内存使用效率更高。</li> <li>调优建议：由于SortShuffleManager默认会对数据进行排序，因此如果你的业务逻辑中需要该排序机制的话，则使用默认的SortShuffleManager就可以；而如果你的业务逻辑不需要对数据进行排序，那么建议参考后面的几个参数调优，通过bypass机制或优化的HashShuffleManager来避免排序操作，同时提供较好的磁盘读写性能。这里要注意的是，tungsten-sort要慎用，因为之前发现了一些相应的bug。</li></ul> <p><strong>spark.shuffle.sort.bypassMergeThreshold</strong></p> <ul><li>默认值：200</li> <li>参数说明：当ShuffleManager为SortShuffleManager时，如果shuffle read task的数量小于这个阈值（默认是200），则shuffle write过程中不会进行排序操作，而是直接按照未经优化的HashShuffleManager的方式去写数据，但是最后会将每个task产生的所有临时磁盘文件都合并成一个文件，并会创建单独的索引文件。</li> <li>调优建议：当你使用SortShuffleManager时，如果的确不需要排序操作，那么建议将这个参数调大一些，大于shuffle read task的数量。那么此时就会自动启用bypass机制，map-side就不会进行排序了，减少了排序的性能开销。但是这种方式下，依然会产生大量的磁盘文件，因此shuffle write性能有待提高。</li></ul> <h2 id="数据倾斜原理和现象分析"><a href="#数据倾斜原理和现象分析" class="header-anchor">#</a> 数据倾斜原理和现象分析</h2> <h4 id="数据倾斜概述"><a href="#数据倾斜概述" class="header-anchor">#</a> 数据倾斜概述</h4> <p>有的时候，我们可能会遇到大数据计算中一个最棘手的问题——数据倾斜，此时Spark作业的性能会比期望差很多。</p> <p>数据倾斜调优，就是使用各种技术方案解决不同类型的数据倾斜问题，以保证Spark作业的性能。</p> <h4 id="数据倾斜发生时的现象"><a href="#数据倾斜发生时的现象" class="header-anchor">#</a> 数据倾斜发生时的现象</h4> <p>1、绝大多数task执行得都非常快，但个别task执行极慢</p> <div class="language- extra-class"><pre class="language-text"><code>	你的大部分的task，都执行的特别快，很快就执行完了，剩下几个task，执行的特别特别慢，
前面的task，一般10s可以执行完5个；最后发现某个task，要执行1个小时，2个小时才能执行完一个task。
	
	这个时候就出现数据倾斜了。
这种方式还算好的，因为虽然老牛拉破车一样，非常慢，但是至少还能跑。
</code></pre></div><p>2、绝大数task执行很快，有的task直接报OOM (Jvm Out Of Memory) 异常</p> <div class="language- extra-class"><pre class="language-text"><code>	运行的时候，其他task都很快执行完了，也没什么特别的问题；但是有的task，就是会突然间报了一个OOM，JVM Out Of Memory，内存溢出了，task failed，task lost，resubmitting task等日志异常信息。反复执行几次都到了某个task就是跑不通，最后就挂掉。

	某个task就直接OOM，那么基本上也是因为数据倾斜了，task分配的数量实在是太大了！！！所以内存放不下，然后你的task每处理一条数据，还要创建大量的对象。内存爆掉了。
</code></pre></div><h4 id="数据倾斜发生的原理"><a href="#数据倾斜发生的原理" class="header-anchor">#</a> 数据倾斜发生的原理</h4> <p><img src="/assets/img/数据倾斜.5d19f795.png" alt="数据倾斜"></p> <div class="language- extra-class"><pre class="language-text"><code>如上图所示：
	在进行任务计算shuffle操作的时候，第一个task和第二个task各分配到了1万条数据；需要5分钟计算完毕；第一个和第二个task，可能同时在5分钟内都运行完了；第三个task要98万条数据，98 * 5 = 490分钟 = 8个小时；
	本来另外两个task很快就运行完毕了（5分钟），第三个task数据量比较大，要8个小时才能运行完，就导致整个spark作业，也得8个小时才能运行完。最终导致整个spark任务计算特别慢。
</code></pre></div><h4 id="数据倾斜如何定位原因"><a href="#数据倾斜如何定位原因" class="header-anchor">#</a> 数据倾斜如何定位原因</h4> <h6 id="方法1-主要是根据log日志信息去定位"><a href="#方法1-主要是根据log日志信息去定位" class="header-anchor">#</a> 方法1：主要是根据log日志信息去定位</h6> <p>数据倾斜只会发生在shuffle过程中。这里给大家罗列一些常用的并且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。</p> <p>出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。因为某个或者某些key对应的数据，远远的高于其他的key。</p> <h6 id="方法2-分析定位逻辑"><a href="#方法2-分析定位逻辑" class="header-anchor">#</a> 方法2：分析定位逻辑</h6> <div class="language- extra-class"><pre class="language-text"><code>	由于代码中有大量的shuffle操作，一个job会划分成很多个stage，首先要看的，就是数据倾斜发生在第几个stage中。
	可以在任务运行的过程中，观察任务的UI界面，可以观察到每一个stage中运行的task的数据量，从而进一步确定是不是task分配的数据不均匀导致了数据倾斜。
	比如下图中，倒数第三列显示了每个task的运行时间。明显可以看到，有的task运行特别快，只需要几秒钟就可以运行完;而有的task运行特别慢，需要几分钟才能运行完，此时单从运行时间上看就已经能够确定发生数据倾斜了。
	此外，倒数第一列显示了每个task处理的数据量，明显可以看到，运行时间特别短的task只需要处理几百KB的数据即可，而运行时间特别长的task需要处理几千KB的数据，处理的数据量差了10倍。此时更加能够确定是发生了数据倾斜。
</code></pre></div><p><img src="/assets/img/20170308091203159.7a7d9c14.png" alt="20170308091203159"></p> <h6 id="方法3-某个task莫名其妙内存溢出的情况"><a href="#方法3-某个task莫名其妙内存溢出的情况" class="header-anchor">#</a> 方法3：某个task莫名其妙内存溢出的情况</h6> <p>这种情况下去定位出问题的代码就比较容易了。我们建议直接看yarn-client模式下本地log的异常栈，或者是通过YARN查看yarn-cluster模式下的log中的异常栈。</p> <p>一般来说，通过异常栈信息就可以定位到你的代码中哪一行发生了内存溢出。然后在那行代码附近找找，一般也会有shuffle类算子，此时很可能就是这个算子导致了数据倾斜。</p> <p>但是大家要注意的是，不能单纯靠偶然的内存溢出就判定发生了数据倾斜。因为自己编写的代码的bug，以及偶然出现的数据异常，也可能会导致内存溢出。因此还是要按照上面所讲的方法，通过Spark Web UI查看报错的那个stage的各个task的运行时间以及分配的数据量，才能确定是否是由于数据倾斜才导致了这次内存溢出。</p> <h6 id="方法4-查看导致数据倾斜的key的数据分布情况"><a href="#方法4-查看导致数据倾斜的key的数据分布情况" class="header-anchor">#</a> 方法4：查看导致数据倾斜的key的数据分布情况</h6> <div class="language- extra-class"><pre class="language-text"><code>	知道了数据倾斜发生在哪里之后，通常需要分析一下那个执行了shuffle操作并且导致了数据倾斜的RDD/Hive表，查看一下其中key的分布情况。这主要是为之后选择哪一种技术方案提供依据。针对不同的key分布与不同的shuffle算子组合起来的各种情况，可能需要选择不同的技术方案来解决。
此时根据你执行操作的情况不同，可以有很多种查看key分布的方式：
	如果是Spark SQL中的group by、join语句导致的数据倾斜，那么就查询一下SQL中使用的表的key分布情况。
	如果是对Spark RDD执行shuffle算子导致的数据倾斜，那么可以在Spark作业中加入查看key分布的代码，比如RDD.countByKey()。然后对统计出来的各个key出现的次数，collect/take到客户端打印一下，就可以看到key的分布情况。
	举例来说，对于上面所说的单词计数程序，如果确定了是stage1的reduceByKey算子导致了数据倾斜，那么就应该看看进行reduceByKey操作的RDD中的key分布情况，在这个例子中指的就是pairs RDD。如下示例，我们可以先对pairs采样10%的样本数据，然后使用countByKey算子统计出每个key出现的次数，最后在客户端遍历和打印样本数据中各个key的出现次数。
</code></pre></div><div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> sampledPairs <span class="token operator">=</span> pairs<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> sampledWordCounts <span class="token operator">=</span> sampledPairs<span class="token punctuation">.</span>countByKey<span class="token punctuation">(</span><span class="token punctuation">)</span>
sampledWordCounts<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">(</span>_<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">//sample算子时用来抽样用的，其有3个参数</span>

<span class="token comment">//withReplacement：表示抽出样本后是否在放回去，true表示会放回去，这也就意味着抽出的样本可能有重复</span>

<span class="token comment">//fraction ：抽出多少，这是一个double类型的参数,0-1之间，eg:0.3表示抽出30%</span>

<span class="token comment">//seed：表示一个种子，根据这个seed随机抽取，一般情况下只用前两个参数就可以，那么这个参数是干嘛的呢，这个参数一般用于调试，有时候不知道是程序出问题还是数据出了问题，就可以将这个参数设置为定值</span>
</code></pre></div><h4 id="数据倾斜原因总结"><a href="#数据倾斜原因总结" class="header-anchor">#</a> 数据倾斜原因总结</h4> <p>数据本身问题</p> <div class="language- extra-class"><pre class="language-text"><code>（1）、key本身分布不均衡（包括大量的key为空）
（2）、key的设置不合理
</code></pre></div><p>spark使用不当的问题</p> <div class="language- extra-class"><pre class="language-text"><code>（1）、shuffle时的并发度不够
（2）、计算方式有误	
</code></pre></div><h4 id="数据倾斜的后果"><a href="#数据倾斜的后果" class="header-anchor">#</a> 数据倾斜的后果</h4> <div class="language- extra-class"><pre class="language-text"><code>（1）spark中的stage的执行时间受限于最后那个执行完成的task,因此运行缓慢的任务会拖垮整个程序的运行速度（分布式程序运行的速度是由最慢的那个task决定的）。

（2）过多的数据在同一个task中运行，将会把executor内存撑爆，导致OOM内存溢出。
</code></pre></div><h2 id="spark中数据倾斜的解决方案"><a href="#spark中数据倾斜的解决方案" class="header-anchor">#</a> spark中数据倾斜的解决方案</h2> <h5 id="解决方案一-使用hive-etl预处理数据"><a href="#解决方案一-使用hive-etl预处理数据" class="header-anchor">#</a> 解决方案一：使用Hive ETL预处理数据</h5> <p>方案适用场景：<strong>导致数据倾斜的是Hive表</strong>。如果该Hive表中的数据本身很不均匀(比如某个key对应了100万数据，其他key才对应了10条数据)，而且业务场景需要频繁使用Spark对Hive表执行某个分析操作，那么比较适合使用这种技术方案。</p> <p>方案实现思路：此时可以评估一下，是否可以通过Hive来进行数据预处理(即通过Hive ETL预先对数据按照key进行聚合，或者是预先和其他表进行join)，然后在<strong>Spark作业中针对的数据源就不是原来的Hive表了，而是预处理后的Hive表</strong>。此时由于数据已经预先进行过聚合或join操作了，那么在Spark作业中也就不需要使用原先的shuffle类算子执行这类操作了。</p> <p>方案实现原理：这种方案从根源上解决了数据倾斜，因为彻底避免了在Spark中执行shuffle类算子，那么肯定就不会有数据倾斜的问题了。但是这里也要提醒一下大家，这种方式属于治标不治本。因为毕竟数据本身就存在分布不均匀的问题，所以Hive ETL中进行group by或者join等shuffle操作时，还是会出现数据倾斜，导致Hive ETL的速度很慢。我们<strong>只是把数据倾斜的发生提前到了Hive ETL中，避免Spark程序发生数据倾斜而已</strong>。</p> <p>方案优点：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，<strong>Spark作业的性能会大幅度提升</strong>。</p> <p>方案缺点：<strong>治标不治本，Hive ETL中还是会发生数据倾斜</strong>。</p> <p>方案实践经验：在一些Java系统与Spark结合使用的项目中，会出现Java代码频繁调用Spark作业的场景，而且对Spark作业的执行性能要求很高，就比较适合使用这种方案。将数据倾斜提前到上游的Hive ETL，每天仅执行一次，只有那一次是比较慢的，而之后每次Java调用Spark作业时，执行速度都会很快，能够提供更好的用户体验。</p> <p>项目实践经验：有一个交互式用户行为分析系统中使用了这种方案，该系统主要是允许用户通过Java Web系统提交数据分析统计任务，后端通过Java提交Spark作业进行数据分析统计。要求Spark作业速度必须要快，尽量在10分钟以内，否则速度太慢，用户体验会很差。所以我们将有些Spark作业的shuffle操作提前到了Hive ETL中，从而让Spark直接使用预处理的Hive中间表，尽可能地减少Spark的shuffle操作，大幅度提升了性能，将部分作业的性能提升了6倍以上。</p> <p><img src="/assets/img/交互式用户行为分析系统.d04352a8.png" alt="交互式用户行为分析系统"></p> <h5 id="解决方案二-过滤少数导致倾斜的key"><a href="#解决方案二-过滤少数导致倾斜的key" class="header-anchor">#</a> 解决方案二：过滤少数导致倾斜的key</h5> <p>方案适用场景：如果发现<strong>导致倾斜的key就少数几个，而且对计算本身的影响并不大</strong>的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。</p> <p>方案实现思路：如果我们判断那少数几个数据量特别多的key，对作业的执行和计算结果不是特别重要的话，那么干脆就<strong>直接过滤掉那少数几个key</strong>。比如，在Spark SQL中可以使用where子句过滤掉这些key或者在Spark Core中对RDD执行filter算子过滤掉这些key。如果需要每次作业执行时，动态判定哪些key的数据量最多然后再进行过滤，那么可以使用sample算子对RDD进行采样，然后计算出每个key的数量，取数据量最多的key过滤掉即可。</p> <p>方案实现原理：将导致数据倾斜的key给过滤掉之后，这些key就不会参与计算了，自然不可能产生数据倾斜。</p> <p>方案优点：实现简单，而且效果也很好，可以完全规避掉数据倾斜。</p> <p>方案缺点：适用场景不多，<strong>大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个</strong>。</p> <p>方案实践经验：在项目中我们也采用过这种方案解决数据倾斜。有一次发现某一天Spark作业在运行的时候突然OOM了，追查之后发现，是Hive表中的某一个key在那天数据异常，导致数据量暴增。因此就采取每次执行前先进行采样，计算出样本中数据量最大的几个key之后，直接在程序中将那些key给过滤掉。</p> <h5 id="解决方案三-提高shuffle操作的并行度-效果差"><a href="#解决方案三-提高shuffle操作的并行度-效果差" class="header-anchor">#</a> 解决方案三：提高shuffle操作的并行度(<strong>效果差</strong>)</h5> <p>方案适用场景：如果我们必须要对数据倾斜迎难而上，那么建议优先使用这种方案，因为这是处理数据倾斜最简单的一种方案。</p> <p>方案实现思路：在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个shuffle算子执行时shuffle read task的数量。对于Spark SQL中的shuffle类语句，比如group by、join等，需要设置一个参数，即spark.sql.shuffle.partitions，该参数代表了shuffle read task的并行度，该值默认是200，对于很多场景来说都有点过小。</p> <p>方案实现原理：增加shuffle read task的数量，可以让原本分配给一个task的多个key分配给多个task，从而让每个task处理比原来更少的数据。举例来说，如果原本有5个key，每个key对应10条数据，这5个key都是分配给一个task的，那么这个task就要处理50条数据。而增加了shuffle read task以后，每个task就分配到一个key，即每个task就处理10条数据，那么自然每个task的执行时间都会变短了。具体原理如下图所示。</p> <p>方案优点：实现起来比较简单，可以有效缓解和减轻数据倾斜的影响。</p> <p>方案缺点：只是缓解了数据倾斜而已，没有彻底根除问题，根据实践经验来看，其<strong>效果有限</strong>。</p> <p>方案实践经验：该方案通常无法彻底解决数据倾斜，因为如果出现一些极端情况，比如某个key对应的数据量有100万，那么无论你的task数量增加到多少，这个对应着100万数据的key肯定还是会分配到一个task中去处理，因此注定还是会发生数据倾斜的。所以这种方案只能说是在发现数据倾斜时尝试使用的第一种手段，尝试去用最简单的方法缓解数据倾斜而已，或者是和其他方案结合起来使用。</p> <p><img src="/assets/img/1570609831990.def97e5b.png" alt="1570609831990"></p> <h5 id="解决方案四-两阶段聚合-局部聚合-全局聚合"><a href="#解决方案四-两阶段聚合-局部聚合-全局聚合" class="header-anchor">#</a> 解决方案四：两阶段聚合（局部聚合+全局聚合）</h5> <p>方案适用场景：<strong>对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时</strong>，比较适用这种方案。</p> <p>方案实现思路：这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先<strong>给每个key都打上一个随机数</strong>，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后<strong>将各个key的前缀给去掉</strong>，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。</p> <p>方案实现原理：将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。具体原理见下图。</p> <p>方案优点：对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。</p> <p>方案缺点：<strong>仅仅适用于聚合类的shuffle操作，适用范围相对较窄</strong>。如果是join类的shuffle操作，还得用其他的解决方案。</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">//案例</span>
<span class="token comment">//  如果使用reduceByKey因为数据倾斜造成运行失败的问题。具体操作流程如下:</span>
<span class="token comment">//    (1) 将原始的 key 转化为  随机值 + key  (随机值 = Random.nextInt)</span>
<span class="token comment">//    (2) 对数据进行 reduceByKey(func)</span>
<span class="token comment">//    (3) 将  随机值+key 转成 key</span>
<span class="token comment">//    (4) 再对数据进行 reduceByKey(func)</span>

<span class="token keyword">object</span> WordCountAggTest <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;WordCount&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> array <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token string">&quot;you you&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;you you&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;you you&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;you you&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;you you&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;you you&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;you you&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;jump jump&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>array<span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span>
    rdd<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span> line <span class="token keyword">=&gt;</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map<span class="token punctuation">(</span>word <span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
        <span class="token keyword">val</span> prefix <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">new</span> util<span class="token punctuation">.</span>Random<span class="token punctuation">)</span><span class="token punctuation">.</span>nextInt<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
        <span class="token punctuation">(</span>prefix<span class="token operator">+</span><span class="token string">&quot;_&quot;</span><span class="token operator">+</span>word<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>
       <span class="token punctuation">.</span>map<span class="token punctuation">(</span> wc <span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
         <span class="token keyword">val</span> newWord<span class="token operator">=</span>wc<span class="token punctuation">.</span>_1<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;_&quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
         <span class="token keyword">val</span> count<span class="token operator">=</span>wc<span class="token punctuation">.</span>_2
         <span class="token punctuation">(</span>newWord<span class="token punctuation">,</span>count<span class="token punctuation">)</span>
       <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>foreach<span class="token punctuation">(</span> wc <span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
        println<span class="token punctuation">(</span><span class="token string">&quot;单词：&quot;</span><span class="token operator">+</span>wc<span class="token punctuation">.</span>_1 <span class="token operator">+</span> <span class="token string">&quot; 次数：&quot;</span><span class="token operator">+</span>wc<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
注：我们这儿使用的是reduceByKey天然的有调优的效果，如果这儿是groupBykey那么发生数据倾斜的概率就会更大，更严重。
</code></pre></div><h5 id="解决方案五-将reduce-join转为map-join"><a href="#解决方案五-将reduce-join转为map-join" class="header-anchor">#</a> 解决方案五：将reduce join转为map join</h5> <p>方案适用场景：在<strong>对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小</strong>（比如几百M或者一两G），比较适用此方案。</p> <p>方案实现思路：不使用join算子进行连接操作，而<strong>使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作</strong>，彻底避免数据倾斜的发生和出现。将较小RDD中的数据直接通过collect算子拉取到Driver端的内存中来，然后对其创建一个Broadcast变量；接着对另外一个RDD执行map类算子，在算子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。</p> <p>方案实现原理：普通的join是会走shuffle过程的，而一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join，此时就是reduce join。但是如果一个RDD是比较小的，则可以采用广播小RDD全量数据+map算子来实现与join同样的效果，也就是map join，此时就不会发生shuffle操作，也就不会发生数据倾斜。具体原理如下图所示。</p> <p>方案优点：对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。</p> <p>方案缺点：适用场景较少，因为这个方案<strong>只适用于一个大表和一个小表的情况</strong>。毕竟我们需要将小表进行广播，此时会比较消耗内存资源，driver和每个Executor内存中都会驻留一份小RDD的全量数据。如果我们广播出去的RDD数据比较大，比如10G以上，那么就可能发生内存溢出了。因此并不适合两个都是大表的情况。</p> <p>![reduce joinz转换为map join ](spark.assets/reduce joinz转换为map join .png)</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">object</span> MapJoinTest <span class="token punctuation">{</span>
 
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">&quot;WordCount&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> lista<span class="token operator">=</span>Array<span class="token punctuation">(</span>
      Tuple2<span class="token punctuation">(</span><span class="token string">&quot;001&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;令狐冲&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      Tuple2<span class="token punctuation">(</span><span class="token string">&quot;002&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;任盈盈&quot;</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
     <span class="token comment">//数据量小一点</span>
    <span class="token keyword">val</span> listb<span class="token operator">=</span>Array<span class="token punctuation">(</span>
      Tuple2<span class="token punctuation">(</span><span class="token string">&quot;001&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;一班&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      Tuple2<span class="token punctuation">(</span><span class="token string">&quot;002&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;二班&quot;</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">val</span> listaRDD <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>lista<span class="token punctuation">)</span>
    <span class="token keyword">val</span> listbRDD <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>listb<span class="token punctuation">)</span>
    <span class="token comment">//val result: RDD[(String, (String, String))] = listaRDD.join(listbRDD)</span>
     <span class="token comment">//设置广播变量</span>
    <span class="token keyword">val</span> listbBoradcast <span class="token operator">=</span> sc<span class="token punctuation">.</span>broadcast<span class="token punctuation">(</span>listbRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    listaRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>  tuple <span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
      <span class="token keyword">val</span> key <span class="token operator">=</span> tuple<span class="token punctuation">.</span>_1
      <span class="token keyword">val</span> name <span class="token operator">=</span> tuple<span class="token punctuation">.</span>_2
      <span class="token keyword">val</span> map <span class="token operator">=</span> listbBoradcast<span class="token punctuation">.</span>value<span class="token punctuation">.</span>toMap
      <span class="token keyword">val</span> className <span class="token operator">=</span> map<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">)</span>
      <span class="token punctuation">(</span>key<span class="token punctuation">,</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span>className<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span> tuple <span class="token keyword">=&gt;</span><span class="token punctuation">{</span>
      println<span class="token punctuation">(</span><span class="token string">&quot;班级号&quot;</span><span class="token operator">+</span>tuple<span class="token punctuation">.</span>_1 <span class="token operator">+</span> <span class="token string">&quot; 姓名：&quot;</span><span class="token operator">+</span>tuple<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>_1 <span class="token operator">+</span> <span class="token string">&quot; 班级名：&quot;</span><span class="token operator">+</span>tuple<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>get<span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><h5 id="解决方案六-采样倾斜key并分拆join操作"><a href="#解决方案六-采样倾斜key并分拆join操作" class="header-anchor">#</a> 解决方案六：采样倾斜key并分拆join操作</h5> <p>方案适用场景：两个RDD/Hive表进行join的时候，如果数据量都比较大，无法采用“解决方案五”，那么此时可以看一下两个RDD/Hive表中的key分布情况。<strong>如果出现数据倾斜，是因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀</strong>，那么采用这个解决方案是比较合适的。</p> <p>方案实现思路：
　　1、对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，<strong>计算出来数据量最大的是哪几个key</strong>。
　　2、然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key形成另外一个RDD。
　　3、接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀，不会导致倾斜的大部分key也形成另外一个RDD。
　　4、再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，<strong>此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。</strong>
　　5、而另外两个普通的RDD就照常join即可。
　　6、最后将两次join的结果使用union算子合并起来即可，就是最终的join结果。</p> <p>方案实现原理：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，可以将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。</p> <p>方案优点：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，采用该方式可以用最有效的方式打散key进行join。而且只需要针对少数倾斜key对应的数据进行扩容n倍，不需要对全量数据进行扩容。避免了占用过多内存。</p> <p>方案缺点：如果导致倾斜的key特别多的话，比如成千上万个key都导致数据倾斜，那么这种方式也不适合。</p> <p><img src="/assets/img/随机前缀和扩容RDD.5571274f.png" alt="随机前缀和扩容RDD"></p> <h5 id="解决方案七-使用随机前缀和扩容rdd进行join"><a href="#解决方案七-使用随机前缀和扩容rdd进行join" class="header-anchor">#</a> 解决方案七：使用随机前缀和扩容RDD进行join</h5> <p>方案适用场景：如果在进行join操作时，RDD中有大量的key导致数据倾斜，那么进行分拆key也没什么意义，此时就只能使用这一种方案来解决问题了。</p> <p>方案实现思路：
　　1、该方案的实现思路基本和“解决方案六”类似，首先查看RDD/Hive表中的数据分布情况，找到那个造成数据倾斜的RDD/Hive表，比如有多个key都对应了超过1万条数据。
　　2、然后将该RDD的每条数据都打上一个n以内的随机前缀。
　　3、同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，扩容出来的每条数据都依次打上一个0~n的前缀。
　　4、最后将两个处理后的RDD进行join即可。</p> <p>方案实现原理：将原先一样的key通过附加随机前缀变成不一样的key，然后就可以将这些处理后的“不同key”分散到多个task中去处理，而不是让一个task处理大量的相同key。该方案与“解决方案六”的不同之处就在于，上一种方案是尽量只对少数倾斜key对应的数据进行特殊处理，由于处理过程需要扩容RDD，因此上一种方案扩容RDD后对内存的占用并不大；而这一种方案是针对有大量倾斜key的情况，没法将部分key拆分出来进行单独处理，因此只能对整个RDD进行数据扩容，对内存资源要求很高。</p> <p>方案优点：对join类型的数据倾斜基本都可以处理，而且效果也相对比较显著，性能提升效果非常不错。</p> <p>方案缺点：该方案更多的是缓解数据倾斜，而不是彻底避免数据倾斜。而且需要对整个RDD进行扩容，对内存资源要求很高。</p> <p>方案实践经验：曾经开发一个数据需求的时候，发现一个join导致了数据倾斜。优化之前，作业的执行时间大约是60分钟左右；使用该方案优化之后，执行时间缩短到10分钟左右，性能提升了6倍。</p> <h5 id="解决方案八-把上面的几种数据倾斜的解决方案综合的灵活运行"><a href="#解决方案八-把上面的几种数据倾斜的解决方案综合的灵活运行" class="header-anchor">#</a> 解决方案八：把上面的几种数据倾斜的解决方案综合的灵活运行</h5> <p>------------------------spark第三次课-------------------------------------</p> <h2 id="rdd的依赖关系"><a href="#rdd的依赖关系" class="header-anchor">#</a> RDD的依赖关系</h2> <h5 id="依赖类型"><a href="#依赖类型" class="header-anchor">#</a> 依赖类型</h5> <p>RDD根据依赖关系，可以分为父RDD和子RDD，父RDD就是被子RDD依赖的RDD。</p> <p>而父RDD与子RDD的依赖关系，可以分为两种类型：</p> <ol><li>窄依赖（narrow dependency）</li> <li>宽依赖（wide dependency）</li></ol> <h5 id="窄依赖"><a href="#窄依赖" class="header-anchor">#</a> 窄依赖</h5> <p>窄依赖：指的是每一个父RDD的Partition最多被子RDD的一个Partition使用，可比喻为独生子女。</p> <p>map/flatMap/filter/union等算子操作都是窄依赖，所有的窄依赖不会产生shuffle</p> <h5 id="宽依赖"><a href="#宽依赖" class="header-anchor">#</a> 宽依赖</h5> <p>宽依赖：指的是多个子RDD的Partition会依赖同一个父RDD的Partition，可比喻为超生。</p> <p>reduceByKey/sortByKey/groupBy/groupByKey/join等算子操作都是宽依赖，所有的宽依赖会产生shuffle</p> <h5 id="示意图"><a href="#示意图" class="header-anchor">#</a> 示意图</h5> <p><img src="/assets/img/image-20200417040624865.0bd02299.png" alt="image-20200417040624865"></p> <h5 id="补充说明"><a href="#补充说明" class="header-anchor">#</a> 补充说明</h5> <p>由上图可知，join分为宽依赖和窄依赖，如果RDD有相同的partitioner(本质是看分区函数或者分区逻辑是否相同），那么将不会引起shuffle，这种join是窄依赖，反之就是宽依赖。详情看下图：</p> <p><img src="/assets/img/image-20200417042221150.d7b48668.png" alt="image-20200417042221150"></p> <h2 id="lineage-血统-理解即可"><a href="#lineage-血统-理解即可" class="header-anchor">#</a> lineage（血统）理解即可</h2> <p>RDD只支持粗粒度转换：即只记录单个块上执行的单个操作。</p> <p>那么，就需要创建RDD的一系列Lineage（即血统）记录下来，以便恢复丢失的分区。</p> <p>RDD的Lineage会记录RDD的元数据信息和转换行为，lineage保存了RDD的依赖关系，当该RDD的部分分区数据丢失时，它可以根据这些信息来重新运算和恢复丢失的数据分区。</p> <p>比如，下图中的rdd2的1号分区的数据丢失了，那么就可以根据血统lineage保存的RDD的依赖关系和转换行为等，将rdd1中的数据进行flatMap操作恢复丢失的数据。</p> <p><img src="/assets/img/image-20200417042533244.730e3426.png" alt="image-20200417042533244"></p> <h2 id="rdd的缓存机制-★★★★★"><a href="#rdd的缓存机制-★★★★★" class="header-anchor">#</a> RDD的缓存机制（★★★★★)</h2> <h4 id="什么是rdd的缓存"><a href="#什么是rdd的缓存" class="header-anchor">#</a> 什么是rdd的缓存</h4> <p>spark可以把一个rdd的数据缓存起来，后续有其他的job需要用到该rdd的结果数据，可以直接从缓存中获取得到，避免了重复计算。缓存是加快后续对该数据的访问操作。</p> <h4 id="如何对rdd设置缓存"><a href="#如何对rdd设置缓存" class="header-anchor">#</a> 如何对rdd设置缓存</h4> <p>可以通过persist方法或cache方法将前面的RDD的数据缓存。但这两个方法被调用时不会立即执行缓存操作，而是触发后面的action时，才将RDD缓存在计算节点的内存中，并供后面重用。</p> <p>persist方法和cache方法的源代码如下，可以看到cache方法内调用了persist方法，persist方法的参数的默认值是StorageLevel.MEMORY_ONLY。</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">/**
   * Persist this RDD with the default storage level (`MEMORY_ONLY`).
   */</span>
  <span class="token keyword">def</span> persist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token keyword">type</span> <span class="token operator">=</span> persist<span class="token punctuation">(</span>StorageLevel<span class="token punctuation">.</span>MEMORY_ONLY<span class="token punctuation">)</span>

  <span class="token comment">/**
   * Persist this RDD with the default storage level (`MEMORY_ONLY`).
   */</span>
  <span class="token keyword">def</span> cache<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token keyword">this</span><span class="token punctuation">.</span><span class="token keyword">type</span> <span class="token operator">=</span> persist<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p>StorageLevel的部分源码带，StorageLevel是一个object，里面定义了不同的变量来表示不同的存储级别。</p> <ol><li>NONE 不进行缓存</li> <li>DISK_ONLY 缓存到磁盘    DISK_ONLY_2 缓存到磁盘,2份</li> <li>MEMORY_ONLY 缓存到内存    MEMORY_ONLY_2 缓存到内存2份</li> <li>MEMORY_ONLY_SER 序列化后缓存到内存  MEMORY_ONLY_SER_2 序列化后缓存到内存2份</li> <li>MEMORY_AND_DISK  缓存到内存或磁盘 MEMORY_AND_DISK_2  缓存到内存或磁盘2份</li> <li>MEMORY_AND_DISK_SER 缓存到内存或磁盘且序列化  MEMORY_AND_DISK_SER_2 ...</li> <li>OFF_HEAP 缓存到堆外</li></ol> <p>注意：MEMORY_AND_DISK并不是把数据缓存一部分在内存中一部分在磁盘中，而是优先考虑内存，内存不够了才缓存到磁盘。</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">object</span> StorageLevel <span class="token punctuation">{</span>
  <span class="token keyword">val</span> NONE <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> DISK_ONLY <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> DISK_ONLY_2 <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> MEMORY_ONLY <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> MEMORY_ONLY_2 <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> MEMORY_ONLY_SER <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> MEMORY_ONLY_SER_2 <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> MEMORY_AND_DISK <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> MEMORY_AND_DISK_2 <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> MEMORY_AND_DISK_SER <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> MEMORY_AND_DISK_SER_2 <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> OFF_HEAP <span class="token operator">=</span> <span class="token keyword">new</span> StorageLevel<span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="cache和persist的使用示例"><a href="#cache和persist的使用示例" class="header-anchor">#</a> cache和persist的使用示例</h4> <p>打开spark shell</p> <div class="language-sh extra-class"><pre class="language-sh"><code>spark-shell --master spark://node01:7077 --executor-memory 1g --total-executor-cores <span class="token number">2</span>
</code></pre></div><p>登录8080端口的spark页面，找到spark shell对应的Application，点击Spark shell</p> <img src="spark.assets/image-20200417093437067.png" alt="image-20200417093437067" style="zoom:67%;"> <p>点击后，就进入了http://node01:4040/jobs/，然后切换到Storage</p> <img src="spark.assets/image-20200417093646386.png" alt="image-20200417093646386" style="zoom:67%;"> <p>往spark shell一行行执行下列代码，注意刷新观察Storage界面的变化。</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/words.txt&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd2<span class="token operator">=</span>rdd1<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd3<span class="token operator">=</span>rdd2<span class="token punctuation">.</span>cache
rdd3<span class="token punctuation">.</span>collect
</code></pre></div><p>执行完rdd3.collect后，页面才发生了变化，如下图，图中显示存储在内存中的大小为440.0B，磁盘为0：</p> <p><img src="/assets/img/image-20200417094145627.4931f44d.png" alt="image-20200417094145627"></p> <p>继续执行下列代码：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd4<span class="token operator">=</span>rdd3<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd5<span class="token operator">=</span>rdd4<span class="token punctuation">.</span>persist<span class="token punctuation">(</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>storage<span class="token punctuation">.</span>StorageLevel<span class="token punctuation">.</span>DISK_ONLY<span class="token punctuation">)</span>
rdd5<span class="token punctuation">.</span>collect
</code></pre></div><p>执行rdd5.collect后，页面再次发生变化，如下图：</p> <p><img src="/assets/img/image-20200417094636520.31fd3f7e.png" alt="image-20200417094636520"></p> <h4 id="cache和persist的区别-面试题"><a href="#cache和persist的区别-面试题" class="header-anchor">#</a> cache和persist的区别（<strong>面试题</strong>）</h4> <p>简述下如何对RDD设置缓存，以及它们的区别是什么？</p> <p>对RDD设置缓存成可以调用rdd的2个方法： 一个是cache，一个是persist，调用这2个方法都可以对rdd的数据设置缓存，但不是立即就触发缓存执行，后面需要有action，才会触发缓存的执行。</p> <p>cache方法和persist方法区别：</p> <ol><li>cache:   默认是把数据缓存在内存中，其本质就是调用persist方法；</li> <li>persist：可以把数据缓存在内存或者是磁盘，有丰富的缓存级别，这些缓存级别都被定义在StorageLevel这个object中。</li></ol> <h4 id="什么时候需要设置缓存"><a href="#什么时候需要设置缓存" class="header-anchor">#</a> 什么时候需要设置缓存？</h4> <p>首先理解一个概念：transformation算子是延迟加载的，只有在触发action时才会被执行，job执行完之后，前面所有rdd的数据就都不存在了，如果没有action算子，各个rdd之间就只是一个转换</p> <p>1、某个rdd的数据后期被使用了多次</p> <p><img src="/assets/img/1569037915592-1587626129052.97721b45.png" alt="1569037915592"></p> <p>如上图所示的计算逻辑：</p> <p>当第一次使用rdd2做相应的算子操作得到rdd3的时候，就会从rdd1开始计算，先读取HDFS上的文件，然后对rdd1 做对应的算子操作得到rdd2,再由rdd2计算之后得到rdd3。同样为了计算得到rdd4，前面的逻辑会被重新计算。</p> <p>默认情况下多次对同一个rdd执行算子操作， rdd都会对这个rdd及之前的父rdd全部重新计算一次。 这种情况在实际开发代码的时候会经常遇到，但是我们一定要避免一个rdd重复计算多次，否则会导致性能急剧降低。</p> <p>因此，可以把多次使用到的rdd，也就是公共rdd进行持久化，避免后续需要，再次重新计算，提升效率。如下图，在设置了rdd2.cache或rdd2.persist后，得到rrd3时（假设rdd2--&gt;rdd3是一个action），步骤还是HDFS--&gt;rdd1--&gt;rdd2--&gt;rdd3，但是因为rdd3是rdd2经过action算子操作得到的，rrd2的数据得到缓存。</p> <p>那么生成rdd4的时候，步骤就简单了很多，直接从缓存中获取数据，计算得到rdd4。</p> <p><img src="/assets/img/image-20200417095850150.ab100c62.png" alt="image-20200417095850150"></p> <p>2、为了获取得到一个rdd的结果数据，经过了大量的算子操作或者是计算逻辑比较复杂,总之某个rdd的数据来之不易时，可以进行缓存：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd2<span class="token operator">=</span>rdd1<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>函数<span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>函数<span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>函数<span class="token punctuation">)</span><span class="token punctuation">.</span>xxx<span class="token punctuation">.</span>xxx<span class="token punctuation">.</span>xxx<span class="token punctuation">.</span>xxx<span class="token punctuation">.</span>xxx
</code></pre></div><h4 id="清除缓存数据"><a href="#清除缓存数据" class="header-anchor">#</a> 清除缓存数据</h4> <p>自动清除</p> <div class="language- extra-class"><pre class="language-text"><code>一个application应用程序结束之后，对应的缓存数据也就自动清除
</code></pre></div><p>手动清除</p> <div class="language- extra-class"><pre class="language-text"><code>调用rdd的unpersist方法
</code></pre></div><h2 id="rdd的checkpoint机制-★★★★★"><a href="#rdd的checkpoint机制-★★★★★" class="header-anchor">#</a> RDD的checkpoint机制（★★★★★)</h2> <h4 id="checkpoint概念"><a href="#checkpoint概念" class="header-anchor">#</a> checkpoint概念</h4> <p>我们可以对rdd的数据进行缓存，保存在内存或者是磁盘中。后续就可以直接从内存或者磁盘中获取得到，但是它们不是特别安全。</p> <p>cache</p> <p>它是直接把数据保存在内存中，后续操作起来速度比较快，直接从内存中获取得到。但这种方式很不安全，由于服务器挂掉或者是进程终止，会导致数据的丢失。</p> <p>persist</p> <p>它可以把数据保存在本地磁盘中，后续可以从磁盘中获取得到该数据，但它也不是特别安全，由于系统管理员一些误操作删除了，或者是磁盘损坏，也有可能导致数据的丢失。</p> <p>checkpoint（检查点）</p> <p>它是提供了一种相对而言更加可靠的数据持久化方式。它是把数据保存在分布式文件系统，比如HDFS上。这里就是利用了HDFS高可用性，高容错性（多副本）来最大程度保证数据的安全性。</p> <h4 id="如何设置checkpoint"><a href="#如何设置checkpoint" class="header-anchor">#</a> 如何设置checkpoint</h4> <p>1、在hdfs上设置一个checkpoint目录</p> <div class="language-scala extra-class"><pre class="language-scala"><code>sc<span class="token punctuation">.</span>setCheckpointDir<span class="token punctuation">(</span><span class="token string">&quot;hdfs://node01:8020/checkpoint&quot;</span><span class="token punctuation">)</span> 
</code></pre></div><p>2、对需要做checkpoint操作的rdd调用checkpoint方法</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/words.txt&quot;</span><span class="token punctuation">)</span>
rdd1<span class="token punctuation">.</span>checkpoint
<span class="token keyword">val</span> rdd2<span class="token operator">=</span>rdd1<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
</code></pre></div><p>3、最后需要有一个action操作去触发任务的运行</p> <div class="language-scala extra-class"><pre class="language-scala"><code>rdd2<span class="token punctuation">.</span>collect
</code></pre></div><p>查看缓存中hdfs中的数据：</p> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token punctuation">[</span>hadoop@node01 ~<span class="token punctuation">]</span>$ hdfs dfs -ls /checkpoint/e237e2bb-dc0e-47d9-851f-26687b0d7dbe/rdd-5
Found <span class="token number">2</span> items
-rw-r--r--   <span class="token number">3</span> hadoop supergroup         <span class="token number">53</span> <span class="token number">2020</span>-04-17 <span class="token number">10</span>:20 /checkpoint/e237e2bb-dc0e-47d9-851f-26687b0d7dbe/rdd-5/part-00000
-rw-r--r--   <span class="token number">3</span> hadoop supergroup          <span class="token number">4</span> <span class="token number">2020</span>-04-17 <span class="token number">10</span>:20 /checkpoint/e237e2bb-dc0e-47d9-851f-26687b0d7dbe/rdd-5/part-00001
</code></pre></div><h4 id="cache、persist、checkpoint三者区别"><a href="#cache、persist、checkpoint三者区别" class="header-anchor">#</a> cache、persist、checkpoint三者区别</h4> <p>cache和persist</p> <ul><li>cache默认数据缓存在内存中</li> <li>persist可以把数据保存在内存或者磁盘中</li> <li>后续要触发 cache 和 persist 持久化操作，需要有一个action操作</li> <li>它不会开启其他新的任务，一个action操作就对应一个job</li> <li>它不会改变rdd的依赖关系，程序运行完成后对应的缓存数据就自动消失</li></ul> <p>checkpoint</p> <ul><li><p>可以把数据持久化写入到hdfs上</p></li> <li><p>后续要触发checkpoint持久化操作，需要有一个action操作，<strong><strong>后续会开启新的job执行checkpoint操作</strong></strong></p></li> <li><p>它会改变rdd的依赖关系，后续数据丢失了不能够在通过血统进行数据的恢复。</p></li> <li><p>程序运行完成后对应的checkpoint数据就不会消失</p></li></ul> <p>cache或persisit与checkpoint的结合使用：</p> <div class="language-scala extra-class"><pre class="language-scala"><code>   sc<span class="token punctuation">.</span>setCheckpointDir<span class="token punctuation">(</span><span class="token string">&quot;/checkpoint&quot;</span><span class="token punctuation">)</span>
   <span class="token keyword">val</span> rdd1<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/words.txt&quot;</span><span class="token punctuation">)</span>
   <span class="token keyword">val</span> rdd2<span class="token operator">=</span>rdd1<span class="token punctuation">.</span>cache
   rdd2<span class="token punctuation">.</span>checkpoint
   <span class="token keyword">val</span> rdd3<span class="token operator">=</span>rdd2<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
   rdd3<span class="token punctuation">.</span>collect
   
<span class="token comment">//对checkpoint在使用的时候进行优化，在调用checkpoint操作之前，可以先来做一个cache操作，缓存对应rdd的结果数据，后续就可以直接从cache中获取到rdd的数据写入到指定checkpoint目录中   </span>
</code></pre></div><h2 id="dag有向无环图生成"><a href="#dag有向无环图生成" class="header-anchor">#</a> DAG有向无环图生成</h2> <h4 id="dag是什么"><a href="#dag是什么" class="header-anchor">#</a> DAG是什么</h4> <p><strong>DAG(Directed Acyclic Graph)</strong> 叫做有向无环图（有方向,无闭环,代表着数据的流向），原始的RDD通过一系列的转换就形成了DAG。</p> <p>下图是基于单词统计逻辑得到的DAG有向无环图</p> <p><img src="/assets/img/1569047954944-1587626129052.888773b9.png" alt="1569047954944"></p> <h2 id="dag划分stage-★★★★★"><a href="#dag划分stage-★★★★★" class="header-anchor">#</a> DAG划分stage（★★★★★)</h2> <h4 id="stage是什么"><a href="#stage是什么" class="header-anchor">#</a> stage是什么</h4> <p><strong>一个Job会被拆分为多组Task，每组任务被称为一个stage</strong></p> <p>stage表示不同的调度阶段，一个spark job会对应产生很多个stage</p> <p>stage类型一共有2种</p> <ol><li><strong>ShuffleMapStage</strong></li></ol> <ul><li>最后一个shuffle之前的所有变换的Stage叫ShuffleMapStage
<ul><li>它对应的task是shuffleMapTask</li></ul></li></ul> <ol start="2"><li><strong>ResultStage</strong></li></ol> <ul><li>最后一个shuffle之后操作的Stage叫ResultStage，它是最后一个Stage。
<ul><li>它对应的task是ResultTask</li></ul></li></ul> <h4 id="为什么要划分stage"><a href="#为什么要划分stage" class="header-anchor">#</a> 为什么要划分stage</h4> <p>根据RDD之间依赖关系的不同将DAG划分成不同的Stage(调度阶段)</p> <ul><li>对于窄依赖，partition的转换处理在一个Stage中完成计算</li> <li>对于宽依赖，由于有Shuffle的存在，只能在parent RDD处理完成后，才能开始接下来的计算，</li></ul> <p>由于划分完stage之后，在同一个stage中只有窄依赖，没有宽依赖，可以实现流水线计算，
stage中的每一个分区对应一个task，在同一个stage中就有很多可以并行运行的task。</p> <h4 id="如何划分stage"><a href="#如何划分stage" class="header-anchor">#</a> 如何划分stage</h4> <p><strong>划分stage的依据就是宽依赖</strong></p> <p>划分流程：</p> <p>(1) 首先根据rdd的算子操作顺序生成DAG有向无环图，接下里从最后一个rdd往前推，创建一个新的stage，把该rdd加入到该stage中，它是最后一个stage。</p> <p>(2) 在往前推的过程中运行遇到了窄依赖就把该rdd加入到本stage中，如果遇到了宽依赖，就从宽依赖切开，那么最后一个stage也就结束了。</p> <p>(3) 重新创建一个新的stage，按照第二个步骤继续往前推，一直到最开始的rdd，整个划分stage也就结束了</p> <p><img src="/assets/img/划分stage-1587626129053.5b48b0c3.png" alt="划分stage"></p> <h4 id="stage与stage之间的关系"><a href="#stage与stage之间的关系" class="header-anchor">#</a> stage与stage之间的关系</h4> <p>划分完stage之后，每一个stage中有很多可以并行运行的task，后期把每一个stage中的task封装在一个taskSet集合中，最后把一个一个的taskSet集合提交到worker节点上的executor进程中运行。</p> <p>rdd与rdd之间存在依赖关系，stage与stage之前也存在依赖关系，前面stage中的task先运行，运行完成了再运行后面stage中的task，也就是说后面stage中的task输入数据是前面stage中task的输出结果数据。</p> <p><img src="/assets/img/stage-1587626129053.63e187f2.png" alt="stage"></p> <h2 id="spark的任务调度"><a href="#spark的任务调度" class="header-anchor">#</a> spark的任务调度</h2> <p><img src="/assets/img/spark任务调度-1587626129053.491791f8.png" alt="spark任务调度"></p> <div class="language- extra-class"><pre class="language-text"><code>(1) Driver端运行客户端的main方法，构建SparkContext对象，在SparkContext对象内部依次构建DAGScheduler和TaskScheduler

(2) 按照rdd的一系列操作顺序，来生成DAG有向无环图

(3) DAGScheduler拿到DAG有向无环图之后，按照宽依赖进行stage的划分。每一个stage内部有很多可以并行运行的task，最后封装在一个一个的taskSet集合中，然后把taskSet发送给TaskScheduler

(4) TaskScheduler得到taskSet集合之后，依次遍历取出每一个task提交到worker节点上的executor进程中运行。

(5) 所有task运行完成，整个任务也就结束了
</code></pre></div><h2 id="spark的运行架构"><a href="#spark的运行架构" class="header-anchor">#</a> spark的运行架构</h2> <p><img src="/assets/img/spark-1586935313986-1587626129053.eccc2f18.png" alt="spark"></p> <div class="language- extra-class"><pre class="language-text"><code>(1) Driver端向资源管理器Master发送注册和申请计算资源的请求

(2) Master通知对应的worker节点启动executor进程(计算资源)

(3) executor进程向Driver端发送注册并且申请task请求

(4) Driver端运行客户端的main方法，构建SparkContext对象，在SparkContext对象内部依次构建DAGScheduler和TaskScheduler

(5) 按照客户端代码洪rdd的一系列操作顺序，生成DAG有向无环图

(6) DAGScheduler拿到DAG有向无环图之后，按照宽依赖进行stage的划分。每一个stage内部有很多可以并行运行的task，最后封装在一个一个的taskSet集合中，然后把taskSet发送给TaskScheduler

(7) TaskScheduler得到taskSet集合之后，依次遍历取出每一个task提交到worker节点上的executor进程中运行

(8) 所有task运行完成，Driver端向Master发送注销请求，Master通知Worker关闭executor进程，Worker上的计算资源得到释放，最后整个任务也就结束了。
</code></pre></div><h2 id="基于wordcount程序剖析spark任务的提交、划分、调度流程-★★★★★"><a href="#基于wordcount程序剖析spark任务的提交、划分、调度流程-★★★★★" class="header-anchor">#</a> 基于wordcount程序剖析spark任务的提交、划分、调度流程（★★★★★)</h2> <p><img src="/assets/img/job-scheduler-running-1587626129053.77ef4167.png" alt="job-scheduler-running"></p> <h2 id="面试题2"><a href="#面试题2" class="header-anchor">#</a> <strong>面试题2</strong></h2> <ol><li>reduceByKey和groupByKey的区别是什么？</li> <li>下面哪些操作是宽依赖  flatMap/map/filter/reduceByKey</li> <li>简述cache和persist的区别</li> <li>简述如何划分stage</li></ol> <h2 id="spark第四次课"><a href="#spark第四次课" class="header-anchor">#</a> =========*<em>spark第四次课========*</em></h2> <h2 id="sparksql概述"><a href="#sparksql概述" class="header-anchor">#</a> sparksql概述</h2> <h4 id="sparksql的前世今生"><a href="#sparksql的前世今生" class="header-anchor">#</a> sparksql的前世今生</h4> <ul><li>Shark是专门针对于spark的构建大规模数据仓库系统的一个框架</li> <li>Shark与Hive兼容、同时也依赖于Spark版本</li> <li>Hivesql底层把sql解析成了mapreduce程序，Shark是把sql语句解析成了Spark任务</li> <li>随着性能优化的上限，以及集成SQL的一些复杂的分析功能，发现Hive的MapReduce思想限制了Shark的发展。</li> <li>最后Databricks公司终止对Shark的开发
<ul><li>决定单独开发一个框架，不在依赖hive，把重点转移到了<strong>sparksql</strong>这个框架上。</li></ul></li></ul> <h4 id="什么是sparksql"><a href="#什么是sparksql" class="header-anchor">#</a> 什么是sparksql</h4> <p>Spark SQL is Apache Spark's module for working with structured data.</p> <p>SparkSQL是apache Spark用来处理结构化数据的一个模块。</p> <p><img src="/assets/img/1569468946521.e3e03e4c.png" alt="1569468946521"></p> <h2 id="sparksql的四大特性"><a href="#sparksql的四大特性" class="header-anchor">#</a> sparksql的四大特性</h2> <h4 id="易整合"><a href="#易整合" class="header-anchor">#</a> 易整合</h4> <p>将SQL查询与Spark程序无缝混合</p> <p>可以使用不同的语言进行代码开发</p> <ul><li>java</li> <li>scala</li> <li>python</li> <li>R</li></ul> <p><img src="/assets/img/1569469087993.c847658a.png" alt="1569469087993"></p> <h4 id="统一的数据源访问"><a href="#统一的数据源访问" class="header-anchor">#</a> 统一的数据源访问</h4> <p>以相同的方式连接到任何数据源，sparksql后期可以采用一种统一的方式去对接任意的外部数据源，不需要使用不同的Api</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span>  dataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read<span class="token punctuation">.</span>文件格式的方法名<span class="token punctuation">(</span><span class="token string">&quot;该文件格式的路径&quot;</span><span class="token punctuation">)</span>
</code></pre></div><p><img src="/assets/img/1569469225309.8f8a01a4.png" alt="1569469225309"></p> <h4 id="兼容hive"><a href="#兼容hive" class="header-anchor">#</a> 兼容hive</h4> <p>sparksql可以支持hivesql这种语法  sparksql兼容hivesql</p> <p><img src="/assets/img/1569469413038.c62045f6.png" alt="1569469413038"></p> <h4 id="支持标准的数据库连接"><a href="#支持标准的数据库连接" class="header-anchor">#</a> 支持标准的数据库连接</h4> <p>sparksql支持标准的数据库连接JDBC或者ODBC</p> <p><img src="/assets/img/1569469446641.7e4e3874.png" alt="1569469446641"></p> <h2 id="dataframe概述"><a href="#dataframe概述" class="header-anchor">#</a> DataFrame概述</h2> <p>spark core---&gt;操控RDD</p> <p>spark sql---&gt;操控DataFrame</p> <h5 id="dataframe发展"><a href="#dataframe发展" class="header-anchor">#</a> DataFrame发展</h5> <p>DataFrame前身是schemaRDD,这个schemaRDD是直接继承自RDD，它是RDD的一个实现类</p> <p>在spark1.3.0之后把schemaRDD改名为DataFrame,它不再继承自RDD，而是自己实现RDD上的一些功能</p> <p>也可以把dataFrame转换成一个rdd，调用rdd方法即可转换成功，例如 val rdd1=dataFrame.rdd</p> <h5 id="dataframe是什么"><a href="#dataframe是什么" class="header-anchor">#</a> DataFrame是什么</h5> <p>在Spark中，DataFrame是一种<strong>以RDD为基础的分布式数据集</strong>，类似于<strong>传统数据库的二维表格</strong></p> <p>DataFrame带有<strong>Schema元信息</strong>，即DataFrame所表示的二维表数据集的每一列都带有名称和类型，但底层做了更多的优化</p> <p>DataFrame可以从很多数据源构建，比如：已经存在的RDD、结构化文件、外部数据库、Hive表。</p> <p>RDD可以把它内部元素看成是一个java对象</p> <p>DataFrame可以把内部元素看成是一个Row对象，它表示一行一行的数据，每一行是固定的数据类型</p> <p>可以把DataFrame这样去理解-----&gt;RDD+schema元信息, dataFrame相比于rdd来说，多了对数据的描述信息（schema元信息）</p> <p><img src="/assets/img/1569492382924.48958415.png" alt="1569492382924"></p> <p><img src="/assets/img/image-20200617193824609.fda16603.png" alt="image-20200617193824609"></p> <h2 id="dataframe和rdd的优缺点"><a href="#dataframe和rdd的优缺点" class="header-anchor">#</a> DataFrame和RDD的优缺点</h2> <h4 id="rdd优点"><a href="#rdd优点" class="header-anchor">#</a> RDD优点</h4> <p>1、编译时类型安全，开发会进行类型检查，在编译的时候及时发现错误</p> <p>2、具有面向对象编程的风格</p> <h4 id="rdd缺点"><a href="#rdd缺点" class="header-anchor">#</a> RDD缺点</h4> <p>1、构建大量的java对象占用了大量heap堆空间，导致频繁的垃圾回收GC。 :RDD[Java对象]</p> <div class="language- extra-class"><pre class="language-text"><code>由于数据集RDD它的数据量比较大，后期都需要存储在heap堆中，这里有heap堆中的内存空间有限，出现频繁的垃圾回收（GC），程序在进行垃圾回收的过程中，所有的任务都是暂停。影响程序执行的效率
</code></pre></div><p>2、数据的序列化和反序列性能开销很大</p> <div class="language- extra-class"><pre class="language-text"><code>  在分布式程序中，对象(对象的内容和结构)是先进行序列化，发送到其他服务器，进行大量的网络传输，然后接受到这些序列化的数据之后，再进行反序列化来恢复该对象
</code></pre></div><h4 id="dataframe优点"><a href="#dataframe优点" class="header-anchor">#</a> DataFrame优点</h4> <p>DataFrame引入了schema元信息和off-heap(堆外)</p> <p>1、DataFrame引入off-heap，大量的对象构建直接使用操作系统层面上的内存，不再使用heap堆中的内存，这样一来heap堆中的内存空间就比较充足，不会导致频繁GC，程序的运行效率比较高，它是解决了RDD构建大量的java对象占用了大量heap堆空间，导致频繁的GC这个缺点。</p> <p><img src="/assets/img/image-20200417135339845.0d0a2222.png" alt="image-20200417135339845"></p> <p>2、DataFrame引入了schema元信息---就是数据结构的描述信息，后期spark程序中的大量对象在进行网络传输的时候，只需要把数据的内容本身进行序列化就可以，数据结构信息可以省略掉。这样一来数据网络传输的数据量是有所减少，数据的序列化和反序列性能开销就不是很大了。它是解决了RDD数据的序列化和反序列性能开销很大这个缺点</p> <h4 id="dataframe缺点"><a href="#dataframe缺点" class="header-anchor">#</a> DataFrame缺点</h4> <p>DataFrame引入了schema元信息和off-heap(堆外)它是分别解决了RDD的缺点，同时它也丢失了RDD的优点</p> <p>1、编译时类型不安全</p> <ul><li>编译时不会进行类型的检查，这里也就意味着前期是无法在编译的时候发现错误，只有在运行的时候才会发现</li></ul> <p>2、不再具有面向对象编程的风格</p> <h2 id="读取文件构建dataframe"><a href="#读取文件构建dataframe" class="header-anchor">#</a> 读取文件构建DataFrame</h2> <h5 id="spark-context与spark-session的关系"><a href="#spark-context与spark-session的关系" class="header-anchor">#</a> Spark context与Spark session的关系</h5> <p>在spark2.0之前，要操控rdd就要构建spark context对象，要使用sparksql就要构建sqlcontext对象，要使用hive表就要构建hivecontext对象。</p> <p>在spark2.0之后，人们觉得这样太麻烦，就出现了spark session,spark session封装了上面的3个对象。</p> <p>那么，spark2.0之后，就可通过spark session来构建spark context、sql context...</p> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> sc
res0<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkContext <span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkContext<span class="token annotation punctuation">@5fdb7394</span>

scala<span class="token operator">&gt;</span> spark
res1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>SparkSession <span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>SparkSession<span class="token annotation punctuation">@52285a5f</span>

scala<span class="token operator">&gt;</span> spark<span class="token punctuation">.</span>   <span class="token comment">//下面是spark封装的东西</span>
baseRelationToDataFrame   close   createDataFrame   emptyDataFrame   experimental   listenerManager   range   readStream     sharedState    sql          stop      table   udf    catalog        conf    createDataset     emptyDataset     implicits  newSession   read    sessionState   sparkContext   sqlContext   streams   time    version   

scala<span class="token operator">&gt;</span> spark<span class="token punctuation">.</span>sparkContext   
res2<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkContext <span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>SparkContext<span class="token annotation punctuation">@5fdb7394</span>

scala<span class="token operator">&gt;</span> spark<span class="token punctuation">.</span>sparkContext<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">//使用spark封装的sparkContext</span>
res3<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at parallelize at <span class="token generics"><span class="token punctuation">&lt;</span>console<span class="token punctuation">&gt;</span></span><span class="token operator">:</span><span class="token number">24</span>
</code></pre></div><p><img src="/assets/img/image-20200417140545035.afe16427.png" alt="image-20200417140545035"></p> <h5 id="读取文本文件创建dataframe"><a href="#读取文本文件创建dataframe" class="header-anchor">#</a> 读取文本文件创建DataFrame</h5> <p>创建文本文件：</p> <div class="language- extra-class"><pre class="language-text"><code>vi /tmp/person.txt
1 zhangsan 20
2 lisi 32
3 laowang 46

hdfs dfs -put /tmp/person.txt /
</code></pre></div><p>第一种方式，从结果可以看到DataFrame默认使用一个string类型的value列</p> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> personDF<span class="token operator">=</span>spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token string">&quot;/person.txt&quot;</span><span class="token punctuation">)</span>
personDF<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>value<span class="token operator">:</span> string<span class="token punctuation">]</span>

<span class="token comment">//打印schema信息</span>
scala<span class="token operator">&gt;</span> personDF<span class="token punctuation">.</span>printSchema
root
 <span class="token operator">|</span><span class="token operator">--</span> value<span class="token operator">:</span> string <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>

<span class="token comment">//展示数据</span>
scala<span class="token operator">&gt;</span> personDF<span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>                                                                 
<span class="token operator">|</span>        value<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span><span class="token number">1</span> zhangsan <span class="token number">20</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">2</span> lisi <span class="token number">32</span><span class="token operator">|</span>
<span class="token operator">|</span> <span class="token number">3</span> laowang <span class="token number">46</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre></div><p>第二种方式</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">//加载数据</span>
<span class="token keyword">val</span> rdd1<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/person.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">//定义一个样例类</span>
<span class="token keyword">case</span> <span class="token keyword">class</span> Person<span class="token punctuation">(</span>id<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>name<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>age<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">)</span>
<span class="token comment">//把rdd与样例类进行关联</span>
<span class="token keyword">val</span> personRDD<span class="token operator">=</span>rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>Person<span class="token punctuation">(</span>x<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toInt<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">//把rdd转换成DataFrame</span>
<span class="token keyword">val</span> personDF<span class="token operator">=</span>personRDD<span class="token punctuation">.</span>toDF

<span class="token comment">//打印schema信息</span>
personDF<span class="token punctuation">.</span>printSchema

<span class="token comment">//展示数据</span>
personDF<span class="token punctuation">.</span>show
</code></pre></div><h5 id="读取json文件创建dataframe"><a href="#读取json文件创建dataframe" class="header-anchor">#</a> 读取json文件创建DataFrame</h5> <div class="language-sh extra-class"><pre class="language-sh"><code>hdfs dfs -put /kkb/install/spark/examples/src/main/resources/people.json /
<span class="token punctuation">{</span><span class="token string">&quot;name&quot;</span><span class="token builtin class-name">:</span><span class="token string">&quot;Michael&quot;</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span><span class="token string">&quot;name&quot;</span><span class="token builtin class-name">:</span><span class="token string">&quot;Andy&quot;</span>, <span class="token string">&quot;age&quot;</span>:30<span class="token punctuation">}</span>
<span class="token punctuation">{</span><span class="token string">&quot;name&quot;</span><span class="token builtin class-name">:</span><span class="token string">&quot;Justin&quot;</span>, <span class="token string">&quot;age&quot;</span>:19<span class="token punctuation">}</span>
</code></pre></div><div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> peopleDF<span class="token operator">=</span>spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">&quot;/people.json&quot;</span><span class="token punctuation">)</span>
peopleDF<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>age<span class="token operator">:</span> bigint<span class="token punctuation">,</span> name<span class="token operator">:</span> string<span class="token punctuation">]</span>          

scala<span class="token operator">&gt;</span> peopleDF<span class="token punctuation">.</span>printSchema
root
 <span class="token operator">|</span><span class="token operator">--</span> age<span class="token operator">:</span> long <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
 <span class="token operator">|</span><span class="token operator">--</span> name<span class="token operator">:</span> string <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>


scala<span class="token operator">&gt;</span> peopleDF<span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span> age<span class="token operator">|</span>   name<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span><span class="token keyword">null</span><span class="token operator">|</span>Michael<span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">30</span><span class="token operator">|</span>   Andy<span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">19</span><span class="token operator">|</span> Justin<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre></div><h5 id="读取parquet文件创建dataframe"><a href="#读取parquet文件创建dataframe" class="header-anchor">#</a> 读取parquet文件创建DataFrame</h5> <div class="language- extra-class"><pre class="language-text"><code>hdfs dfs -put /kkb/install/spark/examples/src/main/resources/users.parquet /
</code></pre></div><div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> parquetDF<span class="token operator">=</span>spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>parquet<span class="token punctuation">(</span><span class="token string">&quot;/users.parquet&quot;</span><span class="token punctuation">)</span>
parquetDF<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>name<span class="token operator">:</span> string<span class="token punctuation">,</span> favorite_color<span class="token operator">:</span> string <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token number">1</span> more field<span class="token punctuation">]</span>

scala<span class="token operator">&gt;</span> parquetDF<span class="token punctuation">.</span>printSchema
root
 <span class="token operator">|</span><span class="token operator">--</span> name<span class="token operator">:</span> string <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
 <span class="token operator">|</span><span class="token operator">--</span> favorite_color<span class="token operator">:</span> string <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
 <span class="token operator">|</span><span class="token operator">--</span> favorite_numbers<span class="token operator">:</span> array <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>  <span class="token comment">//数组类型</span>
 <span class="token operator">|</span>    <span class="token operator">|</span><span class="token operator">--</span> element<span class="token operator">:</span> integer <span class="token punctuation">(</span>containsNull <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>  <span class="token comment">//数组元素的类型</span>


scala<span class="token operator">&gt;</span> parquetDF<span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>                                        
<span class="token operator">|</span>  name<span class="token operator">|</span>favorite_color<span class="token operator">|</span>favorite_numbers<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
<span class="token operator">|</span>Alyssa<span class="token operator">|</span>          <span class="token keyword">null</span><span class="token operator">|</span>  <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">]</span><span class="token operator">|</span>
<span class="token operator">|</span>   Ben<span class="token operator">|</span>           red<span class="token operator">|</span>              <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
</code></pre></div><h2 id="dataframe常用操作"><a href="#dataframe常用操作" class="header-anchor">#</a> DataFrame常用操作</h2> <h4 id="dsl风格语法"><a href="#dsl风格语法" class="header-anchor">#</a> DSL风格语法</h4> <p>就是sparksql中的DataFrame自身提供了一套自己的Api，可以去使用这套api来做相应的处理。</p> <p>创建DataFrame</p> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> rdd1<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/person.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
rdd1<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span> at map at <span class="token generics"><span class="token punctuation">&lt;</span>console<span class="token punctuation">&gt;</span></span><span class="token operator">:</span><span class="token number">24</span>   <span class="token comment">//每一行切分而成的多个元素被封装成一个Array,作为RDD的类型</span>

scala<span class="token operator">&gt;</span> <span class="token keyword">case</span> <span class="token keyword">class</span> Person<span class="token punctuation">(</span>id<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>name<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>age<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">)</span>
defined <span class="token keyword">class</span> Person  <span class="token comment">//创建一个样例类</span>

scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> PersonRDD<span class="token operator">=</span>rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>Person<span class="token punctuation">(</span>x<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toInt<span class="token punctuation">)</span><span class="token punctuation">)</span>
PersonRDD<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>RDD<span class="token punctuation">[</span>Person<span class="token punctuation">]</span> <span class="token operator">=</span> MapPartitionsRDD<span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">]</span> at map at <span class="token generics"><span class="token punctuation">&lt;</span>console<span class="token punctuation">&gt;</span></span><span class="token operator">:</span><span class="token number">27</span>   <span class="token comment">//将rdd1的每一个Array类型转为一个Person对象</span>


scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> PersonDF<span class="token operator">=</span>PersonRDD<span class="token punctuation">.</span>toDF  <span class="token comment">//将RDD转为DataFrame</span>
PersonDF<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>id<span class="token operator">:</span> string<span class="token punctuation">,</span> name<span class="token operator">:</span> string <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token number">1</span> more field<span class="token punctuation">]</span>

scala<span class="token operator">&gt;</span> PersonDF<span class="token punctuation">.</span>printSchema
root
 <span class="token operator">|</span><span class="token operator">--</span> id<span class="token operator">:</span> string <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
 <span class="token operator">|</span><span class="token operator">--</span> name<span class="token operator">:</span> string <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
 <span class="token operator">|</span><span class="token operator">--</span> age<span class="token operator">:</span> integer <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">)</span>


scala<span class="token operator">&gt;</span> PersonDF<span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>                                                              
<span class="token operator">|</span> id<span class="token operator">|</span>    name<span class="token operator">|</span>age<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>  <span class="token number">1</span><span class="token operator">|</span>zhangsan<span class="token operator">|</span> <span class="token number">20</span><span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">2</span><span class="token operator">|</span>    lisi<span class="token operator">|</span> <span class="token number">32</span><span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">3</span><span class="token operator">|</span> laowang<span class="token operator">|</span> <span class="token number">46</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre></div><p>DataFrame.select()操作,select操作返回的还是一个DataFrame类型</p> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> PersonDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span>
res12<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>name<span class="token operator">:</span> string<span class="token punctuation">]</span>

scala<span class="token operator">&gt;</span> PersonDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
<span class="token operator">|</span>    name<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
<span class="token operator">|</span>zhangsan<span class="token operator">|</span>
<span class="token operator">|</span>    lisi<span class="token operator">|</span>
<span class="token operator">|</span> laowang<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>

scala<span class="token operator">&gt;</span> PersonDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
<span class="token operator">|</span>    name<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
<span class="token operator">|</span>zhangsan<span class="token operator">|</span>
<span class="token operator">|</span>    lisi<span class="token operator">|</span>
<span class="token operator">|</span> laowang<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>


scala<span class="token operator">&gt;</span> PersonDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
<span class="token operator">|</span>    name<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
<span class="token operator">|</span>zhangsan<span class="token operator">|</span>
<span class="token operator">|</span>    lisi<span class="token operator">|</span>
<span class="token operator">|</span> laowang<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>


scala<span class="token operator">&gt;</span> PersonDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>    name<span class="token operator">|</span>age<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>zhangsan<span class="token operator">|</span> <span class="token number">20</span><span class="token operator">|</span>
<span class="token operator">|</span>    lisi<span class="token operator">|</span> <span class="token number">32</span><span class="token operator">|</span>
<span class="token operator">|</span> laowang<span class="token operator">|</span> <span class="token number">46</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>


scala<span class="token operator">&gt;</span> PersonDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">&quot;name&quot;</span><span class="token punctuation">,</span>$<span class="token string">&quot;age&quot;</span><span class="token punctuation">,</span>$<span class="token string">&quot;age&quot;</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show   <span class="token comment">//age+1</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>    name<span class="token operator">|</span>age<span class="token operator">|</span><span class="token punctuation">(</span>age <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>zhangsan<span class="token operator">|</span> <span class="token number">20</span><span class="token operator">|</span>       <span class="token number">21</span><span class="token operator">|</span>
<span class="token operator">|</span>    lisi<span class="token operator">|</span> <span class="token number">32</span><span class="token operator">|</span>       <span class="token number">33</span><span class="token operator">|</span>
<span class="token operator">|</span> laowang<span class="token operator">|</span> <span class="token number">46</span><span class="token operator">|</span>       <span class="token number">47</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre></div><p>DataFrame.filter()操作：</p> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> PersonDF<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>$<span class="token string">&quot;age&quot;</span><span class="token operator">&gt;</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span> id<span class="token operator">|</span>   name<span class="token operator">|</span>age<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>  <span class="token number">2</span><span class="token operator">|</span>   lisi<span class="token operator">|</span> <span class="token number">32</span><span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">3</span><span class="token operator">|</span>laowang<span class="token operator">|</span> <span class="token number">46</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre></div><h4 id="sql风格语法-推荐"><a href="#sql风格语法-推荐" class="header-anchor">#</a> SQL风格语法（推荐）</h4> <p>可以把DataFrame注册成一张表，然后通过**sparkSession.sql(sql语句)**操作</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">//DataFrame注册成表</span>
personDF<span class="token punctuation">.</span>createTempView<span class="token punctuation">(</span><span class="token string">&quot;Person&quot;</span><span class="token punctuation">)</span>

<span class="token comment">//使用SparkSession调用sql方法统计查询</span>
scala<span class="token operator">&gt;</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select * from Person&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span> id<span class="token operator">|</span>    name<span class="token operator">|</span>age<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>  <span class="token number">1</span><span class="token operator">|</span>zhangsan<span class="token operator">|</span> <span class="token number">20</span><span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">2</span><span class="token operator">|</span>    lisi<span class="token operator">|</span> <span class="token number">32</span><span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">3</span><span class="token operator">|</span> laowang<span class="token operator">|</span> <span class="token number">46</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>

spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select name from person&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select name,age from person&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select * from person where age &gt;30&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select count(*) from person where age &gt;30&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select age,count(*) from person group by age&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select age,count(*) as count from person group by age&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select * from person order by age desc&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
</code></pre></div><h2 id="dataset概述"><a href="#dataset概述" class="header-anchor">#</a> DataSet概述</h2> <h5 id="dataset是什么"><a href="#dataset是什么" class="header-anchor">#</a> DataSet是什么</h5> <p>DataSet是分布式的数据集合，Dataset提供了强类型支持，也是在RDD的每行数据加了类型约束。</p> <p>强类型：所属类型必须在编译时确定。</p> <p>DataSet是在Spark1.6中添加的新的接口。它集中了RDD的优点（<strong>强类型和可以用强大lambda函数</strong>）以及使用了Spark SQL优化的执行引擎。</p> <h5 id="rdd、dataframe、dataset的区别"><a href="#rdd、dataframe、dataset的区别" class="header-anchor">#</a> RDD、DataFrame、DataSet的区别</h5> <p>假设RDD中的两行数据长这样</p> <p><img src="data:image/png;base64,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" alt="1569492571159"></p> <p>那么DataFrame中的数据长这样</p> <p><img src="data:image/png;base64,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" alt="1569492595941"></p> <p>Dataset中的数据长这样</p> <p><img src="data:image/png;base64,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" alt="1569492595941"></p> <p>或者长这样（每行数据是个Object）</p> <p><img src="data:image/png;base64,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" alt="1569492637053"></p> <p>DataSet包含了DataFrame的功能，Spark2.0中两者统一，DataFrame表示为DataSet[Row]，即DataSet的子集。</p> <ol><li>DataSet可以在编译时检查类型</li> <li>并且是面向对象的编程接口</li></ol> <h5 id="dataset与dataframe源码分析"><a href="#dataset与dataframe源码分析" class="header-anchor">#</a> DataSet与DataFrame源码分析</h5> <p>我们来查看以下DataSet与DataFrame的源码，进入IDEA，添加以下pom依赖：</p> <div class="language-xml extra-class"><pre class="language-xml"><code>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-sql_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.3.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><p>按住ctrl+N,搜索DataFrame类，发现搜索不到，搜索DataSet类，成功。download source。</p> <p>发现DataSet的源码包含以下代码：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">def</span> toDF<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> DataFrame <span class="token operator">=</span> <span class="token keyword">new</span> Dataset<span class="token punctuation">[</span>Row<span class="token punctuation">]</span><span class="token punctuation">(</span>sparkSession<span class="token punctuation">,</span> queryExecution<span class="token punctuation">,</span> RowEncoder<span class="token punctuation">(</span>schema<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>toDF()方法是一个返回值类型为DataFrame，点击查看该DataFrame的源码，如下，发现DataFrame类型就是一个Dataset[Row]类型。这就是DataFrame表示为DataSet[Row]，即DataSet的子集的原因。</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">package</span> <span class="token namespace">object</span> sql <span class="token punctuation">{</span>
  <span class="token annotation punctuation">@DeveloperApi</span>
  <span class="token annotation punctuation">@InterfaceStability.Unstable</span>
  <span class="token keyword">type</span> Strategy <span class="token operator">=</span> SparkStrategy

  <span class="token keyword">type</span> DataFrame <span class="token operator">=</span> Dataset<span class="token punctuation">[</span>Row<span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre></div><h5 id="dataframe与dataset互相转换"><a href="#dataframe与dataset互相转换" class="header-anchor">#</a> DataFrame与DataSet互相转换</h5> <p>把一个DataFrame转换成DataSet</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> dataSet<span class="token operator">=</span>dataFrame<span class="token punctuation">.</span>as<span class="token punctuation">[</span>强类型<span class="token punctuation">]</span>
</code></pre></div><p>把一个DataSet转换成DataFrame</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> dataFrame<span class="token operator">=</span>dataSet<span class="token punctuation">.</span>toDF
</code></pre></div><p>补充说明: 可以从dataFrame和dataSet获取得到rdd</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1<span class="token operator">=</span>dataFrame<span class="token punctuation">.</span>rdd

<span class="token keyword">val</span> rdd2<span class="token operator">=</span>dataSet<span class="token punctuation">.</span>rdd
</code></pre></div><p>转换示例：</p> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> df<span class="token operator">=</span>spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token string">&quot;/person.txt&quot;</span><span class="token punctuation">)</span>
df<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>value<span class="token operator">:</span> string<span class="token punctuation">]</span>

scala<span class="token operator">&gt;</span> df<span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>                                                                 
<span class="token operator">|</span>        value<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span><span class="token number">1</span> zhangsan <span class="token number">20</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">2</span> lisi <span class="token number">32</span><span class="token operator">|</span>
<span class="token operator">|</span> <span class="token number">3</span> laowang <span class="token number">46</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>


scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> ds<span class="token operator">=</span>df<span class="token punctuation">.</span>as<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span>
ds<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Dataset<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>value<span class="token operator">:</span> string<span class="token punctuation">]</span>

scala<span class="token operator">&gt;</span> ds<span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>                                                                 
<span class="token operator">|</span>        value<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span><span class="token number">1</span> zhangsan <span class="token number">20</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">2</span> lisi <span class="token number">32</span><span class="token operator">|</span>
<span class="token operator">|</span> <span class="token number">3</span> laowang <span class="token number">46</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre></div><h2 id="构建dataset"><a href="#构建dataset" class="header-anchor">#</a> 构建DataSet</h2> <h5 id="_1、通过sparksession调用createdataset方法"><a href="#_1、通过sparksession调用createdataset方法" class="header-anchor">#</a> 1、通过sparkSession调用createDataset方法</h5> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> ds<span class="token operator">=</span>spark<span class="token punctuation">.</span>createDataset<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>
ds<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Dataset<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>value<span class="token operator">:</span> int<span class="token punctuation">]</span>

scala<span class="token operator">&gt;</span> ds<span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>value<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>    <span class="token number">1</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">2</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">3</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">4</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">5</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">6</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">7</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">8</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">9</span><span class="token operator">|</span>
<span class="token operator">|</span>   <span class="token number">10</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>

scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> ds<span class="token operator">=</span>spark<span class="token punctuation">.</span>createDataset<span class="token punctuation">(</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/person.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
ds<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Dataset<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>value<span class="token operator">:</span> string<span class="token punctuation">]</span>

scala<span class="token operator">&gt;</span> ds<span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>        value<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span><span class="token number">1</span> zhangsan <span class="token number">20</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">2</span> lisi <span class="token number">32</span><span class="token operator">|</span>
<span class="token operator">|</span> <span class="token number">3</span> laowang <span class="token number">46</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre></div><h5 id="_2、使用scala集合和rdd调用tods方法"><a href="#_2、使用scala集合和rdd调用tods方法" class="header-anchor">#</a> 2、使用scala集合和rdd调用toDS方法</h5> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> ds<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/person.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toDS
ds<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Dataset<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>value<span class="token operator">:</span> string<span class="token punctuation">]</span>

scala<span class="token operator">&gt;</span> ds<span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>        value<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span><span class="token number">1</span> zhangsan <span class="token number">20</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">2</span> lisi <span class="token number">32</span><span class="token operator">|</span>
<span class="token operator">|</span> <span class="token number">3</span> laowang <span class="token number">46</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>


scala<span class="token operator">&gt;</span> List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toDS
res20<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Dataset<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>value<span class="token operator">:</span> int<span class="token punctuation">]</span>

scala<span class="token operator">&gt;</span> List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toDS<span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>value<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>    <span class="token number">1</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">2</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">4</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre></div><h5 id="_3、把一个dataframe转换成dataset"><a href="#_3、把一个dataframe转换成dataset" class="header-anchor">#</a> 3、把一个DataFrame转换成DataSet</h5> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span> <span class="token keyword">case</span> <span class="token keyword">class</span> Person<span class="token punctuation">(</span>name<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>age<span class="token operator">:</span><span class="token builtin">Long</span><span class="token punctuation">)</span>
defined <span class="token keyword">class</span> Person

scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> peopleDS<span class="token operator">=</span>spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">&quot;/people.json&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>as<span class="token punctuation">[</span>Person<span class="token punctuation">]</span>
peopleDS<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Dataset<span class="token punctuation">[</span>Person<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>age<span class="token operator">:</span> bigint<span class="token punctuation">,</span> name<span class="token operator">:</span> string<span class="token punctuation">]</span>

scala<span class="token operator">&gt;</span> peopleDS
res13<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Dataset<span class="token punctuation">[</span>Person<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>age<span class="token operator">:</span> bigint<span class="token punctuation">,</span> name<span class="token operator">:</span> string<span class="token punctuation">]</span>

scala<span class="token operator">&gt;</span> peopleDS<span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span> age<span class="token operator">|</span>   name<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span><span class="token keyword">null</span><span class="token operator">|</span>Michael<span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">30</span><span class="token operator">|</span>   Andy<span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">19</span><span class="token operator">|</span> Justin<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre></div><h5 id="_4、通过一个dataset转换生成一个新的dataset"><a href="#_4、通过一个dataset转换生成一个新的dataset" class="header-anchor">#</a> 4、通过一个DataSet转换生成一个新的DataSet</h5> <div class="language-scala extra-class"><pre class="language-scala"><code>scala<span class="token operator">&gt;</span>  List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toDS<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span>
res22<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>Dataset<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>value<span class="token operator">:</span> int<span class="token punctuation">]</span>

scala<span class="token operator">&gt;</span>  List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toDS<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>value<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>   <span class="token number">10</span><span class="token operator">|</span>
<span class="token operator">|</span>   <span class="token number">20</span><span class="token operator">|</span>
<span class="token operator">|</span>   <span class="token number">30</span><span class="token operator">|</span>
<span class="token operator">|</span>   <span class="token number">40</span><span class="token operator">|</span>
<span class="token operator">|</span>   <span class="token number">50</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre></div><h2 id="通过idea开发程序实现把rdd转换dataframe"><a href="#通过idea开发程序实现把rdd转换dataframe" class="header-anchor">#</a> 通过IDEA开发程序实现把RDD转换DataFrame</h2> <h5 id="官网学习如何创建spark-sql-scala程序"><a href="#官网学习如何创建spark-sql-scala程序" class="header-anchor">#</a> 官网学习如何创建spark sql Scala程序</h5> <p><img src="/assets/img/image-20200417205422106.7a106f98.png" alt="image-20200417205422106"></p> <h5 id="添加依赖"><a href="#添加依赖" class="header-anchor">#</a> 添加依赖</h5> <div class="language-xml extra-class"><pre class="language-xml"><code>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-sql_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.3.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><h5 id="方法1-利用反射机制"><a href="#方法1-利用反射机制" class="header-anchor">#</a> 方法1：利用反射机制</h5> <p>定义一个样例类，后期直接映射成DataFrame的schema信息。</p> <p>case class Person(id:String,name:String,age:Int)</p> <p>适用场景：在开发代码之前，可以先确定好DataFrame的schema元信息</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Column<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">case</span> <span class="token keyword">class</span> Person<span class="token punctuation">(</span>id<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>name<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>age<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">)</span>
<span class="token keyword">object</span> SparkSqlDemo <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment">//1、创建SparkSession</span>
    <span class="token keyword">val</span> spark<span class="token operator">=</span>SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">&quot;SparkSqlDemo1&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span>spark<span class="token punctuation">.</span>sparkContext

    <span class="token keyword">val</span> data<span class="token operator">:</span>RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;F:\\test\\person.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//将样例类与RDD关联,即RDD[Array[String]]----&gt;RDD[Person]</span>
    <span class="token keyword">val</span> personRDD<span class="token operator">:</span>RDD<span class="token punctuation">[</span>Person<span class="token punctuation">]</span><span class="token operator">=</span>data<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>Person<span class="token punctuation">(</span>x<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toInt<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//将RDD转为DataFrame</span>
    <span class="token comment">//RDD本身是没有toDF方法的,要导入隐式转换(详细参考scala.md)</span>
    <span class="token keyword">import</span> <span class="token namespace">spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_
    <span class="token keyword">val</span> personDF<span class="token operator">=</span>personRDD<span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token punctuation">)</span>
    personDF<span class="token punctuation">.</span>printSchema<span class="token punctuation">(</span><span class="token punctuation">)</span>
    personDF<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> firstRow<span class="token operator">=</span>personDF<span class="token punctuation">.</span>first<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">//获取第一行数据</span>
    println<span class="token punctuation">(</span><span class="token string">&quot;firstRow: &quot;</span><span class="token operator">+</span>firstRow<span class="token punctuation">)</span>
    <span class="token keyword">val</span> top2<span class="token operator">=</span>personDF<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment">//获取前2位数据</span>
    top2<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

    <span class="token comment">//获取name字段</span>
    personDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    personDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    personDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token keyword">new</span> Column<span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    personDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    personDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">&quot;name&quot;</span><span class="token punctuation">,</span>$<span class="token string">&quot;age&quot;</span><span class="token punctuation">,</span>$<span class="token string">&quot;age&quot;</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//按照age过滤</span>
    personDF<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>$<span class="token string">&quot;age&quot;</span> <span class="token operator">&gt;</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> count<span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> personDF<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>$<span class="token string">&quot;age&quot;</span> <span class="token operator">&gt;</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string">&quot;count:&quot;</span><span class="token operator">+</span>count<span class="token punctuation">)</span>

    <span class="token comment">//分组</span>
    personDF<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    personDF<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    personDF<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>row <span class="token keyword">=&gt;</span> println<span class="token punctuation">(</span>row<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//使用foreach获取每一个row对象中的name字段</span>
    personDF<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>row <span class="token keyword">=&gt;</span>println<span class="token punctuation">(</span>row<span class="token punctuation">.</span>getAs<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    personDF<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>row <span class="token keyword">=&gt;</span>println<span class="token punctuation">(</span>row<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    personDF<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>row <span class="token keyword">=&gt;</span>println<span class="token punctuation">(</span>row<span class="token punctuation">.</span>getString<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    personDF<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>row <span class="token keyword">=&gt;</span>println<span class="token punctuation">(</span>row<span class="token punctuation">.</span>getAs<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//todo：----------------- DSL风格语法--------------------end</span>


    <span class="token comment">//todo：----------------- SQL风格语法-----------------start</span>
    personDF<span class="token punctuation">.</span>createTempView<span class="token punctuation">(</span><span class="token string">&quot;person&quot;</span><span class="token punctuation">)</span>
    <span class="token comment">//使用SparkSession调用sql方法统计查询</span>
    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select * from person&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select name from person&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select name,age from person&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select * from person where age &gt;30&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select count(*) from person where age &gt;30&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select age,count(*) from person group by age&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select age,count(*) as count from person group by age&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select * from person order by age desc&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show
    <span class="token comment">//todo：----------------- SQL风格语法----------------------end</span>

    <span class="token comment">//关闭sparkSession对象</span>
    spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><h5 id="方法2-通过structtype动态指定schema"><a href="#方法2-通过structtype动态指定schema" class="header-anchor">#</a> 方法2：通过StructType动态指定Schema</h5> <p>该方法的应用场景：在开发代码之前，无法确定需要的DataFrame对应的schema元信息，需要在开发代码的过程中动态指定。</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>types<span class="token punctuation">.</span></span><span class="token punctuation">{</span>IntegerType<span class="token punctuation">,</span> StringType<span class="token punctuation">,</span> StructField<span class="token punctuation">,</span> StructType<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Row<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> StructTypeDemo <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> spark<span class="token operator">=</span>SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">&quot;Demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span>spark<span class="token punctuation">.</span>sparkContext
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;warn&quot;</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> data<span class="token operator">:</span>RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;F:\\test\\person.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//使用Row包装一行数据，Row可以封装任意类型任意数目的数据</span>
    <span class="token keyword">val</span> rowRDD<span class="token operator">:</span>RDD<span class="token punctuation">[</span>Row<span class="token punctuation">]</span><span class="token operator">=</span>data<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>Row<span class="token punctuation">(</span>x<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toInt<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> schema<span class="token operator">=</span>StructType<span class="token punctuation">(</span>
        StructField<span class="token punctuation">(</span><span class="token string">&quot;id&quot;</span><span class="token punctuation">,</span>StringType<span class="token punctuation">)</span><span class="token operator">::</span>
        StructField<span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">,</span>StringType<span class="token punctuation">)</span><span class="token operator">::</span>
        StructField<span class="token punctuation">(</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">,</span>IntegerType<span class="token punctuation">)</span><span class="token operator">::</span>Nil
    <span class="token punctuation">)</span>
    <span class="token keyword">val</span> personDF<span class="token operator">=</span>spark<span class="token punctuation">.</span>createDataFrame<span class="token punctuation">(</span>rowRDD<span class="token punctuation">,</span>schema<span class="token punctuation">)</span>

    personDF<span class="token punctuation">.</span>printSchema<span class="token punctuation">(</span><span class="token punctuation">)</span>
    personDF<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    personDF<span class="token punctuation">.</span>createTempView<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">)</span>
    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select * from user&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>说明：</p> <ol><li>因为后面要使用spark.createDataFrame(rowRDD:RDD[Row],schema:StructType)来创建DataFrame，所以要想创建RDD[Row]和StructType类型的变量</li></ol> <p><img src="/assets/img/image-20200418031619386.f8379fc2.png" alt="image-20200418031619386"></p> <ol><li><p>Row类有伴生对象object Row,伴生对象里有apply方法，该apply方法的参数是Any*,所以创建Row对象时不需要new,参数也可以多种类型和多个，Row(x(0),x(1),x(2).toInt)</p></li> <li><p>StructType的参数类型是：</p> <p><img src="/assets/img/image-20200418031038117.a119cf76.png" alt="image-20200418031038117"></p></li> <li><p>StructField是一个样例类，源代码大致如下：</p></li></ol> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">case</span> <span class="token keyword">class</span> StructField<span class="token punctuation">(</span>
    name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span>   <span class="token comment">//名称</span>
    dataType<span class="token operator">:</span> DataType<span class="token punctuation">,</span>  <span class="token comment">//数据类型</span>
    nullable<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">,</span>   <span class="token comment">//表示是否允许该值为空</span>
    metadata<span class="token operator">:</span> Metadata <span class="token operator">=</span> Metadata<span class="token punctuation">.</span>empty<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span>
</code></pre></div><h2 id="sparksql-操作hivesql"><a href="#sparksql-操作hivesql" class="header-anchor">#</a> sparksql 操作hivesql</h2> <p>添加依赖</p> <div class="language-xml extra-class"><pre class="language-xml"><code>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-hive_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.3.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><p>person.txt</p> <div class="language- extra-class"><pre class="language-text"><code>1 zhangsan 43
2 lisi 21
3 laowang 47
</code></pre></div><p>Demo1.scala</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span>SparkSession

<span class="token keyword">object</span> Demo1 <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment">//注意：要开启对hive的支持：.enableHiveSupport()</span>
    <span class="token keyword">val</span> spark<span class="token operator">=</span>SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">&quot;spark sql control hive sql&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>enableHiveSupport<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span>spark<span class="token punctuation">.</span>sparkContext
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;Warn&quot;</span><span class="token punctuation">)</span>

    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span>
      <span class="token triple-quoted-string string">&quot;&quot;&quot;
        |create table if not exists person(id string,name string,age int)
        |row format delimited fields terminated by &quot; &quot;
        |&quot;&quot;&quot;</span><span class="token punctuation">.</span>stripMargin<span class="token punctuation">)</span>    <span class="token comment">//stripMargin的作用是将 | 变成空格</span>
      
    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;load data local inpath 'file:///F:/test/person.txt' into table person&quot;</span><span class="token punctuation">)</span>
    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select * from person&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>运行结果为：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span> id<span class="token operator">|</span>    name<span class="token operator">|</span>age<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>  <span class="token number">1</span><span class="token operator">|</span>zhangsan<span class="token operator">|</span> <span class="token number">43</span><span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">2</span><span class="token operator">|</span>    lisi<span class="token operator">|</span> <span class="token number">21</span><span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">3</span><span class="token operator">|</span> laowang<span class="token operator">|</span> <span class="token number">47</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre></div><p>说明：</p> <ol><li>文件的路径一定要加上file:///，否则会报错</li> <li>运行成功后，会在当前project的根目录下创建两个目录：metastore_db和spark-warehouse</li> <li>metastore_db用于存放刚才在本地创建的表的元数据，spark-warehouse用于保存表的数据</li></ol> <img src="spark.assets/image-20200418154332266.png" alt="image-20200418154332266" style="zoom:80%;"> <h2 id="spark-sql-操作jdbc数据源-★★★★★"><a href="#spark-sql-操作jdbc数据源-★★★★★" class="header-anchor">#</a> spark sql 操作JDBC数据源(★★★★★)</h2> <p>spark sql可以通过 JDBC 从关系型数据库中读取数据的方式创建DataFrame，通过对DataFrame一系列的计算后，还可以将数据再写回关系型数据库中</p> <h5 id="通过sparksql加载mysql表中的数据"><a href="#通过sparksql加载mysql表中的数据" class="header-anchor">#</a> 通过sparksql加载mysql表中的数据</h5> <p>在node03创建表，准备数据</p> <div class="language-sql extra-class"><pre class="language-sql"><code>mysql<span class="token operator">&gt;</span> <span class="token keyword">create</span> <span class="token keyword">database</span> spark<span class="token punctuation">;</span>
mysql<span class="token operator">&gt;</span> <span class="token keyword">use</span> spark<span class="token punctuation">;</span>
mysql<span class="token operator">&gt;</span> <span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">user</span><span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span>age <span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
mysql<span class="token operator">&gt;</span> <span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">user</span><span class="token punctuation">(</span>id<span class="token punctuation">,</span>name<span class="token punctuation">,</span>age<span class="token punctuation">)</span> <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'krystal'</span><span class="token punctuation">,</span><span class="token number">21</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">'jimmy'</span><span class="token punctuation">,</span><span class="token number">22</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
mysql<span class="token operator">&gt;</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> <span class="token keyword">user</span><span class="token punctuation">;</span>
<span class="token operator">+</span><span class="token comment">------+---------+------+</span>
<span class="token operator">|</span> id   <span class="token operator">|</span> name    <span class="token operator">|</span> age  <span class="token operator">|</span>
<span class="token operator">+</span><span class="token comment">------+---------+------+</span>
<span class="token operator">|</span>    <span class="token number">1</span> <span class="token operator">|</span> krystal <span class="token operator">|</span>   <span class="token number">21</span> <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">2</span> <span class="token operator">|</span> jimmy   <span class="token operator">|</span>   <span class="token number">22</span> <span class="token operator">|</span>
<span class="token operator">+</span><span class="token comment">------+---------+------+</span>
<span class="token number">2</span> <span class="token keyword">rows</span> <span class="token operator">in</span> <span class="token keyword">set</span> <span class="token punctuation">(</span><span class="token number">0.11</span> sec<span class="token punctuation">)</span>
</code></pre></div><p>添加mysql连接驱动jar包</p> <div class="language-xml extra-class"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>mysql<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>mysql-connector-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
	<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>5.1.38<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><p>开发代码：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Properties

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{</span>DataFrame<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo2 <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> spark<span class="token operator">=</span>SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">&quot;demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> url<span class="token operator">=</span><span class="token string">&quot;jdbc:mysql://node03:3306/spark&quot;</span>
    <span class="token keyword">val</span> tableName<span class="token operator">=</span><span class="token string">&quot;user&quot;</span>
    <span class="token keyword">val</span> properties<span class="token operator">=</span><span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>
    properties<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;root&quot;</span><span class="token punctuation">)</span>
    properties<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">&quot;password&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;123456&quot;</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> mysqlDF<span class="token operator">:</span>DataFrame<span class="token operator">=</span>spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>jdbc<span class="token punctuation">(</span>url<span class="token punctuation">,</span>tableName<span class="token punctuation">,</span>properties<span class="token punctuation">)</span>
    mysqlDF<span class="token punctuation">.</span>printSchema<span class="token punctuation">(</span><span class="token punctuation">)</span>
    mysqlDF<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    mysqlDF<span class="token punctuation">.</span>createTempView<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">)</span>
    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select * from user&quot;</span><span class="token punctuation">)</span>

    spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p>运行结果为：</p> <div class="language-scala extra-class"><pre class="language-scala"><code>root
 <span class="token operator">|</span><span class="token operator">--</span> id<span class="token operator">:</span> integer <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
 <span class="token operator">|</span><span class="token operator">--</span> name<span class="token operator">:</span> string <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
 <span class="token operator">|</span><span class="token operator">--</span> age<span class="token operator">:</span> integer <span class="token punctuation">(</span>nullable <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
 
 <span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span> id<span class="token operator">|</span>   name<span class="token operator">|</span>age<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>  <span class="token number">1</span><span class="token operator">|</span>krystal<span class="token operator">|</span> <span class="token number">21</span><span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">2</span><span class="token operator">|</span>  jimmy<span class="token operator">|</span> <span class="token number">22</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre></div><h5 id="通过sparksql保存结果数据到mysql表中-本地"><a href="#通过sparksql保存结果数据到mysql表中-本地" class="header-anchor">#</a> 通过sparksql保存结果数据到mysql表中(本地)</h5> <p>继续往user表插入数据：</p> <div class="language-sql extra-class"><pre class="language-sql"><code>mysql<span class="token operator">&gt;</span> <span class="token keyword">use</span> spark
mysql<span class="token operator">&gt;</span> <span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">user</span><span class="token punctuation">(</span>id<span class="token punctuation">,</span>name<span class="token punctuation">,</span>age<span class="token punctuation">)</span> <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">'zhangsan'</span><span class="token punctuation">,</span><span class="token number">34</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token string">'lisi'</span><span class="token punctuation">,</span><span class="token number">46</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
mysql<span class="token operator">&gt;</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> <span class="token keyword">user</span><span class="token punctuation">;</span>
<span class="token operator">+</span><span class="token comment">------+----------+------+</span>
<span class="token operator">|</span> id   <span class="token operator">|</span> name     <span class="token operator">|</span> age  <span class="token operator">|</span>
<span class="token operator">+</span><span class="token comment">------+----------+------+</span>
<span class="token operator">|</span>    <span class="token number">1</span> <span class="token operator">|</span> krystal  <span class="token operator">|</span>   <span class="token number">21</span> <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">2</span> <span class="token operator">|</span> jimmy    <span class="token operator">|</span>   <span class="token number">22</span> <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">3</span> <span class="token operator">|</span> zhangsan <span class="token operator">|</span>   <span class="token number">34</span> <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">4</span> <span class="token operator">|</span> lisi     <span class="token operator">|</span>   <span class="token number">46</span> <span class="token operator">|</span>
<span class="token operator">+</span><span class="token comment">------+----------+------+</span>
<span class="token number">4</span> <span class="token keyword">rows</span> <span class="token operator">in</span> <span class="token keyword">set</span> <span class="token punctuation">(</span><span class="token number">0.00</span> sec<span class="token punctuation">)</span>
</code></pre></div><p>代码开发(本地运行)</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Properties

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{</span>DataFrame<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo2 <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> spark<span class="token operator">=</span>SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">&quot;demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> url<span class="token operator">=</span><span class="token string">&quot;jdbc:mysql://node03:3306/spark&quot;</span>
    <span class="token keyword">val</span> tableName<span class="token operator">=</span><span class="token string">&quot;user&quot;</span>
    <span class="token keyword">val</span> properties<span class="token operator">=</span><span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>
    properties<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;root&quot;</span><span class="token punctuation">)</span>
    properties<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">&quot;password&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;123456&quot;</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> mysqlDF<span class="token operator">:</span>DataFrame<span class="token operator">=</span>spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>jdbc<span class="token punctuation">(</span>url<span class="token punctuation">,</span>tableName<span class="token punctuation">,</span>properties<span class="token punctuation">)</span>
    mysqlDF<span class="token punctuation">.</span>createTempView<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> resultDF<span class="token operator">:</span>DataFrame<span class="token operator">=</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select * from user where age &gt; 30&quot;</span><span class="token punctuation">)</span>

    resultDF<span class="token punctuation">.</span>write<span class="token punctuation">.</span>mode<span class="token punctuation">(</span><span class="token string">&quot;append&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>jdbc<span class="token punctuation">(</span>url<span class="token punctuation">,</span><span class="token string">&quot;user2&quot;</span><span class="token punctuation">,</span>properties<span class="token punctuation">)</span>

    spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p>查询user2表：</p> <div class="language-sql extra-class"><pre class="language-sql"><code>mysql<span class="token operator">&gt;</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> user2<span class="token punctuation">;</span>
<span class="token operator">+</span><span class="token comment">------+----------+------+</span>
<span class="token operator">|</span> id   <span class="token operator">|</span> name     <span class="token operator">|</span> age  <span class="token operator">|</span>
<span class="token operator">+</span><span class="token comment">------+----------+------+</span>
<span class="token operator">|</span>    <span class="token number">3</span> <span class="token operator">|</span> zhangsan <span class="token operator">|</span>   <span class="token number">34</span> <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">4</span> <span class="token operator">|</span> lisi     <span class="token operator">|</span>   <span class="token number">46</span> <span class="token operator">|</span>
<span class="token operator">+</span><span class="token comment">------+----------+------+</span>
</code></pre></div><p>说明：</p> <ol><li>resultDF.wirte.mode(&quot;...&quot;)的参数有四种，mode用来指定数据的插入模式。
//overwrite: 表示覆盖，如果表不存在，事先帮我们创建
//append   :表示追加， 如果表不存在，事先帮我们创建
//ignore   :表示忽略，如果表事先存在，就不进行任何操作
//error    :如果表事先存在就报错（默认选项）</li> <li>将数据处理后保存到MySQL中，还可以使用rdd方法，详情查看spqrk.md</li> <li>如果要将本地运行改成打jar包到集群运行，只需要修改2个地方：
<ol><li>删掉.master()</li> <li>将resultDF.write.mDFode(args(0)).jdbc()的第2个参数设为args(1)</li></ol></li></ol> <h5 id="通过sparksql保存结果数据到mysql表中-集群"><a href="#通过sparksql保存结果数据到mysql表中-集群" class="header-anchor">#</a> 通过sparksql保存结果数据到mysql表中(集群)</h5> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Properties

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{</span>DataFrame<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo2 <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> spark<span class="token operator">=</span>SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">&quot;demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> url<span class="token operator">=</span><span class="token string">&quot;jdbc:mysql://node03:3306/spark&quot;</span>
    <span class="token keyword">val</span> tableName<span class="token operator">=</span><span class="token string">&quot;user&quot;</span>
    <span class="token keyword">val</span> properties<span class="token operator">=</span><span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>
    properties<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;root&quot;</span><span class="token punctuation">)</span>
    properties<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">&quot;password&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;123456&quot;</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> mysqlDF<span class="token operator">:</span>DataFrame<span class="token operator">=</span>spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>jdbc<span class="token punctuation">(</span>url<span class="token punctuation">,</span>tableName<span class="token punctuation">,</span>properties<span class="token punctuation">)</span>
    mysqlDF<span class="token punctuation">.</span>createTempView<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> resultDF<span class="token operator">:</span>DataFrame<span class="token operator">=</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select * from user where age &gt; 30&quot;</span><span class="token punctuation">)</span>

    resultDF<span class="token punctuation">.</span>write<span class="token punctuation">.</span>mode<span class="token punctuation">(</span><span class="token string">&quot;append&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>jdbc<span class="token punctuation">(</span>url<span class="token punctuation">,</span>args<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>properties<span class="token punctuation">)</span>

    spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p>提交任务脚本</p> <div class="language-shell extra-class"><pre class="language-shell"><code>spark-submit <span class="token punctuation">\</span>
--master spark://node01:7077 <span class="token punctuation">\</span>
--class com.kaikeba.sql.Data2Mysql <span class="token punctuation">\</span>
--executor-memory 1g <span class="token punctuation">\</span>
--total-executor-cores <span class="token number">4</span> <span class="token punctuation">\</span>
--driver-class-path /home/hadoop/jars/mysql-connector-java-5.1.38.jar <span class="token punctuation">\</span>
--jars /home/hadoop/jars/mysql-connector-java-5.1.38.jar <span class="token punctuation">\</span>
original-spark_class05-1.0-SNAPSHOT.jar <span class="token punctuation">\</span>
append  t_kaikeba


--driver-class-path：指定一个Driver端所需要的额外jar
--jars ：指定executor端所需要的额外jar
</code></pre></div><h2 id="sparksql-保存数据到不同类型文件"><a href="#sparksql-保存数据到不同类型文件" class="header-anchor">#</a> sparksql 保存数据到不同类型文件</h2> <p>创建F:\test\score.json文件：</p> <div class="language-json extra-class"><pre class="language-json"><code><span class="token punctuation">{</span><span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;zhangsan1&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;classNum&quot;</span><span class="token operator">:</span><span class="token string">&quot;10&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;score&quot;</span><span class="token operator">:</span><span class="token number">90</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span><span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;zhangsan11&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;classNum&quot;</span><span class="token operator">:</span><span class="token string">&quot;10&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;score&quot;</span><span class="token operator">:</span><span class="token number">90</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span><span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;zhangsan2&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;classNum&quot;</span><span class="token operator">:</span><span class="token string">&quot;10&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;score&quot;</span><span class="token operator">:</span><span class="token number">80</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span><span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;zhangsan3&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;classNum&quot;</span><span class="token operator">:</span><span class="token string">&quot;10&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;score&quot;</span><span class="token operator">:</span><span class="token number">95</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span><span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;zhangsan4&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;classNum&quot;</span><span class="token operator">:</span><span class="token string">&quot;20&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;score&quot;</span><span class="token operator">:</span><span class="token number">90</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span><span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;zhangsan5&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;classNum&quot;</span><span class="token operator">:</span><span class="token string">&quot;20&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;score&quot;</span><span class="token operator">:</span><span class="token number">91</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span><span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;zhangsan6&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;classNum&quot;</span><span class="token operator">:</span><span class="token string">&quot;20&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;score&quot;</span><span class="token operator">:</span><span class="token number">86</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span><span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;zhangsan7&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;classNum&quot;</span><span class="token operator">:</span><span class="token string">&quot;20&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;score&quot;</span><span class="token operator">:</span><span class="token number">78</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span><span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;zhangsan8&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;classNum&quot;</span><span class="token operator">:</span><span class="token string">&quot;30&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;score&quot;</span><span class="token operator">:</span><span class="token number">60</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span><span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;zhangsan9&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;classNum&quot;</span><span class="token operator">:</span><span class="token string">&quot;30&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;score&quot;</span><span class="token operator">:</span><span class="token number">88</span><span class="token punctuation">}</span>
<span class="token punctuation">{</span><span class="token property">&quot;name&quot;</span><span class="token operator">:</span><span class="token string">&quot;zhangsan10&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;classNum&quot;</span><span class="token operator">:</span><span class="token string">&quot;30&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;score&quot;</span><span class="token operator">:</span><span class="token number">95</span><span class="token punctuation">}</span>
</code></pre></div><p>代码开发：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Properties

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{</span>DataFrame<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo3 <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> spark<span class="token operator">=</span>SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">&quot;demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> dataDF<span class="token operator">:</span>DataFrame<span class="token operator">=</span>spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">&quot;file:///F:/test/score.json&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">//处理数据：</span>
    dataDF<span class="token punctuation">.</span>createTempView<span class="token punctuation">(</span><span class="token string">&quot;tableDemo&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> result<span class="token operator">=</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select * from tableDemo where score &gt; 80&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">//保存数据：</span>
    result<span class="token punctuation">.</span>write<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">&quot;file:///F:/test/out_json&quot;</span><span class="token punctuation">)</span>
    result<span class="token punctuation">.</span>write<span class="token punctuation">.</span>parquet<span class="token punctuation">(</span><span class="token string">&quot;file:///F:/test/out_parquet&quot;</span><span class="token punctuation">)</span>
    result<span class="token punctuation">.</span>write<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">&quot;file:///F:/test/out_save&quot;</span><span class="token punctuation">)</span>
    result<span class="token punctuation">.</span>write<span class="token punctuation">.</span>csv<span class="token punctuation">(</span><span class="token string">&quot;file:///F:/test/out_csv&quot;</span><span class="token punctuation">)</span>
    result<span class="token punctuation">.</span>write<span class="token punctuation">.</span>saveAsTable<span class="token punctuation">(</span><span class="token string">&quot;t1&quot;</span><span class="token punctuation">)</span>
    result<span class="token punctuation">.</span>write<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token string">&quot;classNum&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">&quot;file:///F:/test/out_partition_json&quot;</span><span class="token punctuation">)</span>
    result<span class="token punctuation">.</span>write<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token string">&quot;classNum&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">&quot;file:///F:/test/out_partition2_json&quot;</span><span class="token punctuation">)</span>

    spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>说明：</p> <ol><li>out_xxx等都是目录来的，而且是由程序来创建，不需要事先创建，否则报错</li> <li>write.save()默认保存为parquet格式</li> <li>经过partitionBy分区后保存的数据文件如下：</li></ol> <img src="spark.assets/image-20200418172427804.png" alt="image-20200418172427804" style="zoom:80%;"> <ol><li>result.write.saveAsTable(&quot;t1&quot;)保存表t1在spark-warehouse目录下：</li></ol> <p><img src="data:image/png;base64,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" alt="image-20200418172519068"></p> <h2 id="sparksql中自定义函数-★★★★★"><a href="#sparksql中自定义函数-★★★★★" class="header-anchor">#</a> sparksql中自定义函数(★★★★★)</h2> <p>创建文件F:/test/test_udf.txt</p> <div class="language- extra-class"><pre class="language-text"><code>hello
Hadoop
DataFrame
spark
</code></pre></div><p>自定义UDF函数</p> <p>代码开发</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span></span>UDF1
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>types<span class="token punctuation">.</span></span>StringType
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{</span>DataFrame<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo3 <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> spark<span class="token operator">=</span>SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">&quot;demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> dataDF<span class="token operator">:</span>DataFrame<span class="token operator">=</span>spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token string">&quot;file:///F:/test/test_udf.txt&quot;</span><span class="token punctuation">)</span>

    dataDF<span class="token punctuation">.</span>createTempView<span class="token punctuation">(</span><span class="token string">&quot;udfTest&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">//自定义函数方法1:小写--》大写</span>
    spark<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>register<span class="token punctuation">(</span><span class="token string">&quot;low2Up&quot;</span><span class="token punctuation">,</span><span class="token keyword">new</span> UDF1<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token punctuation">{</span>
      <span class="token keyword">override</span> <span class="token keyword">def</span> call<span class="token punctuation">(</span>t1<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token keyword">return</span> t1<span class="token punctuation">.</span>toUpperCase<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>StringType<span class="token punctuation">)</span>

    <span class="token comment">//自定义函数方法2：大写--》小写</span>
    spark<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>register<span class="token punctuation">(</span><span class="token string">&quot;up2Low&quot;</span><span class="token punctuation">,</span><span class="token punctuation">(</span>x<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">)</span><span class="token keyword">=&gt;</span>x<span class="token punctuation">.</span>toLowerCase<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select value from udfTest&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select low2Up(value) from udfTest&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;select up2Low(value) from udfTest&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre></div><p>运行结果为：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>UDF<span class="token operator">:</span>low2Up<span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>            HELLO<span class="token operator">|</span>
<span class="token operator">|</span>           HADOOP<span class="token operator">|</span>
<span class="token operator">|</span>        DATAFRAME<span class="token operator">|</span>
<span class="token operator">|</span>            SPARK<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>

<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>UDF<span class="token operator">:</span>up2Low<span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>            hello<span class="token operator">|</span>
<span class="token operator">|</span>           hadoop<span class="token operator">|</span>
<span class="token operator">|</span>        dataframe<span class="token operator">|</span>
<span class="token operator">|</span>            spark<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre></div><p>说明：</p> <ol><li>udf.register()支持的参数如下, (函数名称，函数，返回值类型) ，通过该方法，我们可以自定义函数</li></ol> <p><img src="/assets/img/image-20200418173539916.9109aadf.png" alt="image-20200418173539916"></p> <ol><li>使用UDF1接口可以自定义1个输入参数的函数，UDF2接口可以自定义2个输入参数的函数，UDF3接口可以自定义3个输入参数的函数，依次类推....</li> <li>new UDF1[String,String]的第一个参数是要定义的函数的输入参数类型，第二个参数是要定义的函数的返回值类型</li> <li></li></ol> <h2 id="sparksql整合hive"><a href="#sparksql整合hive" class="header-anchor">#</a> sparksql整合hive</h2> <h5 id="spark整合hive步骤"><a href="#spark整合hive步骤" class="header-anchor">#</a> spark整合hive步骤</h5> <p>把node03的hive安装目录下的配置文件hive-site.xml拷贝到每一个spark安装目录下对应的conf文件夹中（3台机器）</p> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token builtin class-name">cd</span> /kkb/install/hive-1.1.0-cdh5.14.2/conf
<span class="token function">cp</span> hive-site.xml /kkb/install/spark/conf/
<span class="token function">scp</span> hive-site.xml node01:/kkb/install/spark/conf/
<span class="token function">scp</span> hive-site.xml node02:/kkb/install/spark/conf/
</code></pre></div><p>把node03的hive的libe目录下的连接mysql驱动的jar包拷贝到spark安装目录下对应的jars文件夹中（3台机器）</p> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token builtin class-name">cd</span> /kkb/install/hive-1.1.0-cdh5.14.2/lib
<span class="token function">cp</span> mysql-connector-java-5.1.38.jar /kkb/install/spark/jars/
<span class="token function">scp</span> mysql-connector-java-5.1.38.jar node01:/kkb/install/spark/jars/
<span class="token function">scp</span> mysql-connector-java-5.1.38.jar node02:/kkb/install/spark/jars/
</code></pre></div><p>可以使用spark-sql脚本 后期执行sql相关的任务</p> <h5 id="启动hive相关的spark-sql"><a href="#启动hive相关的spark-sql" class="header-anchor">#</a> 启动hive相关的spark sql</h5> <p>启动整合hive的spark sql</p> <div class="language-shell extra-class"><pre class="language-shell"><code>spark-sql <span class="token punctuation">\</span>
--master spark://node01:7077 <span class="token punctuation">\</span>
--executor-memory 1g <span class="token punctuation">\</span>
--total-executor-cores <span class="token number">4</span> <span class="token punctuation">\</span>
--conf spark.sql.warehouse.dir<span class="token operator">=</span>hdfs://node01:8020/user/hive/warehouse 
</code></pre></div><p>启动之后，可以看到如下shell:</p> <p><img src="/assets/img/image-20200419011931846.5c4a6ac9.png" alt="image-20200419011931846"></p> <p>我们之前了解过，spark sql是兼容hive sql 的，因此，在这里我们可以像在hive shell那样，进行对hive数据仓库的操作。如：</p> <div class="language-sql extra-class"><pre class="language-sql"><code>spark<span class="token operator">-</span><span class="token keyword">sql</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">show</span> <span class="token keyword">databases</span><span class="token punctuation">;</span>
databaseName
db1
<span class="token keyword">default</span>

spark<span class="token operator">-</span><span class="token keyword">sql</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">use</span> db1<span class="token punctuation">;</span>

spark<span class="token operator">-</span><span class="token keyword">sql</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">show</span> <span class="token keyword">tables</span><span class="token punctuation">;</span>
<span class="token keyword">database</span>        tableName       isTemporary
db1     hivedemo        <span class="token boolean">false</span>
db1     sparkdemo1      <span class="token boolean">false</span>

spark<span class="token operator">-</span><span class="token keyword">sql</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> sparkdemo1<span class="token punctuation">;</span>
id      name    age
<span class="token number">1</span>       krystal <span class="token number">21</span>
</code></pre></div><h5 id="写运行spark-sql语句的脚本"><a href="#写运行spark-sql语句的脚本" class="header-anchor">#</a> 写运行spark sql语句的脚本</h5> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token punctuation">[</span>hadoop@node01 ~<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> sparkTest
<span class="token builtin class-name">cd</span> sparkTest
<span class="token function">vi</span> sparkHiveDemo.sh
</code></pre></div><div class="language-shell extra-class"><pre class="language-shell"><code><span class="token shebang important">#!/bin/sh</span>
<span class="token comment">#定义sparksql提交脚本的头信息</span>
<span class="token assign-left variable">SUBMITINFO</span><span class="token operator">=</span><span class="token string">&quot;spark-sql --master spark://node01:7077 --executor-memory 1g --total-executor-cores 2 --conf spark.sql.warehouse.dir=hdfs://node01:8020/user/hive/warehouse&quot;</span> 
<span class="token comment">#定义一个sql语句</span>
<span class="token assign-left variable">SQL</span><span class="token operator">=</span><span class="token string">&quot;select * from db1.sparkDemo1;&quot;</span> 
<span class="token comment">#执行sql语句   类似于 hive -e sql语句</span>
<span class="token builtin class-name">echo</span> <span class="token string">&quot;<span class="token variable">$SUBMITINFO</span>&quot;</span> 
<span class="token builtin class-name">echo</span> <span class="token string">&quot;<span class="token variable">$SQL</span>&quot;</span>
<span class="token variable">$SUBMITINFO</span> -e <span class="token string">&quot;<span class="token variable">$SQL</span>&quot;</span>
</code></pre></div><p>运行脚本：</p> <div class="language-sh extra-class"><pre class="language-sh"><code><span class="token function">sh</span> sparkHiveDemo.sh
</code></pre></div><p>运行结果为：</p> <div class="language- extra-class"><pre class="language-text"><code>id      name    age
1       krystal 21
</code></pre></div><h2 id="sparksql处理点击流日志数据案例-★★★★★"><a href="#sparksql处理点击流日志数据案例-★★★★★" class="header-anchor">#</a> sparksql处理点击流日志数据案例(★★★★★)</h2> <h5 id="需求描述"><a href="#需求描述" class="header-anchor">#</a> 需求描述</h5> <p>通过sparsql对用户访问产生点击流日志数据进行分析处理，计算出对应的指标</p> <p><img src="/assets/img/image-20200419015002531.abcb9b26.png" alt="image-20200419015002531"></p> <h5 id="工具类开发"><a href="#工具类开发" class="header-anchor">#</a> 工具类开发</h5> <p>代码开发——校验日志数据进行字段解析提取的工具类AccessLogUtils</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">scala<span class="token punctuation">.</span>util<span class="token punctuation">.</span>matching<span class="token punctuation">.</span></span>Regex

<span class="token comment">//定义一个样例类，将切分后的一行数据封装在该类里：</span>
<span class="token keyword">case</span> <span class="token keyword">class</span> AccessLog<span class="token punctuation">(</span>
                      ipAddress<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token comment">// IP地址</span>
                      clientId<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token comment">// 客户端唯一标识符</span>
                      userId<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token comment">// 用户唯一标识符</span>
                      serverTime<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token comment">// 服务器时间</span>
                      method<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token comment">// 请求类型/方式</span>
                      endpoint<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token comment">// 请求的资源</span>
                      protocol<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token comment">// 请求的协议名称</span>
                      responseCode<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token comment">// 请求返回值：比如：200、401</span>
                      contentSize<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> <span class="token comment">// 返回的结果数据大小</span>
                      url<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token comment">//访问的url地址</span>
                      clientBrowser<span class="token operator">:</span><span class="token builtin">String</span> <span class="token comment">//客户端游览器信息</span>
                    <span class="token punctuation">)</span>
<span class="token keyword">object</span> MyUtils <span class="token punctuation">{</span>
  <span class="token keyword">val</span> regex<span class="token operator">:</span>Regex<span class="token operator">=</span><span class="token triple-quoted-string string">&quot;&quot;&quot;^(\S+) (\S+) (\S+) \[([\w:/]+\s[+\-]\d{4})\] &quot;(\S+) (\S+) (\S+)&quot; (\d{3}) (\d+) (\S+) (.*)&quot;&quot;&quot;</span><span class="token punctuation">.</span>r

  <span class="token comment">//自定义过滤方法来过滤脏数据</span>
  <span class="token keyword">def</span> isValidLine<span class="token punctuation">(</span>line<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span><span class="token builtin">Boolean</span><span class="token operator">=</span><span class="token punctuation">{</span>
    <span class="token comment">//findFirstMatchIn 是一个匹配方法，返回值是Some或者None</span>
    <span class="token keyword">val</span> options<span class="token operator">=</span>regex<span class="token punctuation">.</span>findFirstMatchIn<span class="token punctuation">(</span>line<span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>options<span class="token punctuation">.</span>isEmpty<span class="token punctuation">)</span><span class="token punctuation">{</span>
      <span class="token boolean">false</span>
    <span class="token punctuation">}</span><span class="token keyword">else</span><span class="token punctuation">{</span>
      <span class="token boolean">true</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>

  <span class="token comment">//定义一个方法，将一行数据切分，并封装在AccessLog类中，并返回AccessLog对象：</span>
  <span class="token keyword">def</span> parseLine<span class="token punctuation">(</span>line<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> AccessLog <span class="token operator">=</span><span class="token punctuation">{</span>
    <span class="token keyword">val</span> options<span class="token operator">=</span>regex<span class="token punctuation">.</span>findFirstMatchIn<span class="token punctuation">(</span>line<span class="token punctuation">)</span>
    <span class="token keyword">val</span> matcher<span class="token operator">=</span>options<span class="token punctuation">.</span>get
    AccessLog<span class="token punctuation">(</span>
      matcher<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment">// 获取匹配的字符串中的第一组的值</span>
      matcher<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      matcher<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      matcher<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      matcher<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      matcher<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      matcher<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      matcher<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toInt<span class="token punctuation">,</span>
      matcher<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toLong<span class="token punctuation">,</span>
      matcher<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      matcher<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
  <span class="token punctuation">}</span>


<span class="token punctuation">}</span>

</code></pre></div><p>说明：</p> <ol><li>正则表达式：可以利用notepad的正则表达式方式的查找功能来解析每个正则表达式的意思
<ol><li>^代表开头的意思</li> <li>\S代表非空格和非Tab键   + 代表至少一个字符  (\S+)代表至少一个非空格Tab键的字符</li> <li>(\S+)代表至少有一个非空格非Tab键的字符</li> <li>\[([\w:/]+\s[+\-]\d{4})\] 中的
<ol><li>\[代表 [</li> <li>\w代表大小写字母，数字和下划线，</li> <li>[\w:/]+代表 大小写字母，数字和下划线、冒号:、斜线/中的任意字符至少一位，</li> <li>\s代表空格或tab键</li> <li>[+\-]代表 +或者-</li> <li>\d{4}代表4为数字</li> <li>]代表]</li> <li>匹配举例：[19/Sep/2013:04:08:36 +0000]</li></ol></li> <li>.*代表任意个数的任意字符</li> <li>正则表达式中的括号() 代表一个组，我们的正则表达式有11个括号()，所以有11个组</li> <li>第一个括号就是第1组，依次类推，后期我们可以获取指定第几组的数据，因此，对匹配到的一行数据就不需要split(&quot; &quot;)切分了。</li> <li>findFirstMatchIn()是匹配到第一个成功匹配的数据</li></ol></li> <li>val regex:Regex=&quot;xxx&quot;.r的是字符串上的方法，该方法可以返回一个new Regex对象</li> <li>正则表达式中会出现特殊字符等，Scala中可以使用三对引号来直接输特殊字符，不需要转义符</li></ol> <h5 id="指标统计"><a href="#指标统计" class="header-anchor">#</a> 指标统计</h5> <p>大致步骤：构建sparkSession和sparkContext对象---》加载数据为RDD---》过滤掉脏数据---》将数据转为DataFrame---》将DataFrame注册成一张表---》指标统计分析---》将分析统计结果保存到mysql---》关闭资源</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Properties

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span>SparkSession

<span class="token keyword">object</span> LogAnalysis <span class="token punctuation">{</span>

  <span class="token keyword">val</span> url<span class="token operator">=</span><span class="token string">&quot;jdbc:mysql://node03:3306/spark&quot;</span>
  <span class="token keyword">val</span> properties<span class="token operator">=</span><span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>
  properties<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;root&quot;</span><span class="token punctuation">)</span>
  properties<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">&quot;password&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;123456&quot;</span><span class="token punctuation">)</span>

  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> spark<span class="token operator">=</span>SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">&quot;demo&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">=</span>spark<span class="token punctuation">.</span>sparkContext
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;warn&quot;</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> lineRDD<span class="token operator">=</span>sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;E:\\LearningAll\\8-HadoopEcosystem-Video\\spark下载资料\\spark_day05\\案例数据\\access.log&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> lineCleanRDD2<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token operator">=</span>lineRDD<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>line<span class="token keyword">=&gt;</span>MyUtils<span class="token punctuation">.</span>isValidLine<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> parseRDD<span class="token operator">:</span>RDD<span class="token punctuation">[</span>AccessLog<span class="token punctuation">]</span><span class="token operator">=</span>lineCleanRDD2<span class="token punctuation">.</span>map<span class="token punctuation">(</span>line<span class="token keyword">=&gt;</span>MyUtils<span class="token punctuation">.</span>parseLine<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//RDD---&gt;DataFrame</span>
    <span class="token keyword">import</span> <span class="token namespace">spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_
    <span class="token keyword">val</span> dataDF<span class="token operator">=</span>parseRDD<span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token punctuation">)</span>
    dataDF<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>

    <span class="token comment">//注册</span>
    dataDF<span class="token punctuation">.</span>createTempView<span class="token punctuation">(</span><span class="token string">&quot;accesslog&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">//开始分析数据</span>
    <span class="token keyword">val</span> result1<span class="token operator">=</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span>
      <span class="token triple-quoted-string string">&quot;&quot;&quot;
        |select
        |date_sub(from_unixtime(unix_timestamp(),'yyyy-MM-dd'),1) as time,
        |AVG(contentSize) as avg_contentSize,
        |MAX(contentSize) as max_contentSize,
        |MIN(contentSize) as min_contentSize
        |from accesslog
        |&quot;&quot;&quot;</span><span class="token punctuation">.</span>stripMargin<span class="token punctuation">)</span>
    result1<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//PV,UV</span>
    <span class="token keyword">val</span> result2<span class="token operator">=</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span>
      <span class="token triple-quoted-string string">&quot;&quot;&quot;
        |select
        |date_sub(from_unixtime(unix_timestamp(),'yyyy-MM-dd'),1) as time,
        |count(*) as PV,
        |count(distinct ipAddress) as UV
        |from accesslog
        |&quot;&quot;&quot;</span><span class="token punctuation">.</span>stripMargin<span class="token punctuation">)</span>
    result2<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> result3<span class="token operator">=</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span>
      <span class="token triple-quoted-string string">&quot;&quot;&quot;
        |select
        |date_sub(from_unixtime(unix_timestamp(),'yyyy-MM-dd'),1) as time,
        |responseCode as code,
        |count(*) as count
        |from accesslog
        |group by responseCode
        |&quot;&quot;&quot;</span><span class="token punctuation">.</span>stripMargin<span class="token punctuation">)</span>
    result3<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//求访问url次数最多的前N位</span>
    <span class="token keyword">val</span> result4 <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span>
      <span class="token triple-quoted-string string">&quot;&quot;&quot;
        |select
        |*,date_sub(from_unixtime(unix_timestamp(),'yyyy-MM-dd'),1) as time
        |from (
        |select
        |url as url,
        |count(*) as count
        |from accesslog
        |group by url) t
        |order by t.count desc limit 5
          &quot;&quot;&quot;</span><span class="token punctuation">.</span>stripMargin<span class="token punctuation">)</span>
    result4<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//求各个请求方式出现的次数</span>
    <span class="token keyword">val</span> result5 <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span>
      <span class="token triple-quoted-string string">&quot;&quot;&quot;
        |select
        |date_sub(from_unixtime(unix_timestamp(),'yyyy-MM-dd'),1) as time,
        |method as method,
        |count(*) as count
        |from accesslog
        |group by method
          &quot;&quot;&quot;</span><span class="token punctuation">.</span>stripMargin<span class="token punctuation">)</span>
    result5<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//保存result5数据到mysql</span>
    result5<span class="token punctuation">.</span>write<span class="token punctuation">.</span>jdbc<span class="token punctuation">(</span>url<span class="token punctuation">,</span><span class="token string">&quot;t_method&quot;</span><span class="token punctuation">,</span>properties<span class="token punctuation">)</span>  <span class="token comment">//不需要事先自己创建表</span>

    spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>说明：</p> <ol><li>DATE_SUB(date,INTERVAL expr type)是一个将日期减去指定的时间间隔的函数，<em>date</em> 参数是合法的日期表达式。<em>expr</em> 参数是您希望添加的时间间隔。</li> <li>函数：FROM_UNIXTIME
作用：将MYSQL中以INT(11)存储的时间（时间戳）以&quot;YYYY-MM-DD&quot;格式来显示。
语法：<strong>FROM_UNIXTIME(unix_timestamp,format)</strong></li> <li>unix_timestamp()可以获取当前时间的时间戳</li> <li>unix_timestamp()也可以传入一个date参数，表示获取date的时间戳，Unix timestamp(date) 中的date需满足格式：yyyy-MM-dd HH:mm:ss或者yyyy-MM-dd</li> <li>date_sub(from_unixtime(unix_timestamp(),'yyyy-MM-dd'),1)表示当前时间减1天，进行减1天的原因大概是在实际工作当中，一般是对昨天的数据进行统计分析的，所以在当前时间减1天</li></ol> <p>运行结果为：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
<span class="token operator">|</span>     ipAddress<span class="token operator">|</span>clientId<span class="token operator">|</span>userId<span class="token operator">|</span>          serverTime<span class="token operator">|</span>method<span class="token operator">|</span>            endpoint<span class="token operator">|</span>protocol<span class="token operator">|</span>responseCode<span class="token operator">|</span>contentSize<span class="token operator">|</span>url<span class="token operator">|</span>       clientBrowser<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
<span class="token operator">|</span><span class="token number">194.237</span><span class="token number">.142</span><span class="token number">.21</span><span class="token operator">|</span>       <span class="token operator">-</span><span class="token operator">|</span>     <span class="token operator">-</span><span class="token operator">|</span><span class="token number">18</span><span class="token operator">/</span>Sep<span class="token operator">/</span><span class="token number">2013</span><span class="token operator">:</span><span class="token number">06</span><span class="token operator">:</span><span class="token number">49.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>|   GET<span class="token operator">|</span><span class="token operator">/</span>wp<span class="token operator">-</span>content<span class="token operator">/</span>uploa<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>|HTTP<span class="token operator">/</span><span class="token number">1.1</span><span class="token operator">|</span>         <span class="token number">304</span><span class="token operator">|</span>          <span class="token number">0</span><span class="token operator">|</span><span class="token string">&quot;-&quot;</span><span class="token operator">|</span>&quot;Mozilla<span class="token operator">/</span><span class="token number">4.0</span> <span class="token punctuation">(</span>com<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>|
<span class="token operator">|</span> <span class="token number">163.177</span><span class="token number">.71</span><span class="token number">.12</span><span class="token operator">|</span>       <span class="token operator">-</span><span class="token operator">|</span>     <span class="token operator">-</span><span class="token operator">|</span><span class="token number">18</span><span class="token operator">/</span>Sep<span class="token operator">/</span><span class="token number">2013</span><span class="token operator">:</span><span class="token number">06</span><span class="token operator">:</span><span class="token number">49.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>|  HEAD<span class="token operator">|</span>                   <span class="token operator">/</span><span class="token operator">|</span>HTTP<span class="token operator">/</span><span class="token number">1.1</span><span class="token operator">|</span>         <span class="token number">200</span><span class="token operator">|</span>         <span class="token number">20</span><span class="token operator">|</span><span class="token string">&quot;-&quot;</span><span class="token operator">|</span><span class="token string">&quot;DNSPod-Monitor/1.0&quot;</span><span class="token operator">|</span>
<span class="token operator">|</span> <span class="token number">163.177</span><span class="token number">.71</span><span class="token number">.12</span><span class="token operator">|</span>       <span class="token operator">-</span><span class="token operator">|</span>     <span class="token operator">-</span><span class="token operator">|</span><span class="token number">18</span><span class="token operator">/</span>Sep<span class="token operator">/</span><span class="token number">2013</span><span class="token operator">:</span><span class="token number">06</span><span class="token operator">:</span><span class="token number">49.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>|  HEAD<span class="token operator">|</span>                   <span class="token operator">/</span><span class="token operator">|</span>HTTP<span class="token operator">/</span><span class="token number">1.1</span><span class="token operator">|</span>         <span class="token number">200</span><span class="token operator">|</span>         <span class="token number">20</span><span class="token operator">|</span><span class="token string">&quot;-&quot;</span><span class="token operator">|</span><span class="token string">&quot;DNSPod-Monitor/1.0&quot;</span><span class="token operator">|</span>
<span class="token operator">|</span><span class="token number">101.226</span><span class="token number">.68</span><span class="token number">.137</span><span class="token operator">|</span>       <span class="token operator">-</span><span class="token operator">|</span>     <span class="token operator">-</span><span class="token operator">|</span><span class="token number">18</span><span class="token operator">/</span>Sep<span class="token operator">/</span><span class="token number">2013</span><span class="token operator">:</span><span class="token number">06</span><span class="token operator">:</span><span class="token number">49.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>|  HEAD<span class="token operator">|</span>                   <span class="token operator">/</span><span class="token operator">|</span>HTTP<span class="token operator">/</span><span class="token number">1.1</span><span class="token operator">|</span>         <span class="token number">200</span><span class="token operator">|</span>         <span class="token number">20</span><span class="token operator">|</span><span class="token string">&quot;-&quot;</span><span class="token operator">|</span><span class="token string">&quot;DNSPod-Monitor/1.0&quot;</span><span class="token operator">|</span>
<span class="token operator">|</span><span class="token number">101.226</span><span class="token number">.68</span><span class="token number">.137</span><span class="token operator">|</span>       <span class="token operator">-</span><span class="token operator">|</span>     <span class="token operator">-</span><span class="token operator">|</span><span class="token number">18</span><span class="token operator">/</span>Sep<span class="token operator">/</span><span class="token number">2013</span><span class="token operator">:</span><span class="token number">06</span><span class="token operator">:</span><span class="token number">49.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>|  HEAD<span class="token operator">|</span>                   <span class="token operator">/</span><span class="token operator">|</span>HTTP<span class="token operator">/</span><span class="token number">1.1</span><span class="token operator">|</span>         <span class="token number">200</span><span class="token operator">|</span>         <span class="token number">20</span><span class="token operator">|</span><span class="token string">&quot;-&quot;</span><span class="token operator">|</span><span class="token string">&quot;DNSPod-Monitor/1.0&quot;</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
only showing top <span class="token number">5</span> rows

<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>      time<span class="token operator">|</span>   avg_contentSize<span class="token operator">|</span>max_contentSize<span class="token operator">|</span>min_contentSize<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span><span class="token number">15882.708061002179</span><span class="token operator">|</span>         <span class="token number">432916</span><span class="token operator">|</span>              <span class="token number">0</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>

<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
<span class="token operator">|</span>      time<span class="token operator">|</span>   PV<span class="token operator">|</span>  UV<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span><span class="token number">13770</span><span class="token operator">|</span><span class="token number">1027</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>

<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>      time<span class="token operator">|</span>code<span class="token operator">|</span>count<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span> <span class="token number">500</span><span class="token operator">|</span>    <span class="token number">1</span><span class="token operator">|</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span> <span class="token number">502</span><span class="token operator">|</span>    <span class="token number">8</span><span class="token operator">|</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span> <span class="token number">301</span><span class="token operator">|</span>   <span class="token number">94</span><span class="token operator">|</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span> <span class="token number">400</span><span class="token operator">|</span>   <span class="token number">13</span><span class="token operator">|</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span> <span class="token number">403</span><span class="token operator">|</span>    <span class="token number">3</span><span class="token operator">|</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span> <span class="token number">404</span><span class="token operator">|</span>  <span class="token number">201</span><span class="token operator">|</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span> <span class="token number">408</span><span class="token operator">|</span>    <span class="token number">1</span><span class="token operator">|</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span> <span class="token number">200</span><span class="token operator">|</span><span class="token number">12340</span><span class="token operator">|</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span> <span class="token number">304</span><span class="token operator">|</span>  <span class="token number">949</span><span class="token operator">|</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span> <span class="token number">499</span><span class="token operator">|</span>    <span class="token number">8</span><span class="token operator">|</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span> <span class="token number">302</span><span class="token operator">|</span>  <span class="token number">152</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>

<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
<span class="token operator">|</span>                 url<span class="token operator">|</span>count<span class="token operator">|</span>      time<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
<span class="token operator">|</span>                 <span class="token string">&quot;-&quot;</span><span class="token operator">|</span> <span class="token number">5204</span><span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span>
<span class="token operator">|</span>&quot;http<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>blog<span class="token punctuation">.</span>fens<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>|  <span class="token number">547</span><span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span>
<span class="token operator">|</span>&quot;http<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>blog<span class="token punctuation">.</span>fens<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>|  <span class="token number">377</span><span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span>
<span class="token operator">|</span>&quot;http<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>blog<span class="token punctuation">.</span>fens<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>|  <span class="token number">360</span><span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span>
<span class="token operator">|</span>&quot;http<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>blog<span class="token punctuation">.</span>fens<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>|  <span class="token number">274</span><span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>

<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>      time<span class="token operator">|</span>method<span class="token operator">|</span>count<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span>  POST<span class="token operator">|</span>  <span class="token number">449</span><span class="token operator">|</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span>  HEAD<span class="token operator">|</span> <span class="token number">2941</span><span class="token operator">|</span>
<span class="token operator">|</span><span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span><span class="token operator">|</span>   GET<span class="token operator">|</span><span class="token number">10380</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre></div><p>查看保存到mysql的数据：</p> <div class="language-scala extra-class"><pre class="language-scala"><code>mysql<span class="token operator">&gt;</span> show tables<span class="token punctuation">;</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span> Tables_in_spark <span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span> t_method        <span class="token operator">|</span>
<span class="token operator">|</span> t_students      <span class="token operator">|</span>
<span class="token operator">|</span> user            <span class="token operator">|</span>
<span class="token operator">|</span> user2           <span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token number">4</span> rows in set <span class="token punctuation">(</span><span class="token number">0.00</span> sec<span class="token punctuation">)</span>

mysql<span class="token operator">&gt;</span> select <span class="token operator">*</span> from t_method<span class="token punctuation">;</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span> time       <span class="token operator">|</span> method <span class="token operator">|</span> count <span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span> <span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span> <span class="token operator">|</span> POST   <span class="token operator">|</span>   <span class="token number">449</span> <span class="token operator">|</span>
<span class="token operator">|</span> <span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span> <span class="token operator">|</span> HEAD   <span class="token operator">|</span>  <span class="token number">2941</span> <span class="token operator">|</span>
<span class="token operator">|</span> <span class="token number">2020</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">18</span> <span class="token operator">|</span> GET    <span class="token operator">|</span> <span class="token number">10380</span> <span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre></div><h2 id="spark调优-分配更多的资源"><a href="#spark调优-分配更多的资源" class="header-anchor">#</a> Spark调优——分配更多的资源</h2> <p>分配更多的资源是性能优化调优的王道，就是增加和分配更多的资源，这对于性能和速度上的提升是显而易见的。</p> <p>基本上，在一定范围之内，增加资源与性能的提升，是成正比的；写完了一个复杂的spark作业之后，进行性能调优的时候，首先第一步，就是要来调节最优的资源配置；</p> <p>在这个基础之上，如果说你的spark作业，能够分配的资源达到了你的能力范围的顶端之后，无法再分配更多的资源了，公司资源有限；那么才是考虑去做后面的这些性能调优的点。</p> <p>相关问题：</p> <ol><li>分配哪些资源？</li> <li>在哪里可以设置这些资源？</li> <li>剖析为什么分配这些资源之后，性能可以得到提升？</li></ol> <h4 id="分配哪些资源"><a href="#分配哪些资源" class="header-anchor">#</a> 分配哪些资源</h4> <div class="language-scala extra-class"><pre class="language-scala"><code>executor<span class="token operator">-</span>memory、executor<span class="token operator">-</span>cores、driver<span class="token operator">-</span>memory
</code></pre></div><h4 id="在哪里可以设置这些资源"><a href="#在哪里可以设置这些资源" class="header-anchor">#</a> 在哪里可以设置这些资源</h4> <p>在实际的生产环境中，提交spark任务时，使用spark-submit shell脚本，在里面调整对应的参数。</p> <div class="language-sh extra-class"><pre class="language-sh"><code>spark-submit <span class="token punctuation">\</span>
 --master spark://node1:7077 <span class="token punctuation">\</span>
 --class com.kaikeba.WordCount <span class="token punctuation">\</span>
 --num-executors <span class="token number">3</span> <span class="token punctuation">\</span>    配置executor的数量
 --driver-memory 1g <span class="token punctuation">\</span>   配置driver的内存（影响不大）
 --executor-memory 1g <span class="token punctuation">\</span> 配置每一个executor的内存大小
 --executor-cores <span class="token number">3</span> <span class="token punctuation">\</span>   配置每一个executor的cpu个数
 /export/servers/wordcount.jar
</code></pre></div><h4 id="参数调节到多大-算是最大"><a href="#参数调节到多大-算是最大" class="header-anchor">#</a> 参数调节到多大，算是最大</h4> <p>Standalone模式</p> <div class="language- extra-class"><pre class="language-text"><code> 	先计算出公司spark集群上的所有资源 每台节点的内存大小和cpu核数，
 	比如：一共有20台worker节点，每台节点8g内存，10个cpu。
 	实际任务在给定资源的时候，可以给20个executor、每个executor的内存8g、每个executor的使用的cpu个数10。
</code></pre></div><p>Yarn模式</p> <div class="language- extra-class"><pre class="language-text"><code> 	先计算出yarn集群的所有大小，比如一共500g内存，100个cpu；
 	这个时候可以分配的最大资源，比如给定50个executor、每个executor的内存大小10g,每个executor使用的cpu个数为2。
</code></pre></div><p>使用原则</p> <div class="language- extra-class"><pre class="language-text"><code>在资源比较充足的情况下，尽可能的使用更多的计算资源，尽量去调节到最大的大小
</code></pre></div><h4 id="为什么调大资源以后性能可以提升"><a href="#为什么调大资源以后性能可以提升" class="header-anchor">#</a> 为什么调大资源以后性能可以提升</h4> <h5 id="executor-memory-2"><a href="#executor-memory-2" class="header-anchor">#</a> --executor-memory</h5> <ul><li>表示每一个executor进程需要的内存大小，它决定了后期操作数据的速度</li></ul> <div class="language- extra-class"><pre class="language-text"><code>比如说一个rdd的数据量大小为5g,这里给定的executor-memory为2g, 在这种情况下，内存是存储不下，它会把一部分数据保存在内存中，还有一部分数据保存在磁盘，后续需要用到该rdd的结果数据，可以从内存和磁盘中获取得到，这里就涉及到一定的磁盘io操作。

,这里给定的executor-memory为10g，这里数据就可以完全在内存中存储下，后续需要用到该rdd的数据，就可以直接从内存中获取，这样一来，避免了大量的磁盘io操作。性能得到提升。


在实际的工作，这里 --executor-memory 需要设置的大一点。
比如说10G/20G/30G等
</code></pre></div><h5 id="total-executor-cores-2"><a href="#total-executor-cores-2" class="header-anchor">#</a> --total-executor-cores</h5> <p>--total-executor-cores表示任务运行需要总的cpu核数，它决定了任务并行运行的粒度</p> <p>比如说要处理100个task，注意一个cpu在同一时间只能处理一个task线程。</p> <ol><li><p>如果给定的总的cpu核数是5个，这里就需要100/5=20个批次才可以把这100个task运行完成，如果平均每个task运行1分钟，这里最后一共运行20分钟。</p></li> <li><p>如果给定的总的cpu核数是20个，这里就需要100/20=5个批次才可以把这100个task运行完成，如果平均每个task运行1分钟，这里最后一共运行5分钟。</p></li> <li><p>如果如果给定的总的cpu核数是100个，这里就需要100/100=1个批次才可以把这100个task运行完成，如果平均每个task运行1分钟，这里最后一共运行1分钟。</p></li></ol> <p>在实际的生产环境中，--total-executor-cores 这个参数一般也会设置的大一点，比如说 30个/50个/100个</p> <p>注意：如果分配的cpu核数比总的task线程数量还打会造成资源浪费。</p> <p><img src="/assets/img/image-20200416204239271-1587626129053.112e3ee6.png" alt="image-20200416204239271"></p> <p><img src="/assets/img/spark性能优化--分配资源.5ebf8ac5.png" alt="spark性能优化--分配资源"></p> <h2 id="spark调优-提高并行度"><a href="#spark调优-提高并行度" class="header-anchor">#</a> Spark调优——提高并行度</h2> <h4 id="spark的并行度指的是什么"><a href="#spark的并行度指的是什么" class="header-anchor">#</a> Spark的并行度指的是什么</h4> <p>spark作业中，各个stage的task的数量，也就代表了spark作业在各个阶段stage的并行度！</p> <p>当分配完所能分配的最大资源了，然后对应资源去调节程序的并行度，如果并行度没有与资源相匹配，那么导致你分配下去的资源都浪费掉了。同时并行运行，还可以让每个task要处理的数量变少（很简单的原理。合理设置并行度，可以充分利用集群资源，减少每个task处理数据量，而增加性能加快运行速度。）</p> <h4 id="如何提高并行度"><a href="#如何提高并行度" class="header-anchor">#</a> 如何提高并行度</h4> <h5 id="可以设置task的数量"><a href="#可以设置task的数量" class="header-anchor">#</a> 可以设置task的数量</h5> <p>task数量至少设置成与spark Application 的总cpu core 数量相同。最理想情况，150个core，分配150task，一起运行，差不多同一时间运行完毕</p> <p>官方推荐，task数量，设置成spark Application 总cpu core数量的2~3倍 。</p> <div class="language- extra-class"><pre><code>比如150个cpu core ，基本设置task数量为300~500. 与理想情况不同的，有些task会运行快一点，比如50s就完了，有些task 可能会慢一点，要一分半才运行完，所以如果你的task数量，刚好设置的跟cpu core 数量相同，可能会导致资源的浪费。
</code></pre></div><p>因为比如150个task中10个先运行完了，剩余140个还在运行，但是这个时候，就有10个cpu core空闲出来了，导致浪费。如果设置2~3倍，那么一个task运行完以后，另外一个task马上补上来，尽量让cpu core不要空闲。同时尽量提升spark运行效率和速度。提升性能。</p> <h5 id="设置task数量方法1-spark-default-parallelism"><a href="#设置task数量方法1-spark-default-parallelism" class="header-anchor">#</a> 设置task数量方法1——spark.default.parallelism</h5> <p>spark.default.parallelism</p> <p>参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。</p> <p>参数调优建议：Spark作业的默认task数量为500~1000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。</p> <p>可以通过在构建SparkConf对象的时候设置，例如：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>set<span class="token punctuation">(</span><span class="token string">&quot;spark.defalut.parallelism&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;500&quot;</span><span class="token punctuation">)</span>
</code></pre></div><h5 id="设置task数量方法2-给rdd重新设置partition的数量"><a href="#设置task数量方法2-给rdd重新设置partition的数量" class="header-anchor">#</a> 设置task数量方法2——给RDD重新设置partition的数量</h5> <p>使用rdd.repartition 来重新分区，该方法会生成一个新的rdd，使其分区数变大。</p> <p>此时由于一个partition对应一个task，那么对应的task个数越多，通过这种方式也可以提高并行度。</p> <h5 id="设置task数量方法3-提高sparksql运行的task数量"><a href="#设置task数量方法3-提高sparksql运行的task数量" class="header-anchor">#</a> 设置task数量方法3——提高sparksql运行的task数量</h5> <p>通过设置参数 spark.sql.shuffle.partitions=500  默认为200；</p> <p>可以适当增大，来提高并行度。 比如设置为 spark.sql.shuffle.partitions=500。</p> <p>该参数的作用：Configures the number of partitions to use when shuffling data for joins or aggregations.</p> <h2 id="spark调优-rdd的重用和持久化"><a href="#spark调优-rdd的重用和持久化" class="header-anchor">#</a> Spark调优——RDD的重用和持久化</h2> <h5 id="实际开发遇到的情况说明"><a href="#实际开发遇到的情况说明" class="header-anchor">#</a> 实际开发遇到的情况说明</h5> <p><img src="/assets/img/rdd重用1.6fec577d.png" alt="rdd重用1"></p> <p>如上图所示的计算逻辑：</p> <p>（1）当第一次使用rdd2做相应的算子操作得到rdd3的时候，就会从rdd1开始计算，先读取HDFS上的文件，然后对rdd1做对应的算子操作得到rdd2,再由rdd2计算之后得到rdd3。同样为了计算得到rdd4，前面的逻辑会被重新计算。</p> <p>（3）默认情况下多次对一个rdd执行算子操作，去获取不同的rdd，都会对这个rdd及之前的父rdd全部重新计算一次。这种情况在实际开发代码的时候会经常遇到，但是我们一定要避免一个rdd重复计算多次，否则会导致性能急剧降低。</p> <p>总结：可以把多次使用到的rdd，也就是公共rdd进行持久化，避免后续需要，再次重新计算，提升效率。</p> <p><img src="/assets/img/rdd重用2.3d1ba6e5.png" alt="rdd重用2"></p> <h5 id="如何对rdd进行持久化"><a href="#如何对rdd进行持久化" class="header-anchor">#</a> 如何对rdd进行持久化</h5> <p>可以调用rdd的cache或者persist方法。</p> <p>（1）cache方法默认是把数据持久化到内存中 ，例如：rdd.cache ，其本质还是调用了persist方法</p> <p>（2）persist方法中有丰富的缓存级别，这些缓存级别都定义在StorageLevel这个object中，可以结合实际的应用场景合理的设置缓存级别。</p> <p>例如： rdd.persist(StorageLevel.MEMORY_ONLY),这是cache方法的实现。</p> <h5 id="rdd持久化的时可以采用序列化"><a href="#rdd持久化的时可以采用序列化" class="header-anchor">#</a> rdd持久化的时可以采用序列化</h5> <p>（1）如果正常将数据持久化在内存中，那么可能会导致内存的占用过大，这样的话，也许会导致OOM内存溢出。</p> <p>（2）当纯内存无法支撑公共RDD数据完全存放的时候，就优先考虑使用序列化的方式在纯内存中存储。将RDD的每个partition的数据，序列化成一个字节数组；序列化后，大大减少内存的空间占用。</p> <p>（3）序列化的方式，唯一的缺点就是，在获取数据的时候，需要反序列化。但是可以减少占用的空间和便于网络传输</p> <p>（4）如果序列化纯内存方式，还是导致OOM，内存溢出；就只能考虑磁盘的方式，内存+磁盘的普通方式（无序列化）。</p> <p>（5）为了数据的高可靠性，而且内存充足，可以使用双副本机制，进行持久化</p> <p>持久化的双副本机制，持久化后的一个副本，因为机器宕机了，副本丢了，就还是得重新计算一次；</p> <p>持久化的每个数据单元，存储一份副本，放在其他节点上面，从而进行容错；</p> <p>一个副本丢了，不用重新计算，还可以使用另外一份副本。这种方式，仅仅针对你的内存资源极度充足。</p> <p>比如: StorageLevel.MEMORY_ONLY_2</p> <h2 id="spark调优-广播变量的使用"><a href="#spark调优-广播变量的使用" class="header-anchor">#</a> Spark调优——广播变量的使用</h2> <h5 id="场景描述"><a href="#场景描述" class="header-anchor">#</a> 场景描述</h5> <p>在实际工作中可能会遇到这样的情况，由于要处理的数据量非常大，这个时候可能会在一个stage中出现大量的task，比如有1000个task，这些task都需要一份相同的数据来处理业务，这份数据的大小为100M，该数据会拷贝1000份副本，通过网络传输到各个task中去，给task使用。</p> <p>这里会涉及大量的网络传输开销，同时至少需要的内存为1000*100M=100G，这个内存开销是非常大的。不必要的内存的消耗和占用，就导致了你在进行RDD持久化到内存，也许就没法完全在内存中放下；就只能写入磁盘，最后导致后续的操作在磁盘IO上消耗性能；这对于spark任务处理来说就是一场灾难。</p> <p>由于内存开销比较大，task在创建对象的时候，可能会出现堆内存放不下所有对象，就会导致频繁的垃圾回收器的回收GC。GC的时候一定是会导致工作线程停止，也就是导致Spark暂停工作那么一点时间。频繁GC的话，对Spark作业的运行的速度会有相当可观的影响。</p> <p><img src="/assets/img/task共享数据.eee3133d.png" alt="task共享数据"></p> <h5 id="广播变量引入"><a href="#广播变量引入" class="header-anchor">#</a> 广播变量引入</h5> <p>Spark中分布式执行的代码需要传递到各个executor的task上运行。对于一些只读、固定的数据,每次都需要Driver广播到各个Task上，这样效率低下。广播变量允许将变量只广播给各个executor。</p> <p>该executor上的各个task再从所在节点的BlockManager(负责管理某个executor对应的内存和磁盘上的数据)获取变量，而不是从Driver获取变量，从而提升了效率。</p> <p><img src="/assets/img/广播变量.cfe386bf.png" alt="广播变量"></p> <p>广播变量，初始的时候，就在Drvier上有一份副本。通过在Driver把共享数据转换成广播变量。</p> <p>task在运行的时候，想要使用广播变量中的数据，此时首先会在自己本地的Executor对应的BlockManager中，尝试获取变量副本；如果本地没有，那么就从Driver远程拉取广播变量副本，并保存在本地的BlockManager中；</p> <p>此后这个executor上的task，都会直接使用本地的BlockManager中的副本。那么这个时候所有该executor中的task都会使用这个广播变量的副本。也就是说一个executor只需要在第一个task启动时，获得一份广播变量数据，之后的task都从本节点的BlockManager中获取相关数据。</p> <p>executor的BlockManager除了从driver上拉取，也可能从其他节点的BlockManager上拉取变量副本，网络距离越近越好。</p> <h5 id="使用广播变量后的性能分析"><a href="#使用广播变量后的性能分析" class="header-anchor">#</a> 使用广播变量后的性能分析</h5> <p>比如一个任务需要50个executor，1000个task，共享数据为100M。</p> <p>(1)在不使用广播变量的情况下，1000个task，就需要该共享数据的1000个副本，也就是说有1000份数需要大量的网络传输和内存开销存储。耗费的内存大小1000<em>100=100G.</em></p> <p>(2)使用了广播变量后，50个executor就只需要50个副本数据，而且不一定都是从Driver传输到每个节点，还可能是就近从最近的节点的executor的blockmanager上拉取广播变量副本，网络传输速度大大增加；内存开销 50*100M=5G</p> <p>总结：
不使用广播变量的内存开销为100G，使用后的内存开销5G，这里就相差了20倍左右的网络传输性能损耗和内存开销，使用广播变量后对于性能的提升和影响，还是很可观的。
广播变量的使用不一定会对性能产生决定性的作用。比如运行30分钟的spark作业，可能做了广播变量以后，速度快了2分钟，或者5分钟。但是一点一滴的调优，积少成多。最后还是会有效果的。</p> <h5 id="广播变量使用注意事项"><a href="#广播变量使用注意事项" class="header-anchor">#</a> 广播变量使用注意事项</h5> <ol><li><p>能不能将一个RDD使用广播变量广播出去？</p> <p>不能，因为RDD是不存储数据的。可以将RDD的结果广播出去。</p></li> <li><p>广播变量只能在Driver端定义，不能在Executor端定义。</p></li> <li><p>在Driver端可以修改广播变量的值，在Executor端无法修改广播变量的值。</p></li> <li><p>如果executor端用到了Driver的变量，如果不使用广播变量在Executor有多少task就有多少Driver端的变量副本。</p></li> <li><p>如果Executor端用到了Driver的变量，如果使用广播变量在每个Executor中只有一份Driver端的变量副本。</p></li></ol> <h5 id="如何使用广播变量"><a href="#如何使用广播变量" class="header-anchor">#</a> 如何使用广播变量</h5> <p>(1) 通过sparkContext的broadcast方法把数据转换成广播变量，类型为Broadcast，</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> broadcastArray<span class="token operator">:</span> Broadcast<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>broadcast<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>(2) 然后executor上的BlockManager就可以拉取该广播变量的副本获取具体的数据。</p> <p>获取广播变量中的值可以通过调用其value方法</p> <div class="language-scala extra-class"><pre class="language-scala"><code> <span class="token keyword">val</span> array<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> broadcastArray<span class="token punctuation">.</span>value
</code></pre></div><h2 id="spark调优-尽量避免使用shuffle类算子"><a href="#spark调优-尽量避免使用shuffle类算子" class="header-anchor">#</a> Spark调优——尽量避免使用shuffle类算子</h2> <h5 id="shuffle描述"><a href="#shuffle描述" class="header-anchor">#</a> shuffle描述</h5> <p>spark中的shuffle涉及到数据要进行大量的网络传输，下游阶段的task任务需要通过网络拉取上阶段task的输出数据，shuffle过程，简单来说，就是将分布在集群中多个节点上的同一个key，拉取到同一个节点上，进行聚合或join等操作。比如reduceByKey、join等算子，都会触发shuffle操作。</p> <p>如果有可能的话，要尽量避免使用shuffle类算子。</p> <p>因为Spark作业运行过程中，最消耗性能的地方就是shuffle过程。</p> <h5 id="哪些算子操作会产生shuffle"><a href="#哪些算子操作会产生shuffle" class="header-anchor">#</a> 哪些算子操作会产生shuffle</h5> <p>spark程序在开发的过程中使用reduceByKey、join、distinct、repartition等算子操作，这里都会产生shuffle，由于shuffle这一块是非常耗费性能的，实际开发中尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。</p> <h5 id="避免产生shuffle的小案例"><a href="#避免产生shuffle的小案例" class="header-anchor">#</a> 避免产生shuffle的小案例</h5> <p>错误的做法：</p> <p>传统的join操作会导致shuffle操作。因为两个RDD中，相同的key都需要通过网络拉取到一个节点上，由一个task进行join操作。</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">val</span> rdd3 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>join<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span>
</code></pre></div><p><img src="/assets/img/image-20200419135700724.7db21c1d.png" alt="image-20200419135700724"></p> <p>正确的做法：Broadcast+map的join操作，不会导致shuffle操作</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">// 使用Broadcast将一个数据量较小的RDD作为广播变量。</span>
<span class="token keyword">val</span> rdd2Data <span class="token operator">=</span> rdd2<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd2DataBroadcast <span class="token operator">=</span> sc<span class="token punctuation">.</span>broadcast<span class="token punctuation">(</span>rdd2Data<span class="token punctuation">)</span>

<span class="token comment">// 在rdd1.map算子中，可以从rdd2DataBroadcast中，获取rdd2的所有数据。</span>
<span class="token comment">// 然后进行遍历，如果发现rdd2中某条数据的key与rdd1的当前数据的key是相同的，那么就判定可以进行join。</span>
<span class="token comment">// 此时就可以根据自己需要的方式，将rdd1当前数据与rdd2中可以连接的数据，拼接在一起（String或Tuple）。</span>
<span class="token keyword">val</span> rdd3 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span>rdd2DataBroadcast<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token comment">//写一个方法来事先拼接操作</span>

<span class="token comment">// 注意，以上操作，建议仅仅在rdd2的数据量比较少（比如几百M，或者一两G）的情况下使用。</span>
<span class="token comment">// 因为每个Executor的内存中，都会驻留一份rdd2的全量数据。</span>
</code></pre></div><h5 id="使用map-side预聚合的shuffle操作"><a href="#使用map-side预聚合的shuffle操作" class="header-anchor">#</a> 使用map-side预聚合的shuffle操作</h5> <p>map-side预聚合</p> <p>如果因为业务需要，一定要使用shuffle操作，无法用map类的算子来替代，那么尽量使用可以map-side预聚合的算子。</p> <p>所谓的map-side预聚合，说的是在每个节点本地对相同的key进行一次聚合操作，类似于MapReduce中的本地combiner。</p> <p>map-side预聚合之后，每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。</p> <p>通常来说，在可能的情况下，建议使用reduceByKey或者aggregateByKey算子来替代掉groupByKey算子。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合。而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。</p> <p>比如如下两幅图，就是典型的例子，分别基于reduceByKey和groupByKey进行单词计数。其中第一张图是groupByKey的原理图，可以看到，没有进行任何本地聚合时，所有数据都会在集群节点之间传输；第二张图是reduceByKey的原理图，可以看到，每个节点本地的相同key数据，都进行了预聚合，然后才传输到其他节点上进行全局聚合。</p> <p><strong>groupByKey进行单词计数原理</strong></p> <p><img src="/assets/img/groupByKey.5fdbbc1a.png" alt="1577080609633"></p> <p><strong>reduceByKey单词计数原理</strong></p> <p><img src="/assets/img/reduceByKey.a735f59c.png" alt="1577080686083"></p> <h2 id="spark调优-使用高性能的算子"><a href="#spark调优-使用高性能的算子" class="header-anchor">#</a> Spark调优——使用高性能的算子</h2> <h5 id="使用reducebykey-aggregatebykey替代groupbykey"><a href="#使用reducebykey-aggregatebykey替代groupbykey" class="header-anchor">#</a> 使用reduceByKey/aggregateByKey替代groupByKey</h5> <ul><li>reduceByKey/aggregateByKey 可以进行预聚合操作，减少数据的传输量，提升性能</li> <li>groupByKey 不会进行预聚合操作，进行数据的全量拉取，性能比较低</li></ul> <h5 id="使用mappartitions替代普通map"><a href="#使用mappartitions替代普通map" class="header-anchor">#</a> 使用mapPartitions替代普通map</h5> <p>mapPartitions类的算子，一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些。</p> <p>但是有的时候，使用mapPartitions会出现OOM（内存溢出）的问题。因为单次函数调用就要处理掉一个partition所有的数据，如果内存不够，垃圾回收时是无法回收掉太多对象的，很可能出现OOM异常。所以使用这类操作时要慎重！</p> <h5 id="使用foreachpartitions替代foreach"><a href="#使用foreachpartitions替代foreach" class="header-anchor">#</a> 使用foreachPartitions替代foreach</h5> <p>原理类似于“使用mapPartitions替代map”，也是一次函数调用处理一个partition的所有数据，而不是一次函数调用处理一条数据。</p> <p>在实践中发现，foreachPartitions类的算子，对性能的提升还是很有帮助的。比如在foreach函数中，将RDD中所有数据写MySQL，那么如果是普通的foreach算子，就会一条数据一条数据地写，每次函数调用可能就会创建一个数据库连接，此时就势必会频繁地创建和销毁数据库连接，性能是非常低下；</p> <p>但是如果用foreachPartitions算子一次性处理一个partition的数据，那么对于每个partition，只要创建一个数据库连接即可，然后执行批量插入操作，此时性能是比较高的。实践中发现，对于1万条左右的数据量写MySQL，性能可以提升30%以上。</p> <h5 id="使用filter之后进行coalesce操作"><a href="#使用filter之后进行coalesce操作" class="header-anchor">#</a> 使用filter之后进行coalesce操作</h5> <p>通常对一个RDD执行filter算子过滤掉RDD中较多数据后（比如30%以上的数据），建议使用coalesce算子，手动减少RDD的partition数量，将RDD中的数据压缩到更少的partition中去。</p> <p>因为filter之后，RDD的每个partition中都会有很多数据被过滤掉，此时如果照常进行后续的计算，其实每个task处理的partition中的数据量并不是很多，有一点资源浪费，而且此时处理的task越多，可能速度反而越慢。</p> <p>因此用coalesce减少partition数量，将RDD中的数据压缩到更少的partition之后，只要使用更少的task即可处理完所有的partition。在某些场景下，对于性能的提升会有一定的帮助。</p> <h5 id="使用repartitionandsortwithinpartitions替代repartition与sort类操作"><a href="#使用repartitionandsortwithinpartitions替代repartition与sort类操作" class="header-anchor">#</a> 使用repartitionAndSortWithinPartitions替代repartition与sort类操作</h5> <p>repartitionAndSortWithinPartitions是Spark官网推荐的一个算子，官方建议，如果需要在repartition重分区之后，还要进行排序，建议直接使用repartitionAndSortWithinPartitions算子。</p> <p>因为该算子可以一边进行重分区的shuffle操作，一边进行排序。shuffle与sort两个操作同时进行，比先shuffle再sort来说，性能可能是要高的。</p> <h2 id="spark调优-使用kryo优化序列化性能"><a href="#spark调优-使用kryo优化序列化性能" class="header-anchor">#</a> Spark调优——使用Kryo优化序列化性能</h2> <h5 id="spark序列化介绍"><a href="#spark序列化介绍" class="header-anchor">#</a> spark序列化介绍</h5> <p>Spark在进行任务计算的时候，会涉及到数据跨进程的网络传输、数据的持久化，这个时候就需要对数据进行序列化。Spark默认采用Java的序列化器。默认java序列化的优缺点如下:</p> <p>其好处：处理起来方便，不需要我们手动做其他操作，只需要在使用一个对象和变量的时候，实现Serializble接口即可。</p> <p>其缺点：默认的序列化机制的效率不高，序列化的速度比较慢；序列化以后的数据，占用的内存空间相对还是比较大。</p> <p>Spark支持使用Kryo序列化机制。Kryo序列化机制，比默认的Java序列化机制，速度要快，序列化后的数据要更小，大概是Java序列化机制的1/10。所以Kryo序列化优化以后，可以让网络传输的数据变少；在集群中耗费的内存资源大大减少。</p> <h5 id="kryo序列化启用后生效的地方"><a href="#kryo序列化启用后生效的地方" class="header-anchor">#</a> Kryo序列化启用后生效的地方</h5> <p>Kryo序列化机制，一旦启用以后，会生效的几个地方：</p> <p>（1）算子函数中使用到的外部变量</p> <p>算子中的外部变量可能来着与driver需要涉及到网络传输，就需要用到序列化。</p> <p>最终可以优化网络传输的性能，优化集群中内存的占用和消耗</p> <p>（2）持久化RDD时进行序列化，StorageLevel.MEMORY_ONLY_SER</p> <p>将rdd持久化时，对应的存储级别里，需要用到序列化。</p> <p>最终可以优化内存的占用和消耗；持久化RDD占用的内存越少，task执行的时候，创建的对象，就不至于频繁的占满内存，频繁发生GC。</p> <p>（3）产生shuffle的地方，也就是宽依赖</p> <p>下游的stage中的task，拉取上游stage中的task产生的结果数据，跨网络传输，需要用到序列化。最终可以优化网络传输的性能</p> <h5 id="如何开启kryo序列化机制"><a href="#如何开启kryo序列化机制" class="header-anchor">#</a> 如何开启Kryo序列化机制</h5> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">// 创建SparkConf对象。</span>
<span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
<span class="token comment">// 设置序列化器为KryoSerializer。</span>
conf<span class="token punctuation">.</span>set<span class="token punctuation">(</span><span class="token string">&quot;spark.serializer&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;org.apache.spark.serializer.KryoSerializer&quot;</span><span class="token punctuation">)</span>

<span class="token comment">// 注册要序列化的自定义类型。</span>
conf<span class="token punctuation">.</span>registerKryoClasses<span class="token punctuation">(</span>Array<span class="token punctuation">(</span>classOf<span class="token punctuation">[</span>MyClass1<span class="token punctuation">]</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>MyClass2<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="spark调优-使用fastutil优化数据格式"><a href="#spark调优-使用fastutil优化数据格式" class="header-anchor">#</a> Spark调优——使用fastutil优化数据格式</h2> <h5 id="fastutil介绍"><a href="#fastutil介绍" class="header-anchor">#</a> fastutil介绍</h5> <p>fastutil是扩展了Java标准集合框架（Map、List、Set；HashMap、ArrayList、HashSet）的类库，提供了特殊类型的map、set、list和queue；</p> <p>fastutil能够提供更小的内存占用，更快的存取速度；我们使用fastutil提供的集合类，来替代自己平时使用的JDK的原生的Map、List、Set.</p> <h5 id="fastutil好处"><a href="#fastutil好处" class="header-anchor">#</a> fastutil好处</h5> <p>fastutil集合类，可以减小内存的占用，并且在进行集合的遍历、根据索引（或者key）获取元素的值和设置元素的值的时候，提供更快的存取速度</p> <h5 id="spark中应用fastutil的场景和使用"><a href="#spark中应用fastutil的场景和使用" class="header-anchor">#</a> Spark中应用fastutil的场景和使用</h5> <h6 id="算子函数使用了外部变量"><a href="#算子函数使用了外部变量" class="header-anchor">#</a> 算子函数使用了外部变量</h6> <p>（1）你可以使用Broadcast广播变量优化；</p> <p>（2）可以使用Kryo序列化类库，提升序列化性能和效率；</p> <p>（3）如果外部变量是某种比较大的集合，那么可以考虑使用fastutil改写外部变量；</p> <p>首先从源头上就减少内存的占用(fastutil)，通过广播变量进一步减少内存占用，再通过Kryo序列化类库进一步减少内存占用。</p> <h6 id="算子函数里使用了比较大的集合map-list"><a href="#算子函数里使用了比较大的集合map-list" class="header-anchor">#</a> 算子函数里使用了比较大的集合Map/List</h6> <p>在你的算子函数里，也就是task要执行的计算逻辑里面，如果有逻辑中，出现，要创建比较大的Map、List等集合，可能会占用较大的内存空间，而且可能涉及到消耗性能的遍历、存取等集合操作； 那么此时，可以考虑将这些集合类型使用fastutil类库重写，</p> <p>使用了fastutil集合类以后，就可以在一定程度上，减少task创建出来的集合类型的内存占用。
避免executor内存频繁占满，频繁唤起GC，导致性能下降。</p> <h6 id="fastutil的使用"><a href="#fastutil的使用" class="header-anchor">#</a> fastutil的使用</h6> <p>第一步：在pom.xml中引用fastutil的包</p> <div class="language-xml extra-class"><pre class="language-xml"><code>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>fastutil<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>fastutil<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>5.0.9<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre></div><p>第二步：平时使用List(Integer)的替换成IntList即可。</p> <p><code>List&lt;Integer&gt;</code>的元素类型对应到fastutil就是IntList类型</p> <div class="language- extra-class"><pre><code>使用说明：
</code></pre></div><p>基本都是类似于IntList的格式，前缀就是集合的元素类型；</p> <p>特殊的就是Map，Int2IntMap，代表了key-value映射的元素类型。</p> <h2 id="spark调优-调节数据本地化等待时长"><a href="#spark调优-调节数据本地化等待时长" class="header-anchor">#</a> Spark调优——调节数据本地化等待时长</h2> <p>Spark在Driver上对Application的每一个stage的task进行分配之前，都会计算出每个task要计算的是哪个分片数据，RDD的某个partition；Spark的task分配算法，优先会希望每个task正好分配到它要计算的数据所在的节点，这样的话就不用在网络间传输数据；</p> <p>但是通常来说，有时事与愿违，可能task没有机会分配到它的数据所在的节点，为什么呢，可能那个节点的计算资源和计算能力都满了；所以这种时候，通常来说，Spark会等待一段时间，默认情况下是3秒（不是绝对的，还有很多种情况，对不同的本地化级别，都会去等待），到最后实在是等待不了了，就会选择一个比较差的本地化级别，比如说将task分配到距离要计算的数据所在节点比较近的一个节点，然后进行计算。</p> <p><img src="/assets/img/image-20200419142802894.bfe41e9c.png" alt="image-20200419142802894"></p> <h5 id="本地化级别"><a href="#本地化级别" class="header-anchor">#</a> 本地化级别</h5> <p>（1）PROCESS_LOCAL：进程本地化</p> <p>代码和数据在同一个进程中，也就是在同一个executor中；计算数据的task由executor执行，数据在executor的BlockManager中；性能最好</p> <p>（2）NODE_LOCAL：节点本地化</p> <p>代码和数据在同一个节点中；比如说数据作为一个HDFS block块，就在节点上，而task在节点上某个executor中运行；或者是数据和task在一个节点上的不同executor中；数据需要在进程间进行传输；性能其次</p> <p>（3）RACK_LOCAL：机架本地化</p> <p>数据和task在一个机架的两个节点上；数据需要通过网络在节点之间进行传输； 性能比较差</p> <p>（4）ANY：无限制</p> <p>数据和task可能在集群中的任何地方，而且不在一个机架中；性能最差</p> <h5 id="数据本地化等待时长"><a href="#数据本地化等待时长" class="header-anchor">#</a> 数据本地化等待时长</h5> <p>spark.locality.wait，默认是3s</p> <p>首先采用最佳的方式，等待3s后降级,还是不行，继续降级...,最后还是不行，只能够采用最差的。</p> <h5 id="如何调节参数并且测试"><a href="#如何调节参数并且测试" class="header-anchor">#</a> 如何调节参数并且测试</h5> <p>修改spark.locality.wait参数，默认是3s，可以增加</p> <p>下面是每个数据本地化级别的等待时间，默认都是跟spark.locality.wait时间相同，默认都是3s</p> <p>(可查看spark官网对应参数说明，如下图所示)</p> <p>spark.locality.wait.node</p> <p>spark.locality.wait.process</p> <p>spark.locality.wait.rack</p> <p>在代码中设置：</p> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>set<span class="token punctuation">(</span><span class="token string">&quot;spark.locality.wait&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;10&quot;</span><span class="token punctuation">)</span>
</code></pre></div><p>然后把程序提交到spark集群中运行，注意观察日志，spark作业的运行日志，推荐大家在测试的时候，先用client模式，在本地就直接可以看到比较全的日志。</p> <p>日志里面会显示，starting task .... PROCESS LOCAL、NODE LOCAL.....</p> <p>例如：</p> <div class="language-sh extra-class"><pre class="language-sh"><code>Starting task <span class="token number">0.0</span> <span class="token keyword">in</span> stage <span class="token number">1.0</span> <span class="token punctuation">(</span>TID <span class="token number">2</span>, <span class="token number">192.168</span>.200.102, partition <span class="token number">0</span>, NODE_LOCAL, <span class="token number">5254</span> bytes<span class="token punctuation">)</span>
</code></pre></div><p>观察大部分task的数据本地化级别，如果大多都是PROCESS_LOCAL，那就不用调节了。</p> <p>如果是发现，好多的级别都是NODE_LOCAL、ANY，那么最好就去调节一下数据本地化的等待时长。应该是要反复调节，每次调节完以后，再来运行，观察日志 看看大部分的task的本地化级别有没有提升；看看整个spark作业的运行时间有没有缩短。</p> <p>注意注意：在调节参数、运行任务的时候，别本末倒置，本地化级别倒是提升了， 但是因为大量的等待时长，spark作业的运行时间反而增加了，那就还是不要调节了。</p> <h2 id="spark调优-基于spark内存模型调优"><a href="#spark调优-基于spark内存模型调优" class="header-anchor">#</a> Spark调优——基于Spark内存模型调优</h2> <h4 id="spark中executor内存划分"><a href="#spark中executor内存划分" class="header-anchor">#</a> spark中executor内存划分</h4> <p>Executor的内存主要分为三块</p> <ul><li>第一块是让task执行我们自己编写的代码时使用；</li> <li>第二块是让task通过shuffle过程拉取了上一个stage的task的输出后，进行聚合等操作时使用</li> <li>第三块是让RDD缓存时使用</li></ul> <h4 id="spark的内存模型"><a href="#spark的内存模型" class="header-anchor">#</a> spark的内存模型</h4> <div class="language- extra-class"><pre class="language-text"><code>	在spark1.6版本以前 spark的executor使用的静态内存模型，但是在spark1.6开始，多增加了一个统一内存模型。
	通过spark.memory.useLegacyMode 这个参数去配置
			默认这个值是false，代表用的是新的动态内存模型；
			如果想用以前的静态内存模型，那么就要把这个值改为true。
</code></pre></div><h5 id="静态内存模型"><a href="#静态内存模型" class="header-anchor">#</a> 静态内存模型</h5> <p><img src="/assets/img/1570604272790.f2118621.png" alt="1570604272790"></p> <p>实际上就是把我们的一个executor分成了三部分，</p> <ol><li>Storage内存区域，</li> <li>execution区域，</li> <li>Others其他区域。</li></ol> <p>如果使用的静态内存模型，那么用这几个参数去控制：</p> <ol><li>spark.storage.memoryFraction：默认0.6</li> <li>spark.shuffle.memoryFraction：默认0.2</li> <li>所以第三部分就是0.2</li></ol> <p>如果我们cache数据量比较大，或者是我们的广播变量比较大，那我们就把spark.storage.memoryFraction这个值调大一点。</p> <p>但是如果我们代码里面没有广播变量，也没有cache，shuffle又比较多，那我们要把spark.shuffle.memoryFraction 这值调大。</p> <h6 id="静态内存模型的缺点"><a href="#静态内存模型的缺点" class="header-anchor">#</a> 静态内存模型的缺点</h6> <p>我们配置好了Storage内存区域和execution区域后，我们的一个任务假设execution内存不够用了，但是它的Storage内存区域是空闲的，两个之间不能互相借用，不够灵活，所以才出来我们新的统一内存模型。</p> <h5 id="统一内存模型"><a href="#统一内存模型" class="header-anchor">#</a> 统一内存模型</h5> <p><img src="/assets/img/image2018-11-1_16-39-33.be97fbc3.png" alt="img"></p> <p>动态内存模型先是预留了300m内存，防止内存溢出。动态内存模型把整体内存分成了两部分，由这个参数表示spark.memory.fraction 这个指的默认值是0.6 代表另外的一部分是0.4,</p> <p>然后spark.memory.fraction 这部分又划分成为两个小部分。这两小部分共占整体内存的0.6 .这两部分其实就是：Storage内存和execution内存。由spark.memory.storageFraction 这个参数去调配，因为两个共占0.6。如果spark.memory.storageFraction这个值配的是0.5,那说明这0.6里面 storage占了0.5，也就是executor占了0.3 。</p> <p>统一内存模型有什么特点呢?</p> <p>Storage内存和execution内存 可以相互借用。不用像静态内存模型那样死板，但是是有规则的</p> <p><strong>场景一</strong>: Execution使用的时候发现内存不够了，然后就会把storage的内存里的数据驱逐到磁盘上,腾出来的内存空间将借给Execution。</p> <p><img src="/assets/img/1570604662552.ae2833ff.png" alt="1570604662552"></p> <p><strong>场景二</strong>: 一开始execution的内存使用得不多，但是storage使用的内存多，所以storage就借用了execution的内存，但是后来execution也要需要内存了，这个时候就会把storage的内存里的数据写到磁盘上，腾出内存空间。</p> <p><img src="/assets/img/1570604675176.71e159e5.png" alt="1570604675176"></p> <p>为什么受伤的都是storage呢？是因为execution里面的数据是马上就要用的，而storage里的数据不一定马上就要用。</p> <h6 id="任务提交脚本参考"><a href="#任务提交脚本参考" class="header-anchor">#</a> 任务提交脚本参考</h6> <p>以下是一份spark-submit命令的示例，大家可以参考一下，并根据自己的实际情况进行调节</p> <div class="language-sh extra-class"><pre class="language-sh"><code>./bin/spark-submit <span class="token punctuation">\</span>
  --master yarn-cluster <span class="token punctuation">\</span>
  --num-executors <span class="token number">100</span> <span class="token punctuation">\</span>
  --executor-memory 6G <span class="token punctuation">\</span>
  --executor-cores <span class="token number">4</span> <span class="token punctuation">\</span>
  --driver-memory 1G <span class="token punctuation">\</span>
  --conf spark.default.parallelism<span class="token operator">=</span><span class="token number">1000</span> <span class="token punctuation">\</span>
  --conf spark.storage.memoryFraction<span class="token operator">=</span><span class="token number">0.5</span> <span class="token punctuation">\</span>
  --conf spark.shuffle.memoryFraction<span class="token operator">=</span><span class="token number">0.3</span> <span class="token punctuation">\</span>
</code></pre></div><h6 id="个人经验"><a href="#个人经验" class="header-anchor">#</a> 个人经验</h6> <div class="language-java extra-class"><pre class="language-java"><code><span class="token class-name"><span class="token namespace">java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span></span>OutOfMemoryError</span>
<span class="token class-name">ExecutorLostFailure</span>
<span class="token class-name">Executor</span> exit code 为<span class="token number">143</span>
executor lost
hearbeat time out
shuffle file lost

如果遇到以上问题，很有可能就是内存除了问题，可以先尝试增加内存。如果还是解决不了，那么请听下一次数据倾斜调优的课。
</code></pre></div><h2 id="招聘要求介绍"><a href="#招聘要求介绍" class="header-anchor">#</a> 招聘要求介绍</h2> <p><img src="/assets/img/1565872653413.873c5f50.png" alt="1565872653413"></p> <p><img src="/assets/img/1565872766577.a48d73d7.png" alt="1565872766577"></p></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/MaLunan/press/edit/dev-mln/docs/spark/spark.md" target="_blank" rel="noopener noreferrer">在GitHub 上编辑此页！</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="last-updated"><span class="prefix">上次更新时间:</span> <span class="time">1/19/2021, 1:41:59 AM</span></div></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.fdd7a502.js" defer></script><script src="/assets/js/16.375b747e.js" defer></script><script src="/assets/js/4.e9b44388.js" defer></script>
  </body>
</html>
